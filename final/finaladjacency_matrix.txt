So in our previous lesson, we discussed
one possible way of
storing and representing a graph in
which
we used two list. One to store the
vertices and another to store the
edges. A record in vertex list here
is name of a node
and a record in edge list is an
object
containing references to the two endpoints
of an edge and also the weight of that edge
because this example graph that I am showing
you here is a
weighted graph. We called this kind of
representation
edge list representation but we realised
that this kind of storage is not very
efficient in terms of
time cost of most frequently performed
operations
like finding nodes adjacent to a given
node
or finding if two nodes are
connected are not.
To perform any of these operations, we
need to scan the whole
edge list. We need to perform a
linear search on the edge list.
So the time complexity is big oh of number
of
edges and we know that number of edges
in the graph
can be really really large. In worst case
it can be close to square of number of
vertices.
In a graph, anything running in order
of number of
edges is considered very costly. We
often want to keep the cost
in order of number of vertices. So we
should think of some other efficient
design.
We should think of something better than
this. One more possible design is that
we can store the edges in a
two-dimensional array
or matrix. We can have a
two-dimensional matrix
or array of size V*V
where V is number of vertices.
As you can see, I have drawn an 8*8
array here because number of vertices
in my sample graph here
is 8. Let's name this array A.
Now if we want to store a graph that is
unweighted. Let's just remove the weights
from this sample graph here
and now our graph is unweighted and if we
have
of value or index between 0 and V-1
for each vertex which we have here
if we are storing the vertices in a
vertex list
than we have an index between 0 and V-1
for each vertex. We can say that A
is zeroth node,
B is 1th node, C is
2th
node and so on. We are picking up
indices from vertex list. Okay
so if the graph
is unweighted and each vertex has an
index between 0 and
V-1, then in this matrix
or 2d array. We can set ith row
and jth column that is A[i][j]
as 1 or boolean value
true. if there is an edge from i to j
0 or false otherwise. If I have
to fill this matrix for this example
graph here then I'll go vertex by vertex.
Vertex 0 is connected to Vertex 1
2 and 3. Vertex 1
is connected to 0, 4 and 5.
This is an undirected graph so if we
have and edge from 0 to 1,
we also have an edge from 1 to 0
so
1th row and 0th column should also be
set as 1.
Now let's go to nodes 2, it's connected
to 0
and 6, 3 is connected to 0 and 7,
4 is connected to 1 and 7,
5 once again is connected to 1 and 7,
6 is connected to
2 and 7 and 7 is connected
to 3, 4, 5 and 6.
All the remaining positions in
this array should be set as 0.
Notice that this matrix
is symmetric. For an undirected graph,
this matrix would be symmetric
because A[i][j] would be equal to A[j][i].
We would have two positions filled for
each edge.
In fact to see all the edges in the graph,
we need to go through only one of these
two halves.
Now this would not be true for our
directed graph. Only one position will be
filled for each
edge and we will have to go through
the entire matrix
to see all the edges. Okay,
now this kind of representation of a
graph in which
edges or connections are stored in a
matrix
or 2D array is called adjacency matrix
representation. This particular matrix that
I have drawn here
is an adjacency matrix. Now with this
kind of storage or representation,
what do you think would be the time cost
of finding
all nodes adjacent to a given node. Let's say
given this vertex list
and adjacency matrix, we want to find
all nodes adjacent to node named F.
If we are given name of a node than
we first need to know it's
index and to know the index, we will have to
scan the vertex list.
There is no other way. Once we figured out
index
like for F index is 5 then
we can go to the row with that index
in the adjacency matrix
and we can scan this complete row to
find all the
adjacent nodes. Scanning the vertex
list
to figure it out the index in worst case
will cost us time proportional to the
number of vertices
because in worst case we may have to
scan the whole list,
and scanning a row
in the adjacency matrix would once again
cost us time proportional to number of
what vertices because
in a row we would have exactly
V columns where V is number of a
vertices.
So overall time cost of this operation
is big oh of V. Now most of the time
while performing operations,
we must pass indices to avoid
scanning the vertex list all the time.
If we know an index, we can figure out
the name in constant time,
because in an array we can access element at
any index in constant time but if we know
a name
want to figure out index then it will
cost us big oh of V.
We will have to scan the vertex list.
wWe will have to perform linear search
on it. Okay moving on.
Now what would be the time cost of
finding if 2 nodes
are connected or not. Now once again the
two nodes can be given to us
as indices or names. If the nodes
would be passed test as indices
then we simply need to look at value in
a particular row and
particular column. We simply need to look
at
A[I][J] for some values of I and J
and this will cost us constant time.
You can look at Value in any cell in
a two-dimensional array in constant time.
So if
indices are given time complexity of
this operation would be big oh of 1
which simply means that we will
take constant time
but if names are given then we also need
to do the scanning
to figure out the indices which will
cost us big oh of V.
Overall time complexity would be 
Big oh of V.
The constant time access would not mean
anything.
The scanning of vertex list all the
time to figure it out
indices can be avoided. We can use
some extra memory to create
a hash table with names and indices
as key value pairs and then the time
cost of finding
index from name would also be big oh
of 1 that is constant. Hash table is
a data structure
and I have not talked about it in any of
my lessons so far.
If you do not know about hash table, just
search online for
a basic idea of it. Okay, so as you can
see
with adjacency matrix representation
our time cost of some of the most
frequently performed operations
is in order of number of vertices
and not in order of number of
edges which can be as high as square of
number of vertices.
Okay now if we want to store
a weighted graph in adjacency matrix
representation
then A[i][j] in the matrix can be set as
weight of an edge. For non-existent ages we
can have
a default value like a really large
or maximum possible integer value
that is never expected to be an edge
weight. I have just filled in infinity
have to mean that
we can choose the default as infinity
minus infinity
or any other value that would never
ever be a valid
edge weight. Okay, now for further
discussion
I'll come back to an unweighted graph.
Ajacency matrix
looks really good so should we not use it
always.
Well, with this design we have improved
on
time, but we have gone really high on
memory usage
instead of using memory units exactly
equal to the number of edges
what we're doing with
edge list kind of storage.
Here we're using exactly V square
units of memory.
We are using big oh of V square space.
We are not just storing the information
that these two
nodes are connected, we are also storing not
of it
that is these two nodes side not connected
which probably is
redundant information. If a graph is
dense,
if the number of edges is really close
to V square
then this is good but if the graph is
sparse
that is if number of edges is lot lessser
than V square
then we are wasting a lot of
memory in storing the zeros.
Like for this example graph that I have
drawn here, in the edge list we were
consuming
10 units of memory we had ten rows
consumed in the edge list
but here we are consuming 64 unit.
Most graphs with
really large number of vertices would
not be very dense,
would not have number of edges anywhere
close to V sqaure
like for example, Let's say we are modeling
a social network like Facebook as a
graph such that a user in the network
is a node
and there is an undetected edge if two
users are friends.
Facebook has a billion users but I'm
showing only a few in my example graph
here because I'm short of space.
Let's just assume that we have a billion
users in our network,
so number of vertices in a graph is
10 to the power 9
which is billion. Now do you think number
of connections
in our social network can ever be close
to square of number of users
that will mean everyone in the network
is a friend of
everyone else. A user of our social
network will not be friend to all other
billion users.
We can safely assume that a user
on an average would not have more than
a thousand friends
with this assumption we would have
10 to the power 12
edges in our graph. Actually, this is an
undirected graph
so we should do a divide by 2 here. So
that we do not
count an edge twice. So if
average number of friends is 1000 then total
number of connections in my graph is
5 * 10 to power 11. Now this
is lot lesser than a square of number
of vertices.
So basically if you would use an adjacency
matrix for this kind of a graph,
we would waste a hell lot of space
and moreover
even if we are not looking in relative
terms 10 to the power 18
units of memory, even in absolute
sense
is alot. 10 to the power 18 bytes
would be about a 1000 petabytes.
Now this really is a lot of space. This
much data would never ever fit on one
physical disk.
5 into 10 to the power 11 byts on the other
hand
it's just 0.5 terabytes. A typical
personal computer these days would have this
much of storage.
So as you can see for something like a
large
social graph adjacency matrix
representation is not very efficient.
Agency matrix is good when a graph is
dense
that is when the number of edges is
close to square of number of vertices
or sometimes when total number of
possible connection that is V square
is so less that wasted space would not
even matter
but most real-world graphs would be
sparse
and adjacency matrix would not be a good
fit.
Let's think about another example. Let's
think about
world wide web as are directed graph.
If you can think of web pages as nodes
in a graph
and hyperlinks as directed edges
then a webpage would not have linked to
all other pages
and once again number of webpages
would be in order of millions.
A webpage would have link to only
the
a few other pages, so the graph would be
sparse.
Most real world graphs would be sparse
and adjacency matrix. Even though it's
giving us good running time for most
frequently performed
operations would not be a good fit
because it's not very efficient in terms
of space
so what should we do. Well there's
another
representation that gives us similar
or maybe even better running time than
adjacency matrix and does not consume so
much space
It's called adjacency list
representation and we will talk about it
in our next lesson.
This is it for this lesson. 
Thanks for watching
Hello and Welcome to Unit 7.2!
In this unit we want to import and prepare
the crystallographic information
of HKUST-1 into TOPOS.
Download the ZIP file,
that we provide as an additional material to this unit.
Extract it - to a location of your choice.
In this case I choose my Desktop.
Now, I have another folder in which there is a CIF file.
Please keep this CIF file inside this folder.
Because it is easier to work with TOPOS that way.
Now open TOPOS. We will now import the CIF file.
Go to Database. Click Import.
Go to the location where you have placed
the folder of HKUST-1 and choose
the CIF file and open it.
TOPOS will then ask you to 
create a TOPOS database file.
You can just click OK.
It asks you to confirm to 
create this database and you click Yes.
Now you have to enter a user code.
And I always enter 1 and hit OK.
But you can enter any value except 0.
We have converted one compound.
Now, HKUST-1 shows up in your TOPOS database.
Before we can determine the underlying net of HKUST-1,
we must first create an adjacency matrix.
What is an adjacency matrix?
Computer programs like TOPOS
use an adjacency matrix
to keep track of all the connections between atoms.
Let me show you how this works in principle
with this hypothetical five-atomic molecule.
A very simple adjacency matrix for
this molecule looks like this.
If any two atoms are connected,
the corresponding cell of this entry has the value 1.
If there is no connection the value is zero.
A simple adjacency matrix like this
can easily be prepared by hand.
But in the case of our example
HKUST-1, we use an algorithm
within TOPOS to build an adjacency matrix,
which is then a little more complex, than this one here.
Because the adjacency matrix
in TOPOS also documents
the type of connection between atoms.
For example, if two atoms are connected to each other
via a covalent or a hydrogen bond.
Now, let’s build the adjacency matrix in TOPOS.
Select HKUST-1. And then click on this
button to run the AutoCN routine.
Another window opens.
There are plenty of options available,
but we can ignore all these
because the default settings of
TOPOS work just fine for us.
So, we just hit "Run"
and this window produces a little text
with details on the adjacency matrix.
The adjacency matrix itself is stored
within the TOPOS database of HKUST-1.
We can close this window.
And usually a warning like this pops up.
This is harmless. We can just click
OK, because all the information
we need is stored inside the adjacency matrix.
To view the adjacency matrix right-click
on the HKUST-1 entry and click Edit.
Now move to Adjacency Matrix tab.
There you see a list of all the
atoms inside the crystal structure.
You can unfold each entry to
view the bonding partners
of the respective atoms in the crystal structure.
TOPOS also offers the possibility to
display the imported crystal structure.
Click on the Pencil symbol and a new window opens.
And if you click on this pencil
again, a single unit cell is drawn.
You can also rotate the structure
by using the rotate tool.
Of course, there are also different
styles of representation available.
Click Display, Model and choose for
instance the sphere and wire mode.
What I like about this viewer in
particular is the growth function.
Simply click on this leaf and your
structure will grow bond by bond.
Give it a try. If the extended
network now exceeds your screen
hit space for an automatic fit to screen.
You can also change the color of the
atoms by using the magic wand tool.
Select the magic wand from the
toolbar and then click on
the respective element in the legend
to change the color of this element.
OK. That’s it for this unit.
Now, I suggest that you try
out the viewer a little bit
and get to know its functions.
recall that two graphs G and H are
isomorphic and this is the notation if
and only if there exists a by Jackson
alpha from the vertex set of G to the
vertex set of H such that alpha of U
alpha V is an edge of H if and only if
UV is an edge of G this condition is
what's telling you that the by ejection
alpha preserves adjacency and non
adjacency quick question it seems like
you would be able to determine if two
graphs are isomorphic using their
adjacency matrices how would this work
all of the information in a graph is
contained in its adjacency matrix so it
definitely is possible to determine if
two graphs are isomorphic using just
their adjacency matrices and in this
video I'll show you how it turns out
that G is isomorphic to H if and only if
a G is equal to P times H times P
transpose for some permutation matrix P
and notice here that AG represents the
adjacency matrix of graph G and a H
represents the adjacency matrix of graph
H we're going to take a look at how this
works using an example so our graph G
will be a green graph on these five
vertices and I'll just label them our
graph H is going to be a red graph also
on five vertices because I chose such a
small example it should already be
pretty clear that these two graphs are
essentially the same in other words
isomorphic but it will be useful to work
through all of the steps in this example
anyways if we wanted to find an
isomorphism between these two graphs
let's consider what by ejection we might
use we'll take alpha to map from V of G
to V of H and we'll say that alpha can
map vertices 1 2 3 4 5 of G 2 vertices 5
4 1 2 3 respectively in H a different
notation for this is alpha equals in
brackets
one five three and then in brackets to
four
this tells us that one goes to five five
goes to three and then three goes back
to one and also tells us that two goes
to four and for respect to that's known
as cycle notation for this by Junction
alpha in order to prove that alpha is
indeed an isomorphism we would need to
check every pair of vertices in the
graph G and show that if they were
adjacent in the graph G then after the
mapping they get mapped to a pair of
vertices that are adjacent in the graph
H and also if they were not adjacent in
the graph G then they need to map to a
pair of vertices which are not adjacent
in the graph H to demonstrate this I'll
just go through two little examples we
notice that one two is an edge in the
graph G so alpha 1 alpha 2 ends up being
5 4 which is an edge in the graph H so
that worked next we notice that 1 4 is
not an edge in the graph G and alpha of
1 alpha 4 maps to 5 2 which is not an
edge in the graph H so those two
examples worked out if you want you can
check for yourself that alpha is indeed
an isomorphism but hopefully at this
point you're pretty convinced that it
will work to see how we would view this
in terms of matrices we'll start by
writing down the adjacency matrices of
the two graphs so we'll use green to
represent the adjacency matrix of the
graph G it's going to have 5 rows
corresponding to the 5 vertices and 5
columns also corresponding to the 5
vertices if we look at the first row
vertex 1 is adjacent only to vertex 2 so
that means we put a 1 in the 2 column
and zeros everywhere else similarly we
can fill in the rest of the adjacency
matrix if you'd like a review of the
details of how an adjacency matrix is
made click on this video or see the
links in the description below we build
the adjacency matrix of the graph H in
exactly the same way and we end up with
these two adjacency matrices our next
step is to determine if there is a
permute
matrix P such that P times the adjacency
matrix of H times P transpose will give
us the adjacency matrix of G this
problem of finding the permutation
matrix P is essentially equivalent to
finding a mapping alpha like we did
before if you find such a matrix P it
will be associated with a mapping alpha
and if you find a mapping alpha it will
be associated with a permutation matrix
P so since we already know that our
mapping alpha worked out let's use that
to try to build ourselves a nice
permutation matrix we have to remember
what alpha does and in particular alpha
maps one to five so in Row one we'll put
a one only in the five s column and
zeros everywhere else
similarly we fill in the rest of the
permutation matrix according to what
alpha tells us to map to to find P
transpose remember that the transpose of
a matrix is found just by swapping rows
four columns so if we look at our old
matrix P and we find the first row that
gives us our first column in P transpose
and we just finish off and write down P
transpose our next step is to take a
look at the product we get when we take
P times a H times P transpose okay so
let me copy and paste our matrix P and
copy and paste our matrix aah and also P
transpose now because multiplication of
matrices is associative I'm just going
to go ahead and multiply the first two
together you've probably seen matrix
multiplication before but let me just
remind you that if you're looking for
the entry in Row one column one of the
product what you need to do is to look
at Row one of the first matrix and
column one of the second Matrix and you
look along that row and along that
column and you take the dot product what
that means is that you just multiply
corresponding entries and keep doing
that multiplying corresponding entries
but you take the sum of all of that if
you do that in this particular example
you're going to get a zero here if I'm
looking for the next entry that's going
to go into the first row I still look at
the first row of the first
matrix but now I look into the second
column and I again take that dot product
again I get a zero and I'm going to get
a zero again until I get to the fourth
column I will end up getting a one there
so that tells me to put a 1 in the
product and the last entry is zero check
all of this for yourself now we're done
with the first row in the product to
figure out the second row we just repeat
this procedure but now looking at the
second row of the first matrix and again
looking into every individual column of
the second Matrix once we're finished
calculating the product of these two
matrices we are not done we still need
to multiply that product by P transpose
so I'll copy P transpose and now we just
have to run through all the matrix
multiplication again we work out the
product of these two matrices again
using matrix multiplication and after
you finish that you'll notice that the
corresponding matrix you get is exactly
the adjacency matrix of the graph G so
that's precisely what we were looking
for
we found a permutation matrix that
satisfied the property we were looking
for actually we did it in a little bit
of a roundabout way because we found
that permutation matrix by already
knowing an alpha mapping that would work
but again I'm reminding you that finding
this permutation matrix is as difficult
as finding the mapping alpha once you
know one you know the other if you have
any graph theory questions let us know
in the comments below click here for
related videos and keep having fun with
graph theory I'll see you next time
This video is on graph representations.  It is the second video in a basic
graph algorithm playlist, after the introduction to graphs.  This one goes
over the two most common ways to implement graphs, adjacency matrices
and lists.  After a few simple representation related algorithms, I'll
compare their strengths and weaknesses. 
So you have this abstract
graph out there, with vertices and edges, and maybe each of those has
information that goes with it.  The graph representation we choose
is just some implementation which captures that abstract graph
information, but you can come up with different implementations to
capture the same graph.  The two most common models
are the adjacency matrix, and the adjacency list.  
Starting with
an adjacency matrix for a directed graph, we use a two dimensional
matrix.  We assume that vertices are numbered, and an edge from vertex i
to j goes in row i, column j.  What do we store for the edge?
In the simplest case, just a single bit, true or false, if the edge exists.
In the most complex case, you can store an edge object, or maybe a
reference to an edge, where that edge can store whatever information you want:
weight, name, hobbies, whatever you need for your problem.
A common case between those two extremes is when you just need an
edge weight.  So great, just store the edge weight in the matrix.
But what do we store if there is no edge?  Some languages might allow
you to store nil, or a null reference, but even then, each time you need an
edge weight, you first need to see if the edge exists, and then use it.
That slows your code down a bit, and also makes it clunky.
Instead, depending on what the weights represent, it's common to store a dummy
weight for missing edges.  If the weights represent something you are trying to minimize,
like a cost, you store a huge value, like infinity.
If you are minimizing costs, you should never take an infinite
weight edge, unless you can't solve the problem without one.  Again,
depending on what the weights represent, other dummy weights for non-existent edges
might make sense.  Hugely negative, 0, or hugely positive
are the most common values, where negative infinity might be used if
edge weights are profits that you are trying to maximize.  Finally,
for undirected graphs, the matrix is symmetric over the diagonal,
so you could try to halve your space by just keeping one side.
The Cormen book mentions keeping the top part, but I think the indices come
out cleaner with the bottom part.
Next comes the
adjacency list representation.  Here, we have an array of vertices,
and for each, you have a list of it's edges.  In the simplest case,
if your current vertex i has an edge to j, maybe you only need
to store that index j in i's list to mark
that the edge exists.  You can't get away with just a single true/
false bit here, you have to identify the other vertex.
For a weighted graph, you can't just store weights, you also need an
index or reference.
What do you use for lists?
You can use any list, and if the graphs don't change, you can even just
use static arrays.  If the graph never changes AND
you frequently have to look up whether or not edges exist, you
could even use sorted arrays, and then use binary search if you are looking for a
particular vertex in a list.  If you care about quick
lookup and also want to let edges be added or removed,
you could even use a balanced binary tree structure.  But, for lots
of algorithms, you only look at all edges incident on a vertex
in arbitrary order.  There, pretty much anything you use is fine.
I'll just show comma separated text in my slides.
For undirected graphs in the adjacency list model,
you store each edge twice, once in the list for each vertex,
unless you don't care how long it takes you to look anything up.
For directed graphs, you have a choice:  for each vertex,
you can store all of the vertices that it has an edge to, or
all of the vertices that it has an edge from.  Those are two different ways of storing
the same graph, and you pick one depending on how you are going to need
to access your data.  Storing outgoing edges is more common.
For some problems, you might want both lists.
What if you are given the data as an outgoing adjacency list, but you want the incoming
list?  You can go from one format to the other in time linear
in the size of the graph:  given an outgoing representation,
you create a new incoming representation with the same vertices,
and then for each vertex i in the graph, for each vertex
j in i's outgoing list, append $i$ to $j$'s incoming
list.   Let's quickly run through an example.
If vertex 1 has a link to 3, append 1 to 3's incoming list.
If 1 has a link to 5, append 1 to 5's list, and if 2 has a link
to 4, append 2 to 4's list.  Do that over all edges, it takes
constant time per edge plus constant time per vertex, done.
Going from the incoming list to the outgoing list is the same algorithm.
Going from an adjacency list to a matrix is
very similar.  Make an empty matrix, or for a weighted graph, a
matrix filled with dummy values.  Then, for each vertex, for
each outgoing edge, add that edge to the matrix.  It takes
time no more than the size of the matrix, the number of vertices squared.
To go from the matrix to the outgoing list format,
create an empty list, step through every location in the matrix, and when
there is an edge, add it to the appropriate list.  It takes time proportional to the number
of vertices squared to look through the matrix.
One final
basic graph manipulation algorithm: flipping the direction
of each edge in a graph is called taking the graph's transpose,
because if you are using the adjacency matrix format,
you just take the transpose of the matrix.  If you are using the outgoing
adjacency list format, just find the incoming adjacency
list for the same graph, and interpret that incoming list as the
outgoing list, that's the transpose.
So great, we have
multiple representations for the same graph, and can transform
one to another as needed.  Assume you have whichever representation
suits your needs most.  Let's compare the outgoing list
to the matrix to get an idea of when to use each.
First let's look at the space, or memory usage.  The adjacency list
has one list for each vertex, and each edge shows up in one
of the lists, or two for undirected graphs.  That's space linear
in the size of the graph.  The adjacency matrix takes up
size quadratic in number of vertices.  Is that bad?  It depends
on how dense the graph is.  If the graph has enough edges, the matrix
could actually use somewhat less space than the adjacency list,
but for sparse graphs, the adjacency list is asymptotically
better.  If we think about Facebook, each user has
on average a couple hundred friends.  It's a lot easier to store a hundred
links per user than to store a billion by billion matrix
for the graph as a whole.
What tasks does
each representation do well?  The most common basic graph
operations are to ask what vertices are adjacent to a vertex,
and to ask if an edge between two vertices exists.
Iterating through a list of vertices adjacent to a vertex is easy with an
outgoing adjacency list.  It takes time linear in the size
of the list, which is the vertex's outdegree.  The matrix
format takes time linear in the total number of vertices in the graph.
Again, not bad if the graph is dense and the vertex has an edge to
most other vertices, but it gets worse and worse the more sparse
the graph is.  Again, for Facebook, imagine how wasteful it would be if they
had to run through over a billion users just to see what they
should stick on your freakin' feed.  No one is that popular.
The matrix can find out if some edge exists in constant time,
while the list might take time linear in the degree of one of the edge
vertices to run a linear search.  If you expect to do lots
of those lookups, and decide to have the lists sorted in arrays or trees,
each lookup will only take time logarithmic in the degree of
the vertex, which might be small compared to the number of vertices.
That might be worth doing sometimes, but for lots of nice algorithms,
we don't look up whether or not an edge exists, we only want to
list vertices by adjacency.  Even though we will occasionally use
the adjacency matrix, the adjacency list is our default,
including for the videos up next on this playlist,
breadth first search, and depth first search.  For now,
I've got to go practice my miming skills.
[Sound of a mime screaming]
the graph data structure is not the same
as a graph you may have learned about a
math class graphs are collections of
things and the relationships or
connections between them the data in a
graph are called nodes or vertices the
connections between the nodes are called
edges one example of graphs is a social
network where the nodes are you and
other people and the edges are whether
two people are friend with each other
there are two major types of graphs
directed and undirected undirected
graphs are graphs without any direction
on the edges between nodes directed
graphs are graphs with a direction and
its edges an example of an undirected
graph could be a social network the
nodes are people and the edges are
friendships an example of a directed
graph could be the internet and web page
links the nodes are web pages and the
directed edges are links to other pages
which might not necessarily point the
other way I'm going to show you three
ways to represent a graph the first way
is called an adjacency list this
representation for a graph associates
each vertex in the graph with the
collection of its neighboring vertices
or edges in this image a is connected to
B B is connected to a and C and C is
connected to B this is how you could
show a relationship with texts and here
is how you could show this adjacency
list with JavaScript this is an
undirected graph because it does not
show the direction of the edges this can
also be more simply represented as an
array where the nodes just have numbers
rather than string labels another way to
represent a graph is to put it in an
adjacency matrix an adjacency matrix is
a two-dimensional array where each
nested array has the same number of
elements as the outer array so it's
basically a matrix of numbers where the
numbers represent the edges zeroes means
there is no edge or relationship and one
means there is a relationship this table
shows an adjacency matrix to represent
the image you can see that the labels
for the nodes are on the top and left
now here's a JavaScript representation
of the same thing unlike an adjacency
list each row of the matrix has to have
the same number of elements as nodes in
the graph here we have a 3 by 3 matrix
which means we have 3 nodes our graph
and adjacency matrix can be used to
represent a directed graph here's a
graph where the second node has an edge
pointing toward the first node and then
the third node has an edge pointing to
the first node notice how the numbers in
the array change there are only ones
where a node is pointing toward another
node and since there are only two points
there are only two nodes the final way I
will show to represent a graph is an
incidence matrix like the adjacency
matrix and incidence matrix is a
two-dimensional array however the rows
and columns means something else here
the adjacency matrix use both rows and
columns to represent nodes and incidence
matrix uses roads rose to represent
nodes and the columns to represent edges
this means that we can have an uneven
number of rows and columns each column
will represent a unique edge also each
edge connects two nodes to show that
there is edge between two nodes you will
put a 1 in the two rows of a particular
column as you can see in the diagram
edge 1 is connected to nodes a and B now
look at the column for edge 1 in the
incidence matrix table you will see a 1
in both the a row and the B row this
shows the edge 1 connects the nodes a
and B here is a directed graph for a
directed graph use negative 1 for an
edge leaving a particular node and 1 for
an edge entering a node and here is a
JavaScript implementation of the
incidence matrix graphs can also have
weights on their edges so far we have
unweighted edges where just the presence
and lack
of edges binary zero one you can have
different weights depending on your
application a different way is
represented as a number greater than one
well now you know about different types
of graphs and how to represent them in
JavaScript in my next video about graphs
I will cover graph traversal algorithms
thanks for watching my name is Bo Carnes
don't forget to subscribe and remember
use your code for good
welcome to our 27th video with data
structures and algorithms we're going to
continue with graphs probably should
have done this one before the last two
videos but that's okay let's do it now
we're going to do a jason see lists and
adjacency matrices so we let's start off
with an adjacency list we're going to
kind of go in a different direction here
now this is what this is a
representation of our graph so let's do
some practice with converting this into
an adjacency matrix so firstly with the
adjacency matrix what we're going to
write a 1 if there's an edge between the
two right and we're going to write zeros
otherwise right so we're going to start
from a left right this will be the nodes
that are in the actual array here and
these will be its adjacency list this is
top the columns ok you'll see what I
mean in a second so for a in its
adjacency list we have C D and G so
along this row we are going to write
ones at C oh let's say at C D and G now
everything else is going to be zeroes
we're going to write in zeroes later so
that we can kind of visualize this a
little better let's keep going so with B
it has a jason Siletz with e all right
so E is in its adjacency list it's
connected to visit there's an edge from
B to e C has an edge right it has a
self-loop D also has a self-loop it also
has an edge from D to E and there's also
an edge from D to F with e U has an edge
to G all right has a direct path to G F
has a path to B right an edge between F
and B and another edge there's another
edge between G are from G to B ok so
that's kind of what our matrix
looks like now this is a directed graph
and we know that because this is not
symmetrical okay that means there's not
an edge you can see this is an edge from
A to C but there is not an edge from C
to a okay so this is this is a directed
graph so now let me just pick a
different color and we're going to put
in zeros okay for the rest of this just
to be a little bit more complete okay
that's a lot of zeros I know just hang
with me for a second
zero zero all these zeros fun times
there we go here we go zero zero zero
zero okay and there we go so that's what
our adjacency matrix looks like for this
graph now let's do a little something
else let's translate this into the graph
like a visual representation that we are
used to so I'm kind of running out of
space here so we're going to have to
kind of go back and forth that's okay so
let's start with node a so we have a
node a here let's put it like this okay
and we know that there's an edge from A
to C so I'm going to put C up here okay
there's that there's also an edge from A
to D so let's draw a D node and we'll do
an edge there and then another one to G
so we're going to put G down here okay
there we go that's our first one you did
the same looking at this right so
looking at this we're going to show
another one but we'll do it from this
side so let's do B from this side so B
has an edge there's an edge from B to e
right here so let's do that
so let's do be down here and there's
another ed right there's a edge from B
to e so we're going to put e right here
okay
make that a little better well that's
not better at all that's okay
so next one is C right C has a self loop
you can see that right here if you'd
like to look at this one instead right
there's a one at C C so there is a self
loop on C for D D has an edge from D to
D so this also has a self loop there's
an edge from D to e okay so let's do
that here I've horrible arrows all right
let's just clean that one up a bit it's
a little better and there's also an edge
from D to F so f is not on here so let's
draw our F node okay so there's that he
has an edge to G so let's scroll down so
we can make a little loop here so we
have a edge from E to G and from F we
have an edge to be you know what I'm
going to redraw this to come over here
and F has an edge to be there we go you
don't have to cross lines and then G
also has an edge to be able to go that
works out good stuff okay so there is
our graph right now let's do some more
exercise while we're here and let's do
on line just a second here let's grab my
color I'll have the right color I lost
it so let's do this
okay let's do depth-first search on this
depth-first search just for some
practice and let's start from here
actually we can signify starting with
just this one oh wow that was not right
so we start here right have one now
we're going to take this we're going to
do this in this order the order of our
list so C is going to be the first place
that we go all right so let's go along
see we've discovered this at time two
and now let's do C right C has a
self-loop so it's already been
discovered so we're done with this one
three now back to a right so the next
one in a is d now you can see that here
so let's go that path okay and time for
this was discovered so let's look at D
the first one D is a self-loop so that's
already been discovered already gray he
is the next one so let's take that path
so time five so e down here has a path
from E to G alright so let's take this
path and it's been discovered at times
six G has a path to be right it has an
edge from G to B so now B has been
discovered at time seven let's go up to
B let's take the path to e except E has
already been discovered so we're done
with this one so it's been discovered a
time eight back to G this is done at
time nine there's nothing left and it's
list back to e
there's nothing left in its list right
so that's done at time 10 back to D the
next one in these lists is f so let's
take a path over to F and this has been
discovered at time 11 so f has be right
in its
adjacency list bees already been
discovered so we're done with this one
at time 12 and that means that we are
done with D at time 13 and then we are
done with a because G has already been
discovered so we were done with this at
time 14 all right that was kind of fun
let's do breadth-first search on this on
the same one let's just redraw this
alright let's just get some practice in
might as well so we got C over here
we've got G we put F over here whoops
it's kind of messed up
but F over here B is down here and E is
over here so we've got this kind of
crazy lines here okay there's a path
here so path here here and here I think
that's all of them yep okay
and let's do breadth-first search over
here breadth-first search now we have a
queue remember so here's our Q first
it's empty we're going to start at a
alright start here its distance is zero
so we put a right in the queue we take a
out of the queue and we put its
adjacency list on all right
all the distance of one so we have C D
and G we take C off right see points to
itself so we have we don't put anything
else on the queue next we take D off and
we put E and F on right who comes
first he comes first in the adjacency
list so that's we're going to put on
first so we've got G E and F all right
these are distance of two so next we
take G off and we put B on here all
right so now our cue looks like this
e F B okay next in the queue is e so you
take a off G has already been discovered
so we don't put anything else on so I'm
going to write this over here so f and B
are now on the queue we take F off the
cube B has already been discovered it's
already in the queue so we don't put
anything in there right B we would put
we take B off the queue now that would
be e right except E has already been
discovered so we don't put anything on
the queue and there's no nodes left
that's we've gone through all the nodes
and that's it so there's our depth-first
search or breadth-first search and our
adjacency matrix in our adjacency list
so there you have it
so what is the matrix a matrix is a
rectangular array of numbers like this
we put square brackets around them for
notational purposes matrices are a very
useful tool to store information in an
organized way let me give you some
examples for example you can use
matrices to represent your Facebook
connections I'll show you how you
probably see one of these facebook
thread wheels each node in this picture
stand for a facebook friend of this
person named Toma and each line shows a
facebook connection between his friends
you can turn this into a matrix by
listing Tomas friends in the horizontal
ray i dont have space to list all of
them here so i'll only list some of them
and then listing them and again in a
vertical array and then put a number
that's either 0 or 1 at the intersection
of these arrays for example David is
connected with will so we'll write down
a one here will is not connected with
Ellie so we write down a 0 here let's
assume that each person is not Facebook
friends with themselves so we put zeros
and David with David ally with Ellie and
drew with Andrew wil with will faisal
with faisal and Jing with Jim these
numbers are called entries or elements
of a matrix and if we keep filling up
with this matrix David is connected with
Ellie
he's also connected with Andrew
as well as will faisal and gene Ali is
connected with david andrew and gene but
she's not connected with will or faisal
in the end we end up with this matrix
for part of Tomas social network on
facebook now let me ask you how many
connections does David have in this
network five you say how did you get a
number that's right one way to figure
that out is to look at horizontal ray
that describes who is connected with
David this horizontal ray is called a
row of a matrix each row of this matrix
tells us about the connections of one
specific person for example the third
rail is about Andrews connections in the
force rail is about Wales connections if
you add up the entries of the third row
the result is called a row sum and in
this example the row sum of the third
row tells you about how many connections
andrew has in this network equivalently
in this is the info you can also look at
the vertical arrays of this matrix each
vertical array is called a column of a
matrix if you add up the entries of a
column you get a column sum in this
example the rows and columns happen to
store the same kind of information
because you might have noticed there's a
symmetry in this matrix this symmetry
comes from the fact that you can be a
facebook friend with someone without him
or her being a facebook friend with you
but don't worry we'll see examples later
were rows and columns store different
information now let me ask you how many
people are there in this social network
and if everybody's connected with
everybody including themselves how many
connections were there be these are
information about the size of the
network and how can you get that
information from the matrix that's right
there are six rows and six columns in
this matrix so there are six people and
if everybody is connected with everybody
include
themselves then there are six times six
equals 36 connections as you can see the
number of rows and the number of columns
in the matrix tell us about the size or
the dimension of the matrix in general a
matrix with M rows and n columns is
called an m-by-n matrix so this matrix
for example is a 6 by 6 matrix
you
you
welcome to module 5 of chapter eight in
this module we are going to discuss
various properties of photography's own
group of a graph if G is an automorphism
then we will associate a permutation
matrix pz to it will show that a
permutation g of an automorphism is a is
an automorphism if and only if its
permutation matrix commutes with its in
C matrix of the graphics automorphism
group acts on the vertex attend as well
as it is it automorphism will go into
classify the graphs based on the action
of its automorphism groups on subsets of
what exit for example a graph is said to
be vertex turns to graph if it acts on
the vertex a transitively means that for
any two vertices there exists an
automorphism which takes one vertex to
another vertex in module 5 of chapter
eight we are going to discuss
automorphism bruise and its relation
with tennessee matrix objectives of this
module our relationship between
automorphisms of a graph and each agency
matrix what takes and edgy turns two
graphs distance trans two graphs recall
two graphs x 1 equal to v 1 e 1 and x 2
equal to v 2 e 2 are said to be
isomorphic written X 1 is isomorphic to
X 2 if there is a one-to-one
correspondence between v1 to v2 vertex
set of x 12 artic set of x 2 that is
there is a mapping sigh v1 to v2 such
that u 1 V 1 belongs to even if and only
if say a few 1 comma sy of V 1 belongs
to e 2 we discussed isomorphisms of
graphs in module 5 of chapter 1 as well
so now here we are going to discuss the
results of all these in terms of aids in
cymatics of a graph
the maps I is called isomorphism of x1
and x2 an isomorphism of X unto itself
is Karl an automorphism the collection
of all automorphisms of a graphics
denoted Artifex forms a group under
composition of two maps if X is a graph
on n vertices then automorphism of X is
a subgroup of s in the symmetric group
on n symbols under this correspondence
the maps in automorphism of x consists
of n cross in permutation matrices also
for each G in automorphism of X
corresponds a permutation matrix denoted
by P G now we state to results one of
which gives a method to check whether a
given permutation matrix is an element
of automorphism effects are not and
other gives information about few I ghen
values of x that means when the graph is
going to have few eigenvalues under it
effects our tamar facin group of x r if
the automorphism group have a nice
structure then the graph is going to
have few eigenvalues this is one of the
important result G belongs to our tamar
FISMA of ex-offender only if its
permutation matrix PG commutes with
agency matrix of the graphics so lemma
statement is let a be the adjacency
matrix of a graph X then G belongs to
automorphism of X if and only if PG into
a equal to a into PG the proof let G be
a permutation of vertex set V 1 V 2 and
so on VK and the GF VI is equal to V H
and G of EJ equal to V k
that means G takes vertex V a to vertex
V H and vertex V J to vertex V k each
row of PG has exactly one nonzero entry
namely one this because peace is a
permutation matrix so it is a each row
and each column has to contain only one
so now one has PG into a high-k that is
I ik 10-3 of PG into a is equal to
summation t equal to one to n PG I t
into a TK so which is equal to since the
8th row of our teeth column of PG
contains exactly 11 so we are going to
have it is big yes it becomes one only
when in the H element that means PG IH
is one remaining all other are 0 that is
why this is equal to PGH into a HK so
which is equal to a HK similarly if you
take a into PG its ik thin tree then it
is equal to t is equal to one to n AIT
into p g TK so in this case in the teeth
row of PG contains only 11 that is
exactly when PG of JK as gmaps VJ to VK
that is why we have PG JK thin trees one
so we are going to get AJ so
consequently what we proved is a HK and
a IJ they are equally fun down leaf pga
equal to a PG if and only if vh and VK
is an edge of fee if and only if v + VJ
is in a jiffy that is if and only if g
is an automorphism of X now we are going
to you prove some applications of the
previous result
the first one is we are going to show
that automorphism of X equal to
automorphism of X compliment corollary
let X be a graph then automorphism of X
equal to automorphism of X compliment
first note that a matrix B commutes with
the J decal jay is a matrix with every
entry is one so be commutes with j means
j be equal to bj that means that
actually if you multiply jb what will
happens the first entry is going to be
the sum of interest in the first row so
in that way j be equal to bj means every
rossum in b is equal to every column sum
so consequently every permutation matrix
commutes with j so it is because the
Rossum our column sum of every
permutation matrix is 1 so every
permutation matrix commutes with j with
this no proof becomes easy PG into a
equal to a PG if and only if PG into j
minus i minus EI j minus i minus a is
the identity matrix of X compliment so
which is equal to j minus i minus a into
PG it is because PG matrix now PG
permutation matrix commutes with J as
well as I always so we have this result
now we are going to show that
automorphism group of complete graph or
automorphism group of null graph is the
symmetric group s in this proof is easy
the proof is obvious as every
permutation matrix comes commutes with
zero matrix 0 matrix is the adjacency
matrix of the null graph and further we
know that cane is equal to n n
compliment so because of the previous
theorem automorphism group of KN is
equal to automatism group of NN
compliment
it is equal to n n so we have this part
now we are going to put an important
result let lambda gamma a be an eigen
pair of X if lambda is a simple eigen
value then G belongs to our Tamar fisma
fix then PG of PG into a is equal to
plus or minus a that means the
eigenvector a of X is also behaves like
an eigenvector of PG so pga the plus AR
minus a that means that PG a is and i
also an eigenvector of PG as a into PG
of a is equal to PG into a it is because
g is an automorphism so PG commutes with
a so we have PG into lambda a we see
that PG a comma lambda is also noggin
pair it is because we have capital a
into PG of a equal to PG into lambda l
lambda into PG of a soapy GFE is also an
eigen vector of a corresponding to eigen
value lambda so PG of a comma lambda is
an eigen pair but lambda is a simple
eigen value of a hence we have PG of a
is equal to MU into a foursome you
belongs to R a real number as lambda is
a real eigen value of x this because the
identity matrix of a graph is a real
symmetric matrix the eigenvalues of real
symmetric matrix are all real that we
prove it earlier so PG power s is equal
to identity for some s belongs to n as
PG is a permutation matrix so it is an
element of the group SN so there exists
in SS that PG power s equal to 1 so we
have you power s equal to 1 r since u is
real so u equal to plus or minus 1 if
all eigenvalues of a graphics are simple
then its automorphism group is an
elementary billion group so
there is a restriction of the
automorphism group if whenever if our
eigen values are simple okay so
statement of the theorem is if all
eigenvalues of a graphics are simple
then automorphism group of x is an
elementary a billion to group if G is an
automorphism effects then using previous
result PG of a equal to plus or minus a
for all eigenvectors a of X a of a it is
because every eigenvalue is a simple
eigenvalue so some previous result we
have this as all eigenvectors of a forms
a basis for R power n so p.p.g of be
equal to plus or minus B for all B
belongs to R power n thus PG square
equal to identity for all g belongs to
our tamar FISMA fix that means for every
automorphism g of x we have g square
equal to identity so that is why
automorphism of x is an elementary
billion to group now we are going to
define a class of graphs called vertex
trans two graphs a graph X equal to V
comma e is said to be worth extends to
graph if art of Murphy some of X ax
transitively on V that is for any two
vertices X comma Y in V X not equal to y
there exists a automorphism G such that
G of X equal to a so for every distinct
vertices X and Y there is an autumn are
fields which takes one to the other so
because of this what happens all
vertices will behave in the same way so
automatically consequently what x-trans
two graphs are regular graphs not only
that it has more property that we cannot
distinguish one vertex to another vertex
we proved in the previous module that is
module 5 of chapter one that there
exists X regular graphs which are
asymmetric so it is not only what
x-trans degrees now
regular but it is more than that for
example automorphism group of KN is
equal to SN automorphism group of cyclic
graph CN is d hydral group hence the
graphs KN and CNR over text hands to
johnson graphs and k cube graphs defined
in the module 1 of chapter 6 are also
what takes turns to let x equal to V
comma IE bak regular what takes turns to
graph if lambda is a simple eigen value
of x then lambda equals k if mod v is
odd and is contained in minus K comma K
minus k plus 2 and so on k minus 2 comma
k so for a curricular what takes turns
to graph already for text trans to
midget is regular but we are assuming we
are specifying it is K regular so if
lambda is an eigen value of lambda a
simple eigen value of a then we are
specifying what is its value is it is
going to be one of these only so but
this is possible only if mod V is even
that means if mod V is our then k equal
to exactly equal to K if mod V is even
then the lambda is one of these values
minus k minus k plus 2 and so on k minus
2 comma k now we will prove an important
result curl if every cali graph is
vertex turns to be call cali graphs we
defined in chapter 6 of module 1 let x
equal to a cali graph on the group g
with the connection set s then for every
g belongs to G X comma Y is an edge of X
if and only if X Y inverse belongs to
use that is a definition of the cali
graph so this is if and only if GX into
GX means here XG rgx means that G acting
on X G of X G take X to some other
vertex so g of x RX g into y gr GFI
whole inverse which belongs to s so that
means that g of x RX g comma y g is an
edge of x hence what we prove is g
itself is a subset of automorphism
effects hence if a comma B belongs to
vertex 8v that in this case the caligra
vertex at is the group G then the group
element a inverse B takes a to be we are
not only proved it is vertex tends to be
showed which element is taking vertex a
to vertex B now recall a circulant graph
diagraph a circus a tulane diagraph
means that it said since the matrix is a
circulant matrix let Jaden be Jaden
denote the cyclic group of order n then
every Callie diagraph CA by j dennis is
a circulant diagraph Callie graph j
dennis is a circulant graph conversely
every circulant diagraph cali j dennis
for some nonempty subset s of jaden so
every Callie diagraph is a actually it
will circulant diagraph is a Carrie
graph hence every circulant graph is
what extends to every vertex trans to
graph is not a cali graph but every
vertex turns to graph of primary
circulant graph now we will give an
example of a what vertex turns to grow
but not a cali growth pettersen graph is
that example so that Peterson graph is
what takes turns to but not a cali graph
the proof of vortex x 2 is left hand
exercise
in fact one can use the construction of
paterson graph given in these roads it
is known that up to isomorphism there
are only two groups of order 10 namely
cyclic group under dihedral group it is
easy to verify that none of the cubic
cali graphs obtained from these groups
is isomorphic to peterson graph we
showed that every cali graph is vertex
turns to graph but converse is not true
peterson graph is an example now we are
going to study few results on edge it
turns to graphs and distance strands two
graphs now we will discuss another class
of graphs called a trans two graphs a
graphics is set to be g trans to if for
any pair of edges there exists an
automorphism which maps 182 another that
is if a comma B and C comedy are edges
of graphics then there exists an
automorphism G belongs to art of X such
that G takes edge a b2 hdcd the prism
graph given below is a vertex turns to
but not edgy turns to graph one can see
that the sum of the J's cannot map to
another it is complete bipartite graph
km in for m not equal to n are examples
of edgy trans two graphs that that are
not vertex transitive if X is a xB a
connected graph if ax is AG turns to
graph which is not vertex x 2 then x is
bipartite so this theorem is
characterizing which the grass which are
in g trans to but not over text x 2 that
automatically bipartite graphs there are
only bipartite graphs so we let X comma
Y be an edge of a graphics WB any vertex
of X
we define a is equal to t of x that is a
very t is an automorphism t of x is our
is a vertex of x and b is equal to t FY
again t is an automorphism here as x is
not over text as to the sets a and B
that corresponds to equivalence classes
of the vertices X and Y respectively
they already joined also since X is edgy
trans too so edgy edgy set of X is
contained in a cross B as the as the
sets a and B gives a by partition of V
of X as that is X is a bipartite graph
it is difficult to find an example of a
regular connected graph which is edgy
turns to but not what takes turns to one
of the example is given below so but one
has to check carefully this graph is
edgy turns to but not vertex turns to
and further it is a regular graph a
graph X is said to be distance trans to
if all the vertices U V X Y of X with
distance of U comma V is equal to
distance of X comma Y there is an
automorphism SAT is satisfying GFU equal
to X and G of V equal to Y that means a
graph is a distance trans to graph if I
if you take a pair of vertices such that
their distance distance between them are
equal that means d UV is one pair and XY
is another pair distance between them is
equal then automatically there exists an
automorphism which takes you to X and V
2 y so that is why it is called a
distance trans two graphs it is
is Irving the distances the distance
trans two graphs are clearly both over
text has two and edge it has two
complete graphs KN cycle graph CN and
complete bipartite graphs k MN when m
equal to n are few examples of distance
trans two graphs there are few class of
graphs which attained the lower bound in
the inequality d plus 1 is less than or
equal to dimension of addition see
algebra of X less than or equal to n the
class of distance trans two graphs are
one armed one among them that means if
ax is a distance trans to graph then the
dimension of it since the algebra of X
is equal to exactly deep listen so that
is what the theorem state if x is a
distance trans to graph with diameter D
then dimension of a of X equal to D plus
1 in fact in case of distance trans two
graphs something more is true and to
state it we need the following
definition let G be a group acting on a
non-empty set V then G also acts on V
cross v by g f x y is equal to G of X
comma GF I for a fixed element u comma V
of V cross V the set that is our beta of
you v is equal to set of all ordered
pairs which takes UV v by g that means G
is varying here UV is fixed so we are
collecting all ordered pairs which are
mapped by the automorphism zuv g 2 u
comma V so this is called arbatov UV
under the action of G the distinct
orbits of UV under the action of G are
called orbitals so in the context of a
graph that is X equal to V comma IE the
orbitals of X are distinct orbits of
the ID set B Class V under the action of
automorphisms of the automorphism of X
that these orbitals are our bits of arcs
are non arcs of the graphics arc means
here just an edge means here we are
looking a direction as well the number
of orbitals is called rank of the
graphics note that for each fixed seed
UV belongs to V cross V we can associate
a 0 1 matrix M mij such that we're Maj
equal to one if I JS belongs to orbit of
UV and zero otherwise the matrices
obtained the by the above method are
called orbital matrices also note that
for any orbital matrix all it's nonzero
increase either appear on the main
diagonal are they appear on the off
diagonal as GF VV is always equal to G
of V comma gfv for all V belongs to V
and G belongs to automorphism of X the
orbitals containing once on the diagonal
will be called diagonal orbits if X is a
distance trans to graph then the
arbitral matrices and the distance
matrices defined in module 2 of chapter
eight will coincide moreover they form a
basis for agency algebra of x so now we
are going to prove an important result
that is decomposition of the complete
graph and prime number of vertices as
isomorphic copies of circling diagraphs
let P be a prime number let K be any
factor of P minus 1 then edgy set of KP
that is a jet p comma e the complete
graph on p vertices can be partitioned
into K subsets even a 2 and so on EK
such that the diagraphs xie equal to V
comma EA for one less than or equal to i
less than or equal to K are our regular
circling diagraphs
where r is equal to P minus 1 by K
moreover the diagraphs xixj for one less
than or equal to i less than it I lie
less than j less than or equal to K are
isomorphic so this contains two parts
will prove one by one proof of the first
part let alpha be a generator of jet p
star jerk p star means deleting 0 from p
jetp then h equal to alpha power k 1
that is 1 alpha power k and so on alpha
power k into r minus 1 is a subgroup of
jet p star having our elements and let h
j is equal to alpha power j into h for j
equal to 0 1 2 3 and so on k minus one
with the cosets of h in jet p star with
h naught equal to H it is important to
note that HJ as a subset of JP generates
jetp for each j equal to 0 1 2 3 and so
on k minus 1 because of that the this is
going to be useful we will see how it is
useful now we will define a matrix a j
is equal to h belongs to capital h j WP
power hitch recall WP is is the
adjacency matrix of a directed cycle on
p vertices so WP is a circulant matrix
and any polynomial a circulant matrix so
AJ is a circulant matrix further it is a
0 1 matrix so AJ is 0-1 circulant matrix
let us now define a diagraph HJ by
taking jetp as its vertex it and for any
X comma Y belongs to jet p XY x comma y
is an edge of XJ if and only if y minus
X belongs to H J then it is easy to
verify that XJ is Carrie diagraph so
that is a colleague of jet p comma
Jay since the cosets HJ for 0 less than
or equal to j less than or equal to k
minus one already d joint one has
obtained KD joint diagraphs that are our
regular and this completes the proof of
the first part now we will prove the
second part we now need to show that all
these k diagraphs xj40 less than or
equal to j less than or equal to k minus
1 are mutually isomorphic we will do so
by proving that the diagraphs x 0 and x
j are isomorphic for one less than or
equal to j less than or equal to k minus
1 here we are changing j but we are
proving that XJ is isomorphic to x0
where j is arbitrary so let us define
the map sigh from vertex set of x0 to
vertex set of XJ by sy off so FS is
equal to alpha power J into s for each s
belongs to what it set of X naught then
it can be easily verified that size 11
and on to the Sui just need to show that
sy of X is an edge of XJ if and only if
XY is an edge of X 0 or equivalently we
need to show that sy of X minus ify
belongs to HJ if and only if X minus y
belongs to H and this holds true as X
minus y belongs to H if and only if
alpha power J into X minus y belongs to
HJ that is if and only if alpha power J
into X minus alpha power J into y
belongs to HJ this is same as sigh of X
minus IFI belongs to H J so this
completes the proof of
distance trans to graph have lot of
symmetry distance trans two graphs are
vertex times 2 as well as AG trans two
graphs the orbital matrices and distance
matrices are coincide for distance trans
two graphs further they form a basis for
its NC algebra of these graphs with this
we end this module as well as this
chapter
hi guys is video mohandro Janek a
decency matrix representation guevara
when the adjacent vertices of a graph is
represented in the form of matrix then
such type of representation is called
adjacency matrix representation of a
graph is named number of rows equal
within number of columns the number of
physically gravelly things example me
crappity kept his calm logo bow it is in
c matrix representation nikola autumn
locus in occulta belly-to-belly vodka
number of rows Disney okay number of
columns on get the number of cross or
number of forms my basket has six in
take a is hot I'm putting one two three
four five six to use 69 okay
how is cool represent gets a cut ends of
zip LFO diagonally up to one say two
mega octane or one six six nine take it
to once you do or one six six two
thousand eight one four one field that
night or baggage it may be a submit zero
which there is a tuba dect led not to up
they can to say up three me a sec there
to say up one mega set then take it to
one but three may up one finger thing or
baggy samba zero is whether three school
is called a attended three say to us at
the three step four we have seven three
seven is equal to 2 for 5 negative 2 for
5 May 1 1 1 he cut thing her back is sum
is 0
she dropped for say up three me for say
out 5 me as a head to force a three
sorry 43 over say 5 to 3 or 5 3 4 5 yeah
1 or e ah 1 dollar 1 1000 a pullback is
something 0 was you throw 5 me pipes is
6 5 0 5 C 3 a nigga 3 4 6 May 1 1
Pickering or bakasana 0 6 7 more 6fi
method 105 yen you keep one code 5 BM 1
min 1 / 5 new one
tell me one one filter in your bucket
sum is 0 0 0 the key here is graph
a decency matrix representation thanks
for watching
you
welcome to module 2 of chapter eight in
this module we are going to study
adjacency matrix of a graph the identity
matrix is an n-by-n matrix where n is
the number of vertices of the graph
which is a 0 1 matrix and is defined as
the IJ entry of the it's NC matrix is 1
if I is adjacent to vertex J otherwise 0
from now onwards I ghen values and
characteristic polynomial of a graph we
mean that eigen values and
characteristic polynomial of adjacency
matrix now we are going to show that the
IJ entry of a power K gives the number
of walks of length K from vertex I to
vertex J because of that we can show
that the trace of a square is equal to
the twice of the number of edges in the
graph and trace of a cube provides
information about the number of
triangles in the graph in module 2 of
chapter eight we are going to study
adjacency matrix of a graph the learning
objectives of this module are
introduction to agency matrix of a graph
addition see algebra of a graph Co
spectral graphs distance matrices of a
graph introduction to matrices of graphs
there are various matrices associated to
groves so given a graph we can associate
several matrices which record
information about vertices and how they
are interconnected the question then
arises given that you know the
eigenvalues of some matrix associated
with a the graph what can you say about
the graph spectral graph theory looks at
answering questions of this type by
looking at these eigenvalues it is
possible to get information about a
graph that might otherwise be difficult
to obtain it is in C matrix of a graph
Let X be a graph on n vertices
let us fix a labeling of the vertices of
X then the addition C matrix of X
denoted a of x which is equal to a IJ
are simply we can say a if you X is
clear from the contest instead of
writing a of X we simply say a is an
n-by-n matrix with a j is equal to 1 if
I thuat X is adjacent to jet vertex and
0 otherwise note that another labeling
of the vertices of X gives rise to
another matrix B such that B equal to P
inverse into AP for some permutation
matrix P for a permutation matrix recall
that we have P transpose is equal to P
inverse hence we walk we talk of its in
C matrix of a graphics and we do not
worry about the labeling of the vertices
of X so if you change the labeling will
get under matrix that is similar to the
original matrix a so the eigen values
are going to be same clearly the
adjacency matrix a is real symmetric
matrix that means actually we are
considering it is in C matrix of a
simple graph it is undirected and as
well as finite so a is a n by n matrix
hence a has n real eigenvalues and a is
diagonalizable and the eigenvectors can
be chosen to form an orthogonal basis of
our power in the eigenvalues
eigenvectors the minimal polynomial and
the characteristic polynomial of a
graphics are defined to be that of its
edges in C matrix so now onwards we say
eigenvalues of a graph means that eigen
values of it S&amp;C matrix minimal
polynomial effect graph means minimal
pollen are free of its edison c matrix
and so on
if a is a decency matrix of a graphics
then we do not f EA in general c of AC
is the complex numbers or you can take
any field in fact but generally will
confine two complex numbers f of a is a
sub algebra of MN of f generated by a
that is actually f of a set of all
polynomials in da with coefficients from
f as we already pointed out we will take
coefficients from complex numbers it is
denoted by a of X called H&amp;C algebra fix
so agency algebra of x is he is a set of
all polynomials in a and you can show
that it is an algebra algebra what we
mean is it is as both vector space
structure as well as ring structure we
will illustrate with a till now what we
done will illustrate with an example let
us take graph is k3 then its efficiency
matrix is 0 1 1 1 0 1 and 1 10 it is
because one-to-one there is no self loop
so there is no edge from 1 to 1 so 0 but
there is an edge from one to two there
is an edge from one to three so entire
row of first row is contains once except
the diagonal element so this the
identity matrix of a complete graph only
diagonal mints are 0 remaining all are
going to be one the characteristic
polynomial is X minus 1 whole square
into X minus 2 the minimal polynomial of
a are X is X minus 1 into X minus 2 and
the addition see algebra in this case is
alpha I plus beta into a where alpha
beta belongs two complex numbers now we
are going to prove that number of box of
length K from vertex I to vertex J is
obtained from in the a power K IJ entry
of a power K so the statement is let X
be a graph with a agency matrix a then
for every positive integer K
a power a power k IJ entry of a power k
is equals to the number of wax of length
K from vertex V a 28 x vijay so the
proof will prove the result by induction
on k base step if k equal to 1 by
definition a j is equal to one if VI +
VJ are adjacent zero otherwise this is a
definition of adjacency matrix assume
the result is true for k equal to l now
consider the matrix a power l plus 1 so
the IJ 10 tree of a power n plus 1 is
equal to summation h equal to one to n a
power l IH into a I HJ so therefore I
jate entry of a power l plus 1 is equal
to number of walks of length L from VA
to vh then a whack of length 1 that is
Edison see from vh to VJ for all
vertices v h of v that means for thick
set of x thus a power l plus 1 IJ thin 3
equals to number of works of length l
plus 1 from VA to VJ as a corollary to
this result it is easy to see so we are
emitting the proof Let X be a connected
simple graph on n vertices capital gamma
IJ of K denote the number of paths of
length K for a mite vertex 2 J thortex
also n be the matrix whose eyes a thin
tree is given by n IJ is equal to
summation k equal to 1 to infinity gamma
IJ of K into X power K that means it is
a power series each i J theta is a power
series then n is equal to 1 by identity
identity matrix
minus x times matrix a the agency matrix
now we are looking important result what
the trace of the agency matrix will
provide to us let a be dead since a
matrix of a simple graph x which is
equal to v comma IE let lambda 1 lambda
2 and so on lambda n be the eigenvalues
of a then lambda 1 plus lambda 2 and so
on plus lambda n is equal to 0 that is
some of the eigenvalues is of trace so
trace is equal to 0 at lambda 1 square
plus lambda 2 square and so on plus
lambda n square is equal to twice the
number of edges as we know that modulus
of G of X is the number of edges in the
graph so it is important that trace of a
square is giving the twice the number of
edges so if you can understand that by
using its in C matrix it is possible to
find the number of edges and lambda 1 Q
plus lambda 2 cube and so on lambda and
cube is equal to 6 times T of X where T
of X is the number of triangles in the
graph so now that means the trace of a
cube is equal to 6 times the number of
triangles now we are you get the proof
of this one let a be an n-by-n matrix
with eigenvalues lambda IFA where one
less than or equal to i less than or
equal to n then lambda 1 plus lambda
lambda 2 + and so on lambda n is equal
to trace of a that we know earlier from
the results of matrix theory lambda 1
square plus lambda 2 square and so on
lambda and square is equal to trace of a
square lambda 1 cube and so on lambda n
cube is equal trace of a cube but lambda
1 plus lambda 2 plus lambda n is equal
to 0 as X is simple graph it sits in
somatic CA has zeros on the diagonal and
stress of a equal to zero
are some of the eigenvalues is equal to
zero so use equation one to get the
required result now lambda 1 square plus
lambda 2 square and so on lambda n
square equal to 2 twice the number of
edges note that that we have to show
note that diagonal increase of a square
counts the number of closed box of
length 2 that is a square of i is equal
to degree of VA the I taught x of x that
is trace trace of a square is equal to
summation i is equal to one to n degree
of VA but we know that some of the
degrees of all vertices is equal to
twice the number of edges that the
result follows using equation 2 now we
need to show that lambda 1 cube plus
lambda 2 cubic and so on lambda and cube
is equal to 6 times number of triangles
note that the diagonal entries of a cube
counts the number of closed box of
length 3 hence trace of a cube is equal
to summation i is equal to one to n a
cube I a that is equal to six times
number of triangle suffix as each
triangle safe our would buy the vertices
I JK are counted as a closed box of the
firm I to J from J to K and K 2 I I to K
2 K to j and j 2i j 2i to k2j like that
we have for a single triangle we are
counting six times starting with I two
times starting with j 2 time starting
with k 2 times thus the result of
follows hence the proof that the spec
simple graphics determines the number of
vertices adjacent triangles now we will
going to see co spectrographs what is a
co spectral graph two graphs are said to
be co spectral if they have same
eigenvalues with same multiplicities
for example if you look at this graph
these two graphs it is clear that
isomorphic graphs are co spectral but
the converse need not be true in the
figure shown above that to two graphs
one is k1 Union C for that is a cycle
and we put a one vertex in the middle so
that is k1 Union c4 and K 14 * graph
with five vertices our co spectral as
both have the same characteristic
polynomial x cube minus four x cube but
they do not have same number of four
cycles thus we see that several
properties of graphs cannot be
determined by grass spectrum that is
connectivity degree sequence etcetera
the following graphs are the smallest Co
spectral connected graphs which are not
isomorphic this graph as well as this
graph we can show that they are not
isomorphic but they are Co spectral that
means they have same agency spectrum
that means eigenvalues of the edson
cymatics of first graph and the
eigenvalues of it since matrix of second
graph are equal now we will count the
total number of Arc's of length K next
suppose that we want to count total
number of Arc's of length K in a simple
graphics on n vertices then we need to
consider e transpose a power K into e
very agency matrix of X and E is a
column vector of all ones as is a real
symmetric matrix its eigen vector say X
1 X 2 and so on xn corresponding to the
eigen values lambda 1 lambda 2 and so on
lambda n can be chosen from orthogonal
basis of our power n then for some
appropriate constants a is a is equal to
i is equal to one to n AXA where again
recall capital e that is bolis column
vector with all one's thus one can check
easily that e transpose a power k into e
is going to be summation i is equal to
one to n a X I transpose into a power k
summation i is equal to one to an ax I
so if you multiply a power k if you take
a power can side the second summation
and we the fact that each X I is an
eigenvector of a so it is automatically
eigenvector of a power k so we have
summation i is equal to one to n ax I
transpose into summation i is equal to
one to n a lambda power lambda I power K
into X I which is equal to summation i
is equal to one to n a square lambda I
power K into X I transpose into X I
which is equal to i is equal to one to n
a square lambda our k we proved that
isomorphic graphs have same eigenvalues
that means if x1 and x2 are two
isomorphic graphs the eigen values of x1
are equal to the eigen values of x to
butt converse of this result is not true
that means there exists graphs their
eigenvalues are same but they are not
going to be isomorphic we named them as
co spectral graphs now we are going to
prove following thing we are going to
assume that if d is a diameter of the
graph x then we are going to show that
the identity matrix of the graphics has
at least d plus 1 eigen values and also
we are going to show that the dimension
of its NC algebra of the graph x is
equal to the number of distinct eigen
values of x so consequently if d is a
diameter of the graph x then the
dimension of S&amp;C algebra lies in between
d plus 1 and n including d plus 1 and n
now we are going to show that the
dimension of agency algebra lies in
between D plus 1 and n including D plus
1 and n so lemma says that Let X be a
connected simple graph on n vertices if
d is the diameter of the graph X then D
plus 1 is less than or equal to
dimension of a of X is less than or
equal to n since these a diameter of X
there exists X comma Y belongs to V with
distance of X comma Y is equal to D
suppose X equal to W naught comma w 1
and so on X equal to W naught comma w 1
and so on WD equal to Y is a path of
length D in X then from the lemma
previous lemma we saw that for each I
belongs to 12 d there exists at least
one path of length I from w naught to wi
but no shorter work consequently a power
I has a nonzero entry in a position
where corresponding entries I a square
and so on a power i minus 1 are 0 so I a
a square and so on a power I minus one
comma a power I is a linearly
independent set thus I a square and so
on a power D minus one comma a power D
is a linearly independent set hence D
plus 1 is less than or equal to
dimension of a of X further the upper
bound is achieved by well-known cali
Hamilton theorem hence the result
follows as we know that by a cali
Hamilton theorem the maximum number of
eigen values is n only so we have the
result now we will prove that the
identity matrix has at least D plus 1
eigen values distinct eigenvalues
whenever
d is the diameter of the graph the
abortion has a nice consequence in
particular it relates to the number of
distinct eigenvalues of a simple
connected graph the with the diameter of
the graph that we stated here as a
corollary let a connected simple
graphics with a diameter d has at least
d plus one distinct eigenvalues so it is
a though it is a direct consequence of
the previous result but this is a very
powerful result that diameter D and
distant eigenvalues these are related so
a graph with diameter D connected graph
diameter D has at least D plus one
distinct eigenvalues we use this
corollary several times since the agency
matrix is real symmetric matrix it's
minimal polynomial is the product of
distinct linear polynomials hence
dimension of a of X equal to also equal
to the number of distinct eigenvalues of
a does if graphics has a diameter D then
it has at least d plus one distinct
eigenvalues so no proof is not required
but we given the proof the above curler
is not true for directed graphs for
example the following directed path has
diameter to wear as he said cincy matrix
has only 0 as its eigen value so the
directed path graph there is an edge
from one to two but there is no edge
from two to one so it is a directed path
and each citizen C matrix is given as 0
1 0 0 0 1 and 0 0 0 here there is a we
are going to put one in the entry 1
comma 2 since there is an edge from one
to two there is no edge from one to
three so it is 0 and also we are not
taking entry from 3322 as we are not
taking entry into three to two as one it
is we
there is no edge from three to two but
there is an edge from two to three
directed edge so the path graph and n
vertices has indistinct up I ghen values
this is one of the nice application of
the previous corollary as we already
mentioned we are going to use that
corollary several times so since a path
graph on n vertices the diameter is
going to be exactly equal to n minus 1
so damn it d plus 1 eigen values a a
graph will have at least distant
eigenvalues so the diameter of path is n
minus 1 so path graph has at least and
distinct eigenvalues if all eigenvalues
of a simple graph are equal then its
diameter is 0 the simple graph has only
one distinct eigen value if and only if
it is a null graph Let X be a connected
graph then it has exactly two distinct
eigenvalues if and only if it is a
complete graph that is diameter of the
complete graph is one so it is a very
nice result that it has two distinct
eigenvalues if and only if it is
complete graph so with by using
eigenvalues we are characterizing the
graph let x be a graph with the two
distinct eigenvalues and then x is a
regular graph that is also nice property
that means if you have a graph as two
diction tagging values we are saying
that X is a regular graph the proof goes
like this let x be a graph with two
decent eigen values then dimension of a
of x equal to two ends I and a forms a
basis for instance I algebra fix
consequently a square is equal to small
ain't to capitalize identity matrix plus
b into a variant BR some integers thus a
square of IJ i is equal to a for all I
that means every diagonal element
three of a square is same that is equal
to a so that is why it is a regular
graphs as we know that the diagonal
entry of a square gives a degree of the
vertex now another result is Let X be a
connected graph on n vertices if a is
its addition C matrix then every entry
of I plus a whole power n minus 1 is
positive this result we are going to use
in the other modules also so there we
are not going to give proof so reader
has to recall this proof whenever
required so this is an important result
from lemma 1 we see that IJ think three
of I plus a plus a square and so on a
power n minus 1 equal to total number of
works of length less than or equal to n
minus 1 as in the Clemmie we proved that
the IJ entry of a power k gives number
of walks of length K from I to J but now
we are adding a square a cube and so on
a power n minus 1 including I so it
gives total number of Arc's of length
less than or equal to n minus 1 as X is
connected graph on n vertices diameter
of X is less than or equal to n minus 1
and see each entry of a I plus a plus a
square and so on a power n minus 1 is
positive thus the result follows from
the fact that I plus a whole power n
minus 1 is greater than or equal to i
plus a plus a square and so on a power n
minus 1 here one has to define what is
here greater than or equal to how we are
defining greater than or equal to among
the matrices it is simply if i take IJ
entry in a plus i plus a whole power n
minus one that has to be greater than or
equal to aij thin three of I plus a plus
i square and so on a power n n minus 1
that means we say that two matrices a
and B and we say that a is greater than
or equal to B if every IJ thing to every
entry in a is greater equal to every
entry of b IJ entry of p
now we are going to define Kate distance
matrix of a graph let x equal to V comma
IE be a connected graph with diameter D
40 is less than or equal to K less than
or equal to D the K the distance matrix
of X is denoted AK is defined as AK rs8
entry is equal to one if the distance
from VR to vs is equal to K 0 otherwise
so now we are going to define D plus 1
matrices like this the first matrix is a
zero that is identity matrix itself a 1
is the identity matrix a 2 onwards will
get other matrices all are 0 and
matrices and also we can see nice
properties of these matrices from above
definition it is clear that a knot is
identity matrix a one is identity matrix
of the graphics a naught plus a 1 plus a
d equal to j remember that this j is
matrix of all once that means every into
in j is equal to 1 AK 4 0 less than or
equal to k less than or equal to D is a
symmetric matrix since we are looking
the distance matrix of a graph graph the
identity matrix itself is symmetric so
all these mattresses are going to be
symmetric does the set a not a 1 and so
on a poverty is a linear independent set
in MN of our now we are going to define
a graph by using the distance matrices
let X be a connected graph with diameter
D let a k of x for 0 less than or equal
to k less than or equal to d be the
distance matrix of X then X is set to be
distance polynomial graph if acre of X
belongs to a of X agency algebra of X in
other words if every distance matrix is
a polynomial in the agency matrix of a
the complete graph KN the cyclic graph
CN complete bipartite graph KN in
paterson graph are few example
of distance polynomial graph we request
reader to verify these things this is
all why all these graphs are going to be
distance polynomial graphs if d is a
diameter of the graphics we devoted k
the distance matrix AK where 0 is less
than or equal to k less than or equal to
D is the K the distance matrix AK is
defined as the IJ entry of AK is one if
there is a path of length K from i to j
0 otherwise we defined distance
polynomial graphs as the graph in which
all distance matrices are belongs to
edison see algebra of the graphics that
is every distance matrix is a polynomial
in the identity matrix of that graphics
with this we end this module
hello friends welcome back in this
tutorial we will study about the
adjacency matrix of a digraph the
adjacency matrix of a digraph having n
vertices is up and cross and binary
matrix in which entry at at row and jth
column is 1 if and only if there is an
arc from vertex a to vertex G each
diagonal entry in the adjacency matrix
of a digraph is 0 for example see this
diagraph this is the adjacency matrix of
this diagraph order of this matrix is 4
cross 4 because there are 4 vertices in
diagraph ndaya graph there is an arc
from vertex 1 to vertex 2 therefore in
adjacency matrix of this diagraph entry
at first row and second column is 1
similarly there is an arc from vertex 1
to vertex 4 therefore in adjacency
matrix the entry at first row and fourth
column is 1 there is an arc from vertex
2 to vertex 3 therefore in adjacency
matrix the entry at second row and third
column is 1 there is an arc from vertex
3 to what X 1 they
for in adjacent C matrix the ant react
third row and first column is one there
is an arc from vertex four to vertex 3
therefore in adjacency matrix the ant
react
fourth row and third column is one thank
you very much
the soldier andré do santos launched in
Saturday morning in southern Argentina
silver goal
is a dream now it's all our focus is
the return in the drawer and human elvis
mathematics in the world or the new
Zealand rounds the Colombian was
more room to store our there on the farm
but so far no one can do in
arena it in the analysis of the film
island still nathan hale in guinea
Bench amon violinist who linked the
we already have the fabulous urban
the wardrobe in the washing machine and
so the dollar continues in the village aurora
on Tuesday 6 urn hardware
our discipline and then walked in xuxa
land than you think the machine more
estimated net see us the chance to
get out
shows the circular carriers on line
I will show her the forana ships
see our way to the best film
Europe
imagine tam pn and never missed it augurs
a future now it's time fall
There was a scene at the time end of the fight
I never spoke and not only speak doors and
anabel animation is not stop this one
edges of the island atmosphere of the Faial
athletes injunction to photo time
nothing is nor only home photo is l or
out there if we win in China
follows the help of the bull player or tantrum
or the fall who has the backing of the UN kofi
annan only matrix and now friends
london or just the fact tantrum has
an irregular athlete
you want a car in the neighborhood of uruguay
in Bahia fantasy island adopted in
Europe
in a note to nato should also act in
Please cinema Roland du Luart now
females stood up and he said yes at the time
a change in either tone or transit
good on the street led to a lady laura
Anal new form of water of time
tide r
there reassured me one rate rise
normal VAT will that he and and
Bosnian heard of the weakest law
key
closing tomorrow danin music i and ii
changing the fine per year
now comes to me is not that athlete
now the Maracana language
Mantega in exchange for the note will raise the
bed're not rolling the pitch of the note
gibran there was only done in thin mud ii
Head up the hill from adi a cute and he tb
is behind renan not care in the micro
New village in September in keeping it
as now than it was a soldier of the UN
citing the Democrat harry reid'm not
photo plump produce 101
is the analysis - street after control
girl sister as well as original
tur only one
already the rain the rain there was only
I joined steals the asylum tenerife Brazil
then gives them to off the end said that
the Brazil is out andréa dellal
Health guard has done great this
protein horde killed online store to vote
and now leave me proof software in
Italy
Now our Google now only plays
Golf IETab and l'amour
thus only at the end of the race uefeira
rafa moon zeal of new zealand italy
screwdriver in the same attack
now or attacking the village brasília
Brazil the arena now to Figure NaPA
brown frog humid night causing
rain or anything but be providing
box office head of the new including
Samsung wants to tie the shoes is that
You should set the order is not to hear
tell me he has this law into force
UN suffers Hilton et l'amour ie Kupatekuma
ii armed of
ana dalva the ball when it exposes
and also eliminates cancan dancer
tenth and renan
he says that there is one proof that the
rule saw the camera go in bias street
Filardo guardian and criminal Atimus
great-grandmother and now no one leaves only
rob you change the name of the director
eliane is still Butantã
analyzing the pond rises board 1 in which
- the valley has street violet mossoró
smaller or said it is good to have in
bar and would you now off the noise has
and steal him and suffers it easy feeling
there're missing someone did not know
occurs only very easy to think telemar
that our memory is still suffering land
in one year is r in history're only
It has is in the world and not only steals
in addition to the drug to which the blog okay
the new big one alloy baby left off
You will now sing in one act
I thought that line
there has nothing changed row walked on
wounded street governed by uefa decided
take it women's draw
Orani hotel was also here to
me
besides gold ii
you have a currency that is not window
Queen of proof of the reason war ii
Sambu is talk alone ITN name is
there has only italy and street now one ciro
One year file and Brazil saw 10 years
the son of Lieutenant tena woman
Brazil street year and the athlete already in
Europe
000-100000 1-0 petrol more
me that there not only set aside the
a rope in the area and little Rho Rho line
Motorola will suit well in 000
Girón trust i5 is álvaro me
now
gives some see the author to wireless network
african culture has on the globe Ronald
street information of the silva eduardo
sleep by software
efe if i vtec the boy came to have
none is bad
bean ufpe
robby ray bab al Zawahiri neighborhood
avalone love only have 10 and less of
street and attracted
now that we're feeling pretty familiar
with graphs we're going to look at ways
of represent
graphs using matrices
let's take a look at
example graph G what I'm going to do is
label the vertices of G as 1 2 3 &amp; 4 so
I want to talk about the adjacency
matrix of this graph G and also the
incidence matrix let's start with the
idea of an adjacency matrix
in an adjacency matrix we think of the
rows of the matrix as well as the
columns of the matrix to be labeled by
the vertices so here we have 1 2 3 and 4
vertices and we also have 1 2 3 &amp; 4
so the actual labeling that we give can
be anything but then when we look at the
actual adjacency matrix it will all
start to make sense so let's call our
adjacency matrix a and this is the
actual definition of our matrix we all
know that an entry in row I column J
will be equal to either 1 or 0 it will
be equal to 1 if the edge I J is
actually an edge and if I J is not an
edge that's when you get the 0 if you
look at the vertex 1 and you ask is
vertex 1 adjacent to vertex 1 the answer
is no because that would be a loop so
you put a 0 here is vertex 1 adjacent to
vertex 2 yes that is an edge so you put
a 1 is vertex 1 adjacent to vertex 3 no
it is not so you put a 0 and is vertex 1
adjacent to vertex 4 yes it is so we put
a 1 notice that we don't have any loops
in this graph that means that vertex 2
is not going to be adjacent to itself so
we can already put that 0 3 is not
adjacent to itself it doesn't have a
loop so that's already a 0 and same
thing with 4 so let's continue to look
through if vertex 2 is adjacent to
vertex 1 yes we know that's true
so we put in a 1 vertex 2 is also
adjacent to vertex 3 so that's a 1 and
vertex 2 is adjacent to vertex 4 now we
look at vertex 3 which is adjacent to
vertices 2 and 4 so we know that at 2
and at 4 we need a 1 we need a 0
everywhere else we knew that this was a
0 and we also put a 0 here finally
vertex 4 happens to have degree 3 its
adjacent to everything except itself so
it has all of these as a 1 and of course
0 here because it doesn't have a loop
remember that in an adjacency matrix
rows and columns represent vertices so
if you look at the row sum you're going
to get the degree of the vertex that
that row so if we look at vertex 2 and
we look at the row sum here we sum all
of these up we get 3 and the row sum 3
tells us that vertex 2 has degree 3
which we can see clearly in the graph
since columns also represent vertices
the same is true for the column sum if
you look at the column that represents
the vertex 2 you will also get a 3 which
represents its degree so keep in mind
that the adjacency matrix of a graph has
all the same information that's
contained in the graph so these are two
ways of representing the same exact data
and an adjacency matrix is a little bit
more friendly for a computer here I'm
going to show you how we can do exactly
that using sage which is a free online
tool it's excellent for using when when
you're working with graphs so here I'll
put links in the description below so
the first thing I'm going to do is to
create a new sage worksheet and this is
where I'm working inside of the sage
cloud you can also work locally with
sage and download it to your machine so
here I've just created a worksheet
called graph theory and I'll just get it
started so the first thing that I'm
going to do in this worksheet is just
set up our adjacency matrix and I'm
going to use the matrix that we have
been working with with our little
example on 4 vertices so I've set up a
matrix and I'm starting to put in there
rows the rows are exactly the the rows
that we've written down in the video so
the first row was 0 1 0 1 and then we
just continue to write each of these
rows and we end up with an array of
arrays now what we're going to do is
we're going to just print our matrix to
make sure that we have the right thing
so I'll ask it to print by pressing
shift enter and indeed I can check that
this is the correct matrix that we've
been working with now I'm going to write
G equal to the graph of this adjacency
matrix and now I want to see that graph
so I'm going to use G show and again
pressing shift enter I'm going to get a
graph notice that this graph has been
shown to us in any random way that the
computer generates the visuals if I was
to run the G dot show
again I would again get a different
picture but no matter how I run it I'll
get the same relationship between those
vertices and edges so here I'm running
it again and I see something that looks
a bit more similar to the way that I
originally drew it one thing to notice
is that by default sage will label
vertices starting at zero so it's
labeled the vertices 0 1 2 3 instead of
1 2 3 4 in this case vertex 0 is like
our vertex 1 now let's check out the
incidence matrix so the incidence matrix
is usually denoted by an M instead of an
A and there's one key difference we
still are going to be labeling our rows
of our matrix via our vertices so 1 2 3
&amp; 4 but now what we want to do is label
the columns using edges so what I could
have done is written here column number
1 is going to be the edge 1 2 but that's
going to be a little bit tedious so what
I'm going to do is call this edge 1 to a
and then I'll call this B C D and E so
that I can represent these edges right
here a B C D and E so that's one key
difference already rows represent
vertices and columns represent edges and
we define the IJ entry of the matrix M
to be a 1 if vertex I belongs to edge J
and 0 otherwise so again let's take a
look at our example we can see vertex 1
has several edges that it lies on it
lies on edge a and it also lies on edge
D so when we look into this row what we
have to do is put a 1 at the a position
and also at the D position but vertex 1
doesn't lie on any of these other edges
so that's why we put zeroes there using
the same kind of logic we can complete
the rest of this matrix now when you
look into the row some of the matrix
where you're looking at the incidence
matrix you're still going to get the
degree of the vertex that's there so if
you look again at the row sum of vertex
number 2 you're still going to get a 3
because all this is telling you is that
there
are a total of three edges that too is
incident with so that gives you again
the degree three for vertex two now
something is different about the column
sum though because columns represent
edges so in this case if you look down
up any column you'll notice that the
number of ones is always two the reason
for that is because the columns
represent edges which means that every
Edge has two ends so if I look at column
D right here
I say okay that means that the two ends
of column D are vertex one and vertex
four and in fact if you look back at the
graph you'll see that edge D does indeed
have two ends one of them is vertex one
and the other one is vertex 4
that's actually the definition of an
edge that it has two ends at least in
the case of graphs not hypergraphs so to
recap the row sum equals the degree and
the column sum equals two now when we're
dealing with simple graphs we never need
to worry about things like multiple
edges or loops but this fact that the
column sum should equal two has an
interesting property in terms of the
loop it means that if you were to have a
loop in your graph and let's maybe call
our loop f where we'll go back up here
and we'll put in a new edge called f so
on vertex three i'm going to tack on a
loop and that one is called f the way i
would represent this in the incidence
matrix is to say well vertex three is
incident with f but my column sum should
equal two and in fact what we do is we
make a loop count as two so we have
zeros everywhere else in that column and
the loop counts twice so that's sort of
a finicky thing that can happen with
loops loops will count twice in your
incidence matrix but in general when
we're worrying about simple graphs we
don't need to worry about loops at all
so the key thing here is that you can
represent any graph using a matrix you
can either choose to use the adjacency
matrix version or the incidence matrix
I believe the adjacency matrix is most
commonly used but there are certain
instances when of the incidence matrix
could also be very useful for a
particular application see you next time
hello and welcome to this screencast on
the Aegean Sea and incident matrix of a
graph so I'm going to go straight ahead
and just draw a simple graph and this
graph has four vertices just to recall a
graph is simply a label these vertices a
as my ID a B C and D okay so if you
recall a graph is a set of vertices
which are joined by a set of edges so
each edge joins two vertices and I've
just made up this graph stuff my head
okay so straight away I'm going to stop
them to talk first about the adjacency
matrix an adjacency matrix has the same
number of rows and columns as the
disease in your grass and in this case
we have four vertices so we're gonna
have a four rows and four columns in the
adjacency matrix okay each row of the
adjacency matrix corresponds to one of
the vertices and likewise with the
columns so I'm just going to label
columns ABC rows ABCD and columns ABCD
as well okay so what do you Jason C
matrix is is if two vertices are
adjacent and by that I mean they're
connected with an edge for example here
a and B are adjacent because they're
connected by the edge a B we put a one
in you Jason C matrix corresponding to
the row of one a vertex and the column
of the other so in this case a B I'm
going to put a one in here okay in
addition to a B AC is also an edge so
we've got an edge doing an A and C
therefore a and C are also adjacent so
here's my row corresponding with the
vertex a so I also put a 1 next to AC
okay well any element corresponding to
AC okay finally D as you notice down
here a is not adjacent to D there's no
edge joining a or D so I'm gonna put a 0
okay in that element okay so I've done
the first row just to make things easy
you might notice but we could a vertex
is never adjacent to itself in this case
okay so we haven't got any edges looping
around back to D here so on the main
diagonal I'm going to just insert zeros
so a is not adjacent to a B is not
adjacent to B and so on and so forth
okay so let's move on to the next
element B okay well B is adjacent to a
so I put a 1 in here B is adjacent to
see someone put a 1 in here and finally
B is also adjacent to D so I'm going to
put a 1 in here it has the vertex B done
move on to the vertex C C is adjacent to
a so I'm going to put a 1 in here
C is also adjacent to B we've got a 1 in
here and finally C isn't adjacent today
there's no edge join it CMD sort of is 0
okay and lastly D the only L of the only
vertex sorry but D is adjacent to is B
so it's going to be all zeros apart from
the B column which is one okay and
that's the adjacency matrix for this
graph do I know to see Jason C matrix or
this one is symmetric now this is a good
general general rule for all adjacency
matrix because they're always square
you're also going to be symmetric
okay this maze onto the incidence matrix
now an incidence matrix is slightly
different we start by forming a matrix
with the same number of rows as we have
vertices okay so in this case I'm still
going to have four rows now with the
incidence matrix each column represents
an edge okay so we loop through where we
go through all the edges and we put a 1
next to the vertices which the edge
joins ok so in this case if I take the
edge a B I have an edge a B so going
down the column its edge joins a
to be and no other that's okay so in
this case this column defines edge a B
okay let's move on to AC I have the edge
AC here so in the next column have a 1x2
a oh one next to C and zeros with B and
D okay um for this edge here joining B
and C I have a 1 next to be a 1 next to
C and zeros X to a and D and finally
this this edge here B and D so this edge
joins B and D I have a 1 next to be a 1
next to D and zeros and the other two
elements okay and that's the instance
matrix for this graph here so instead of
matrix and doesn't always have to be
square it is square in this case because
because we have four edges but the thing
to remember our instance mate matrix is
each row represents a vertex and each
column represents an edge okay so I have
a look at a further example just kind of
scroll down a bit I'm going to define
another graph it's one slightly more
complicated so just try and make it a
bit more complicated than what we've
seen before I'm going to start off by
just drawing a cloud of vertices and
I'll join these words seize up put some
edges in a minute
so okay well we have here D E G okay so
let's just make up some edges Oh might
draw that edge again so a 2 fc2 fa2 see
why not a 2 D D 2 F I'm gonna have F to
G I'm not going to make this graph here
I'm going to make it unconnected so you
notice we have some vertices which
aren't connected to the main graph here
ok so we start with the
I see matrix so I have one two three
four five six seven so I'm gonna have
seven rows so seven rows and my AJ since
he can't matrix okay and I have seven
columns and we label the columns as well
okay so start with vertex a a is not
linked or not adjacent to B so I put a 0
there a is adjacent to see likewise it's
adjacent to D it's not - Jason - E is
adjacent to F and it's not adjacent to G
okay so that's the first row done and
also a is an adjacent to itself
okay second row B into Jace is not sorry
adjacent to a and also it's not adjacent
to itself and the only one B as adjacent
to its actually e so it's going to be
one in the e column and zeros elsewhere
okay a vertex C C is adjacent to a see
it's not adjacent to B and the only
other element
sorry vertex is adjacent to as F ignore
the others to zero okay D is adjacent to
a and F so a and F are going to be ones
and everything else is going to be zero
e that's meant to be an e down here just
tidied up a bit
e is only Jason to be a so going to have
one in a B column and zeros elsewhere F
is adjacent to see a D and G a C D and G
and we're going to zeros elsewhere and
finally we have G which is only adjacent
to F
and zeros elsewhere okay so that's the
adjacency matrix of this graph so it's a
7 by 7 matrix because there are 7
vertices and as you can see it is also
symmetric about the main diagonal
okay that's adjacency matrix what about
the instance matrix well remember the
incidence matrix has 7 well in this case
has 7 rows this number of this C's G and
each column is going to represent the
edges how many edges do we have here so
we have 1 2 3 4 5 6 7
oh this is also going to have 7 edges
just by coincidence okay so the first
edge let's say AC so I have an edge
between an A and C and F of zeroes in
all the other rows that's my first edge
I've got an edge joining AF so a and 0 0
0 0 1 corresponds to F and a 0 the
bottom a to D so for one next to a a
zero zero one next to D and all the
others are 0 ok C to F so I have a 1
next to c1 next to F I got zeros
elsewhere D to F okay so the one next to
D and it's about there 1 X 2 F and I've
zeros elsewhere at F to G so one next F
and G zeros elsewhere and finally B to e
so one next to B and one next to E and
zeros elsewhere okay so that's the
adjacency air sorry the incidence matrix
for that graph there and one final thing
about the incidence matrix is if we want
the degree of a vertex now a degree is a
number of edges which which intersect
vertex so in this case a has three edges
there there and there
that can be found by summing the row or
the incident matrix corresponding to
that vertex so in here with some row of
a we can see one plus one plus one is
three so the degree of vertex a will be
three okay and that's adjacency matrix
and instant matrix or the graph
welcome to the first in a series of
demonstrations on the graph data
structure what we're going to be
starting out with is a look at a graph
implementation specifically looking at a
graph implemented as an adjacency matrix
and trying to determine what kind of
graph that adjacency matrix represents
so we're going to draw out a graph
corresponding to this adjacency matrix
first thing that we're going to do is
we're going to try to figure out what
kind of graph we've got in the first
place now if we take a look at the
matrix the rows and columns are labeled
ABCD and E which means we have five
vertices which we're going to dry out
and label them a B C D and E now the
contents of the matrix itself are
numeric which means that there's going
to be some kind of weight associated
with the edges between each vertex now
if these have been boolean instead we
would say that it was an unweighted
graph but since we have numbers we're
going to associate those with the edges
the other thing that we can determine is
that by taking a look at the main
diagonal and the values on either side
the values on either side of the main
diagonal aren't identical so for example
evaluate Row one column two is not the
same as the value at Row two column one
what this means is the matrix is not
symmetric and therefore the graph is
bi-directional so we're going to have to
draw arrow heads as we go on each four
edges so let's start out with the first
row
and take a look at the edges that
originated a now there's two edges
originating at a one divert X B was
weight of three and another one to
vertex E with a weight of one now again
this is a directed graph so we're
drawing arrow heads on each edge as we
go there's only one edge originating a B
and that's an edge to D with wait to see
has three edges rigid a and they have
different weights we have one from C to
a with wait for one from C to B with
weight 2 and 1 from C to e with weight 5
there are two edges originating from d1
that goes to C with weight six and one
that goes to E with weight one
and then finally in the last row of our
matrix we have two edges originating at
row e1 back to a with weight one now
notice that we already have an edge from
A to E with weight one and the edge
going back will also have the same
weight so instead of drawing it in
another edge let's just draw in another
arrowhead indicating that this edge
happens to be bi-directional and the
other one is an edge from e to D with
weight three now although we already
have an edge from D to e we can't just
draw it in another arrowhead because
this new edge has a different weight so
I'll have to draw in another line with
an arrow going in the opposite direction
and label this one as having weight
three and that's our complete graph
based on that adjacency matrix for the
second demonstration we're going to take
a look at a different implementation of
a graph in this case a graph implemented
as an adjacency list there are six
vertices labeled a through F this will
start out by drawing our graph by
drawing those six vertices now we don't
know exactly where the best place to
draw these vertices are so we'll just
kind of take a guess and spread them
apart nicely so that we have lots room
to draw on edges the first item in our
adjacency list shows us all of the edges
originating at vertex a now a has an
edge going to see a soldier on that one
and in the absence of any evidence to
the contrary we're going to make this a
directed edge from A to C the second
item shows us the B has two edges
originating at B one to D and one to E
see has three edges one returning back
to a now in this case we don't have any
kinds weights so we'll just draw in an
arrow back to a 1/2 D and 1/2 e D has an
edge going to be well we already have an
edge from B to D so this is just now a
bi-directional edge and one back to C
again just another arrowhead on an
existing edge e has three edges one
returning back to be drawn another
arrowhead one back to C and one to F and
finally the last item in our Jason C
list shows us that there is an edge from
F returning back to e we take a careful
look at our graph we can see that all of
the edges that we've drawn in in fact
have arrowheads on both ends in other
words our graph is undirected now there
was no way for us to tell that from
actually looking at the original
adjacency list it's just something that
we had to discover as we went along
but that's our complete graph
all right in this video I just want to
talk a little bit about some graph
theory and just some basic terminology
and ideas they get used so definitely
not going to be a you know a complete
version of everything you need to know
but definitely some basic ideas so graph
theory got started by really kind of I
think really came about by Leonardo and
what he did is he solved a problem the
famous bridge of coningsburgh problem
and that kind of a put graph theory sort
of out there for people to start
thinking about and for a while graph
theories kind of kind of poo-pooed on it
was kind of considered I think sort of a
recreational branch of math not really a
ton of uses but uh definitely with the
advent here of computer science that's
changed all that graph theory gets used
all the time in computer science lots of
other places as well
definitely become a very hot area to
research and I like it just because the
problems are easy to understand you can
draw pictures and visualize I definitely
enjoy it but let's see so the definition
of a graph that we're going to use and
these vary again from person to person
things still aren't really set in stone
a lot of the notation and definitions
but for us a graph is going to be a
non-empty finite set of vertices some
people will let it be infinite with a
set of two elements subsets of V we call
the elements of V vertices and the
elements of a are called edges so that
sounds may be a little more confusing
that it is all a graph is it's just dots
and lines connecting that's all a graph
is okay so we talked about graph theory
we're not talking about y equals x
squared
just just points and lines connecting
them so we would say the vertex set V
for this
graphs maybe we'll call it G are just v1
v2 v3 v4 v5 and v6 and you can think
really you know maybe these are just six
people at a party and v1 knows v2 v3 v4
you can see that v5 only knows person v4
and v6 maybe that's what an edge
represents is if they know each other
okay you know and you can make the edges
represent whatever you want to so maybe
we'll just think about the edges as
meaning there's a connection between
them and they know each other so the
edge set that's just going to be all two
elements subsets and basically we just
list all the vertices that have an edge
between them so v1 and v2 v1 and v3 v1
and v4
let's see v4 is connected to V 5 and
then vertex V 5 is connected to V 6 and
I think that's everything we need you
know we don't need to list V 6 is
connected to V 5 for example it's just
redundant already so if I had you know
again basically just this set in this
set e again it's just basically telling
me all the information in this original
graph so I still know that a couple
things the cardinality the cardinality
of a graph just represents the number of
vertices
the notation I've seen is they'll put an
absolute value so the absolute value of
G the cardinality of G is just the
number of vertices which in this case is
six
let's see another thing that we often
talk about is the degree of a vertex so
for example the degree of vertex v1
which will abbreviate little deg v1 all
that tells you is the number of edges
coming out from vertex v1 so there's one
two three edges leaving v1 so we would
say the degree of vertex v1 is three
again so vertex v1 knows three other
people is all that says another kind of
convention for a typical graph we don't
let a vertex have a loop back to itself
okay I mean definitely that certainly
happens in a lot of applications but
when we lao graphs to have loops back to
themselves typically people will call
those multi graphs so multi grass have
loops regular graphs don't have loops so
pretend that loops not there and we just
got the original the original matrix
that we are the original graph we
started with a couple other things to
the way that you draw the graph is
irrelevant
so here's V one here's V two here's V
three here's V 4 V 5 down there I want
to make it too crazy v 6 you know they
don't have to be straight lines they can
be whatever they want so okay so V 1 is
still connected to V 2 V 1 should still
be connected to V 3 V 1 is still
connected to V 4
we'll have v4 still connected to v5 and
hey v5 is still connected to vertex v6
so all the original connections are
still preserved and there's sort of no
new connections in there that weren't
there before
so when you have a graph where basically
all the original information is
preserved the original connections
there's no new connections there's
nothing missing and again this is very
kind of loose definition but we would
say that the original graph and this new
graph are isomorphic and all that means
is from a graph theory point of view
they're one in the same they're exactly
the same graph okay so typically tribuna
will try to draw them as a you know in
the least confusing manner as possible
but definitely an important idea the way
that you draw the graph in general
doesn't matter let's talk about a couple
other ideas just a way to describe a
graph one way is with what's called an
adjacency list and I don't know how
useful these are I never really saw them
much but again I didn't take a
tremendous amount of graph theory so
that doesn't mean that they don't get
used all the time and I just haven't ran
into it but all an adjacency list is
exactly what you think so all we do is
just list vertex that our vertices that
are adjacent so for v1 it's adjacent to
v1
excuse me fee one's adjacent to v2 v3
and v4
so we'll list those v2 v3 v4 vertex V 2
is only adjacent to v1 v3 is only
connected to v1 v4 is connected to V 1
and V 5
v5 is connected to v4 and v6 and v6 is
connected to v5 and again it's just
another way of summarizing you know so
this is Jason C list this set V in the
set E and this graph again are telling
me all the exact same information
another way that I know gets used all
the time is instead of doing an
adjacency list we'll make what's called
an adjacency matrix okay so I'm going to
imagine v1 v2 v3 typically people won't
even write these but you know this is
what makes sense to me so a lot of times
I used to always stick them in there v1
v2 v3 v4 v5 v6 all we do is if there's a
loop if there's a connection from a
vertex to another vertex we'll put a 1
and if there's not we'll put a 0 so
since there's not a loop from v1 to v1
we'll put a 0 there but v1 is connected
to v2 v3 and v4 so V once connected to
v2 v3 and v4 but it's not connected to
v5 or v6 there's not an edge present
likewise v2 is only connected to v1 so
we'll put a 1 there and then we'll put
zeros everywhere else
let's see v3 is also only connected to V
ones we'll put a 1 there and zeros
everywhere else v4 is connected to v1
and also to v5 so we'll put ones there
zeros everywhere else v5 is connected to
v4 and v6 so put ones there zeroes
everywhere else
lastly v6 is only connected to v5 so
we'll put a one there
and zeros everywhere else so this is
nice because you can do math of major
Z's ok so definitely there's a lot of
study done with you know matrix
representations of graphs you can do
stuff with them two less things just
maybe two last ideas notice for any
vertex here if you you know so imagine
maybe these are islands now and there's
a little bridge connecting the islands
notice in this this graph if you ever
were to leave an island suppose I was at
Island v1 and I went to Island v4 the
only way I can get back to Island v1 is
the sort of backtrack you know I could
go all the way to v5 and v6 but
eventually to get back I have to take
you know the bridges back so there's no
loops or what are called circuits if
there are no loops or circuits we say
that this is an example of a what's
called a tree and the idea with trees is
you can always sort of rewrite them and
the reason why we call them trees is we
sort of can rewrite them you know so
here's v1 it's connected to V 2 V 3 V 4
V 4 is connected to V 5 and V five is
connected to V 6 so again these would be
isomorphic graphs but now it's kind of
if you flip it over and maybe it had
some more branches the idea that starts
to look like a tree trees get used all
the time for example you know imagine a
chess algorithm you know it's the first
move you know maybe you've got one two
three reasonable reasonable moves that
you're disposable at your disposal not
disposable at your disposal
you know and then maybe you know once
you consider this move maybe there's
only one logical move from that and then
from that there's only one logical move
so trees can help sort of represent sort
of searches you know a computer search
so definitely one place I know for sure
that they get studied again if a graph
so maybe this is a whole separate little
graph over here this graph we would say
has a circuit and the idea is a circuit
you know for example if I met this
vertex I can leave that vertex and still
manage to get back to it without really
ever backtracking through through an
edge or a vertice I don't have to visit
the same place twice as all it says ok
so this would be an example of a graph
that does have a circuit so graph theory
I think is really interesting you know
there's tons of open problems if you're
a budding math person out there and what
some challenging problems
there's definitely tons of open graph
theory problems that are very simple to
understand you know definitely you've
got to learn some of the techniques to
be able to attack things but a lot of it
is very sort of intuitive and I think
open you know sort of it's very user
friendly because what I'm trying to say
there's still some reasonable open
problems out there for people to tackle
for sure so if you are interested in
kind of getting your hands wet and doing
some harder problems
I say graph theory is a great place to
start maybe I can even post some open
questions so all right I hope this
little introduction makes some sense you
get nothing too heavy I definitely plan
on doing some more you know detailed
stuff but again hopefully this is a good
little warm-up and just a good little
intro to some of the ideas
friends welcome back in this tutorial we
will study about adjacency matrix of a
graph the adjacency matrix of a graph
having n vertices is a n cross n matrix
whose non diagonal entry add I have true
and giant column is the number of edges
joining vertex I and vertex g and
diagonals Aintree at i true and I'd
column is twice the number of loops at
what X I it would be more clear after
this example and the sensi matrix of
this graph is this matrix since there
are four vertices in this graph
therefore the adjacency matrix of this
graph is a 4 cross 4 matrix there is an
edge joining vertex 1 and vertex 2
therefore the entry at first row and
second column is 1 and entry add second
row and first column is also 1
there are two edges joining vertex 2 and
vertex 3 therefore the entry at second
row and third column is 2 similarly the
entry act third row at second column is
also 2 same way entry at first row and
fourth column is 1 and entry at 4th row
and first column is also 1 because there
is an edge joining vertex 1 and 4 decks
full and we add third row and fourth
column is 1 and anti add fourth row and
third column is also 1 because there is
an edge joining vertex 3 and vertex for
the diagonals and tree at second row and
second column is 2 because there is a
loop at vertex - thank you very much
hi I'm Jonah in this video I'm going to
explain two different ways to implement
a graph and then I'm going to explain
some of the pros and cons of each and
I'll show you how to implement both of
these methods in Python so the first way
to implement a graph is using an
adjacency list so let's look at this
undirected graph it has five vertices
and some edges connecting them an
adjacency list actually is a set of
adjacency lists because each list is
stored in its own vertex so a keeps its
own list of directly connected neighbors
other vertices that it has an edge to so
a has neighbors B C and E node B has
neighbors a and C as we can see here
this is going to be stored within each
node or each vertex is going to store
its own adjacency list now the other way
is using an adjacency matrix and the
adjacency matrix is a two dimensional
array and it basically stores a zero
where there is no edge or a one where
there is an edge from A to B we can see
there is an edge there or from A to C
there is an edge as you'd expect since
this is an undirected graph this is
going to be symmetrical across this
diagonal so from A to B is a 1 from B to
a is also going to be a 1 then the
adjacency matrix like I said it's a 2d
array and is stored in the graph object
so there's one adjacency matrix
centrally located in the graph object
how about if you have weighted edges on
an undirected graph well it's much
easier to implement weighted edges with
an adjacency matrix instead of putting a
one for edges where there is a
connection you just put the weight of
that edge so it's very easy to do that
you already have the cell you can put
instead of a 1 you can just put the
number of the cost or the distance or
weight of that edge in the cell so
extremely easy to implement using
adjacency matrix you can also implement
weighted edges in an adjacency list but
it's a little bit trickier so if you
have a directed graph again very easy to
do this using an adjacency list so here
we would have
a has one outbound edge to see so we
list under a only C as a neighbor that's
the only neighbor we can get to from a
so we're going to list all the outbound
edges for that vertex so C has edges to
B D and E and we list all the outbound
edges from C here in C's a Jason C list
you know Jason C matrix the same thing
we're basically going to put ones where
we have an edge outbound from that
vertex so we have the from on the left
and the two is div columns so which is
better well before we can answer that
question let's look at some other
characteristics of graphs a dense graph
is a graph where this is not absolute
value this is the number or count of
edges and the count of vertices so a
dense graph is a graph where you have
the number of edges is about equal to 2
the number vertices squared in other
words almost every vertex is connected
to every other vertex in the graph so
you get a really large number of edges
relative to the number of vertices a
sparse graph is a graph where E is about
equal to V which is what we have here in
this picture so there are a lot of
possible edges that are not actually
there another thing we're going to look
at before we answer the question which
is better adjacency matrix takes up V
squared space right this is a big factor
the amount of space required for this
adjacency matrix is going to be V
squared or number of vertices squared
regardless of how dense the graph is so
very very sparse graph you still are
going to take up the same amount of
space so for our little 5x5 you know we
only have 5 vertices in this example who
cares right but if you can picture a
graph that has ten thousand or a hundred
thousand vertices that's going to take a
project gigantic amount of storage space
so with those things in mind an
adjacency list is better in cases where
you have a sparse graph because it's
going to be faster and it uses less
space but the disadvantage of an
adjacency list this is slower for very
dense graphs large dense graphs is going
to be slower and the adjacency matrix is
going to be better for dense graphs
it's going to be faster and the space
complexity is the same as it would be
thrown on dense graph and another
advantage is that is simpler to
implement for weighted edges but the
disadvantage of this adjacency matrix is
that it uses more space and especially
for large sparse graphs or perhaps to
have a lot of vertices but relatively
few edges the adjacency matrix is not a
good choice so depending on the nature
of your graph you have to decide which
one of these is a better implementation
to go with so I'll give a quick
explanation of the adjacency list
version of the graph implementation
first we have our vertex class which
basically has two variables as a name
and it has a neighbors list and as we
add neighbors we see we have an add
neighbor function that basically is just
appending that vertex to the list and
then sorting it in the graph itself we
only have one graph variable which is a
dictionary of vertices so that we can
find any vertex by its name so when we
add a vertex we basically just check
that that object that you passed in
actually is a vertex object and then it
doesn't exist in the vertices dictionary
yet and if those two conditions are met
then it goes in as the vertex to the
vertices dictionary and when you try to
add an edge with vertices U and V then
it's first going to check if u and V are
both actually in this vertices
dictionary before adds it so if there's
an invalid vertex and it's not going to
be able to add that edge then we iterate
through the vertices and we locate
vertex U and vertex V and we add the
other to its neighbors and that's pretty
much it then I have a print graph
function down here at the bottom so this
is a pretty straightforward
implementation of graph I think it's a
little bit simpler so I usually favor
this over the matrix version although
the matrix version is not too hard and
then down below I have some test code
that we can test our our code up here so
implementing a graph using an adjacency
matrix this version is actually going to
support both weighted and unweighted
edges for undirected graphs and you have
to do slight modifications to support
directed graphs
so our vertex class you'll notice only
has one variable and that's just the
name of the vertex we don't need
adjacency this stored locally in the
vertex that doesn't happen here they're
stored centrally under the graph so we
have the same vertices dictionary so
that we can locate any vertex given its
name we also have this edges list which
is going to be our two-dimensional array
of edges that's the matrix and then we
have edge indices so that we can quickly
locate the index of any edge given its
name so when we add a vertex first we're
gonna check if it's actually vertex and
it is not in the vertices list already
and if not we add to the dictionary and
then our for loop here and the statement
right after that basically we need to
add another row and column of all zeros
to our edges matrix so we're going to do
that here we're add another row of zeros
and in another column of zeros on to
that edges matrix because we have mapped
any edges to this new vertex yet but we
need to add it to this matrix with all
zeros and lastly we add the index for
this vertex name into our edge indices
dictionary so to add an edge we're first
going to verify that both vertices U and
V are in our vertices dictionary and if
they both are then recall that this
edges matrix is symmetrical along the
diagonal so we want to add this edge we
want to enter the weight in the matrix
in both the top right bar in the bottom
left part so we're going to add the edge
to both u comma V and to V comma u we'll
set the edge weight and that's it for
add edge if we achieve that and we'll
return true and if not the return false
then lastly I have a pretty pretty
simple print graph function that prints
a pretty crudely formatted edges matrix
for us so you can see what that looks
like and our interface is exactly the
same as for the adjacency list version I
have exactly the same test code down
here below where we we set up a graph we
add some vertices and some edges to it
and we print it out I posted all of my
Python code here in my github site and
you can download that pin you also have
access to the PowerPoint file posted
here Omega up site so I hope this video
was helpful for you if you liked it
please click like and subscribe to my
channel I'm Joe James thanks for
watching
