alright so again good afternoon and
welcome to the second part of the second
mini course which will focus on
introduction of subspace segmentation
problem first I'm going to state what
the problem is I'm going to spend a
little bit time on providing a
mathematical proof that motion
segmentation problem is is actually a
special case of subspace segmentation
problem tomorrow you can expect that
some of the presenters will provide
experimental results on the air on a
data set that they come under the title
for face recognition or for motion
segmentation so so you can get a head
start with the tomorrow's presentation
with this after them going to talk about
principal component analysis principal
component analysis is used to reduce
dimensionality of data set for example
instead of working even very high
dimension data set first you can project
your data in a lower dimensional space
and then you can do all the analysis in
the moment fashion space I'm going to
show that with principal component
analysis we do nothing but least square
estimation on least square approximation
of a subspace so and I'm going to try to
link it to the singular value
decomposition analysis attack the bar
just presented and then I hope it will
be linked to the use of single well so
I'm going to provide another route
instead of just single decomposition I
will try to explain it to another
approach which uses the covariance
matrix of your denim attics so that's
also an approach as I said spec to the
class right like magic it works so it is
a very modern a clustering technique
that some of the presenters tomorrow
will be using I'm expecting so here in
many engineering and in many engineering
science and mathematics problems actual
data leaves the union of low-dimensional
subspaces I'm expecting that you know
what union of subspace means now from
the first part so for example face face
facial expression recognition
problem we can't consider so to get
those faces we have six phases of the
same person right and the same person
the same facial expression under
different illumination conditions of
different lighting conditions we can
show that all of those six phases
actually lies in a multinational
subspace approximately lies in a non
dimensional subspace of a very high
dimensional space another example will
be motion segmentation I'm not talking
about it as well most of the actually
this area of future subspace clustering
has attracted a lot of interest from
computer science mathematics and
engineering and most of the notable
research has been done in recent years
so this is a very finely ailea
especially if you're a PhD she looking
for a dissertation I can tell you that
this is a very fun area to work with and
as this as other possible dissertation
area here is the face you can issue
problem assume that we have this image
one face of a person assume that is like
25-30 pizza that means that are like 600
pixels here let's say in other words we
can take the first image the first phase
and you can convert it to x 600 x 1
vector right assume that this vector is
used to represent that image similarly
the second leg to represent the second
phase third fourth fifth and sixth so
that means each phase is nothing but a
data point in a 600 dimensional space
right in our six hundred and we can
experimentally show that those vector
goes data point six data points
approximately lie in a mind dimensional
subspace of our 600 so those fake legs
are face a face recognition problem is
nothing but in this I mean I'm kind of
exaggerating things but it is kind of
you know finding this for my
international subspace out of our 600
right
so that's the subspace segmentation from
so what is our problem here is the
problem we have assume that getting our
three we have a bunch of data points the
special thing about this is that those
data points are not random data points
some of them for example here comes from
what a two dimensional subspace of our
three some of them comes from one
dimensional subspace of our three
another view look at this be a bunch of
data and we our data lives in our three
that means all the data points are in
our three but some of those data points
come from a plane which is what two
dimensional subspace of our three some
of those data points comes from a line
which is what the national subspace of
our three and some of them comes from
another line which is also another one
dimensional subspace of what are three
in fact those all of those data points
comes from union of s1 s2 s3 isn't it so
the problem becomes what the problem is
given data so basically in this case we
have data points that comes from reading
of three subspaces so that's all what we
know we don't know those subspaces what
all we know is that we have data points
somehow they comes from reading of three
substrate greening of subspaces what are
the possible problems that we need to
solve first pletely determine how many
subspaces right so subspace clustering
problem deals with given the data points
without knowing anything about subspaces
all you know is that they come from enid
of certain subspaces the first thing
that you need to answer is what are the
number of subspaces have a sub spaces
that we have second problem is how do we
determine each sub space and dirt after
we determine the subspaces how do we
cluster the data for example all those
data points come from the same subspace
how I
Master them how could I say that these
are the data point that comes from the
same subspace how do I say that these
are the other data points that comes
from the same subspace and and these are
the other data pointers confirm so
subspace class in problem you are giving
it data set that comes from you know
subspaces that's all what you know then
you try to determine the number of
subspaces and then you try to determine
what those sub spaces are and then you
want to go back and cluster the data
points or group the data points that
blown to the same subspace that clear so
here is a little bit more formal
definition or the statement of the
problem here is the data set we are
giving a data set that's it we are
giving all the data set what we know
about this data set is that they are
drawn from a union of subspaces so here
a bunch of data points all you know is
they are coming from a union of certain
subspace then we don't know low
subspaces so our problem is to find a
model for this Union and then use that
model go back and classify our data into
clusters that is subspace segmentation
problem and here is more mathematical
definition and it uses Hilbert and
Banach space concepts let me discuss in
the first part so what we have is assume
that we are in a panic or hilbert space
be ok so we are dealing with a bonnet or
Hilbert space V and we have added
subspaces of this Banach space b or
hilbert space v
okay so what the assume is we are
working on my next space or invest base
B and we have end sub spaces of this
Banach space and a suit that we are
given and data points w1 w2 all the way
to WF n we are given n data points and
all what we know is that those data
points are drawn from union of and union
off some subspaces so the problem is how
do we determine the number of subspace
then how do we determine its subspace
determining a subspace means finding an
orthonormal basis for the subspace and
then once we determine the subspaces how
do we group the data points that loan to
the same subspace into the same cluster
so that is more formal definition of or
statement of the problem so what we have
we have different approaches to solve
this problem first of all is the problem
clear I want to make sure that the
problem is clear to do to the audience
are there any questions about the
problem yes what kind of conditions do
we have they guarantee that this should
cost during the subspaces as a
to something that maybe doesn't include
zero like some some plane that's away
from the origin Oh approach is that I
mean it depends on the approach right i
mean the data the assumption is that
your data comes from union of subspaces
of course that will be noise for example
your data is going to deviate from that
subspace so algorithms that are down
below should be handled the noise or
there will be some hardliners for
example certain points will go really
far far away from what from your
subspace but the algorithms should be
also able to take care of those kind of
cases so so it transform algorithm to
taking care but there are certain cases
I mean the day that will be so deviated
from a subspace it is no longer subspace
clustering problem so then you can
assume the data leaves knit one big
springs and then you can for examples
pca and things like that for like a
general class and problem is that answer
to a question okay so some of the
approaches that i categorize them as
like sparsely methods this is very
recent and tomorrow we will have dr.
Renee doll he is going to our first
keynote speaker he's going to talk about
sparse than algebraic methods so the
first keynote speaker will give and
overly off and actually that a doctor in
every now is the is work on something
called generalized principal component
analysis which is algebraic technique
and I am assuming that he's going to
talk about it and also recently we have
recent techniques like more rank
approximations who have to dr. V Donnell
and also we're going to have another
presented from China he's going to talk
about more rank approximations for some
space cluster then we will have
iterative and statistical methods actual
our second keynote speaker tomorrow
background really is going to mainly
talk about those methods that's what I'm
assuming and there are of course other
methods and the invited speakers I'm
expecting that they're going to provide
different views of different approaches
so by the end of tomorrow I expect that
you understand what subspace clustering
problem is and you know what is the
state of the art
in subspace clustering okay so first I'm
going to now introduce or provide
mathematical proof that motion
segmentation is a subspace segmentation
problem by motion segmentation what I
mean is motion segmentation problem is
identifying independently moving rigid
objects in the video so we are giving a
video file what's the video one everyday
file is nothing but bunch of frames they
can consequently right for example you
may have like hundreds frames altogether
if you play them back to back you have a
video right so in suit that we have two
cars this is our first frame and we have
two cars and in each car we have some
feature points when I say featured forms
it may be very clear to some computer
scientist it may not be clear to
mathematicians but pigeon point is
nothing but for example a corner might
be a featured point on the car okay
maybe the door might be featured point
on the car assume that there are certain
feature points that we can extract on
those rigid bodies okay now this is
second frame third frame for frame so
watch the segmentation simply deals with
determining the number of rigid objects
in a video file number of moving rigid
objects on a video file okay so that's
what you're going to show hmm I had some
animations here but I think it's messed
up so here is the car when I say for
example I have four feature points on
the car right look at this this x1 y1
one means x and y assume that the camera
is really far far away from the car so
it seemed that you know we are looking
from the sky or from really far away so
everything is in 2d so now x1 y1 what
means the coordinates x and y
coordinates of the first feature point
in frame number 1 x 2 y 2 11 means the x
and y coordinates of the second feature
point in frame 1 similarly the x and y
coordinates of the fourth feature point
in friend number one ranked number two
car moved here so this feature point
move from here to here right so this x1
y1 two names XM white fulness of the
first feature point in frame 2 similarly
x and y coordinates of the fourth
feature point in frame too and we move a
lot and then assume that we have f
frames like 200 frames on f frames and
this feature point move from here here
all the way here x1 y1 f means x and y
coordinates of the future point one in
frame f that clear so these are the just
representation of the coordinates so
what does this vector representing x 1 y
1 1 x1 y1 to all the way x1 y1 f I want
an answer from the audience what does
this vector represents if they presented
trajectory exactly so basically it
represents the trajectory of what first
featured point or a pact right so this
is nothing but the pad or trajectory of
the first feature point across all the
frames and similarly what does this
represent this represents the trajectory
of the second future point across all
what frames and we have dots right so
what am I going to show what I'm going
to show is that do you see the dimension
of this vector what is the dimension of
this vector or where does it leave it
leaves in r2f right because we have x1
y1 x and we have x1 y1 f x that means
this data is actually this is one data
point in our to F what we are going to
show that all the treasure
therese of the old featured points on
the same rigid body why in a four
dimensional subspace of r2f so instead
of three clustering on our 2f i am going
to determine those four dimensional sub
spaces so all the future points in the
first car are going to lie in a 14
dimensional subspace and all the
features on the other car or the
trajectories of the futures on the
second car rely on another four
dimensional subspace so motion
segmentation problem became what a
subspace segmentation fault is it clear
so now I'm going to show really this is
the case and I'm going to show is since
it is very difficult to write I will go
little with some animations but you can
stop me and ask me questions if they are
not if the sort of the points are not
clear so assume that we have a frame
which is called world Frank capital z
capital X captain why this is the world
frame wall frame is what that is the
frame that does not change that's our
reference point ok so we start with a
word frame anything is going to be with
respect to what this won't bring any
motion will be with respect to what this
more prey ok initially it shouldn't be a
car car and this is we have work frame
and you have an object frame but object
frame will change as the car moves
object frame moves with the car but the
world's rain stays stupid right so we
have to coordinate systems warframe that
doesn't change and the object frame
that's going to be moving with the car
and assume that this is once featured
point on the car and also assume that
little are one little are two little are
three are the basis vectors for this
world frame
now what happens if the car rotates
can't rotates does the world frame
change no world frames stay still but as
you see the object frame X little lower
case explore caves in lower case Y just
rotated right so this is basically what
happened to our car p is p was here now
it moved there now my question is this
with respect to object frame with let's
take the object frame does or does the
coordinate or do the coordinates of this
feature point does that do they change
as the object rotates for example this
point p with respect object frame and
the car rotated the speed they speak the
object frame does it change how many of
you say changes
right how's my change so the P that the
point p which they expect Arctic frame
does might change it is still for
example here it was this much distance
from object frame it is still the same
distance from the object well this is
our three because this much distance
from our three it's still the same
distance so it is the view of it so I
just moved it here let's look at this
let's forget the point P let's consider
just this point what is the coordinates
of this point with respect to object
frame the coordinates of this point with
respect the object frame will be 100 do
you agree with them but the coordinates
of this point with respect the world
frame will be one simply are one isn't
it the coordinates of this point with
respect object frame is what 011 but
with respect the world frame it is what
are 2 similarly the coordinates of this
point with respect to out geek frame
will be 001 but with less take the world
frame is what are 3 will agree with that
then what can I say about this point
this point let's say with respect the
optic frame let's say it is a be a be be
PCP and with respect the world frame it
is nothing but AP times r1 plus B P
times r2 plus CP times r3 we agree with
them okay so p0 a be a PvP CP is the
coordinates of this point with respect
to object frame and pw is the
coordinates of this point with respect
the world frame ok that is physically
what it is
so what can I do can I rewrite this as a
matrix whose columns are r1 r2 r3 and
point p dot p 0 which is this vector
this statement is equivalent to this
right and if you look at this matrix it
is nothing but a rotation matrix so i
can say corn is so filled with respect
the work frame is a rotated version of
the coordinates of the point with
respect object ring ok I want to give
you like 10 seconds so because I'm gonna
build on this
alright
so this slide simply says what I
explained I'm just going to skip it but
whenever you have time after we put on
the internet you can you know read it
and then it's exactly what I am saying
now it soon that the optic does not only
rotate but it also translate so what
happens to coordinate of this point P
betrays take the world ring before
translation it was just rotation it was
rotation of the point into aspect object
frame right now we will all say what a
translational turn so P with respect the
world frame is a rotation matrix times P
with respect the object frame plus TW TW
is the coordinate of the center of the
object with respect one world frame
thank you to
now assume that we have you know an
image plane that's the camera plane what
does it means is that your camera is
really far far far far away and the
optical zoom of the you know the the
axis of your camera is your z-axis okay
and see this is X this is y this is e
your camera exit is also in this
connection assume that the this is
Freight number K so we have one two
three four javiel in frame number K and
in Frank number k I had a future point p
0 p 0 is the cord ends of this pigeon
point with respect the object frame
which is a be vp hcv right this never
changes this coordinate never changes
when i go to for example later the
second frame this coordinate will be
still the same because the coordinates
with respect object frame of a feature
point does not change from one frame to
another one only with respect the world
frame changes ok so r 1 r 2 r 3 k are
the basis vectors for the object frame
in frame number k so what i am doing is
I am going to project because when I
take an image with a camera what happens
I just project that feature point on the
image exit right or image plane and here
is the projection of this point in the
image plane let's call it XP YP chain
that means x and y coordinates of the
future point p in frame number check
okay
and of course this is pw t w that means
the coordinates of future point P with
respect to work frame for frame number
what okay okay so let's check this do we
know that pw k is equal to a rotation
matrix p 0 plus a translational vector
so this is what you know right and and
the coordinates of this sky this point
with respect the world frame will have
actually three components XYZ right that
means X Y Z with respect the word frame
is nothing but this matrix multiplied by
this and then then another vector x y&amp;z
coordinates of what the the center of
the object frame the right but since we
assume that the camera axis is in line
with the z-axis I am NOT interested in
the Z component so I only considered x
and y coordinates in other words instead
of having a three-dimensional are one I
truncate the last element of our one and
I obtain r 1 tilde so r 1 tilde is the
same as our one just you know you
truncate the third element of our one
okay so basically XP YP k is nothing but
x and y coordinates of this feature
point p with respect to work print that
clear okay good so here's the first
thing now in this this was frame k now
i'm in frame k plus 1 whatever sin frame
k plus 1 does the coordinates of this
widget point p with respect to object
frame does it change it does not right
with respect object frame it was ABC it
is still ABC but what happened to do to
to to r 1 r 2 r
we have different basis vectors ok
because object rotates and when I
project this feature point to the image
plane now I have XP YP I say k plus 1
that means x and y coordinates of this
Richard point with respect the wall
frame in frame number k plus 1 similarly
now the future point is here I project
it and I have that so what does tragic
that of features point means on the
image plane isn't it just this one right
for example the object was here now the
object is here mount objects in here
when I say that rejected off a future
point on the image plane it is nothing
but you know linking those points
together so now here is my data matrix
for motion segmentation let's forget
this what is the first column first
column it is is the trajectory of the
first feature point across all the
frames x and y coordinates of the first
feature point in the first frame all the
way x and y coordinate so first feature
poet in frame number left for example
this one x and y coordinates of the
feature number s in your first frame and
the same thing x and y course of future
as in what frame number n so each column
is nothing but trajectory of one feature
point for example if this is our car we
have n feature points and the track all
those and future points across how many
frames f frames is it clear so far ok
now let's take this trajectory ok let's
take this trajectory let's go back to
this we know that XP YP k is a b c and
linear combinations of our 1 tilde are 2
tilde are three tilde and then what t
tilde that right and we know that a
bc they do not change for the same
feature point all right now let's go
back to that here consider this this
feature point x and y-coordinate of the
future point as in frame number one will
be a as x this BS times this CS times
only the first two and then this first
two similarly if i say x s ys in frame
number two the coefficients a b c they
don't change the only thing that changes
is the vectors are 1 tilde instead of r
1 tilde r 2 tilde are three days i will
have different r1 r2 and r3 basically
trajectory as can be written linear
combination of one two three and four
vectors so what does it mean it means
that that trajectory has is little
linear combination of three vectors and
if i take another feature point another
feature point for example i take this
feature point this will be this field is
also linear combination of what leave
another linear combination of the same
basis vectors instead of asp SCSI will
have a2 b2 c2 for example right but the
feature vectors i'm sorry the basis
vectors will be the same for all the
future points that are coming from the
same rigid object in other words all the
trajectories that belong to the featured
points or the same rigid body leaves the
four dimensional subspace of our to
death because we can represent each
trajectory as linear combination of four
vectors in our freedom is it clear
yes so for this you knew before you
started this analysis that you had full
essentially four dimensions that you're
going to be actually we didn't I mean
the first mathematical proof that was
provided they they derive this so they
didn't know but they mathematically dry
they mathematically proved that you know
that it comes from four dimensional
subspace so I start with no assumption
that it comes from four dimensions of
space I don't have that assumption but
finally I have that conclusion yes
well that's a good question in this in
this in this analysis we assume that we
can track all the future points in every
frame okay let's say that there are
certain future points that you can laugh
track okay they are called missing data
points for example some of those
mattresses let's say this your data
metrics right according to what you are
saying sometimes you may not have
certain entries you may not know so
subspace clustering algorithm some
algorithms can deal with that they can
say hey I have missing data points but I
can still go subspace cluster sometimes
we may have outliers that means while I
was taking one feature points from one
frame to another one I did something
wrong and instead of get real
coordinates I did a mistake and now that
feature present a off then let's go out
like and in that case against subspace
clustering algorithm should be able to
handle those cases or sometimes due to
measurement error instead of real XY
coordinates I may have an order and in
that case this will be noisy matrix and
that should be still there via Twitter
on subspace class about it and why am i
right back a little be an expert sir
okay yes
to me
too many frames okay exactly this
doesn't matter the number of frames as
long as you can track the same feature
across all the frames it doesn't matter
but of course if you have too many
frames one feature will not exist in you
know so the assumption is all the future
points or a future point can be tracked
across all those frames yes provided
that you're viewing for instance house
I'll go to distinguish between having
like glossy multiple cars having the
same physical features movement
altogether so so it does not matter you
have multiple cars but that's the
feature extraction and feature tracking
is a different problem so we assume that
we don't have that problem so we assume
that we can detect features and we can
track the features across the frames
that's our assumption but otherwise
that's another computer vision problem
which has nothing to do itself is
clustering for example there are things
like corner Morse measures so that's a
good feature to track but our assumption
is these are given to you you have the
features and you can track them
any other questions yes all the features
are off same man all the features are of
the same length actually it makes a not
much sense in this context because all
the interest is the coordinates of the
future points I have XYZ coordinates of
the switching point here and now the
switcher point is here in this other XYZ
coordinates if I may say the lengths i
know all the pictures it may be like an
early or finally on the plane so
featured points1 feature point exists
across all frames and somehow you can
track this feature point from one frame
to another frame in terms of coordinates
of the future point yes
don't think about the perspective
formation prospective information so
deformation camera lens well in this
assumption we have a fine projection
model in other words camera is really
far far away so and yeah that we have
that assumption thank youuu okay look i
hope this problem is clear because in
the talks tomorrow they may not have
time to go in this death to the
description of the problem okay so now
i'm going to jump to another important
topic principal component analysis iming
of you have used pca before okay yeah so
PCA is is a very fundamental tool that
you know is commonly using data
clustering so the goal of PCA is to
reduce dimension of a data set with
minimal loss of information so you are
in a very high dimension space but you
don't want to work in that hydrogen
because of computational complex these
or you know the the cost of computation
and for many reasons you want are going
to load the management space but you
don't want to lose a lot of information
when you project your data from a
high-dimensional space tail or domestic
venues for example if two points we are
separated in high dimension you still
want them to be separated in the lower
dimension you don't want to lose that
information use the phone information so
basically you go from high dimensional
space to elude the national space
without losing much push I don't do
something but you don't want to lose
much you still want to be able to
separate data in the lower dimension is
it yeah so we project the feature space
on to a smaller subspace that represent
a toga the plot the data well means if
the points were separated in the high
dimension they are still separated to
some extent to an acceptable extent that
they are still separated in the
in the whole dimension so actually so
what we are trying to do is we are
trying to search for a subspace that
will maximize the variance of the
projected points so we project them in a
lowest mass appeal but you want to
maximize the variance of beta in that
subspace we can project at the beta sub
spaces right but beach for me a config
we are going to pick the one that will
keep the variance of the data maximum in
that subspace this is a fuel problem of
the linear least squares fitting I am
sure some of you are familiar with it by
basically finding a sub space that is
the the best in list square
approximation is actually that subspace
that we are looking forward okay and
Rico okay so let me go pca i will show
that can be done by SVD of a data matrix
or via an icon value decomposition of
data covariance matrix so I'm going to
talk about but I want to give you first
and understand look at look at this
these are my data points in our two I
don't want to work it out so I want
working on one what am I going to do I'm
going to measure subspace to that right
but beach subspace the subspace that
will when I project it onto this
subspace we see the separation between
this two point these two point is to
point this took what they are high so it
is not any line but a line that is going
to be the best match so that the
variance is still high and that best
match happens to be the least square
approximation in other words the square
distance is the distance here this point
to the projected point this point of the
projected point if you get the square of
the square of all those distances they
are maximized if you take any other one
dimensional space and if you find the
square of those distances it's going to
be less than this or if you think in our
to as you see these are also in r3 these
are my points so I want to match it
playing to those points but when I miss
the plane I don't match any plane I
wanted to play that when I projected
those date on the plane the variance of
that will be maximum or in the least
square approximation sense the squared
distances this square of the on the sum
of the square of the distances is gonna
be one maximum in this case so basically
PCA finds and subspace that match data
in a lower dimension but the separation
of data is maximum or the variance of
theta is maximum in that subscript okay
so what are we trying to do okay I say
another view assume that this is our
data metrics what does that mean each
column is a data point for you in other
words we are working in an n-dimensional
space we have P data points want to all
the way to pee and each data point is in
on em let's say okay they're clear each
column is a data point so my data matrix
is n by P i have p data points and each
data point is in RN okay but what I know
is that even though each data point is
in our end actually there is some
redundancy because I know that some of
those components are somehow related
okay so I don't want to keep the related
conference I want to say hey I don't
meet the related things let me get rid
of the related things I just want to
have unrelated things right so basically
from these bad legs I want to go to
another matrix w hat or w bar okay and
which is still consisting of people and
so instead of this x1 x2 all the way to
xn my first data point I want to convert
my first data point to another data y 1
y 2 y que but this time this data point
lives in bed in R K and K is less than n
so instead of working in our end now I'm
going to work in R K so the problem
became what having these data matrix n
by P and converting it into another data
matrix K Y P and K
less than n so I'm going to deal with
data clustering instead of our end now
I'm gonna deal by data clustering in
there in RK right so we don't know how
to do it but that's the problem I mean
that's the thing that I want to do I
don't want to work by N by P our work
with k by P and K is less than n okay so
i want to get peed off the related
things within my data so that i did get
rid of redundancy in my data and he is
there how we do it with pca dr. Bob
describe what PCA what singular value
decomposition is right so we have
datamatics and might be this is my data
metrics nyp this is the data metrics so
any matrix regardless of it is rank
regardless of invertible or not any data
that is can be decomposed into three
matrices u sigma and v transpose so
assume that this is my data matrix what
i do i take my data metrics and do SVD
single all decomposition and if the rank
of the matrix is our we will have our
independent columns of you okay so
assume that I want to project into K
dimension I want to project a dimension
what'll be the best subspace what do I
mean by best something I mean what will
be a basis for the best up space isn't
it because a subspace is defined by a
basis so determining the best subspace
means determining a basis for the best
up space here it is you are you to UK in
other words the eigenvalues after I ghen
the first k principal eigenvectors of w
will be a basis for the best sub space
that is or that in the least square
approximation sauce that's it
that's my subspace all you need to do
get the data metrics do SVD you Sigma V
transpose and then get the first k
principal eigenvectors that's going to
be a basis for the best of space but of
course finding the best subspace is not
the whole story after you find the best
subspace you read the project onto that
subspace right and dr. bharat showed you
that a projection is so basically what i
do i project my data k dimension
subspace spent by first k principal I
know makers and if you recall from our
earlier lecture projection of a data
matrix on a subspace is nothing but you
you've transpose W and your w bar is
going to be on with this we get this U
is k by P dimensions that right yeah I'm
sorry it is and by let's see you is and
by K dimensional right what does you
transpose u transpose this k x and the
national and w @ n times P that means u
transpose ee is k times p that is your w
bar so you will replace your w your
original data matrix with this data
matrix if you want to have more deeper
understanding this is nothing but the
coordinates with respect to new basis
this is your basis for the subspace and
this is each column of this matrix is
going to be the coordinates with respect
to this new basis of your original data
and since we have K basis vectors your
data will be K dimensional
so I repeat I know or maybe i'm working
too much and just trying to make sure we
have w and x p and i get the single roll
the composition i do single value
decomposition then I get the first k
principle I convectors right there okay
and then i project my data matrix onto
the subspace fell by those eigenvectors
and then i get the coordinates or the
the new coordinates of each data point
in the new basis and this is nothing but
u tilde transpose W and W was n by P now
w bar is going to be K times ok here is
an example well even before I mean okay
so let me go back a little bit after I
explained those already but I want to
give you an idea about what other that
mean assume that this son team centered
this ex my ex is centimeters and why is
inches in other words i have two routes
with one ruler which is centimeter based
and made in my height then i'm taking
the second ruler which is inch base
inches based and I amazing my height
again okay and this point is my height
as in centimeters and inches okay then i
get a phony and then i do exactly the
same thing i have two rulers i measure
his height in centimeters and then his
eyes in inches here is that data point
there and similarly these are one two
three seven people we measure their
height in centimeters and inches in fact
this is supposed to be linear right
because I mean Santa Mira conversion
from Sunday meter 1 inches always 2.42
points54 centimeters it's supposed to be
linear but during the invasion
whatever's or due to noise it is not but
i know that this data is really curly
right i mean i don't want a keyboard
inches and centimeters
makes no sense I want to get rid off
instead of having two data points 1
centimeter 1 inches I want to get rid of
that and I represent each data with a
single number in other words I want to
reduce my dimension instead of working
in our two I want to work in on one okay
so what can I do I'm going to find a
vector you saw that let me project those
data points in that direction the
variance will be as much as possible
here it is assume that C we have this
and we have that if I project all of my
data in the blue vector the separation
between the points will be this much
right what what if I I bet if I project
i'm in the red vector as you see the
data will not be separated there is this
much right so you don't want to project
your data on the raft you want to
project your data on the book which will
maximize the separation in fact our
problem is how do you find the direction
of you that is what principal component
analysis deals with so we want to
determine you so that then project in
the direction of view data will be as
separate as possible yeah and and I'll
let me go it turns out that it is
actually our datamatics this is inches
centimeters I know they don't have
people like them in those very short for
me
it's okay so this is the first data
point 10 inches 28 centimeters 12 inches
19 son and so on so we have one to
actually six data points okay so I want
to convert this 2 by 6 matrix 2 1 by 6
matrix because I know that the data it
is correlated instead of representing by
two numbers I want to represent it by
100 and so on so that is now banette
principal component analysis how am I
gonna do it by I can do it in different
ways let's do it singular value
decomposition I just explained right
it's singular value decomposition all
you need to do is have a video of your
data metrics and since you want to
convert it from two dimension to
one-dimensional how many principal I
connectors that I might have only one
right only one because we are if we want
to project into the cave national space
we have K Prince verizon vectors by the
regular project into one dimension space
i will only one single I don't Tector in
this case yeah it is but well before I
take anything I want to normalize it
normalization means having zero means
and unit variance of data okay basically
instead of 10 28 what I do first I get
the average of all those numbers I get
the average of all those numbers and i
subtract the average from each one of
them that's going to convert my data to
zero mean and then I do something else
and also I've been zero absolutely unit
variance but I'm just skipping this for
the sake of time so assume that this
data is converted first or normalized
first two so that each column I'm sorry
each as you see each row is unit the
average of each rob is going to what 0
and the variance of each job is what one
then I do SVD my data messages to buy
six you Sigma V transpose my you will be
actually two vectors but which one am I
going to take I'm going to take the
first one that corresponds to the
highest ideal involving that means the
eigenvector that corresponds to the
highest eigen value which is this one
right that is mine this is a basis for a
line it's a basis for a line that's
going to be the best match for my
subspace do you see that this is just a
45-degree angle right so that's just a
line so then what do I do this is my new
tilde and then all I have to do is you
till the transpose W and bump here it is
so instead of working with 2 by 6 matrix
I can work with this matrix in
formulation yes
take the variations you me that same
okay let's let me show right here
because I do it also another way which
will which would answer your question it
is the problem now i'm going to do not
with SPD what I'm going to do it with
what covariance matrix okay which will
have more explicit analysis so these are
my data points x 12 x 6 actually here
are my data but after i calculate see I
first compute what mean of those six
data 10 12 15 20 22 26 I calculate the
mean of it and subtract that mean from
each data point that is the mean right
but for Damian's after that assuming
that now my data is 0 mean I calculate
the variance but I don't work with the
original data anymore I work with what
the the normalize in terms of me Dana
and then I get the variance of this data
by getting the square of each number
adding them up and whiting by six and
then replacing each data point by the
data point divided by the square root of
the variance exactly I've been expected
to see t-virus right right of course you
do that yes yes I know me station so I
need to be really careful I know okay so
so that's the pre-processing so we first
normalize our data okay once I realize
my data my goal is what my goal is
you so I want to maximize the
separations i right I want to maximize
the separation you can data points but
i'll try normalize my data will be will
not be like this my data will be somehow
centered around origin right because I
normalize it so they they will be
centered around origin in other words
maximizing separation is going to be an
equivalent problem of maximizing
distance from the origin for example the
distance of this point from religion is
that if I get the sum of all those
distances from the red line if I get the
sum of all these dances for the blue
line obviously the blue line will have a
figure sum of distances from the origin
so my problem right now is it maximizing
separation or variance is equivalent to
maximizing distance from origin ok so
here it is but if you remember is that
clear about our previous presenter show
if you maintain the point X and if you
want to project it on you projection is
nothing but an inner product isn't it so
if you want to project this all a unit
vector u it is nothing but the inner
product of X with that unit vector u so
this size I mean this point is projected
here this left here is equal to the
inner product of X I with you here it is
X I with you and for our specific cases
we have six data points X I in and for
that you is going to be the distance
from origin to the first data point that
x2 inner product you move with the
distance from origin to the second data
point and so on I'm adding them up but I
want to find a you that will maximize
this son right in other words Pike a
little bit more I can show that the you
that will maximize this separation is
nothing but
and the principal eigenvector of this
madness we call it covariance matrix so
instead of SVD you can solve the same
problem why first called creating a
careerist matrix like this and then
finding it is first principle
eigenvector that's your you so now I do
it in that way and after that of course
we have to after you find you what do we
do we project data right and then get
the coordinates in the projected space
it is my i'm using the same w ok the
same datamatics and this is the
covariance matrix basically this matrix
is right here and then I get the
principal eigenvector of this covariance
matrix is this now this looks similar to
the same matrix the same eigen vector
that we have been SVD right the problem
became exactly the same then I'm going
to replace my original data with project
with data points which is this does this
look similar to this is exactly the same
result if I obtained at work sweetie so
you can do principal component analysis
either with SVD or you want to do with
regular covariance matrix and here are
the by the way and I change the colors
blue red but this is the direction and
these are the projected points in one
dimension so general PCA algorithm if
you don't want to be the SVD here it is
given a data set let's say that we have
n data points and each data point the
least in our end we want to reduce the
date of the K dimensional data set in
other words we will ever and data points
but each each one of them will live in
our chain this time first you normalize
data to 0 mean and unit covariance and
you complete the Kuwaitis matrix and
then find the top k eigenvectors of the
covariance matrix and replace each X I x
y IX
r &amp; but why I has 12 all the AK has K
components in other words why is in our
chain so a data point XK I'm so X in RN
is replaced by another data point which
is in our care okay so that is principal
component analysis I hope it was clear
so we cannot solve subspace classes pro
problems with PCA can somebody tell me
why not can I saw subspace clustering
problem with PCA I cannot why because a
subspace clustering problem what we are
doing is we are trying to find you need
of subspaces right so that means for
each subspace I must have one pca not
too thin but I really don't know which
data phones comes from which subspace so
when I do pca I find only single
subspace that matches the best of the
best of the older data point but that's
not what I meant is a subspace closely I
want to say that hey boldly the points
are coming from one subspace I want to
find that subspace the only person from
another sub so I when I write that
subspace but if I do pca I will find a
single subspace that will match all the
data points so that means that is not
subspace clustering algorithm so
specular cross spectral clustering is a
very modern and been a powerful
clustering algorithm it's very easy to
implement any outperform traditional
clustering algorithms like k-means i'm
assuming that you know what he means is
what king is a very fundamental
clustering algorithms given a number of
data points you can somehow cluster them
based on the center of the clusters of
theta I'm not going to go over it but
with it is not easy to understand why it
works which is not easy but
implementation is very easy okay
basically given a set of data points
what you do is you have given bunch of
data points right what do you want to do
is you want to develop similarity
between all the pairs of the data points
so although most of the subspace
clustering algorithms boiled down to
determining that similarity
once they determine the similarity
between the data points the rest is the
same most of the spectral class and
yogurt I'm sorry most of the substrate
has an algorithms in the last stage it
says now let's apply expect a little
cluster yes okay I will define now good
questions so I will define for example
similarity may be based on distance if
two points are close to each other they
are similar or more similar than two
data points that are not close but they
may not work in subspace clustering
because on a line we may have a data
point right there another data point
here they are really far far away from
each other right but they are very
similar because they are on the same
line so this tues base similarity may
not work in subspace clustering right so
here for example assume that this is
your data if use k means there is no way
that you can cluster this right but if
you expected a class thing you can do it
k means you cannot cluster this but if
we inspect to the class ring you can
come up with a way that this is one
cluster this is another cluster here is
answer to your question actually we have
the data points this is Olivia five data
points between each data points pairs of
data points you somehow determinate
similarity okay but that is the key for
subspace clustering algorithms how do
you determine that similarity sparsely
methods use a certain approaches to
determine the similarity low-rank
approximation is another and so
everybody uses different ways to
determine once you determine that
similar to the proudest fault anyway
okay the problem is so once you turn
that similarity and assume that as 13
means the similarity between X 1 and
point x1 and x3 and this is the
significant point estrella as you see
there is no similarity between 4 &amp; 4 &amp; 4
&amp; 5
okay so what do we do what is the
starting point of specular clustering
specular clustering assumes that you
have the similar to somehow okay assume
that we have n data points and each data
point is in our end is similarity matrix
it's also called infinity 0 matrix is
provided as input this graphics s is
provided for example this is a very
naive way of developing or determining a
similarity and this is like Gaussian
function for example if X I and XJ are
very close to each other the difference
the norm of the difference will be what
small small and that means since we have
the e to the inverse that means similar
twill be high so the points are the more
separated the points the less similar
the points are right so but but this
will not work what for example this will
not work with the examples that I just I
mean well I don't want to say that but
this will not work for me subspace
classroom from but assume that somehow
you have the similarity matrix and look
your data leaves in RN are maybe this
thing like let's say are two thousand
assume that we have 50 data points and
each one lives in our 2,000 regardless
our 2,000 or mod our similarity matrix
will be what 50 by 50 because
similarities between the points so here
one point in our two thousand and other
point in our two thousand somehow we are
developing similarity and you obtain one
number so similarity is simply one
number that represent how similar two
points are regardless of their
innovation ok so my similarity matrix is
what and by n but we also seen inspector
glassing oh there's a way to estimate
not a reliable way to estimate how many
classes that we should have we assume
that also we know the number of clusters
so by the spectacle by the subspace
class and algorithms by before you use
this you should be
similarity and you should have a good
guest about the number of subspaces by
this time yes you do an example of how
you do a similarity metric for something
along the line okay oh yeah I think it
may be at the base right in that case
see if if the angle is you know the
angle base at all of them are I mean
very similar so you can develop
different similarities instead playing I
mean yeah so I think angle base similar
to be more suitable for for a line so
you're not clear I mean I haven't
discussed anything yet but you must know
that similarity matrix is the input to
spectral clusters and the number of
clusters is also provided we know that
there are three clusters two classes and
so on I am just extremely mechanics of
spectral class I'm going to explain that
the idea and why it works it is not
possible for me to explain in 10-15
minutes it's impossible so the first
step is the similarity from the
similarity matrix you are going to
develop a diagonal degree mattox d
diagonal degree matrix is a diagonal
matrix that means all the diagonal
elements are nonzero and each diagonal
element for example the first diagonal
element is nothing but sum of all
similarities on the first row second
diagonal element is the sum of the
similarities on the second row and the
last diagonal element is the sum of the
similarities in other words the sum of
similarity of point n with point one
with point two point three and so on
okay so that is a diagonal matrix so
that was our input now step on using the
similarity matrix I have a diagonal TD
matrix T then step two we compute a
normalized graph laplacian matrix
graph laplacian matrix is nothing but I
mean do you may have different laplacian
matrix but in this specific case i use
this so it is d to the power minus 1
over 2 and my similarity matrix digital
power minus 1 of 2 since these as the
diagonal matrix getting the square root
of diagonal matrix is trivial right get
the squares of the diagonals right so
the third step after you have the
laplacian ethics what you're going to do
is you are going to compute if there are
K clusters if you know that there are K
clusters you are going to compute first
k principle icon vectors of app first
similar to ethics then diagonal degree
matrix then they are not classy emetics
now I'm going to find first k principle
lights vectors of what laplacian matrix
ok step 4 I generate a matrix W which
consists of the whose columns are just
the first k principle I can make use of
what laplacian matrix ok so let's go
back to this what was the dimension of
similarity matrix and buy em right the
dimension of degree matrix is n by n the
laplacian matrix is n by n however this
w is what and by k because we have K
principle eigenvectors and each
eigenvector they said eigenvector of el
L was n by n that means this is n by 1
eigen vector so that means double is
what and by K now last step acquired
traditional clustering techniques such
as k-means in RK to the rows of company
now I corded the problem instead of
crossing my original data points for
example x1 is going to correspond to the
first row of this Dana extremely
correspond to the second row of the
state
next and so on and xn is going to
correspond to the last row of this data
matrix but each row is how each row
lives in RK right let's say if there are
two classes will be in r2 so clustering
in our 2,000 is converted to clustering
in r2 or in RK now i can apply k means
to my problem i know it is not intuitive
but this is what it is ok ok these are
from the lecture notes of this this this
is very well known person in spectral
clustering and I borrow that instead of
generating i generate in my own but
these are really good assume that it's
an example it soon as our data set is
not too and we use very naive similarity
measure just like this ok and we use
completely connected similarity graph
completely connected means somehow you
define the symmetric with all pairs so
every pair is related to each other
because artists are similarity measure
right as long as there is distance
between two points there is a positive
similar to be ok now assume that you
want to look at the classes for two
clusters three four five clusters here
is our L ok since we are looking for up
to five clusters I want to get 25 I can
make theirs of what laplacian matrix L
so if I assume there are five clusters I
will do clustering in what are five that
means my first data point will be this
second at appointment with that third
and so on what if I assume that there
are three clusters instead of five
eigenvectors I'm going to get one the
first what three eigen vector
okay for example here it is this was my
original data assume that this is x1
right this is next one if I say that
there are three clusters I can convert
this problem to this that data point x1
will be one of those red points here
because i am taking the three eigen
vectors that means each data from this
time from r2 i go back to our three I
know this looks a little bad but so I'm
going from our 2 2 R 3 because in r3 I
can separate them better you see in our
three I see three clusters very clearly
right here and then I can apply k-means
to this better than K means to this K
means they apply to this those points
will be you know we don't know but if
you apply k-means to this it will be
more separable right okay and these are
the eigenvalues so we don't know how
many i mean bv say that there are three
classes right but if you don't know how
many clusters by looking at eigen values
for example that laplacian matrix has
three eigen modules which are really
slow and then the other fourth fifth and
so on are bigger so maybe you can have
an estimated based on the eigenvalues
this master this should have three
clusters but that's not always true so I
can't rely on it your assumption is you
know the number of clusters here are
some other examples that I created using
matlab this is a high rolla MO generated
data and then I find the I developed the
similarity based on you know the
Gaussian function very naive similarity
and then I convert that I find and I
know that there are two clusters I find
vectors first two principal eigenvectors
of L and then converted it to k-means
and hear what I get with liquor k-means
you may not get this but with after that
I get that this had better example I
generated this data that I converted it
into two dimensional I said this is the
this is the eigenvectors the coordinate
the rows of the of my w you see how
separable it is here instead of a plane
came instead I applied here this is
better example this one I generated this
data and after i coordinate all of the
points are either dead or there see how
easy an artist to separate into this
with regular K&amp;C cannot be that's
basically what I handful today any
questions
I hope it was useful and I'm around to
hear any questions let's go thank you
and we are going to put those
presentations on workshop website
hopefully tonight so that you know
whenever we have time have a better
about some of those lives
the problem we're going to talk about
today is surface matching and I would
like to place it in kind of a more
global context and first of all what is
surface matching so surfaces are what we
call a two dimensional manifolds as
mathematicians but also can simply
intuitively explain as outer shells of
solids in the three-dimensional world
around us so there are two-dimensional
objects that folded in some interesting
shapes and basically they could
comparison comparing those comparing
surfaces is a core element in many in
many scientific fields and this is by no
means an exhaustive list but just few
interesting applications of confer of
comparing surfaces one is related to
data mining so we think you have a
database of shapes you want to do a
shape retrieval based on on the on
shapes that's a problem people working
on in medical imaging obviously many
people are comparing surfaces whether
it's internal organs or the cortex
surface face matching is again
comparison of surfaces the surface the
describe the faces of people and you
want to kind of be able to recognize
people to be invariant to expressions
and so on another application which is
kind of slightly less explored is
related to biology and that's something
I'm going to emphasize on this talk I
apologize to whoever heard this talk
before that's a lot of it is from last
year so what what what is the business
of pelant ology so they are interested
in shapes and they basically look at
shapes of bones and they kind of
understood very early in their evolution
that shapes have a lot of biological
meaning not just purely functional and
basically they look at the same shape
from different species is the one I want
to extract the maximum information from
the shape in a sense they're the kind of
meta goal is to extract something like a
geometric DNA of a shape and be able to
really say something concrete about
about evolution to kind of understand
little bit what is the problem in
surface comparison when we talk about
biological forms I show you here three
of the same bone it's called the distal
radius bone from three related species
there's a gorilla human
Arango town and i rendered them
especially in this direction so you can
see there is kind of a global similarity
between them but locally it's very hard
to say something and basically when
biologists now come in nowadays to
compare those two surfaces the first
kind of notion that comes into mind is
to basically reduce the problem to maybe
a bunch of numbers or the describe each
of the surfaces then compare the numbers
in some in some reasonable way so
basically they choose points on the
surfaces measure the distance between
them and maybe compare those distances
however these methods are kind of
problematic because there's a lot of
arbitrariness in the process some one
has to choose those points in a
relatively stable weight stable to
natural deformations and it's not clear
how many points you should choose and
whether your choice is already kind of
dictating the answer and so on so this
is really a process which is very a user
dependent and it's not something what
they like to do is to be more like the
DNA colleagues where they have kind of a
way to compare strings without ambiguity
I'll show you an application which is
kind of a recent thing that we tried
which there is no other way to solve it
except using geometry so there are two
groups of species that lived on earth
and according to the current theory it
is believed that there has been a 20
million years gap between when this
species lived in this piece of you so
these by the way are teeth of certain
primates so people believe that there is
20 million years gap between them my
colleague which actually collects this
data his name is Doug Boyer he recently
found two other fossils he actually digs
in certain spots in the world and in
fine fossils and the fact that he digs
them in the same place means that
whoever owned those teeth belong to the
same era and he conjectured that one of
them belonged to one of the groups and
the other belonged to the other but in
order to convince his friends he has no
know kind of a precise way to do that
except kind of reasoning about the
geometry of the stuff and if you look at
it it's pretty hard to say something
decisive about the shapes and my goal in
this talk is to say that we can take
this discussion one level further and
to find something like a common grew up
geometric common ground on which we can
start arguing about so we can I'll
actually show you that there is a pretty
clear answer which belongs to which
group by the way the group contains more
elements I just chose represented
represent two represented representative
of each okay so now I'm going to leave
biology I'm gonna describe the
mathematical machinery that we've used
and at the end of the of the talk I'm
going to go back to this problem and I
will show you a solution okay well not
our not so a solution but let's say one
step toward the formalization of this
question so in surface matching
basically one is given two surfaces so a
surface could could be is basically
virginal think this dog here is the
surface and there are two kind of
products that people expect to get when
they matching surfaces the first product
is a correspondence which can be a map
but not necessarily as we will see which
basically means that for every point on
one surface we want to get a
corresponding point on the other surface
or more than one point and the second
product that people expect is something
which is a scholar which we will have
the natural kind of structure of a
metric which kind of encapsulate the
difference between the two surfaces in
one number this is very useful if you
think about the that like a segmentation
of shapes and so on and the first thing
that comes into mind when you want to
define a metric on this space of
surfaces is you have to choose what is
your notion of equivalence so what do
you call - when do you call two surfaces
the same so the most classical way to
say that to sums of the same is if there
is some kind of a group that will aid
them so for example congruence if there
a rigid motion one of another we
obviously don't want to consider them
different and you want a metric to be
zero the distance between them is zero a
slightly more modern point of view is
the Romanian metric which basically says
okay so this surface has an induced
Romanian matrix form its embedding and
basically all the isometric deformation
the deformations that don't change
distances on the surface do the
existences are basically all the same
the same appearances of the same object
now there is there is really vast amount
of works that try to saw
the matching problem in in very
different fields starting from
structural biology through engineering
fields the computer vision computer
graphics and I don't want to go through
and this is also not exhaustive live but
I want to kind of give the feeling that
there is a strong there is a big gap in
algorithm either there is algorithm
which are more you ristic and provide
good results on certain subclass of the
problem but have no guarantees and
indeed do poorly on other subclasses or
there are very rigorous type of
algorithms like algorithm that directly
discretize notions like home of house of
distance but then they basically boiled
down to np-hard problem when you near
it-- it down and you have to do
something like finding some global
minima based on initial conditions and
so on and it's really hard to find a
global minimum of those problems so this
space this gap is basically a very very
something that people try always to to
narrow down and and basically what what
I'll try to convince that it's actually
it can't be Nirvana little bit I don't
know to what extent but there's
definitely things that can be done in
the future to to to make it smaller so
basically there are few so from looking
at previous work the few basic questions
that comes into mind the first question
is a very simple ones if I'm giving you
two surfaces and I'm just going to ask
you a simple question can you decide
quickly
if those two surfaces are isometric yeah
so obviously if I would ask if they are
congruent if there's really motion
between them everybody going to come up
with lot of suggestions but if I ask you
whether that isometric is there a simple
algorithm when it says simple I mean
reasonable time complexity algorithm if
you can answer these questions once we
can answer this question we can go the
next step and the next step said okay so
we know to figure out when two surfaces
are symmetric that's our kind of
equivalence relation now maybe you can
use this idea to define distances
between surfaces which which have this
kernel but the distance is kind of
extend to any pair of surfaces that we
can compare not just say yes or no
whether there is no metric and maybe the
last question which is extremely big and
definitely contains the the first two
but contains much more is in general if
we take a surface comparison functional
so I want to measure distances between
surfaces can we say something about its
global optimum in a reasonable time
and what I try to convince you by the
end of the talk which is not that far
away is that for surface comparison this
the structure of the problem do often
implies that you can say something about
the global solution and I will get to
that so the main a kind of tool that
we're going to use is the notion of
conformal geometry and I'll give a kind
of a quick introduction to that so
conformal maps are a maps that are
preserving angles here's just a kind of
visualization of a map defined on this
square basically mathematically we can
answer the differential is the
similarity writing down in coordinates
it's basically the Cauchy Riemann
equations
more generally confirmed maps can be
defined between two dimensional domains
not embedded in the plane that is
differentiable surfaces and the
definition is basically the same thing
we just ask that the map the
differential of the map which is defined
between those two tangent planes at
every point is a similarity and we have
a definition of conformal Maps between
surfaces now our goal will be to compute
conformers between surfaces and use them
for something so the first part of the
talk I'm going to I'm going to quickly
say how do we compute conformance
between surfaces so for certain surfaces
everything is known so for example if we
talk about the unit sphere the entire
group of bijective conformal maps that
take the sphere to itself is the
well-known mobius group and if we part
right the sphere with the extended plane
using this famous telegraphic projection
then we have a very nice formula which
we all kind of seen before which is the
fractional in transformation of the
mobius group another canonical surface
is the unit disk and the set of all
bijective conformal mappings self
conformed maps equal to this to itself
are a subgroup of the general mobius
group and it can be parameterized in
this way the really important thing
which we're actually going to build on
in all this thing is the fact that the
dimensionality the dimensionality of
those groups is relatively small
relatively small in comparison to all
the form of physics and we know for
example that to set a memories group on
the sphere type surfaces we need this
six real degrees of freedom or three
complex degrees of freedom and for this
type surface
three real degrees of freedom which is
basically we know that also for women
mapping theorem of simply connected
surfaces a planar domains okay so what
do we need to do in order to complete to
compute all the conformal Maps so be
able to compute all the conformal
between two general surfaces so we have
these two surfaces desire again teeth
and these are homomorphic to disks so
the component that we're missing is the
uniformization theorem which is
basically a celebrated theorem that says
that if we have a simply connected
surface let's say homomorphic to disk
then we can map it globally by ejective
Lee and conformally to the disk once
we've done that we basically now can
explore all the conformal maps between
the surfaces by exploring Mobius
transformation from the disk to itself
so for example here I just pick one
Mobius transformation between the disks
and I compose them with the with the
uniformization in this way and basically
I'm showing you now the conformal map
that that this Mobius element represents
so you can appreciate this conformal
because the grid is orthogonal here and
orthogonal there okay I mean that the
intersection is always 90 degrees so it
means that the angles are preserved it's
not a proof but it's kind it gives the
feeling so it's it's it's basically
approximating an elliptic partial
differential equation finite element
linear but we I can I have slide about
that we can talk about it later let's
say that for this thing you do it once
and then once you do it there is a
closed form formula for the Mobius
transformations and you can basically
explore them in an efficient way how do
you say anything about our multi metric
so far just confirmed mappings something
more general I didn't say anything about
metric now I'm going to say something
about metric so the first problem we're
going to ask is where the two surfaces
are isometric okay so we want to answer
that quickly I want it I want to contact
I want to I want to say that confer maps
can help us to do it very quickly
and the reason it's kind of obvious let
me explain so what what do you mean
again by a dormitory for let me remind
quickly so we have a surface we
basically want to define a metric on it
and we define a metric by taking two
points on the surface and defining their
distance the geodesic this
to be the length of the shortest curve
the class on the surface between the two
points this kind of make this a metric
space which we can call a Romanian
metric we call two surfaces isometric if
there is a map between them which
preserve all those pairwise distances so
that's eye geometry and now given two
surfaces how do we decide or and if
there are symmetric so the really simple
observation here is that isometry is in
particular a projective conformal map
one way to see it from the way I defined
a geometry is that if we take a very
small geodesic triangles they behave
very similar to cleveland triangles and
we all know from high school that
setting three lengths of a triangle also
makes the triangles congruent right so
the angles are also preserved so that
that would mean if we take this
interface female point of view that
isometry is a conformal map so what so
which means that if there is an isometry
it lies in a very small space relatively
to all possible D formalism it lies in
the conformal group which we only said
his six or three degrees of freedom so
it's only enough to look in that space
and we also have an efficient way to
search that space so here's an algorithm
for finding a symmetry we take a surface
we map it to numerical approximation to
the disk conformally we take another
surface we do the same thing by the way
what is this landscape here when we map
something conformally we preserved
angles perfectly but but obviously we
didn't preserve the scaling right we
cannot this is not a flat metric we
cannot flatten it without an arrow so
the information said we can make sure
that angles are preserved but the scales
will be significant so here basically
now it's we can save a positive scholar
function which define how much scale
happens so we can imagine that this peak
it kind of correlates to places with
high Gaussian curvature yeah so
basically the simple observation says
that if those two isometrics there's a
Mobius transformations that takes this
landscape I would call it a density
that's the conformal factors by the way
take this conformal density to this
conformal density so we can just if you
want random of information and see if we
can get from this image to that image
that we mean the two surfaces isometric
here's a an experiment so here's a tooth
versus these are the approximation that
we do for an information I don't want to
talk too much about the actual way how
we do it all I want to say is that we
can kind of expect that these two
surfaces are near isometric why because
when cat moves we can expect that its
skin doesn't stretch too much which
means that the distances intrinsic to
the car do not stretch too much that
that's a vague argument but it means
that if we take that three points three
points again that's exactly six degrees
of freedoms of the Moriscos formation if
we take three points which are kind of
corresponding and we align those three
points in the uniformization space by
aligning the by Morris transformation we
can expect that if we took points from
an isometry or near isometry
then everything else would be rearranged
and we kind of explore pilate's the we
reconstruct the this asymmetry
everywhere so let's do that so I'm just
gonna apply a Mobius transformation here
and what you see happen is that those
black spots here arranged similarly to
the black spots here these black spots
basically could correspond to the
different limbs of the cat so the leg
hand so this is probably the front leg
this is maybe the head node head the leg
and this is the tainment you see that
the image looks very similar so it kind
of gives the sense that you can think
about polynomial algorithm in complexity
of n2 the cube in the number of points
to find a geometries if they exist so
that's the first proof of concept and
now we can move to the real problem of
how to define in AI geometry invariant
distances between general surfaces not
just isometric ones or near the metric
ones in in a which are also efficient so
the point of view is like in including
geometry when you were present
quantities we always like to represent
them in a way which is a rigid motion
invariant why because we don't want to
bother a circle things we don't care
about so we don't care about orientation
of stuff so let's represent it in
environment way the same thing a the
same kind of concept should apply also
to other geometries so if we have a
surface the last thing that we want to
do is remember the surface in
coordinates right a so the formal
discussion kind of gives a natural way
to represent a surface which is
basically an orbit of the conformal
densities up to a Mobius transformation
so this is kind of an object I'm not
suggesting to keep that in a computer
yeah but that'sthat's
conceptually a good thing to think about
why so here's a good reason let's say
that we want to define a metric between
between surfaces and we have a good
metric between measures or between
densities and that we all know that
there are many good measures distance
metrics between measures say let's say
probability measures then there is a
canonical way to connect whatever we got
there to surfaces and how do we do that
we take some metric between probability
measures and then we basically just do
metric quotient thing so we place here
the orbits of of the confirm factors up
to the mobis group and we automatically
would get a metric between surfaces so
basically this kind of a simple idea
connects between general metrics and
measures two metrics on surfaces and the
question now is what kind of metric to
use a choice of metric which is
favorable for this problem is what is
called the vasa style metric and the
vastest time metric is basically a kind
of a metric between distribution or
probability measures which has kind of a
physical intuition basically it says
that it basically looks at things of the
two densities as pile of dirt or a pile
of some pile of some material of mass
one and you want to rearrange this to be
in this configuration you want to do it
as efficient as you can so what is mean
is efficient it means that whatever you
move this is the distance you multiply
but how much you move that's kind of a
cost that takes you from this to there
and obviously there are many ways to
rearrange basically how many ways other
to rearrange these two probability
measures basically you can look at all
measures on the product space which have
a marginal of this density on the left
and this density on the right and this
we can call this is a huge space right
and we we want to choose over this space
the one which does the best so we use
this concept for generalization and you
get you get an algorithm to define
decisions between surfaces and the
bottom line is that is the convex
algorithm because this thing boils down
to linear programming I'm not going to
get too much too details because I want
to talk about the third part on the
biological applications so I'm going to
say whatever I said so far in different
words and
with just images so what did we do you
know what how did we define distances on
surfaces so we had this huge space of
air preserving by measures it means that
measures on the product space of the two
surfaces with the marginals and what we
did is looked for a minimum on the space
up to some functional this is a huge
space however luckily when you
discretize it use explaining some points
on the surfaces and so on this space
comes it becomes a convex polytope right
that's basically those linear
programming constraints we want the sum
of the matrix to to equal one density
and the rows sorry the columns would
sound to the second density and the rows
would summon to the first density and we
get a very nice convex polytope and we
can optimize it in linear in in
polynomial time and then what what do
you do with it we said basically now if
you only use that framework to define
distances between surfaces then they're
not all we did is basically said a
distance between surfaces is basically a
distance between the conformal group
between those two surfaces and the area
preserving by measure the two surfaces
that's that's basically the same way to
say it because what we did is apply the
Mobius transformation on a density and
ask what is the mass transportation
distance between them what is the
vastest and distance between them and
you can imagine that if we had a mobile
source formation which is area
preserving that is an isometry then we
had we wouldn't have a perfect area
preserving and these two would intersect
so in a sense the the distance that were
measuring is the distance between the
conformal group and their area
preserving by measures now the problem
with that is the biologists don't like
by measures and the reason is that by
measures are not necessarily Maps so
they can take piece of mass here and in
in distributed to several points on the
other so a seven point here would
correspond to many points on the other
surface that's not unlikely right right
but so the many people also for many
applications it is important that you
produce map at the end of the day so in
a sense in order to produce map all you
have to do is something that may seem
simple is to change this
with whatever you you want to preserve
so instead of air preserving by measures
we can take air preserving d4 morphisms
yeah so smooth maps that preserve area
and actually we get even a smaller space
the problem is that this space is much
less nice than the than the by measures
right because it's it's nonlinear and we
maybe we know how to flow in it with
divergence free vector fields but we
don't in any way know how to optimize
globally over this space this is the
unity formally it's infinite dimensional
manifold it even took a non-trivial
amount of of Mathematica and ice to
prove that it's not empty although
people understand with infant
dimensional right that's a famous paper
by Moser few years back so how so so we
in this setting we have an air
preserving the formalism with some
functional over it and we want to
implement to to globally optimize it so
how can we achieve that
so obviously the general setting when
the function we can't assume we don't
assume anything on the functional that's
we cannot really say anything however in
our problem where we comparing surfaces
there a very strong kind of another
assumption on the functional that we use
we use the fact that if the distance
between two surfaces is zero the two
surfaces are isometric or congruent
depending on what choice of equivalence
we made and and that's something we're
actually going to use so here's how
we're going to use it in case the two
surfaces are isometric the image looks
like this the group of air preserving
deform of either between the surfaces
and the conformal map actually intersect
why because we know there is an element
which is there isometry which belongs
both to angle preserving conformal maps
and to air preserving rights that's the
definition of a geometry so if we want
to optimize globally this functional dmn
in the case it's zero we can do that why
because we don't need to consider this
human in space we just consider the
conformal Maps that's what we said
before when the surfaces are not
isometric so the distance is greater
than zero then the kind of situation is
something like this the conformal group
is kind of disjoint from the air
preserving so what we're going to do
we're going to do a general kind of
thing which we're actually going to
define in there a preserving the
formalism
a very small set of candidates why do I
mean small set because we're going to
act
going to do something like projection of
the conformed apps on their episode 84
physics so we get a three dimensional
manifold inside the infinite dimensional
manifold so that's very small and we're
only going to work in that space and
what I'm going to claim to you is that
in many cases we can prove that the
global minimum on this group actually
belong to this extremely small set so
let me actually instantiate this idea to
a particular geometric functional that
biologists care about and show you an
algorithm and results so the so let me
explain the functions that we take so we
start for something which is well-known
which is called the Procrustes distance
that's the functional this is how they
compare surfaces you take a bunch of
point on one surface a bunch of point
out the surface defined by the user the
user marked corresponding points here
you can see them by colors and then the
distance is defined factor out the best
rigid motion between those two sets and
take the sum of squared distances that's
the proquest is distance obviously the
user has a very influential role on the
on the distance right he decides the
course the points and the
correspondences so we first of all you
want to get rid of the user so what do
we do we replace the correspondent says
with continuous maps between the two
surfaces we put here an integral on the
first surface and then we also put here
the correspondence inside the search
yeah ignore this minimum let's say that
we didn't prove at this point that there
is a minimum later maybe I'll talk about
that but anyway there is a minimum so we
want to search both for those space of
maps and the rigid motions now the first
question that arises is what class of
transformations do we want three minutes
okay so I'll just two minutes in this
and one minute okay so it turns out that
air preserving deform physics the right
thing I'm not gonna say over here all I
want to say is that now we have this we
call this a continuous proquest is
functional it is defiled area preserving
different morphisms and the theorem that
kind of ties this thing together says
that if we have an area preserving
deform of films that gives small
procrastinates not far from a conformal
map ok so that's kind of continue to
result but why is it important it means
that if the distance is small we can say
something global about this functional
over infinite dimensional group which is
something
particularly interesting because the way
people people can approach this problem
is start with some initial guess that
comes from another place and do gradient
descent but if for small distancing you
could say something global it means it
means that you can do well for these
short distances
so the algorithm okay I'm not talking
about too much the algorithm basically
take the conformal Maps randomize the
conform map project it on this space in
certain way and now we just test all of
them kind of sample the conformal group
test all of them and take the best one
very simple algorithm let me answer just
this thing you know I'll be done so back
to this at 20 million years gap thing so
there are two groups we got 36 models
all of them scanned by our collaborators
these are three-dimensional meshes
achieved by micro CT these things are
actually very small and we there's three
surfaces that have been found in this
special occasion which is me which means
that they both from the same area era
the same the same time in history and
these two groups are believed to be
twenty millions apart so we ran we take
this group of meshes and we just compute
the distances between all pairs so we
get a matrix of 36 by 36 with the
distances between every pair and now in
order to visualize it I'm just going to
show you kind of an embedding with
relatively low distortion of those
points what what you can clearly see is
that the Blue Point is one group the
light blue point is the other group and
the three the three interesting ones
that were found in the same place in the
digging site actually two of them belong
pretty clearly to one group and only one
of them we don't create to the clearly
to the other group which might imply
that these two groups exist is together
in history and they're not really twenty
millions apart they think I want to
highlight here isn't it it's not that
this is a historical proof but what it
means is that there is some objective
measure which did not involve human in
any part of the process and was able to
provide any representation of the data
which gives a clear separation between
the two groups and and I think in that's
kind of my take my kind of my main kind
of
message is that we might want to develop
such algorithms that are able to provide
to provide information on our data which
is kind of more conclusive than it was
originally originally was I know if it
makes sense but that that's that okay
thank you
bismillah ar-rahman ar-rahim nobelium
inshallah be just a Fenny Weiler seen
the fast America volatile oils me at the
Magna carpa father mukada me in in
packet rocking always somebody in
introduction to Beckett Rajan he had a
list of a Java file a general method was
Angelica problem formulation volcanic
even halma skeletal iniquity problem
vamos with the Hamiltonian cycles this
dish Grameen Bank is rocking Pedrosa so
the cartographer holodeck terminus of
the hamon mache kilobit well jigna he
hired 911 a year welcome to Emily and
oil zubatov a friend who a sequential
mean method hananim script sorting
distilled and selection will pop in
while insertion rather the Catawbas not
a scuba wah-wah divide-and-conquer
method mahalia nobility Mia is sorting
the spectrum in merge were a liquid sort
algorithms Bala delicate have
acknowledged to be degree limited
O'Hanlon armed planning on skipping
minimum spanning III were in knapsack
problems but they can I know knapsack
problem screaming ha million to virgins
ilium again the fraction and knapsack
were I bond again zero-one knapsack
politically Demeter darling a partner
Allah diffraction and knapsack come on
rather cat about knowledge tube jadid
what what dynamic programming method
while I'm in Janeiro
Helena Muscatine multistage graphs were
cave allocated by traveling salesperson
mean a problem in the Omaha Dhammapada
Scoobies did what many some have
impacted tracking method while I'm 34
Helena mechanical and McQueen a problem
working dedicated on how many other hand
held on 34 Muscatine hamiltonian mean
cycles a heavenly camino problems are
harmony and booking poon mocha Queen
eight Queenie problems
Aram again for the Queenie problems has
available Queens emoji in indeed come on
you don't have a fan of stupid packet
rocking what happen if mo be cooled
Basava in 30 fucking method warming it
is a general algorithm for finding all
or some solution to some computation and
mean a problem I'm going a national
Imperial backtracking in the world
occasion in the harmony and notable
harmony and mooska that in Turkey
tracking the program
I mean come on we couldn't pass up a hot
animal packet working method
I'm an idiot here and how that again
mean in the graph how many things we had
a chicken in go up ducky how many Yankee
fish turning back is rocking lucky
fucking galactic dominant look for my
get him I'm gonna get a husband peony
multi-tone IVF process why adventuregirl
any problem problem energy the problems
let me at him held her back
Emily young you know it didn't look well
in a village it mean here in the X term
in bath botella nominee el mohammed
abdel fattah who I am
tamam whether I can hammer Amin in a
chicken in my level baffle in condition
LAPD and Haley problem it again yes the
parameter phenomena million mean
recursive namin the math about coming
hiding in mosquito victim in again if I
can how many young and the cantle Eric
Harris the rajala true victory nominee
invest in an emergency who are many and
mean Sofia the mom the mom okaybut a the
Campbells we had in bath or victory huh
committee hata is Italian the problem a
million means inhale the mommy the
cannibal puffs called affirming of
harmony meaning undo a homonym again
taraji arm no potato harmful in about me
in Kearney battalion Emil Halabja near
death emoji t90 had a hell mean had any
problem either Java Virginia had in past
well lists any problems from a newly my
victory American had any problems or
have the journey Falls Road victory
there is no solution any problems with
aromatic aldehyde mean in a problem
happy M onion thicken compacted working
me method in fact it working method our
data tracking algorithms what estimate
Alice systematic search data Madonna is
systematic search
less solutions face bommana in an
American of Ken and Yanina problem or
Haldane the problems here in the are ba
are bajalia the problem come on we
recognize our bajalia Thomas theorem
again optimal solution
the man named jihad from October ha
victory solution space lacunae harmony
and mean our path victory I mean in
practical congrat Amidala in hate carry
our said Amanda chicken has a solution
space hello I'm again three
organizations and warming in depth fears
no the generation our harming
intersecting bounding funk
happy I'm a limitation the search come
on how many in the camp I became that as
in the Caballero of hub or the telly a
TDR meet again later Paula Hockey League
on her fanny half-a-million be shaken
over hand but it means empty neva
respecting her Armenian like instead of
emptiness to the dirty fucking captain
friend happy mean had a friend in
Michigan in between Jenna come on an
American engineer license technically
had impacted working have been held had
in Michigan
okay Taylor had cool American higher
yield or more lava orbit active in
pounding the function and German army
and limitation let's search come on come
on now at any chemical engineering
problem for me a Chanel jacket tracking
ammonium method victory harmony and
novelty and economy I mean a problem
returning as a mahaki trend ahead
hello Lucas aha so mom was and again the
top two Shukla Haley problem come on and
I'm gonna change the problem had a
health issue rules come on no fee then
no can't render me an auto Baha'u'llah
Baha'u'llah money and half of a that he
should be telling semi I may be a
desired solution had a desired solution
came imagine how a piranha and
ejaculation trouble coddled Emily gave
the height methylamine okay and x1 x2 x3
all right XM demand in harmony and
harmony and ok Nanami and the are bar
solution Madonna Finnegan condemning any
other boroughs of a million or four
couples multi demon having a meal and D
happy
solutions our desired solutions
occurring a hectare windy simcha the
Kennedys solution space our culinary
insist the nominee Shekinah as one again
as I tighten a bit metal American
economy Double L mowjood mean Emily and
Andy come on okay and a million on
paternity Emily in the world wahad raha
metal a Meganium Victor what attorney
Rahim economic and halwa had married
appropriate vemana locate any immediate
problems within a two solution matter
nominee Ava - Jamie a-come bro
reclamation and the two row either Road
oh one 1 million mean had a row ten
after
intended to tuples having in the
worldwide right Otaniemi victor Nashua
high meth-addicted wahad or Victoria
libel macadamia in halwa had had about
Danny Mahesh Sharma DNA and evict
attorney Rania Mohammed Amin health any
London and now I mean I'm highly
publicly on the two big stories man
Konami and the two solution
come on behind the problem come on make
an Italian whatever an optimal mean
solution Konami in the double eyelid
have a clean objective led problems
differently they can tell a parent about
done maximize or minimize over time
making technical a perfect condition me
why I am come on
ok bharanam again turned am again mean
um but Eddie lost aradhna
in no pnw mean solution space Armenian
hedge Marbury and um I
tamam lahat a solution in space Victor a
million and her work on the m1 and to
the right mmm
turning economic and I'm the end minute
levels in moji be mean Andy what in hey
I had met anomaly and desired solution
or candidates solution Lahaina problem -
mom I'm in the last nominee Wendy I did
Nina problems with him Hal dad system in
package rocking the Republican
nomination up have got much more mainly
minute constraints how much one should
come on and it constraints phenomenal
you mean you are in the n-dimensional
except missive and M conceived
constraints exclusive constraint
spreading and harmony and divested rule
rule what harm had the day how to hide
this father it means solution come on we
met Alan hello be judgmental added a
layer Emily and outdated rather than
Mujib it the mom or rather the rear self
in Lackey another demodulate we enabled
our million in positive numbers Victor
aha Mia had cool X the item X with
material added its of I be heightened
Noemi I have connected offered to sell
me and set up whatever chicky lanyard
shit data we had a dad emoji B are
non-negative me numbers like in ins
chakra in Germany and zero or one
Ketchikan Amin Amin said Fanny not Rami
in the Buddha again mean Wawa had
enormous a meeting except this across
trance the mom Randy not anymore myself
in implicit consonants when new army
the solution vemana an event amiami no
problems who had held any problem
spending much more maninsuit the telly
had reported issue of metonymy and
hassle vana troubles
al-hasakah again alanine other solutions
return hey here an absurd to somebody
implicit mean constraints with any Amir
hoc Academy and conditions or the
criterion for functions or constraints
American vicuna had a hard worker had a
hand Heidi is in the problem okay okay
and thanks for listening and have a
great day
okay so i'll continue about not into
since now and the first one I want to
show you is a non-interactive
zero-knowledge proof for circuit
satisfiability it will have perfect
completeness perfect soundness and the
zero knowledge property will be
computational okay and what we'll see is
that we could get a very small common
reference during it will just be a small
constant number of group elements and
then will the proof will be also a
number of group elements this time one
that grows linearly in the size of the
circle okay i'm going to use composite
order groups to construct these proofs
okay so just a reminder that composite
order groups so we have n which is a
product of two primes p and q and these
groups here they have order n and what
we're going to assume is a subgroup
decision problem is hard so given n in
the description of the groups and
elements G and H it's hard to
distinguish whether H has order Q or H
has order n so a brief reminder here so
then talked about how you could build
encryption schemes based on the subgroup
decision problem and that's exactly what
we're going to use as a fundamental tool
to construct these non-interactive
zero-knowledge proves so the public key
here is again this description of the
groups and elements G and H the G is a
generator flu group has order n + H has
order q ok and the secret key is a
factorization of n and to encrypt
something with a BG encryption scheme so
to encrypt a we take G to the a and then
multiplied with h to the r and we can
decrypt this by raising ciphertext to q
that gives us g to the aah to the r
raise to q and if you do the math you
see that this is the H just cancels out
and we're left with G to the q raise to
a and if a is a small number then we can
compute the discrete logarithm and the
and as then argued this is an
indistinguishable on the chosen
plaintext attack I'm going to extend
that a little bit so what is called a
commitment scheme ok so the commitment
scheme works exactly the same way so
still have the same public key and a
commitment to an element a is G today
and H times H to the are ok now at this
stage though I'm not restricting it
doesn't have to be a small number this
works for any value a modulo P because a
commitment uniquely determines a modulo
P right so we have this age which has
autocue that can cancel out and and do
bad things of anything in the order q
sub group but in your P sub group we
have a is uniquely determined so
therefore we know a modulo P given this
commitment and just as for the
encryption scheme we can argue this is
computationally hiding that just seeing
equipment and doesn't let you decide
whether is equal to 0 or 1 or something
else now this commitment scheme has
these nice properties of just like the
encryption scheme that if you multiply
two commitments together you get a
commitment to the sum of the elements
that you have committed to and if you
pair two commitments you get a canoe
commitment this time in the target group
which encodes a times B okay so I'll
just leave this slide on for a short
while so you can do the math yourself
and convince you that I'm not cheating
okay so okay so using this as a tool i'm
not going to construct a non-interactive
zero-knowledge proof for circular
satisfiability so just to remind you so
the goal is to argue that we have a
circuit and without loss of generality
we can assume that it just consists of
NAND gates okay so what I want to argue
is that that has some input to the
circuit that will make it output 1 okay
so in other words we have okay so we
have some some input we can give to the
circuit which will lead to this
intermediate and wire well use and the
output will be 1 and the provo has a
witness the proven knows some some
assignment to these input why's that
will make the circuit output 1 now the
provo wants to convince the verify that
yes indeed this circuit is satisfiable
so what the provo will do is to commit
to these values of the input wires and
also the intermediate wires in the
circuit okay and all these commitments
approval send to the verifier and for
the output of the circuit the prove we
will also make a commitment this is a
commitment but here a random is our is 0
right so this is something the verify
can say yes the output commitment yes
that's a commitment to one that's easy
to verify so what remains now is to
prove that all these commitments
actually have our commitments to wire
values that satisfy the circuit and we
need to show two things first of all we
need to show that these wires near their
commitments 201 by all the verify sees
is some commitment it could be any value
modulo P but so the first step for the
program is to prove to the verify that
the program has committed to two values
which are either 0 or 1 for these wires
and the second step then is to show that
all these committed values actually
respect the NAND gates okay so in other
words the committed w-4 should be the
land of the committed w1 and w2 so i'll
show you how these proofs work okay so
the goal here here is we have a
commitment and we want to prove that it
contains zero or one okay and without
loss of generality we can write it as G
to the W for some W which is unique
modulo P okay and we're going to use
here this multiplicative property of the
encryption scheme of the bgm encryption
scheme so what we're going to do is
we're going to take the commitment and
then the commitment multiplies while G
inverse ok and pair these two
commitments together and while the
commitment see has w inside right and
the commitment C times G inverse has w
minus one inside so when we pair these
two commitments together what we get is
a new commitment that contained w times
W minus one and then something that has
order q
okay and the interesting thing is here
if w is 0 then this is a commitment to 0
right and if w is 1 then this is a
commitment to 0 and if w is anything
else modulo P then this is a commitment
to something non zero so what do we want
to convince now the verify prove one's
convince the verify that this is a
commitment to 0 so how do we do that
well the proof is very simple is one
group element it's this part over here
that's the proof and to verify this
proof here the verify will check that CP
it will see that times G inverse is the
same as the pairing of age with a proof
pie ok so it's easy to see it's complete
right because we just took it from here
so let me argue white sound ok so what
what the verifier can deduce is well
that the sum w some some are such that
this pairing here is the same as this
value here and that's apparently the
same as h paired with the proof pie ok
and this thing here has autocue right
because H has autocue and this thing
over here well h-has autocue so this is
also something that has order q the only
thing that has some some order modulo P
possibly is over here right and while if
it has to have order Q as we have over
here then the only way that's possible
if is this thing here is 0 modulo P
so the verified concludes that w times W
minus 1 is 0 modulo P and therefore that
W is 0 modulo P or w is equal to 1
modulo fee okay so this is an extremely
simple proof that a commitment contains
zero one right it's just one group
element that we need to convince the
verifier okay and that's the first step
right now we can use this proof to all
the wires and prove that that contains
zero or ones just as we want it to so
the next step we need now is to prove
that the NAND gates are respected as
well and for that purpose on make this
observation here okay that if we have
bits p naught b1 and b2 then be too is
an and of p naught and be one if and
only if this linear equation here is
either 0 or 1
okay so we're going to use that
observation in a moment so now I'm doing
this for NAND gate without any loss of
generality because you can with with
only linear overhead reduce any circuit
two to one that consists just of NAND
gates but you could do this also if you
had other gates of fan in too so you can
find similar tables for all possible
gates and have two inputs okay so so now
we have these commitments c naught c 1
and c 2 we know that they contain bits
because that's what we proved before and
the remaining question is is it true
that let's see two contains the land of
c naught and c 1 and here we use the
homomorphic property of the commitment
scheme right we take c naught multiplied
with c 1 multiplied with c 2 squared
multiplied with g inverse to okay and by
the homomorphic property that gets as a
commitment to be naught plus b1 plus 2 v
2 minus 2 and well if b 2 is then and
then you speak then this value here is a
0 or 1 right but that we already know
how to do we just use the proof before
we prove that this commitment heat
product here contains 01 and we're done
this is a proof of knowledge yes as well
right I mean so so all these commitments
because it just contains bit 0 a 1 you
could use the BGN decryption mechanism
to get out the bit 0 1 yes so i'll show
you zero knowledge in a moment so so
right now I'm just arguing that we have
soundness okay and then I'll get to the
zero knowledge part later on okay so so
that's it okay now we have we commit to
all the wires for each of them proved
that to contain zero one and for each
NAND gate we take this product here and
prove that contains 0 0 1 and we have
proved everything so now we know that
the circuit with these committed values
will output 1 okay and this is very nice
so the crs is the BGN doubled BGN key
okay so it contains so it contains an
RSA modules and then there's not much
overhead in describing the rest here and
then it contains these two group
elements so so we ended up with
something that's roughly three times
then and Aras a modulus in size and the
proof size while we are committing to
every wire and for every why we're
making one proof okay and each proof is
one group element so that gives us 2
times the wire number of wires sighs
okay of group elements and then for each
NAND gate we have to make a proof so
that's plus the size of the circuit in
the number of NAND gates so constant
size crs and and linear size proof
ok so now I'm getting to the zero
knowledge part why is this Sarah
knowledge so we're going to use the
subgroup decision assumption right here
right it's hard to distinguish whether H
has order Q or each has order any okay
so when we set up a simulated common
reference string we are going to instead
of having H that has auto cube we are
going to have h that has order N and
this is something by the subgroup
decision assumption the adversary has no
clue that we have changed and simulated
the common reference string okay so so
i'm going to choose H that has all right
now I'm actually going to choose such as
there are no value towel such as g is
equal to h raise to the towel okay and
this towel here is a simulation trapdoor
and what the this value here gives us is
that now the commitments are perfectly
hiding trapdoor commitments what this
means is that i can create a commitment
which I can open both as a zero and as a
one whichever way I choose right so I
could commit to 21 as G to the 1 times
h2 they are but that's the same as G to
the 0 and H to the r plus towel ok so
now I have commitments that I can
pretend are either 0 or contain ones and
the verify has no clue what's inside
ok so the simulation what I'm going to
do this how well now I have this new
common reference drink with H has order
n again going to i'm just going to
commit to all the ones now when i'm
simulating i don't know what the
witnesses right so i'll just commit to
one's all over the place then I'll give
the proves that the commitment contains
zero ones that's fine because they
contain ones and then when it comes to
the NAND gates well I can just tweak it
i can just cheat right because I know
how to commit to both the commitments
are both of zeros and ones at the same
time so I'll just pretend that some of
them to contain zeros and now they also
respect the NAND gates and I can give
proofs for the NAND gates so that's how
the simulation works
so so what did you say simulation sound
were that while simulation soundness
says that if you see simulations of
statements you would not be able to
approve a new statement and you've falls
in a false statement right that I don't
think you know I don't think you would
get that from here I mean the ways you
can you can modify these proofs are
malleable and you would be able to cheat
that way so so so you don't get advanced
soundless properties that but no no
that's that's known on and you can you
can get to get that kind of kind of
thing I'm not planning to talk about it
here but I'm I'm happy to go to talk
about it later okay okay so what do we
actually get from these proofs okay so
each of these individuals 01 proves they
actually not zero knowledge it's just
witness indistinguishable okay so let me
show you why they are witnessing
distinct roots so we have some
commitment okay and we want to run this
proof that it's 01 okay and it could be
you know both have one and A zero at the
same time because H has order end and
what I want to argue is that whether you
give a proof where I have the opening 21
or a give a proof with a half the
opening 20 well there's no way you can
tell what I started with a 0 or a 1 okay
it's witness indistinguishable okay so
so depending on what I use the one and
an R or the 0 &amp; applause towel opening I
will get a proof of this form or proof
of this form here okay and then the
verifier will check that the pairing of
C and C times G inverse is the same as a
pairing of age with the proof pot pie
okay and just as before I mean we have
perfect completeness these proofs will
you know we just give the exact same
process before and they verify for the
same reasons that is that it
early on where each had order q okay so
why is this witness indistinct why are
these two exactly the same well because
H has order n so there's only one unique
value pie that fits into this equation
here okay so whether you are using this
proof this proof it's going to be the
same value so this is a bit of a
shortcut to show that I mean you can of
course also do the computations on these
values and see that they are actually
identical these proofs here but this is
a shortcut there's only one possible
proof that fits into the verification
equation and therefore its witness in
this region but all witnesses map to the
same proof so now we know that all these
01 proof our witness indistinguishable
okay now witness in distinguish with
none is not enough what we really want
for the entire proof for circuit
sensibility is of course that it's zero
knowledge so let me show you why that's
the case okay and it works a little like
this okay so we're starting starting
let's say with a real proof okay so we
have an an adversary that's trying to
distinguish am I seeing a real CRS and
the real proof or am I seeing a
simulated series and a simulated proof
right so we start out with the adversary
see is a real proof okay and i'll put
some guess 1 or 0 depending on whether
elise it's a real true for simulated
proof okay and we modify this okay so
let's compare that to an experiment
where we're running a real proof one
other simulated semi TRS okay so that's
kind of in an intermediate situation
where we use a common reference during
where H has order n but where the provo
actually knows the witness and gives a
real proof on this combo referenced ring
okay the only difference between these
two experiments is whether H has autocue
or each has order n
okay and by the subgroup decision
assumption the adversary cannot
distinguish between those two cases so
we know that here that the adversary
would not really be able to distinguish
whether whether we've seen a real
serious or simulated crs now I'm going
to look at another modification of this
game here I'm looking to add a hybrid
where H has order N and where we first
make commitments to one all over the
place instead of committing to the
witness okay but then later on when I
have to prove something I use the track
door to open all the commitment to the
witness and then give the proof okay and
that's actually no modification at all
right because all these commitments well
they are commitment to 0 and 1 at the
same time so I'm not really doing
anything different here I'm just picking
commitments which are really random
group element and giving them okay so
that's exactly the same thing and
there's no way the episode can can see
anything these things are perfectly
indistinct result to that Missouri okay
so so now I'm going to do another
modification so instead of giving so
first we commit to one so all over the
place but instead of using the trap door
to open to a real witness now i'm just
going to use the trap door to open some
commitment to zero and then give the
proofs ok so in other words whenever I
have to prove that a why I'm a your 01
well then I just give the true for that
because it is a commitment to one
whenever have to prove an and gate then
I tweak one of the inputs and then I can
prove the nand gate ok
and the claim is that these two
experiments here also completely
indistinguishable to the adversary and
the reason for this is well because we
have perfect witness
indistinguishability so there's no way
the adversary can tell whether we are
using a real witness for any of these
NAND gates all we're using simulated
witness plenty of the gates okay and now
what are we doing well we're giving a
proof where we start with giving H of
order n then we commit to ones and then
we use the trap door to open some
commitments to 0 to give the nand proofs
oh so you're thinking ok so you if i'll
try to reformulate your questions so
your question is so we have what we're
trying to do is a global proof that this
circuit is satisfiable and your concern
is what we have witnessed in this room
for these individual proves ok but does
that mean we have global witness
indistinguishability for the entire
circuit ok and the answer is yes because
we just need we only need this local
witness indistinguishability so what you
can do is you can take essentially one
of these proofs at a time for commitment
having 0 or 1 and you can show that it's
witness indistinguishable whether we use
in openings to 20 on opening to a one ok
and then you can flip one of these
proofs at a time and then you end up in
this situation here where they all a
what they all use trap door openings for
the commitments good ok so what we have
now is now we have h has order in we're
making commitments to ones and then the
simulator uses a trapped or two of them
some commitments in the nand cruise and
this is exactly what we do in the
simulation so yes
yes so your question is can we sing if
we have a simulator can we prove their
circuit is unsatisfiable and the answer
to that is yes we can do that okay and
and and well there's simply nothing in
the zero knowledge property of the sound
is that guarantees we cannot simulate
things on false statements okay so you
could pick friends in the circuit where
it's put where it's hard to decide
whether it's satisfiable or not right so
it looks like a real satisfiable
circuses I don't know some something
with a one-way function or something
like that so it's not distinguishable
from satisfiable circuit and you could
run the simulator and the simulator have
to be okay on this this one here so so
yeah you could do that yes
yes and I'm going to get back to that
little later yes
okay so what we have here actually this
is a strong form of zero knowledge what
I call composable zero knowledge okay
what it says is that we have on one hand
we could have a real common reference
drink or a signal ated common reference
drink and these are computationally
indistinguishable once we get to have a
simulated common reference during
actually have perfect zero knowledge
right it's perfectly indistinguishable
whether we are simulating or giving a
real proof okay so this is a stronger
notion than the standard zero knowledge
definition that just says combine these
two a indistinguishable from your cruise
okay so to summarize what we have now is
we have this construction of a
non-interactive zero knowledge proof
where we commit to all the wires prove
that each commitment contains zero or
one for each NAND gate we also make a 01
proof to show that it's respected by the
committed values and the total cost is
is a linear in the circuit okay and it
has perfect completes the perfect
soundness and this nice composable
zero-knowledge property and it's also a
proof of knowledge because if we have
this factorization of n if we know Q
then we can simply for all of these
commitments take CI to the q and what we
get out is due to the q raise to wi and
since all the wires are 01 it's easy to
figure out what the wire values are okay
so now i'm going to get to two pennies
that's correct yes it's true it
previously non-interactive xenon spruce
were typically statistically sound and
the reason was you you were sampling
these bits here and you had to have some
structure in the remaining bits but of
course I mean there's some extremely
small probability that you end up with
these hidden bits that don't have that
structure and then the provo could cheat
okay so that was also a tricky thing to
get and we get perfect soundness here we
do pay a little cost in that that in the
sense that we have a special common
reference drink we don't have a uniform
random common reference ring and you can
actually show that for a uniform common
reference ring you cannot have perfect
soundness as and the reason is simply I
mean there must be some common reference
string for which you can actually which
is a simulation string where you can
cheat right and if it's uniformly random
sample there's some probability that you
end up with this simulating camera first
ring and you can cheat so so you cannot
put a uniform random string get perfect
sounds but with a special common
reference during such as the one we use
here you can get perfect soundness yes
yes that's that's true i mean it would
it could be a explain and actually it
would be an exponentially small
probability and you can also have this
kind of mix so what you would have I
mean this is exponentially small
probability that you pick a bad common
reference string for which you do not
have something but if you were lucky
which happens with most probability then
you would actually have perfect
soundness on those common reference
things yes
hmm
perfect yeah that's possible I haven't
thought about that but yeah that's good
observation it very well be so ok ok so
now now I want to switch a live around
and I want to to talk about perfect zero
knowledge ok so just to give you a
little bit of history what was known
about zero knowledge proof so so
interactive truth it was pretty quick
that we got that for all languages in NP
ok computational zero knowledge and
pretty quickly we also figured out how
to do perfect zero knowledge for
interactive proofs and and of course
bloom felt McCauley they came along and
found on how to do nun interactive
proves with computational zero knowledge
and what remained was this the problem
of how to get perfect sara knowledge and
it seems like then this sampling
technique where we have hidden bits and
so forth in its inherently it's very
hard to get perfect serenity and I
certainly don't know any way that that
you can do that okay but with pairings
this is something we can do okay and I
think actually this was essentially what
what betty was just suggesting that
instead of using agent has order q we
use H so that has order n okay so we
simply start with a simulation come a
reference string and use that as a real
common reference string and what happens
now well it's easy to verify we have
perfect completeness that's just as
before and now as we argued before we
had composable zero knowledge right
which means that once we have a
simulated common reference drink we have
perfect zero knowledge so that's also
done if we have perfect your knowledge
and what remains is the to show that we
have computational soundness that
unfortunately fails so and and it's
instructive to see why that fails okay
so here's a natural idea of how would
you prove
that we have computational Sounders so I
would start with age that has order n
some adversary that comes up with a
false statement and a valid proof now I
would switch such as H has order Q and
the adversary would still produce some
statement and a valid proof because
otherwise it could distinguish between
each having order n or each having order
q okay and now we think we're done and
if we're just concerned or none adaptive
soundness where the statement is chosen
independently over the common reference
ring we actually do have that okay
because well if it could pick a false
statement where H has order N and give a
proof then and and the statements picked
in pending Lee of the comb referee
string then it would also pick in the
next instance this false statement now H
has autocue and it has perfect soundness
and we have a contradiction because you
cannot prove a false statement with HS
autocue but it's not adaptively sound
well maybe it is but but we don't know
how to prove it ok and the problem while
roughly did consider something like this
statement that H has order which is some
some prime order for instance ok and
what about this statement here let's try
to go through the argument ok so H has
prime order and when H has order n
that's a false statement right and we
imagine the atmosphere makes this
statement and that gives a proof and now
we switch where 828 the case where H has
ordered few ok and now the adversary
comes up with this statement h-has prime
order um and and here's a proof oh I
guess it's the other way around isn't it
nope
no yeah okay yes okay that's okay and
and now we have sunday the statement is
true right it does actually have prime
motive when H has over Q ok so this
argument doesn't work when the statement
depends on the common reference string
statement might say something about the
common reference string so I said when
we switch from one common reference
Taylor from a real comer reference mean
to simulate a comatose drinking we have
a problem it breaks down so the natural
definition of Sam is it seems like we
cannot actually get better for this type
of argument so let me tell you what we
can get we can get something I called
adaptive culpable sounds okay yes
right so so when H has ordered n it's
not a proof of knowledge because when H
has order in all the commitments are
perfectly hiding they're just random
group elements and then you cannot
extract anything okay so so what does
this definition say well what I'm
looking at here is we generate a common
reference string but what I require now
from that Missouri is not only does it
prove an an unsatisfiable circuit
provide a false statement and the proof
but it also has to prove a witness that
this circuit is not satisfiable okay
that the state it has to come up with a
proof a witness for the fact that the
statement is false okay and if we put
this risk right so so again I mean now
we're placing some restriction on you
know what kind of adversary we are
looking at and we would specifically be
looking at languages for which it's
possible to give proofs that they're not
that some element is not in the language
so we suddenly so we're certainly
putting a restriction on what we can do
here yes okay
III don't know exactly which classes
this would fall in them in what so I'm
not I'm not able to give you a precise
statement of exactly which languages for
which we can do this yeah yeah yeah yeah
yeah I mean again again for for all I
know actually this this this particular
zero support might be fine for all of NP
I don't know but okay so okay so so for
this type of argument here then we say
we have computational a couple the
soundness if for polynomial time
adversary it's hard to find some
unsatisfiable some false statement and
the witness that is false and the proof
that's valid okay and that's the kind of
thing that we get okay so let me sketch
proof that we have computational
culpable soundness here ok so imagine
again an adversary that could break the
culpable soundness so after seeing a
common reference during wage has order n
it comes up with some unsatisfiable
circuit some witness that this circuit
is not satisfiable and a proof ok and
then by the subgroup decision assumption
it should have the same roughly the same
success probability when H has order
cube because otherwise it could
distinguish ok so in other words when H
has autocue comes up with some circuit
some witness that this is not a
satisfiable circuit and the proof and
now we are in the case where we have a
contradiction right because when H has
autocue you cannot prove a false
statement
right so so this is this is the the end
result this is the computational to
somnos we get I personally my belief is
this is the right way to define
soundness for non-interactive zero
knowledge arguments with perfect zero
knowledge so I'll go that to that in the
next slide and try to argue my case okay
okay so so I'm claiming this is the the
right definition we should use for
perfect zero knowledge non-interactive
zero and all the documents okay and the
argument goes as follows first of all we
have some impossibility results so for
instance if you want to do some some
direct black box security reductions
then we can show that that's not
possible for perfect non-interactive
zero knowledge proofs to falsifiable
assumptions so so there's simply a
limitation this is probably the best we
can get with the techniques we know okay
and the second argument is that well
it's a useful notion because very often
we do have and non satisfiability
witness okay so one example would be
verifiable encryption okay I give an
argument that I have encrypted a
particular value okay what is the
witness that this is a false statement
well it could be the decryption key
right then you can just decrypt then you
can see a this was definitely not what I
encrypted right so in practice when we
do cryptographic instructions typically
the wildy and with this somewhere in the
system that this is not a satisfiable
statement this is a false statement okay
and whenever we have a witness that this
is a false statement then we're fine we
can use this on it perfectly a
non-interactive zero-knowledge proof and
finally we can go get kind of like
abstract framework so this is the
universal composability framework which
is a theoretical work that describes how
can we actually compose protocols how do
they fit
together and so forth right and actually
based on this type of perfect
non-interactive they're not we can
construct universally composable
non-interactive Zima knowledgeable this
is exactly what we need to construct
universally composable non-interactive
zero knowledge proofs okay so so I think
it's a right notion of soundness because
essentially what it says is that well
maybe the adversary could prove a false
statement what the adversary would never
know that that was her had proved a
false statement and would never have an
impact on the world that would never
make any difference to anybody ok and
then well do we care about such false
statements being proof no right doesn't
make a difference to anybody so that's
why I think in this particular case and
the natural definition of sound is
actually not the right one I think this
is the right definition of somnos from
non-interactive Sarah Norris proves that
have perfect zero knowledge
ok so to summarize so now we have two
different ways yes okay
yes that that should be fine I think so
yeah because what you're coming up with
you are coming up with so your carnal
example is ok here is a ciphertext it
contains zero or one you know that it
contains zero one and your claim is that
it's zero and you come up with a proof
of that ok and if nobody knows how to
decrypt the ciphertext ok and they all
in distinguish from each other who cares
whether there's a zero or one inside ok
so it may may well we be that is a false
statement but it's just kind of an
uninteresting false statement is a false
statement that doesn't affect the world
yeah ok so what so what do we have now
so we have non Interactive's your nose
proof of circuit satisfiability right
and since second satisfiability is
np-complete this means we have
non-interactive zero-knowledge pros full
of NP and we can set it up in two ways
we have this perfect binding key ok
whether H has autocue and that case we
have perfect completely perfect
soundness and computational zeros or we
can set it up with a perfectly hiding he
wear H has order N and that case we're
perfect completeness we have this
culpable soundness notion and perfect
zero knowledge ok so these are the two
ways we can set up for the common
reference string and the adversary has
no clue which type of camera referenced
ring is looking at you ok any questions
so far on this part
right
are right right okay so okay so then
guarantee you get here from this type of
non-interactive cirno's proof is
essentially you have to trust the setup
hey so there's a um trusted setup okay
so maybe you trust this so you trusted
so right so if you trust that the setup
is with one where H has autocue then you
know you have perfect soundness and
you're you're happy depending on what
kind of properties you want from from
this right and and this is not so
different from what you have with any
other type of non-interactive is your
knowledge proof right because again you
trust the setup to come up with a cum
referenced ring that will give you the
statistical soundness right because
otherwise it could produce a simulation
come a reference ring and you wouldn't
have any soundness okay so i want to i
think i still have a little bit of time
so i think i want to start on the next
part
okay so so what I want to do now is I
want to move to more to what a practical
non-interactive zero-knowledge proof ok
so so again if we look at what kind of
efficiency do we get a 4 non-interactive
0 now this process well we know that
with these hidden encrypted it's it's
just horribly inefficient because the
sampling process took really very
wasteful okay and what I've shown you
now is you know how to get very
efficient than interactive zeros proof
for circuit satisfiability but in
practice people don't go around with
circuits and want to prove that these
are satisfied what they have is
something very concrete right they're
constructing some type of group
signature scheme and they want to prove
that something they have encrypted a
signature on something okay and we would
like to have proves that can work in
this type of context okay so the goal
here is to get something really high
efficient something that's practical
okay and and what I'm trying to do here
is to come up with a non-interactive
zherneau's proof that can be used in
pairing based protocols so whenever you
have some pairing based construction
these are the type of proof that you
should be using okay and and very
importantly here right what we want to
avoid is this kind of NT reduction you
get right i mean obviously we can prove
everything because we've just proven an
NP give improves for circuit
satisfiability which I np-complete so
you can always take some pairing based
statement and reduce it to a large
circuit and then give a proof but that
would be extremely wasteful this
conversion to a circuit so we would
rather have something we can use
directly so i'll give you one concrete
example so this is from boilin and
waters in 2007 they came up with a group
signature scheme okay and the statement
contained a bunch of elements both
modulo n and in a group and something in
the target group and the proof was
witnessed were were these four group
elements that would satisfy these two
equations here okay so this is the kind
of statement that comes up in
practice okay this is a pairing based
type of statement okay involves the
operations we can do in by linear groups
and what they would like to do is to
give an efficient non-interactive
zero-knowledge proof of knowledge that
they have these folk know these four
group elements that satisfy these
equations okay and they came up with a
six element proof of knowledge of this
consisting of these elements here okay
so more generally if we think about the
constructions we can do in by linear
groups okay so we can have elements in
in the group who can have some elements
in integers modulo n we can have some
elements in target group as well okay
and we cannot come up with some
constructions right we can add or
multiply elements modulo n okay or we
can do exponentiation of group elements
to some exponents or we can do some
pairings of different elements okay so
these are the operations we have
available in a bilinear group and now
suppose somebody has come up with some
constructions in a bilinear group right
and then there might be somebody else in
the scheme that says you know are these
constructions actually correct right and
here we would like to be able to say
yeah yes they're correct here's a proof
ok and this proof we would like to be
very efficient
okay so i'm going to use a new type of
commitment scheme a commitments keep to
group elements and it's very simple and
it's very similar to the commitment
scheme i used before so we can set up
the commitment eh this is how order q or
such as it has order n and to a commit
to a group element i'm just going to
take the element x and x h to the are
okay and if this is a real common
reference string where H has autocue
then this is perfectly binding to X in
the order P sub group right because H
lives in the order q sub group but does
not affect what happens in the order P
sub group okay so more precisely if I
let lambda be a value which is 1 modulo
P and 0 modulo Q then c e raise to
lambda is essentially a prediction down
on the order p sub group and it is
uniquely determine some eggs to the lamb
/ and of course if this is a simulation
common reference string well then each
has order n and what we get is just a
random group element and that's
perfectly hiding
and we have some very nice homomorphic
properties also for this commitment
scheme here okay so what we have now is
if we multiply two commitments to group
elements we get a commitment to the
product of the group element and of
course well as a special case we could
have G to the X then we have the
commitment scheme from before right
where we multiply two commitments to
exponents and we get a commitment to the
sum of the exponents we could also do
pairings of commitments so suppose would
care to commitments together commitment
to x and y and what we get now is a
commitment to the pairing of x and y ou
K similarly what if we well from before
we had if we pair two commitments to
exponents that we get a commitment to
the product of the exponents and then
finally we could mix and match ok so
what if we take a commitment to a group
element and pair that with a commitment
to an exponent and what it gets us is a
commitment to the group element raised
to the exponent so in other words with
these commitments to respectively group
elements and exponent we can do all the
bilinear group operations underneath the
commitments we just pair the commitments
together and we get respective pairing
commitments to pairings of group
elements or commitments to
exponentiation zuv group elements or
commitments to sums or products of
exponents
so this is a generalization of what we
had before and it turns out that it's
quite useful and gives us some very
efficient non-interactive zero-knowledge
proof okay I'll let me correct myself
non-interactive with this industry in
visual person okay so let's consider the
equation as an example so I want to
prove that here I have constants
publicly known a and and this target
element eid in the target group and I
want to prove that there's some x and y
that satisfy this equation here and what
I do is I commit to the variable so it
commits to the X I would commit to why
and I want to prove that these committed
values satisfy the equation okay so the
proof will be in on this form and what
we do to verify it well we repair a
publicly known value with a commitment
to y and we pair the commitment to X
with the commitment to why okay and we
would see that this is the same as the
target that we wanted to to hit and
something that has order q ok so now you
can do the computation you can plug in
this this pie here in this equation and
you can see that everything works out
essentially what we have is that the
randomness respectively h to the s used
to hide why and H to the are used to
hide eggs well it all goes out here and
gives us the proof so that gives us
completeness yes
right
yes
okay so you're thinking about say a
multi-party computation setting or
something like that where people have to
commit to their randomness and follow
the protocol is that would
right right right um I think you could I
think you could do that kind of kind of
thing with the weather it was a couple
of a couple of reservations okay so one
one thing is I think for for these type
of construction you actually need a
proof of knowledge of some randomness
are ok now the problem with these
constructions is if you commit to an
exponent which is lives in zp
essentially you may not be able to
compute the discrete logarithm and
extract that exponent so therefore these
proofs I'm going to talk about now
they're not it proves that knowledge
respect to the exponents and that may
interfere with whether what you have in
mind
okay so let me just show you that this
is a sound as well okay so consider an
equation okay so we have this equation
here and we have the corresponding proof
where we just basically take instead of
the variables we put in the
corresponding commitment right and see
check that that's the same as a pairing
of age with the proof okay so why does
this give us soundness when H has order
q well we just take this lambda here the
projection on the order P sub group and
apply that to both sides of the equation
okay and notice here that I chose this
projection such that we project twice we
still get the same thing so the lambda
is the same as lambda square so what we
can do is basically we put lambda square
on both sides and and by the properties
of binding you groups that splits into
the underlying group elements that we're
pairing right so we have here a to the
lambda D to the lambda C to the land d
to the lamp and so forth okay and what
does that give us well it gives us
immediately that in the order P sub
group X which is C to the lambda and y
which is d to the number satisfy the
original equation right because in the
order P sub group this thing just
disappears so that gives us soundness
near order P sub group
okay and finally why is this witness
indistinguishable okay so witnessing
distinguishable ability that's what we
get when we have h has order n okay so
what happens if the H has order in well
all the commitments are now perfectly
hiding and that means that there are
many possible openings of each
commitment right because it's just a
random commitment so there could be many
possible openings that satisfy this
equation here that many witnesses ok but
when H has order n there's one unique
proof which will satisfy this equation
here there's one unique n that will fit
in here that will satisfy the
verification equation because each has
order n ok so in other words even if we
have two or more different openings of
the commitments and they satisfy the
original equation they will all map to
the same unique proof and therefore its
witness indistinguishable all possible
openings of the commitments that would
satisfy the equation they all map to the
same unique proof so the proof does not
reveal which witness we started out with
and that gives us witness
indistinguishability um okay suggest to
recap from from the last part what what
assured was a simple example a simple
equation where we could take have
commitments to the values some of the
values in the equation and show that
these committed values satisfy the
equation right and what's really going
on is that whatever homomorphic
operations operations we can use in the
bi-linear group we can do the same on
the commitments and that the committed
values we are essentially doing the same
operations on the committed values okay
and that gives us a proof
so okay so this was just one equation
okay and this particular equation is
kind of trivial is satisfiable of course
there's some makes and why that satisfy
this equation but when we have many
equations then becomes more tricky right
then it becomes more interesting type of
this statement we can make so so more
generally we can consider statements
that have many equations and we want to
prove that there's some variables X eyes
and that satisfy all the equations at
the same time okay so we have some
variables and we have many equations
over these variables so what we can
prove is that the some secret values x1
throughs exam in the group let's satisfy
all of these equations and what we do is
exactly what we did before we commit to
each variable we just do this once and
then we have commitments to every
variable and then we plug every
commitment into to the equations and
give proofs for every single equation so
that gives us a non-interactive witness
industry improves for a very general
class of equations so these are called
pairing product equations right because
you're taking up trade products of
pairings of group elements and they can
evolve both publicly known constants
that I've known to the verify so the AI
is here or the exponent gamma IJ that
can be no they're known to the verifier
that's part of the statement and then
you have these secret excise and the
claim is that there's some set of secret
exits that satisfy all of the equations
at the same time and you can easily
generalize the example I had before you
commit to every single X I and then you
give a proof for each equation that
these committed values satisfy the
equation
okay and each commitment costs one group
element each proof costs one group
element so what you end up paying is a
price of the number of variables you
have plus the number of equations you
have
you can generalize this even more
because of course we don't have to just
do pairing operations we can also do
exponentiation operations and
multiplications in the group okay or we
can do quadratic equations over the
exponents so we can multiply an ad feel
the 11th module and okay and you can
actually generalize this and do proves
for all of these types of equations you
can commit to some group elements in the
sauce group you can commit to some
exponent values okay and you can prove
these committed source group elements
and exponents satisfy all these
equations where the equations can be
different types so you can have both
carrying products multi exponentiation
products and quadratic equations and
that gives you full generality right
because these are the operations you can
do in bilinear groups yes
right right so yeah so you could ask I
guess more general questions okay so say
you have an arithmetic circuit or
something like that and and you could
say you know if you have an arithmetic
circuit of depth be then you can compose
it in two layers that have depth to so
to speak write and compose them so if
you have some intermediate values you
commit to those intermediate values and
then you can do in full arithmetic
circuit for instance okay then you can
generalize Hera thematic Swagger's to
also include some pairing operations and
multi exponentiation yes so essentially
everything you want to do in the pairing
based world consists of pairing or
multiplications of exponentiation
multiplications and asians of relevance
module and okay I think there's one
exception here we can't really do things
that live in the target group so so we
can because our cook we can commit to
things that are in the sauce group we
can commit to exponents module n but we
can't really commit to things in the
target group into sensible operations on
those so that's still an open problem if
some way to to deal with target group
elements
okay so what are the properties of these
non-interactive witnesses
indistinguishable well the two types of
common reference spring right H can have
order q or H can have order n okay and
these are two indistinguishable types of
reference strings in both cases we get
perfect completeness if it's a real
common reference drink where each has
all the Q then we get perfect soundness
in the order P sub groups and if it's H
has order n then we get perfect witness
indistinguishability so even if you have
many different types of witnesses that
satisfy all these equations you cannot
distinguish with which witness has been
used to generate the proof okay so this
was an example of how to do that with
composite order groups and it's useful
to think a little about what is it
actually that makes things work okay so
try to draw that with some some diagrams
so what we have here are commuting
linear and by linear maps between these
groups right so if we take to source
group elements we can use a paring and
get a target group element so what are
we doing here in this proof well we have
some variables x and y that lived in the
sauce group right and what we did we
commit it to those values so you can see
the commitment as kind of a a mapping
from from the group into the group
itself but where we put some additional
randomness on top of it okay and we
could do some comparing operation on
these group elements and then we'll get
something in the target group right and
we could also map the target group
Baldwin's we could do some randomization
with something that has autocue which
does not affect what happens with order
in the order P sub group of the target
group okay so so we started out with an
equation that lifted in these groups
here and use the pairing and then we
mapped it into commitments and some
verification equation that have some
some proof okay and the proof here
together with H lift in the
you subgroup and then to prove soundness
would use this projection here right we
raised to the lambda exponent which was
one module p + 0 modulo Q so it kills
out anything that has order q okay and
what we get then is the projection of X
to the order P sub group and the
projection of Y to the order P sub group
okay and the projection of target group
element in your P sub group and they
satisfy this original equation but now
just in the order P sub group okay so
all of this construction from a high
level perspective is because we have
these maps that are linear and bilinear
and they commute with each other now I'm
going to generalize this okay go beyond
just the case where we have the sub
group decision assumption okay so more
general when we use pairing based
cryptography well one thing is it's not
to use prime order groups because it's
more efficient to use primordial groups
okay so one nice thing would be to
generalize such we can choose whether we
want prime order of composite order
groups okay also the pairing groups
these groups the source groups well
maybe they're identical or maybe they're
different okay
yes yes yes yes so so so once i get to
the non-interactive witnessed in truth i
will give you some assumptions on what
I'm thinking yes ok ok so suppose we
have modules a-one a-two and a target
module well the statement will be
quadratic equations it's changing right
so we can have some secret variables X's
in a one wise in a tube and the claim is
that while we have a bunch of equations
we have these secret exits and we have
the claim is that there's some secret
X's and Y's that will satisfy all the
equations and all the equations will be
quadratic equations of this form
okay and the provo will know this secret
witness and that satisfy all the
equations and and use that to give
proofs and to simplify things i'll try
to use some some linear algebra notation
okay so so consider this inner product
here right that's just the usual inner
product we take x1 with be one here x2
would be too and so forth and add them
up okay so this equation here can be
written simply in the simpler form like
this where now we have vectors a and why
and so forth so those are the types of
equations that I want to prove a
satisfiable so I want to prove that I
have some some X vector and some Y
vector that satisfy all these equations
have many equations this for me
okay so so I'm going to again do as
before us I would like to make
commitment to these values here okay so
i would like to commit to the X's and
Y's and for that purpose i'm going to
map them from the module a that the
living into a different module be and in
the module be i'll make the commitment
okay so i'm going to assume here that i
have an inclusion map that can map from
a into a module be and i'll assume that
have a projection map that can map from
B to a module C and actually later on
we'll see that its soundness is what we
get in the modules see the sea modules
okay so just if you have the mind in the
example we had before with the composite
all the groups right here the a module
that would be a groove the sauce group
the b-mode work module will also be the
source group right because the
commitments live in the same group and
the sea budget that would be the order P
sub group where we projected into it to
get soundness ok so the setup then the
common reference string will describe
some elements in the module be that we
use for commitments and we're going to
commit to a value by mapping it into B
and then adding random linear
combinations of these new elements
okay and if if the image of the
inclusion map lives in the span of these
elements here then this is perfectly
hiding right because this linear
combination will just give some
something random in the span of the you
values okay and then it's perfectly
hidden whatever element it was that we
mapped into here so that will give us
perfect hiding and then a commitment it
will be perfectly binding to the
projection of that commitment right so
and actually force honest purposes we
would like the projection of these use
to be zero so whenever we project
something we cancel out all the you
values that we have added and again this
is very similar to what we saw before in
composite or a case right here in the
composite order case this age would be
one of these you values here okay there
would just be one of them okay and then
whenever we did the projection right we
mapped it into the order P sub group and
we just killed off the age let me okay
so let me just note one thing that in
general this projection here will be
hard to compute okay that's infeasible
to compute so so we can actually even if
they verify knows the commitment it does
not know what we have committed to okay
on the other hand of the inclusion map
has to be easy to compute because we
have to be able to make these
commitments
okay so let me give you an example in
the order P group ok so here what we'll
do we'll do the inclusion will take so
we'll have one module the a module
that's just the source group okay the B
module that's a cross product of the
source groups okay so that's g2 and then
we'll do projection down again on the
sauce group okay and what does the
inclusion map look like well basically
just take X and map it into 1 comma X
and what does a projection look like
well if we have two group elements we do
this computation here and this is an El
Gamal decryption and what is the alpha
while these elements here have been set
up such as you one is essentially
el-gamal encryption key and then we have
you too which is this random age in H to
the alpha plus towel and there can be
two ways to set this up okay so i could
set it up with tau equal to zero a towel
being different from zero and that will
be kind of respectively a real common
reference stream or a simulation common
reference string okay and if the
decision diffie-hellman problem holes
holes in this group we cannot
distinguish whether we have chosen tau
equal to 0 0 tau different from 0
okay so commitment here while we would
take some linear combination so will
include first we will take X map it to 1
comma X right and then we would take a
linear combination of the you elements
and here we're using multiplicative
notation okay so linear combination of
the you elements would be we have here g
to the r1 okay and then we would have an
and here g to the alpha 2 r1 so that's
our one on the you one element and then
for the you two element we have our two
so we have h to the r 2 and h to the r22
the alpha plus tau
ok so if tau is different from zero this
is actually perfectly hiding commitment
scheme okay because what does it give us
it just gives us some random group
element here and some random group
element here ok so our one random as you
can see our one is randomizing the first
one and r2 randomizing the second one
completely on the other hand if tau is
equal to 0 then this is actually an LG
mal encryption of X because if tau is
equal to 0 well then it would just have
something raise to r 1 r 2 and the same
thing reefs are one or two raised to the
elk MLP alpha and this is just an LG mal
encryption of X and what is the
projection map that's an LG mount
decryption right so they'll kemal
decryption of this thing would give you
X
okay and it's useful to note that if you
do the elca mouth decryption on the
owner LG Malky then you just get one
right so these new elements they just
canceled out under the decryption with
them come up so what we have here is an
example of a commitment scheme which on
when tau is equal to zero is an El Gamal
encryption of X and if tau is not equal
to 0 then it's perfectly hiding
commitment scheme so that's one example
of how you could set these modules up
but there are many different ways you
can sit down and on many different types
of assumptions okay so back to the
modules okay so we have this common
reference string and what it will
specify our zp modules a 1 a 2 a target
B 1 B 2 B target c 1 c 1 c 2 and c
target and linear and by linear maps so
inclusions from a 1 so b1 okay and
projection from b1 2 c1 and simply the
inclusion from a 2 2 b 2 and projection
from b to c 2 and the same for the
target groups and then we have this
bilinear map from a1 a2 into the target
module a and from b1 b2 into the type of
module BTW be and from c1 c2 into the
target see and is useful to think about
where do they take different things take
place so the provers witness that's in
the a modules right the provo has some
X's and Y's that live in the a modules
let's satisfy all these equations so
what's the probe are going to do it's
going to commit to these values these
commitments live in the B modules and
it's going to give a proof that's in the
B modules and we're going to verify the
equation in the B modules and then when
we argue about soundness what we're
going to do we apply the projection map
and we get soundness in the sea modules
now in the example I gave you before we
actually had a module's and see modules
were the same and then you get soundness
in the original group that you wanted so
let me see if I have an example for that
okay and so what do these examples
things look out would look like with
this Elgar Mallos type encryption
commitment scheme okay so we had these
maps here okay and we saw that well if
we had an element X in GG 1 then we
would map it into 1 comma X and if you
project that and do el gamal encrypts
you just get out X again right so that's
that's fine okay and then we we have I
mean we have an equation of a g1 g2 into
the target group okay so we could let by
linear map here would be pairings of
group elements in g1 and g2 now a
corresponding bilinear map from g12 to
the g2 two would be this thing here it's
essentially a tensor product with a
parent and then you could do a
projection here you would essentially
get this last one here so I wrote down
here in details what these particular
maps are
so as one example of these modules here
we could use this particular setting
here and we will get proves
non-interactive with this industry group
rules for statements over this in this
case in a symmetric bilinear group with
a g1 and g2 mapping into a target group
okay and in this particular example here
we can see that the a modules are the
same as the sea modules we get soundness
for the original equation that we
started out with okay okay so what is
the setup here so the common reference
string describes all these modules all
these maps here and also elements that
we use for the commitments and we're
going to set up the common reference
string in two possible ways okay could
be an witness indistinguishability
string and in for that case we want all
the commitments to be perfectly hiding
so we want the inclusion of anyone to be
in the span of the you of the the
commitment elements you want through um
and the inclusion of a two to be in the
corresponding commitment elements in B 2
which is V 1 through VN okay so in that
case the commitments would be perfectly
hiding or we could have instead and
common reference string where we get one
to get soundness in that case we would
like the projection of all the elements
in B 1 to be 0 and the projection of all
the elements in B 2 to be 0 such they
will cancel out when we argue soundness
ok so again the statement consists of
these quadratic equations right which we
can simplify like this okay so we have
some inner product or some some vectors
and we want to show that a bunch of such
equations are satisfied simultaneous by
some X values in some Y values and what
are we going to do while we're going to
do the same thing as we did before we're
going to commit to all these secret x
values and y values plug them into
corresponding equations in the B modules
and give a proof in the B modules and
and that's it and then Sounders will be
argued by projecting down to the sea
modules ok so the first step we do to
give this proof is we commit to all the
X's and all the Y's and again now I'll
use this notation here the inclusion of
of a vector that's just the inclusion of
x1 inclusion of x2 and so forth so that
gives us another vector so we get a
vector of commitments to the X values
and the vector of commitments to the Y
values
okay and each of those commitments
contain a linear combination of the use
so if we have many such then it becomes
a matrix times this new elements and
corresponding thing in b2 for the video
elements okay so now what we do is we
take each of these equations and map
everything to the B modules okay so
we'll map all the eight public a values
into the B modules all the public p
values into the new modules the vector
the matrix gamma or containing some some
exponents that's just the same as before
the still elements in zp ok so we map
everything into the B modules and in the
B modules well we have these commitments
to the Y values and to the X values and
then we'll give some proofs ok so we'll
have from part of the proof will be a PI
vector that lives in bb2 module and
password with these five volume which
lives in be one module and a verified
we'll check that this equation holds
okay so let me ask you why we have
sounded here okay so we have these
equations here and for each equation the
verify will check that this holes so
what happens if we apply the projections
on these well we know that projections
of the you values give us 0 under sound
new string and the projection of the V
values give us 0 on a sounding string so
that means whatever we have over here
we'll just project 20 and whatever we
have here we'll just put it project 20
it will cancel out right because it has
something with the you values something
with v values and they are projected
down to zero and what we're left will
then is the interesting stuff that has
something to do with the secret
variables and the equation we wanted to
verify okay so if I just do some some
redefinition to avoid too much
notational clutter here so after the
inclusion of a and the projection we get
a prime and similar for the other things
what we end up is now this equation here
in the sea modules after projecting so
we'll have a prime times u prime Y Prime
and plus X prime inner product with the
B prime plus X Prime in a project with
gamma times y prime is the same as the
target prime plus 0 for 0 because these
things you and these they just project
it down to zero okay so essentially what
we have now is some X Prime and some
white prime values let's satisfy the
equation after having projected the
equation down to the sea modules okay if
the a modules and the sea modules happen
to be the same and this is the identity
map then we have proven soundness for
the original equation but as we saw
before right I mean for the composite
order case we couldn't get soundness for
original equation what we get was God
was soundness in the order P sub groups
okay so maybe the sea modules
other than the original eight modules
okay so i tried doing this for the
example from before based on el canal
the commitment schemes here so here we
have exactly that the a1 module that's
g1 and the c1 module that's g1 right so
those are the same and after including
and then projecting you just get the
same value as you had before ok so in
that case we get values X values and y
values that satisfy the original
equation that we wanted to prove was
satisfied
okay okay so then I have to argue that
it's complete okay and what we do for
that is essentially a lot of computation
ok so the probe has these commitments
here okay commitments to values the
witness that satisfy the original
equation you map everything down and you
want to construct proof here and prove
here that you can make this equation be
okay and what the proofs look like
something like this and then you do a
lot of linear algebra and you see that
everything works out essentially what's
happening here is after mapping down to
the B modules we have D which is
commitments to the Y values and we have
C which are commitments to the X values
okay but they have both of I of others
in the X values but they also have some
randomness and you take all this
randomness and pull it out and put it in
proof so you balance the equations
okay and finally we have targeted this
is witness indistinguishable okay so if
we have a witness indistinguishability
common reference string and we know that
by definition that the inclusions of a
one and inclusion of a two are respected
within the span of you values and the V
values and the commitments are perfectly
hiding ok so the commitments are
perfectly hiding and that's of course
great but we have to make sure that the
proofs don't leak any information part
of witnesses so what about the proofs
well if the proofs were unique then we
would have perfect witness
indistinguishability because that would
mean that all witnesses mapped to the
same unique proof ok so that was the
case we had in the composite / case now
in general that's not what we get and
generally the proofs are not unique ok
so in particularly in the example I gave
you based on LG mal commitments actually
the proofs are not unique there may be
several different proofs that satisfy
the verification equation so what do we
do if that's not the case well we'll try
to randomize the proofs so the proofs
are completely random ok so in other
words the proof looked like a completely
random proof that satisfies the equation
ok and since they completely randomly
means that any two witnesses they would
just map to some completely random proof
and you could not distinguish between
two witnesses so that's another way to
get perfect witness indistinguishability
make sure that the proof can be
completely randomized
okay so one way to randomize it is the
following so suppose we start out with
some some proof that we have for this
equation here well we can take this
proof pi and add some matrix t
multiplied with the v elements and then
subtracted over here okay and that's you
know those two just adding it here and
subtracting it here that just cancels
out okay so this would be a new proof
for the same statement but now we have
done some randomization of the proof
okay and since this B value here spans
everything that this proof will map into
if we look at the proof that the way it
was constructed actually this is a
completely random proof in the span of
the V vectors so this operation here
randomizes one of the proofs one of the
proof vectors now it's possible that the
second one is unique and then we're done
then we have completely randomized okay
and in the example I gave you based on
these DD age groups and elk Emily
commitments that's actually the case and
we're done we have done complete
randomization and we get witness
indistinguishability it's not always the
case you can come up with for instance
proves based on the decision linear
group where even after doing this
operation here now we have randomized
one per part but but the other part is
still not completely random what you can
do then is to ensure that you also have
some you just add some more randomness
here in the orthogonal space with we
took make it completely random
okay so that's the overview of the
construction so we start out with some
equation in a modules we commit to all
the values just plug them into the
equation the same way after mapping
everything to the B modules and then
we'll get some proofs here in the B
modules okay and essentially yeah we
showed completeness that you can do this
if you have a witness in May modules you
can map everything to something the B
modules that satisfy this equation okay
okay and then we show that well if you
apply the projections this one here
cancels out this one here cancels out
and we get soundness in the sea modules
okay and for witnessing distinguish
ability important thing was simply to
note that all these commitments in the B
modules they're perfectly hiding and we
can randomize the comp roof completely
using a bunch of linear algebra
okay any questions so far yes
that's yes yes okay so so what what do
you gain from from doing this apt
abstraction so what you get is you get
get first of all you get the
generalization that you can get
non-interactive witness individual
proofs in the cases that are not
composite order case but which are
really interesting right so for instance
the a symmetric case whether you had
decision difficult in both groups that's
an important case because that's why we
have the most efficient pairings and
where we get the most efficient schemes
so you get an efficiency again you get
applications in the most efficient
setting for pairings right you also get
some some resilience in terms of
assumptions right because you can
actually you can base this on you can
base it on decision day for helmet as I
did an example but you can also based on
decision linear assumption or you can
base it on the K linear assumption and
so forth so you automatically have a
large class of non-interactive witness
interesting visual proof depending on
the assumption you want to use so it
gives you a lot of flexibility yes so
the instantiations would be would be
different but we have a general compiler
that says you give me any assumption and
the groups and now you can i can give
you the corresponding proofs and system
okay so so what I want to talk about
next is zero knowledge okay so are these
proofs zero knowledge well they are
suddenly perfectly witness
indistinguishable if we happen with this
indistinguishable common reference
string but are they also zero knowledge
okay so do these proofs reveal anything
useful so that is serving okay and the
way to think about this is well if we
want to prove that there's their
knowledge we have to be able to simulate
right and how we're going to simulate
here well it's not clear right we have
we know that we cannot distinguish
between witnesses that if we don't have
a witness to start with we may not be
able to simulate yes
okay so the question is can we can we do
some sort of or proof um well you can do
that in some of these constructions you
can do or proves and if I have the time
I'll get back to that a little later um
but even so you actually get some some
trouble with the simulation even for the
or prove you still need a witness
something you could plug in that looks
plausible for the real construction so
so what you could do you could of course
do a general all or proof in the sense
you reduce it to a circuit which is an
or but then you're losing efficiency
right so you want to do something that's
direct for these groups you don't want
to lose efficiency by doing this kind of
reduction okay so the problem is we
cannot simulate proof without knowing a
witness and the way into to get around
this as I'll show you is that we can try
to set up this witness in this room
should will come a reference drink such
as similar it can actually find the
witness now we cannot do that in general
but we can do that in some special cases
in one special case is if one of the
modules is zp ok so this covers
multiplications of elements modulo P
this covers the exponentiation right but
it doesn't cover pairings of group
elements but it's an important subclass
of problems and here we can get zero
knowledge okay and the way it works is
as follows so suppose a one is instant
CP so this inclusion hear of a one on w
is us would be in the span of the you
elements that means since they're
perfectly hiding that we could set up
the commitments such the inclusion of
one is the same as inclusion of zero for
some known combination of the use
it's exactly the same as we did before
in composite or group we set up a trap
door commitment scheme where we can open
it as one or a zero and that's what
we're going to use as a simulation trap
door now we can rewrite the equations to
this form here so basically I'm taking
the t and moving it to the other side
okay and writing as one x minus T okay
so now we have a new equation okay we
rewrite all the equations that like that
that's fine but now what we can do is we
can pretend that the one is actually a
variable okay so the one here is a
variable eggs not and what we'll do is
we'll say the inclusion of one is a
commitment to X naught of course it's
easy for the verifier can check that
well yes the inclusion of one that's the
commitment see not and it has to be a
commitment to one on the soundness
string on a witness indistinguishability
stream their knowledge string right we
can actually open this X naught to both
a 0 or a 1 because we know a trapdoor
for the commitment scheme
okay and now we have a witness for every
equation the witness is set everything
to be 0 X nor 20 x is 0 Y is 0 now we
just have 0 all over the place that's a
witness so by this little rewriting of
the equations the simulator is now able
to find witnesses and then it can use
that witness to create proofs and buy
the perfect witness indistinguishability
this looks like a real proof okay so
this is a perfect simulation and we get
perfect zero knowledge
ok
the only remaining thing is water if we
have pairing product equation okay there
we can't do this trick here we can trap
door open commitments to group elements
unfortunately but if we restrict
ourselves so the only problem is we
might not be able to find some witness
such as we get that target element in
the end but what if we just restrict
ourselves and say the target element has
to be one okay or each pairing of G with
G rate to zero and in that particular
case now if we choose all the X's and
all the wife-to-be ones as well we
satisfy this equation here everything is
one and the equation is satisfied so in
this particular case restrict the space
of equations we can also give witnesses
for the pairing project equations ok so
in this case the simulator just picks
all the exercise to be one all the YJ is
to be one so these are group elements
and all the exponents to be zero and it
has a witness and it can give simulate a
proof
okay so what kind of efficiency do we
then get here okay so the cost of each
variable g1 if I use the example at
before based on the decision difficult
main assumption well each commitment to
a variable or an exponent in g1 zp
that's two group elements right because
each commitment was an essentially an El
Gamal encryption or two random group
elements and the same for commitments to
Y values just they just live in in g2
and the pairing project equations while
they cost for group elements each okay
and multi exponentiation are a bit
cheaper and the cheapest ones on the
credit radical equations so this gives
us really efficient non-interactive
witness indistinct through proof or if
all the target elements here are one
that gives us zero knowledge Bruce okay
now of course it's not as nice as the
composite or a case where the group
elements had just one group element for
the each commitment one group element
for each proof but these groups here are
much smaller so if we look at it in
practice these proofs actually much more
efficient than new composite order case
okay do I have some time left five
minutes okay let me just pop up some
slides and speed through five minutes
and see how far i get
okay so i just wanted to show a couple
of cool things that one one can do okay
so what we have now is is I guess what
you really want to use in practice we
have these non-interactive witness
indistinct roof non-interactive their
knowledge proof that you can use in
tearing settings right now focused here
on the on the isometric setting where we
have two different g1 and g2 with Prime
order because I think that's the one
that gives the most efficient
constructions in practice okay so let me
see what I can do in five minutes okay
so so one thing I want to remark is
first of all this this question here
what can we do if we don't have a common
reference string and we know that zero
knowledge proves that just out of the
question right that's what approved
before but the interesting thing is that
it turns out you can do non-interactive
proofs that are witnessing distinction
without a common reference string okay
and let me just try to briefly describe
the idea so the ideas are following okay
we could try first a naive idea what
would we do to convince the verifier
well approval would pick a common
reference string and send a proof to the
verifier and of course this is a stupid
idea right because the prover might take
a simulation common reference during and
simulate a proof and you know it
shouldn't convince the verifier ok so
the verify says no to that but what you
can do instead is you can pick tool
common reference string that are related
in a particular way such that the
verifier is guaranteed that one of them
is sound ok but the verify cannot tell
which one of them is the sound of string
but the verified doesn't care right just
catch that one of them is a sound in
string and it's easy a proof
corresponding to that string ok so what
will happen here is that the prove our
pics to related common reference strings
and gives proofs for each of those
common reference strings and if one of
them is sound then the verifier is happy
that we can set up okay let me see BGN
groups are not right yeah yeah proof
proof get two different proofs with the
same common reference string yeah one
might be able to do that I haven't
looked at it so maybe yeah okay right
yeah so that's both an assumption
question I mean because you need two
extra assumptions 2d randomizes apps and
and there's an efficiency question that
with this is an efficient construction
ok so I just wanted to briefly show you
two related crss so this is based on the
decision linear assumption it has a
bunch of group elements and the only
difference between the two camera
reference ring is in the last element
here we have W not here we have W naught
times age ok and then that will
guarantee that well essentially think of
this HS as the Tau that we had before
right so one of them could have tau
equal to zero but not both of them one
of the Taos has to be nonzero ok so
these are two common right for related
common reference rings so you know one
of them is a sounding string and now
we're happy we get witness
indistinguishability i'll skip the proof
of that since I'm short on time and I
wanted to mention briefly a little more
I have two minutes left if I'm correct
here ok so a couple of other nice
properties some things that you cannot
typically do with other types of zero
knowledge proof in particular you cannot
do these things with the fear me
heuristic ok so one of the thing no
things to notice that proves a group
elements what does this mean we can give
proofs of proofs for instance right
because proves are just things over you
prove things about group elements ok so
we can have a proof then we can prove
that we have a proof we can prove that
we have a proof that we have a proof
okay and things like that that would be
horribly inefficient with the field
shamir heuristic because you would have
to prove things about a hash function
and how it evaluates and so forth okay
another nice thing is that we can modify
and and randomized proves okay and this
is something that that Anna is going to
talk a little about tomorrow I think so
so she was one of the first to notice
this and come up with some nice
applications of that so let me just give
a brief example of how one can do that
so suppose we have this proof for this
equation here well you can just
randomize it you can modify the
commitment live you can modify the proof
correspondingly and then we still
satisfy the equation okay so we can
randomize the commitments we can
randomize the proofs and we can also do
other operations and we actually
modifies now we're proving different
statements from what we were proving
before but related to things we've seen
before and this is again is a unique
feature of pairing based proofs
something you cannot do with the future
mirrors take all the other proof systems
we know based on the hidden random bits
model okay and now I'm out of time I'm
afraid okay thank you
hello everybody in this video I will
show you how to implement to a pair
fighting algorithms namely die strong
and a star in Java so what does this
time
so this one adds our entry point class
which will actually execute the program
but since we're they don't be graphs I
think it's reasonable to start from
defining the graph nodes that graph is
short for directed graphics used
throughout literature so get used to it
sorry
so IDE zero actually identifying a
particular graph node and Everson
winning in this video is actually this
set of children I use a hash table so
that we can ask for children in like but
it personal is a child bound in constant
time L so sample going to put those de
Graaff notes in pairs table base data
structures we need to define at least
two methods
and the first is boolean false the
object and also 15 - code so on hash
code is easy just put on the ID it comes
to this 100 is you know or get class the
path come on one
which are false otherwise
yeah so if the nonsense MIT I consider
it to be the same s all when we bring to
it are something like yeah no I do yes
yes that's all it's a good practice to
put those annotations if nothing nothing
else for the sake of documentation L so
22 minutes topic deployed earth below
the note child see you then this has
imposter time finally
that we expose the internal data
structure but we can multiply it
sometimes we prep the set in sort of
unmodifiable wrapper okay let's go on
eat bread weight function yep
this is one this is going to be easy
so we need only to mediscare
yeah
finally okay not not quite finally but
we need the heuristic function for a
star but just we're going to be in
interphase and you see later why
next we're going into actual Euclidean
eristic
hmm
okay we don't
they stopped that time
all right here we go
I will explain you some details before I
go to implementing the a star so let's
start from the node class so once again
de Graaff stands for directed graph
don't don't stress is actually how
people call directly class in computer
scientific literature and the identity
of each notice in specific in just an
integer ID value and also we have this
overriding we'll have over on this
equals and hashcode minutes so basically
it allows us to put and manipulate our D
graphs in hash table data structures so
actually if you don't know what by the
way was over right is it means that we
are operating some method which is
present in some base plus the funky part
about override is that if you sort of
spoil something like the signature of
the method being overriding your ID will
most likely override this and not your
about this issue so it's nice to use
override annotation okay what's next
yeah we actually if you look at this we
have the set of children's children is
not the least but it said the the point
is that you can pretty efficiently add
notes and actually if we have this sort
of remove node operation blah blah blah
it will run in constant time as well I
mean constant I'll for removing note
from this children set so it's nice that
stretch to use is the setting okay next
I actually podcaster this diagraph white
white white function you could actually
sort of hard-code the weights in this
diagraph now type something like the red
pile map big rap now doubly like this
but there I think it's a good idea to
actually separate the concept of graph
from the concept of the weight function
for the graph so I use this explicitly
the graph point function as a pointy
part is that actually if you have some
graph with the Poggi you don't want to
change but you have different wave
functions I think it makes sense to
decouple the wave function from the
extra graph okay next we're gonna need
this
basically this diagraph coordinates cost
doesn't last nothing more but just Maps
the graph node to some point on the
two-dimensional plane so what comes to
heuristic function as a concept well we
just have one minute to get estimate
double bar between two node so it could
be and she's opening a heretic function
uses behind the scenes this distance
method which is an aquarium length
between two two-dimensional point so
let's go let's get back to the actual
search algorithm and start filling in
this code by the way I'm going to need a
helper class here
hmm
and transfer and we want to make it
comparable
you can implement your this place is
gonna be connections with our double
affair this distance to hold another
distance yes
so we need a priority queue this one is
a mineral heap actually but the pretty
efficient and simple to implement but
you don't want to implement it so we
just use whatever is available in that
double ability also
so basically open contains the so called
search point here or notes which are
assumed to be reached by the search in
the closed is the set of notes
who's the best known estimate we already
know show the status them there please
distance is a hash-table for mapping
each node to its best known estimate so
far
and this parents map is added structure
we need to actually reconstruct a
shortest path now we need to initialize
our data structures you entry source and
then estimate is zero actually the at
this point we can put any value because
affects nothing at this point but and we
know it's system based it is estimate
it's obviously zero and this now value
will be a sentinel value which was
signal at the arm we have constructed
constructed ahead the entire path
yeah I'll get back to this press that
path okay by the way I mean they're
actually too excessive so fast you
couldn't get it as well oh crap no and
you
the tentative distance of the channel is
then don't have the best non-technical
business of the current node which is
actually best at this point plus the
wave function so where we all would have
plain function I just want a function we
get from current no no - no now
or
in this case
to the distance or improve it and good
this means that we came to look into
child down from children No
and finally we put an energy panting out
with a shout out and thank the deep
distance loss eristic estimate
okay interesting function is called
poster function get estimated default
shoutouts to die
that's a lot
okay and okay I think the basic brain
structure is you have 1 loop 1 loop
inside another loop before somehow
somehow this open becomes empty before
we should target the things that the
target is not reachable at all for this
reason we return to step into path
signal this good situation
ok now let's get back to this phrase
backpack method and down
finally we need to reverse the path so
that the source not is the first and the
lock our target now is the last node in
the list called bad most specialist
again explain
yeah cool other an election enhances
distance it seems Tony false compare
method which seems budget for power to
kill so on
so here when calling a demonstration
program which will actually run and
measure the time taken by the algorithms
so on
the function the function part about
this saved value and reporting it in the
statement is that assassin if your
friend notes that something goes wrong
everything he needs to do is just to the
report ports it was for his test case
and you can replicate this the same the
very same computation which is nice so
fortunately to create some random graph
is actually a lead
and
random
all the new more readable personages and
oh yeah
get this so we have a graph consisting
of nodes and some arcs between those
some much
next we need to actually sort of PowerPC
right talking about the four units
van Gogh when in just random oil
function as well
metals away
okay is easy you point the double which
is a study from your class as far as I
understand so
okay
so
I need to grab weight function is the
next actually I think better name would
be like create something create
coordinates for get by function but all
over
holy Sh clean out up the glass reflects
to that fish smell and now
so each other across so our point tux
tea
you bring it for better efficiency
action
and the point too is
according out of the child next double
instance is simply c'mon basis to third
and the final weight function will get
something like water so you know child
let's say something like I will
understand our explain later what this
actually needs but does traffic we need
it when is it okay
this is started
mm-hmm
next we choose to note for us to some
know from draft which random graph mode
started to rap doing random south
sauce is them
everyone so actually let's see what we
have at this point okay in disgust
okay we have source and target
as you can see they bribe depending on
the time or the better one to see if is
the best in time
okay now let's see a waste
launch option new toll
okay and now long start as system
let's see um boss should be stuck this
is correct
source to target using wave function in
the healthy functional
f1 for each system of Ln okay
okay we have something let's continue
now you may ask how about Isis
aggravating it's so much work I thought
nah it's nothing for since we have a
star see see what happens
die ha oh my god yes beautiful
oh please
grep search um
now watch what it would be to you we
turn our star or a third sauce
finally it'll cleanse l function blend
and watch the certain zero the bed the
most optimistic estimate for a shopper
spare so
nice sparking and that is is finally
algorithms ugly and the path is simply
as yes
- okay fingers crossed let's see what
happens
actually it would have been really good
idea to actually warm up to Japan but da
goo goo actually I need to do is just
increase the size of the grip and let it
be like this
okay so first of all the paths are the
same and it opens this one and like this
algorithm it took like six times more
six times four times an a-star so I
think it's pretty much correct so on
little bit of visual separation I look
like a shape so I started certain
function hand from form playing back one
yes it takes 15 within the path to and
under if I wanted to play too old to
violence
yeah I think I think we got it
so let me just explain you one saying
why we actually get to a sort of two
birds with one stone but why don't we
just reuse the a start for our staff
Posada little well the point is that you
can sink that Dijkstra is the same as a
starter without heavy stick without in
this context means that every estimate
is always zero so the point about the
the a-star is that it's sort of knows in
what direction it should proceed but -
who doesn't know it so we sort of gross
this the shortest path free in all
possible directions of the graph and and
also but actually you asked me about it
I can tell you zero is so-called be
directional spread search algorithms
which are usually much more efficient
and - Drive and a star but I will leave
it to you so let's just skim through the
code just a little bit and uh so yeah
the crop is just working but was working
on we have like 50,000 nodes and ten is
much tons of arts but basically it's a
very sparse graph and sort of hmm
yeah in this scenario we just use the
Collegium heretics but service also
so-called Manhattan heuristics and some
chebyshev heuristic and long usually you
want your have a stick function to be as
efficient as possible so you don't spend
much time in completing an estimate but
the price is that regardless in the
heuristic function does your algorithm
in which direction to actually proceed
they do not necessarily take into
account so some obstacles they might be
only shortest path but well you get any
wing always and the podcasters estimates
there must be hockey stick which means
they under a teammate is a distance if
this is not the case you may come up
sometimes with a suboptimal path but
think about it was the most optimistic
well which is zero because negative
estimates does not make sense and
actually you are also remembers that
these algorithms doesn't perform are not
veteran best friends with negative
weight cycles so please don't do it
so finally
yeah I think this is pretty much this so
on I hope you enjoyed the fall story and
if you have if you have questions
comments or you want to sort of tell me
how how could they improve my video
tutorials please leave a comment and now
well maybe someday I will continue on
doing those tutorials because I already
like it but um well see you later
alligator
So in our previous lesson, we discussed
one possible way of
storing and representing a graph in
which
we used two list. One to store the
vertices and another to store the
edges. A record in vertex list here
is name of a node
and a record in edge list is an
object
containing references to the two endpoints
of an edge and also the weight of that edge
because this example graph that I am showing
you here is a
weighted graph. We called this kind of
representation
edge list representation but we realised
that this kind of storage is not very
efficient in terms of
time cost of most frequently performed
operations
like finding nodes adjacent to a given
node
or finding if two nodes are
connected are not.
To perform any of these operations, we
need to scan the whole
edge list. We need to perform a
linear search on the edge list.
So the time complexity is big oh of number
of
edges and we know that number of edges
in the graph
can be really really large. In worst case
it can be close to square of number of
vertices.
In a graph, anything running in order
of number of
edges is considered very costly. We
often want to keep the cost
in order of number of vertices. So we
should think of some other efficient
design.
We should think of something better than
this. One more possible design is that
we can store the edges in a
two-dimensional array
or matrix. We can have a
two-dimensional matrix
or array of size V*V
where V is number of vertices.
As you can see, I have drawn an 8*8
array here because number of vertices
in my sample graph here
is 8. Let's name this array A.
Now if we want to store a graph that is
unweighted. Let's just remove the weights
from this sample graph here
and now our graph is unweighted and if we
have
of value or index between 0 and V-1
for each vertex which we have here
if we are storing the vertices in a
vertex list
than we have an index between 0 and V-1
for each vertex. We can say that A
is zeroth node,
B is 1th node, C is
2th
node and so on. We are picking up
indices from vertex list. Okay
so if the graph
is unweighted and each vertex has an
index between 0 and
V-1, then in this matrix
or 2d array. We can set ith row
and jth column that is A[i][j]
as 1 or boolean value
true. if there is an edge from i to j
0 or false otherwise. If I have
to fill this matrix for this example
graph here then I'll go vertex by vertex.
Vertex 0 is connected to Vertex 1
2 and 3. Vertex 1
is connected to 0, 4 and 5.
This is an undirected graph so if we
have and edge from 0 to 1,
we also have an edge from 1 to 0
so
1th row and 0th column should also be
set as 1.
Now let's go to nodes 2, it's connected
to 0
and 6, 3 is connected to 0 and 7,
4 is connected to 1 and 7,
5 once again is connected to 1 and 7,
6 is connected to
2 and 7 and 7 is connected
to 3, 4, 5 and 6.
All the remaining positions in
this array should be set as 0.
Notice that this matrix
is symmetric. For an undirected graph,
this matrix would be symmetric
because A[i][j] would be equal to A[j][i].
We would have two positions filled for
each edge.
In fact to see all the edges in the graph,
we need to go through only one of these
two halves.
Now this would not be true for our
directed graph. Only one position will be
filled for each
edge and we will have to go through
the entire matrix
to see all the edges. Okay,
now this kind of representation of a
graph in which
edges or connections are stored in a
matrix
or 2D array is called adjacency matrix
representation. This particular matrix that
I have drawn here
is an adjacency matrix. Now with this
kind of storage or representation,
what do you think would be the time cost
of finding
all nodes adjacent to a given node. Let's say
given this vertex list
and adjacency matrix, we want to find
all nodes adjacent to node named F.
If we are given name of a node than
we first need to know it's
index and to know the index, we will have to
scan the vertex list.
There is no other way. Once we figured out
index
like for F index is 5 then
we can go to the row with that index
in the adjacency matrix
and we can scan this complete row to
find all the
adjacent nodes. Scanning the vertex
list
to figure it out the index in worst case
will cost us time proportional to the
number of vertices
because in worst case we may have to
scan the whole list,
and scanning a row
in the adjacency matrix would once again
cost us time proportional to number of
what vertices because
in a row we would have exactly
V columns where V is number of a
vertices.
So overall time cost of this operation
is big oh of V. Now most of the time
while performing operations,
we must pass indices to avoid
scanning the vertex list all the time.
If we know an index, we can figure out
the name in constant time,
because in an array we can access element at
any index in constant time but if we know
a name
want to figure out index then it will
cost us big oh of V.
We will have to scan the vertex list.
wWe will have to perform linear search
on it. Okay moving on.
Now what would be the time cost of
finding if 2 nodes
are connected or not. Now once again the
two nodes can be given to us
as indices or names. If the nodes
would be passed test as indices
then we simply need to look at value in
a particular row and
particular column. We simply need to look
at
A[I][J] for some values of I and J
and this will cost us constant time.
You can look at Value in any cell in
a two-dimensional array in constant time.
So if
indices are given time complexity of
this operation would be big oh of 1
which simply means that we will
take constant time
but if names are given then we also need
to do the scanning
to figure out the indices which will
cost us big oh of V.
Overall time complexity would be 
Big oh of V.
The constant time access would not mean
anything.
The scanning of vertex list all the
time to figure it out
indices can be avoided. We can use
some extra memory to create
a hash table with names and indices
as key value pairs and then the time
cost of finding
index from name would also be big oh
of 1 that is constant. Hash table is
a data structure
and I have not talked about it in any of
my lessons so far.
If you do not know about hash table, just
search online for
a basic idea of it. Okay, so as you can
see
with adjacency matrix representation
our time cost of some of the most
frequently performed operations
is in order of number of vertices
and not in order of number of
edges which can be as high as square of
number of vertices.
Okay now if we want to store
a weighted graph in adjacency matrix
representation
then A[i][j] in the matrix can be set as
weight of an edge. For non-existent ages we
can have
a default value like a really large
or maximum possible integer value
that is never expected to be an edge
weight. I have just filled in infinity
have to mean that
we can choose the default as infinity
minus infinity
or any other value that would never
ever be a valid
edge weight. Okay, now for further
discussion
I'll come back to an unweighted graph.
Ajacency matrix
looks really good so should we not use it
always.
Well, with this design we have improved
on
time, but we have gone really high on
memory usage
instead of using memory units exactly
equal to the number of edges
what we're doing with
edge list kind of storage.
Here we're using exactly V square
units of memory.
We are using big oh of V square space.
We are not just storing the information
that these two
nodes are connected, we are also storing not
of it
that is these two nodes side not connected
which probably is
redundant information. If a graph is
dense,
if the number of edges is really close
to V square
then this is good but if the graph is
sparse
that is if number of edges is lot lessser
than V square
then we are wasting a lot of
memory in storing the zeros.
Like for this example graph that I have
drawn here, in the edge list we were
consuming
10 units of memory we had ten rows
consumed in the edge list
but here we are consuming 64 unit.
Most graphs with
really large number of vertices would
not be very dense,
would not have number of edges anywhere
close to V sqaure
like for example, Let's say we are modeling
a social network like Facebook as a
graph such that a user in the network
is a node
and there is an undetected edge if two
users are friends.
Facebook has a billion users but I'm
showing only a few in my example graph
here because I'm short of space.
Let's just assume that we have a billion
users in our network,
so number of vertices in a graph is
10 to the power 9
which is billion. Now do you think number
of connections
in our social network can ever be close
to square of number of users
that will mean everyone in the network
is a friend of
everyone else. A user of our social
network will not be friend to all other
billion users.
We can safely assume that a user
on an average would not have more than
a thousand friends
with this assumption we would have
10 to the power 12
edges in our graph. Actually, this is an
undirected graph
so we should do a divide by 2 here. So
that we do not
count an edge twice. So if
average number of friends is 1000 then total
number of connections in my graph is
5 * 10 to power 11. Now this
is lot lesser than a square of number
of vertices.
So basically if you would use an adjacency
matrix for this kind of a graph,
we would waste a hell lot of space
and moreover
even if we are not looking in relative
terms 10 to the power 18
units of memory, even in absolute
sense
is alot. 10 to the power 18 bytes
would be about a 1000 petabytes.
Now this really is a lot of space. This
much data would never ever fit on one
physical disk.
5 into 10 to the power 11 byts on the other
hand
it's just 0.5 terabytes. A typical
personal computer these days would have this
much of storage.
So as you can see for something like a
large
social graph adjacency matrix
representation is not very efficient.
Agency matrix is good when a graph is
dense
that is when the number of edges is
close to square of number of vertices
or sometimes when total number of
possible connection that is V square
is so less that wasted space would not
even matter
but most real-world graphs would be
sparse
and adjacency matrix would not be a good
fit.
Let's think about another example. Let's
think about
world wide web as are directed graph.
If you can think of web pages as nodes
in a graph
and hyperlinks as directed edges
then a webpage would not have linked to
all other pages
and once again number of webpages
would be in order of millions.
A webpage would have link to only
the
a few other pages, so the graph would be
sparse.
Most real world graphs would be sparse
and adjacency matrix. Even though it's
giving us good running time for most
frequently performed
operations would not be a good fit
because it's not very efficient in terms
of space
so what should we do. Well there's
another
representation that gives us similar
or maybe even better running time than
adjacency matrix and does not consume so
much space
It's called adjacency list
representation and we will talk about it
in our next lesson.
This is it for this lesson. 
Thanks for watching
now that we're feeling pretty familiar
with graphs we're going to look at ways
of represent
graphs using matrices
let's take a look at
example graph G what I'm going to do is
label the vertices of G as 1 2 3 &amp; 4 so
I want to talk about the adjacency
matrix of this graph G and also the
incidence matrix let's start with the
idea of an adjacency matrix
in an adjacency matrix we think of the
rows of the matrix as well as the
columns of the matrix to be labeled by
the vertices so here we have 1 2 3 and 4
vertices and we also have 1 2 3 &amp; 4
so the actual labeling that we give can
be anything but then when we look at the
actual adjacency matrix it will all
start to make sense so let's call our
adjacency matrix a and this is the
actual definition of our matrix we all
know that an entry in row I column J
will be equal to either 1 or 0 it will
be equal to 1 if the edge I J is
actually an edge and if I J is not an
edge that's when you get the 0 if you
look at the vertex 1 and you ask is
vertex 1 adjacent to vertex 1 the answer
is no because that would be a loop so
you put a 0 here is vertex 1 adjacent to
vertex 2 yes that is an edge so you put
a 1 is vertex 1 adjacent to vertex 3 no
it is not so you put a 0 and is vertex 1
adjacent to vertex 4 yes it is so we put
a 1 notice that we don't have any loops
in this graph that means that vertex 2
is not going to be adjacent to itself so
we can already put that 0 3 is not
adjacent to itself it doesn't have a
loop so that's already a 0 and same
thing with 4 so let's continue to look
through if vertex 2 is adjacent to
vertex 1 yes we know that's true
so we put in a 1 vertex 2 is also
adjacent to vertex 3 so that's a 1 and
vertex 2 is adjacent to vertex 4 now we
look at vertex 3 which is adjacent to
vertices 2 and 4 so we know that at 2
and at 4 we need a 1 we need a 0
everywhere else we knew that this was a
0 and we also put a 0 here finally
vertex 4 happens to have degree 3 its
adjacent to everything except itself so
it has all of these as a 1 and of course
0 here because it doesn't have a loop
remember that in an adjacency matrix
rows and columns represent vertices so
if you look at the row sum you're going
to get the degree of the vertex that
that row so if we look at vertex 2 and
we look at the row sum here we sum all
of these up we get 3 and the row sum 3
tells us that vertex 2 has degree 3
which we can see clearly in the graph
since columns also represent vertices
the same is true for the column sum if
you look at the column that represents
the vertex 2 you will also get a 3 which
represents its degree so keep in mind
that the adjacency matrix of a graph has
all the same information that's
contained in the graph so these are two
ways of representing the same exact data
and an adjacency matrix is a little bit
more friendly for a computer here I'm
going to show you how we can do exactly
that using sage which is a free online
tool it's excellent for using when when
you're working with graphs so here I'll
put links in the description below so
the first thing I'm going to do is to
create a new sage worksheet and this is
where I'm working inside of the sage
cloud you can also work locally with
sage and download it to your machine so
here I've just created a worksheet
called graph theory and I'll just get it
started so the first thing that I'm
going to do in this worksheet is just
set up our adjacency matrix and I'm
going to use the matrix that we have
been working with with our little
example on 4 vertices so I've set up a
matrix and I'm starting to put in there
rows the rows are exactly the the rows
that we've written down in the video so
the first row was 0 1 0 1 and then we
just continue to write each of these
rows and we end up with an array of
arrays now what we're going to do is
we're going to just print our matrix to
make sure that we have the right thing
so I'll ask it to print by pressing
shift enter and indeed I can check that
this is the correct matrix that we've
been working with now I'm going to write
G equal to the graph of this adjacency
matrix and now I want to see that graph
so I'm going to use G show and again
pressing shift enter I'm going to get a
graph notice that this graph has been
shown to us in any random way that the
computer generates the visuals if I was
to run the G dot show
again I would again get a different
picture but no matter how I run it I'll
get the same relationship between those
vertices and edges so here I'm running
it again and I see something that looks
a bit more similar to the way that I
originally drew it one thing to notice
is that by default sage will label
vertices starting at zero so it's
labeled the vertices 0 1 2 3 instead of
1 2 3 4 in this case vertex 0 is like
our vertex 1 now let's check out the
incidence matrix so the incidence matrix
is usually denoted by an M instead of an
A and there's one key difference we
still are going to be labeling our rows
of our matrix via our vertices so 1 2 3
&amp; 4 but now what we want to do is label
the columns using edges so what I could
have done is written here column number
1 is going to be the edge 1 2 but that's
going to be a little bit tedious so what
I'm going to do is call this edge 1 to a
and then I'll call this B C D and E so
that I can represent these edges right
here a B C D and E so that's one key
difference already rows represent
vertices and columns represent edges and
we define the IJ entry of the matrix M
to be a 1 if vertex I belongs to edge J
and 0 otherwise so again let's take a
look at our example we can see vertex 1
has several edges that it lies on it
lies on edge a and it also lies on edge
D so when we look into this row what we
have to do is put a 1 at the a position
and also at the D position but vertex 1
doesn't lie on any of these other edges
so that's why we put zeroes there using
the same kind of logic we can complete
the rest of this matrix now when you
look into the row some of the matrix
where you're looking at the incidence
matrix you're still going to get the
degree of the vertex that's there so if
you look again at the row sum of vertex
number 2 you're still going to get a 3
because all this is telling you is that
there
are a total of three edges that too is
incident with so that gives you again
the degree three for vertex two now
something is different about the column
sum though because columns represent
edges so in this case if you look down
up any column you'll notice that the
number of ones is always two the reason
for that is because the columns
represent edges which means that every
Edge has two ends so if I look at column
D right here
I say okay that means that the two ends
of column D are vertex one and vertex
four and in fact if you look back at the
graph you'll see that edge D does indeed
have two ends one of them is vertex one
and the other one is vertex 4
that's actually the definition of an
edge that it has two ends at least in
the case of graphs not hypergraphs so to
recap the row sum equals the degree and
the column sum equals two now when we're
dealing with simple graphs we never need
to worry about things like multiple
edges or loops but this fact that the
column sum should equal two has an
interesting property in terms of the
loop it means that if you were to have a
loop in your graph and let's maybe call
our loop f where we'll go back up here
and we'll put in a new edge called f so
on vertex three i'm going to tack on a
loop and that one is called f the way i
would represent this in the incidence
matrix is to say well vertex three is
incident with f but my column sum should
equal two and in fact what we do is we
make a loop count as two so we have
zeros everywhere else in that column and
the loop counts twice so that's sort of
a finicky thing that can happen with
loops loops will count twice in your
incidence matrix but in general when
we're worrying about simple graphs we
don't need to worry about loops at all
so the key thing here is that you can
represent any graph using a matrix you
can either choose to use the adjacency
matrix version or the incidence matrix
I believe the adjacency matrix is most
commonly used but there are certain
instances when of the incidence matrix
could also be very useful for a
particular application see you next time
hi welcome to the video on complete
bipartite graph my name is Hera Shannon
first of all I would like to tell you
that if you haven't subscribed my
channel yet subscribe it now ok
so today we are going to discuss or at
other type of bipartite graph that is
known as complete bipartite graph we
have studied why pantograph we have a
studied complete job today we are going
to study complete bipartite graph means
the graph which is bipartite and and it
is also complete then that graph is
known as complete bipartite graph let's
see its definition a bipartite graph G V
1 Union V 2 vertices total vertices are
V 1 Union V 2 V 1 and V 2 are two sets
and the total vertex set is V 1 Union V
2 comma E is a set of edges in which
every vertex in V 1 here it is every
vertex in V 1 is adjacent to or every
vertex in V 2 is called complete
bipartite graph okay means every vertex
in one set is adjacent to all other
vertex in another set then that type of
bipartite graph is known as complete by
part arja and we have seen this in this
in the case when des a maximum number of
edges occur in case of bipartite graph
maximum number of edges occur only when
when the when the vertex is and one set
is adjacent to all other vertices in
another set okay so that was complete
bipartite graph let's see some sample so
these are examples of complete bipartite
graph K 1 1 ok K 1 1 means in 1 said
there is one vertex and another another
said there is one vertex and there is
edge between these two vertices ok so
this is K 1 1
k12 one vortex in one set and two vortex
in another cell and there is a edge
between for this vertex to this vertex
this vertex to this vertex but there
will not be as in this edge between
these two vertices because this is these
are the vertices which is lying in the
other set that is V 2 this is in V 1
this is in V 2 now k13 means in V 1
there is only one vertex and V in V 2
there are three vertices V 1 and V 2 are
two sets in which we are dividing the
our whole vertices here it says that in
the first set it contains one vertex and
in another set it contains three
vertices and that this vertex is
adjacent to all the vertices in the
another set okay so this is K 1 1 K 1 2
K 1 3 so one thing you must remember
here that for complete bipartite graph
only we denote it as kml okay this is K
1 1 K 1 2 these are denote these are
denoted for only complete bipartite
graph not for bipartite graph bipartite
graph is just written as bipartite graph
for complete bipartite graph then only
we use k MN okay okay we use in the
complete draft and for complete
bipartite graph we write k MN okay where
m is the word number vertices in first
set and n is the number of vertices in
another set for what you write for k MN
j MN is used for complete bipartite
graph
this is complete bipartite graph let us
see some more example here
look at her this is K 2 1 K 2 2 K 2 3 so
first what is contains to set to word
first set contain two vertex seconds are
contained for one vertex and these two
voices are both adjacent to this vertex
these two Bar K 2 2 in K 2 2 the two
voltage there are 2 what is in first set
into vertex is another set and these two
are both the two vertices are adjacent
to both the other voltages in the second
set and similarly K 2 3 and we can draw
for K 3 1 K 3 to also let me draw K 3 1
it means there are three vertices in one
set and one vertex in another set
oh this is K 3 1 good luck let's draw
for K 3 2 so 3 vertex in one side and
through vertex in another set so this is
k3 - okay so I think this is enough let
me generalize this
how many vortexes total number of autism
in kmn
m+ and we'll be the total number of
vertices number of edges will be M into
n and degree what will be the degree of
kml and the degree will be m of the
vertices which belongs to v2 and degree
of the vertices which belong to v1 will
have n okay so because in one n v2 all
the vertices will we are just sent on v1
so number of vertices in v1 is M and
number of vertices in v2 is n that is
why that degree of vertices which belong
to v2 will have M degree M and that
vertices which have which belong to v1
will have degree n okay so make a note
of it this is very important okay
so you will see more types of graphs in
another video if you like my video don't
forget to hit the like button and
subscribe my channel thanks for watching
okay
the graph data structure is not the same
as a graph you may have learned about a
math class graphs are collections of
things and the relationships or
connections between them the data in a
graph are called nodes or vertices the
connections between the nodes are called
edges one example of graphs is a social
network where the nodes are you and
other people and the edges are whether
two people are friend with each other
there are two major types of graphs
directed and undirected undirected
graphs are graphs without any direction
on the edges between nodes directed
graphs are graphs with a direction and
its edges an example of an undirected
graph could be a social network the
nodes are people and the edges are
friendships an example of a directed
graph could be the internet and web page
links the nodes are web pages and the
directed edges are links to other pages
which might not necessarily point the
other way I'm going to show you three
ways to represent a graph the first way
is called an adjacency list this
representation for a graph associates
each vertex in the graph with the
collection of its neighboring vertices
or edges in this image a is connected to
B B is connected to a and C and C is
connected to B this is how you could
show a relationship with texts and here
is how you could show this adjacency
list with JavaScript this is an
undirected graph because it does not
show the direction of the edges this can
also be more simply represented as an
array where the nodes just have numbers
rather than string labels another way to
represent a graph is to put it in an
adjacency matrix an adjacency matrix is
a two-dimensional array where each
nested array has the same number of
elements as the outer array so it's
basically a matrix of numbers where the
numbers represent the edges zeroes means
there is no edge or relationship and one
means there is a relationship this table
shows an adjacency matrix to represent
the image you can see that the labels
for the nodes are on the top and left
now here's a JavaScript representation
of the same thing unlike an adjacency
list each row of the matrix has to have
the same number of elements as nodes in
the graph here we have a 3 by 3 matrix
which means we have 3 nodes our graph
and adjacency matrix can be used to
represent a directed graph here's a
graph where the second node has an edge
pointing toward the first node and then
the third node has an edge pointing to
the first node notice how the numbers in
the array change there are only ones
where a node is pointing toward another
node and since there are only two points
there are only two nodes the final way I
will show to represent a graph is an
incidence matrix like the adjacency
matrix and incidence matrix is a
two-dimensional array however the rows
and columns means something else here
the adjacency matrix use both rows and
columns to represent nodes and incidence
matrix uses roads rose to represent
nodes and the columns to represent edges
this means that we can have an uneven
number of rows and columns each column
will represent a unique edge also each
edge connects two nodes to show that
there is edge between two nodes you will
put a 1 in the two rows of a particular
column as you can see in the diagram
edge 1 is connected to nodes a and B now
look at the column for edge 1 in the
incidence matrix table you will see a 1
in both the a row and the B row this
shows the edge 1 connects the nodes a
and B here is a directed graph for a
directed graph use negative 1 for an
edge leaving a particular node and 1 for
an edge entering a node and here is a
JavaScript implementation of the
incidence matrix graphs can also have
weights on their edges so far we have
unweighted edges where just the presence
and lack
of edges binary zero one you can have
different weights depending on your
application a different way is
represented as a number greater than one
well now you know about different types
of graphs and how to represent them in
JavaScript in my next video about graphs
I will cover graph traversal algorithms
thanks for watching my name is Bo Carnes
don't forget to subscribe and remember
use your code for good
hi everyone
matrix powers and walks how are they
related that's what we're gonna discuss
today and I have a graph here it is
connected and a definition the length of
a walk is defined by the number of edges
that over there in that walk so we're
talking about length length
- how many walks of link - are there in
this graph from v1 to v3 so you got to
get there in two edges if I go v1 to v3
- by edge one go v1 to v2 v2 by x3 - v3
so if I go edge one that's three that's
one walk if I go edge one and then edge
two that's another walk if I go edge
four there's no other option there if I
go edge four and then edge five I get
the v3 but then take that loop I still
end up there so that counts - so I have
I'm counting three and I don't see any
others well what I want to do is show
you how to use a matrix to do that and
I've already put the matrix in if I look
in wrong place second and then matrix I
put it in matrix a you can let me show
you the edited part of that if you edit
a and what I did was take the should
have talked about that the adjacency
matrix
a the adjacency matrix and basically let
us tell you how many lengths one walks
are there from one vertex to another v1
to v2 v1 to itself there's no loop v1 to
v2
there is one v1 to v3
there is one now let's go to v2 v2 to v1
there's one walk there's one v2 to v3 I
see one way I see - wait that's V 2 to V
2 that's 0 v2 to v3 is to edge 2 and
edge 3 there's two edges that connect
those now v3 to v1 there's one edge edge
for that connects it v3 to v2 there are
two edges on that one that connected MV
3 to v3 since there is that loop there
is one and that's the matrix I have here
so what I'm gonna do is let's quit out
of this go into matrix again I want to
take this matrix a that I made right
here the adjacency matrix and I want to
raise it to the second power and what I
see there 2 2 3 2 5 3 3 3 6 now the
question I had up here
how many walks of length 2 are there
from v1 to v3 and if you'll look at this
entry that that cell has 3 and that's
what we came up with when we counted by
hand and what I'd like to do let's look
at a let's look at v1
itself a length of length to the 1/2
itself I can go efore an e for e 1 e 1 I
can't get any other but that is length 2
back and forth back and forth I'm
interested maybe let's look at V 2 2
itself back and forth edge 1 edge 1 X 3
X 3 H 2 H 2 so I've gotten three so far
X 2 X 3 X 3 X 2 that was 5 I counted 5
as I was doing that so I find this very
interesting
well the next thing we could do is look
at walks of three length 3 and the
adjacency matrix a to the third power
would absolutely give us that now let's
do the matrix multiplication I'm going
to raise that to the third power and I'm
looking at 5 8 9 8 8 15 9 15 15 so how
many lengths three walks
from let's go v2 to v3 here's V 1 V 2 V
3 V 1 V 2 V 3 V 2 2 V 3
there are 15 different walks of length 3
that can get you from V to start at b2
and end of v3 I'm going to stop there
and we will work on that some more in
class and I look forward to seeing you
on Monday
what is a graph sometimes this would be
called a graph but I want to talk about
graphs like this a graph is a set of
vertices and a set of edges that connect
the vertices together this type of
structure can be useful for considering
many different types of problems for
example with a group of people each
vertex could be a person and each edge
could represent a friendship between the
two people another example is a group of
cities and the roads between them where
each vertex is a city and each edge is a
road it is also possible to have various
modifications to graphs such as putting
a number on each edge that represents
the distance between each city or make
the graph into a directed graph where
each edge could mean that one person
knows about the other person but not
necessarily the other way around when
drawing images for a graph out it is
important to remember that the only
things that matter are the vertices and
the way they are connected the actual
arrangement has no effect so this graph
is the same as this graph and this graph
and discraft but this graph is different
because it doesn't have the same edges
there are two main ways that graphs can
be represented first as an adjacency
list this is just a list of all the
vertices enter each of the vertices a
list of what vertices they are connected
to if the graph is directed then only
put the connections in the directions of
the edge the other main representation
is an adjacency matrix of values where r
1 in the matrix means that this vertex
is connected to this vertex by this edge
a zero means that the two vertices are
disconnected extra values can also be
stored on each edge by putting the
values on the edges in the corresponding
place in the matrix and that is what a
graph is
so in the previous video we got to know
how we can represent a graph so we got
to know that we can represent the graph
in two ways with the help of adjacency
lists and it is in C mattresses so we
will be implementing as a senseless
representation so what we need an
adjacency list representation we need we
will use an array of linked lists right
so we will be using an array of linked
lists and the size of array would be
equals to the number of vertices and
each entry in array I represents a
linked list of vertices adjacent to the
eyath virtus vertex this we do from the
previous video so how we can now
implement it in C code right so so we
would be needing three structures for
maintaining this so the structure of
graph would look like it would contain
the number of vertices that we will be
having in our graph and it will also
contain the array of linked list and
each linked list would contain a pointer
that will point to the head node of a
linked list and what linked list would
contain linked lists would contain two
fields one would be data field and
another one would be the pointer to the
next node so for example if this is the
adjacency list representation of a graph
these would be the nodes attribute that
we would be needing and that linked list
would contain and this is the array of
linked lists so we would be needing
three structures one for the node one
for the list and one for the graph now
this would take care of all the
structures that we would be needing in
our graph now how we can access the
fields so for example if you want to
access the field corresponding to the
array index one let's say if we want to
access the linked list corresponding to
the array index 1 so what we will do we
would go to the graph and access its
array field
array index 1 if you want to
if we want to access its array index one
now we will go to the head node of that
array at that linked list so we would
access that head like this so this would
give us access to this linked list so
now we will create a graph so we would
make a function for it so it would take
as an input the number of vertices in
the graph so first of all we will
allocate a memory to the graph
dynamically so this would return to us a
pointer that would point to the graph
and now we will set this data fields so
what are its data field so these are the
number of vertices and an array of
adjacency lists so what we would do is
we would set as number of our tie so
data feed as number of vertices that we
took as an input and its adjacency list
array of adjacency list now we would
create an array of adjacency lists but
which will contain this ritual which
would have the size as the number of
vertices so this line would create an
array of adjacency list and the size of
array will be the number of vertices
that is we in this case so now we will
initialize eat adjacency list as empty
by making headers no because at first we
don't have anything in the adjacency
list so after this but we would get as
if we have given an input as 5 so our
this graph would be returned what I kind
of graph would build on it would contain
these array index
zero to four and each array would point
to each other index would point to a
list empty list that is null because at
first we don't have anything in the
adjacency list so now we will be
creating a function that would add an
edge to the graph so what it would take
as an input as the graph to which we
want to add an age and from which vertex
to which vertex we want to add an edge
so in this case so in this case we would
be adding an edge from source to
destination so what our edge would look
like our edge would look like this
there would be an edge between source
and destination
so in our adjacency list representation
so we would create a node corresponding
to test and we would attach it to the
array index source that would be add
adjustments he lists corresponding to a
source so what this function would do is
it would create a node corresponding to
desk data field destination data field
and it would go to that source adjacency
list and it would attach this node to it
so what this function it would do it
would create a temporary node with test
data field this was this was a create
tooth function that we have created this
was our create node function it would
create a node with the input and it's it
would set that's next to null so the
kree we will create of we will create a
node now what we would do we would we
have to attach this node to the source
index source adjacency list so what we
would do is we would set its next to the
source so this line would go to that
array source head and attach temp next
so this would be this now our new head
would become this so after this after
this function what this adjacency list
representation would look like this
would look like this it would be good it
would be a node corresponding to dest at
a field it would be attached to the
source in the sense a list and head of
that adjacency list would be the node
corresponding to test so this is how our
attach function would work so now we
will be creating a function to print a
graph so it would take as an input as a
graph figure which we want to print so
what we will do is we will traverse all
the adjacency lists from end to
beginning so we would traverse all the
adjacency lists from end to beginning
and we would print all the data
corresponding to each adjacency list so
what we would do is we would create a
pointer named Traverse and it would
point to each adjacency list one by one
so at first it would point to the
adjacency list corresponding to this
array index so it would print all the
data that has attached to this linked
list that is attached to this adjacency
list it would print it then it would go
to the next index it would traverse this
whole adjacency list and it would print
it so what we would do is we would
create a pointer named Traverse that
would point to the head of that
resistancy list while that Traverse is
not null they will Traverse we will
print the data and we would move that
pointer to next to next to next till it
is null so this function would print the
data for us so this was all about the
adjacency list representation of a graph
now in the length description below we
have that code you can take a look at
recall that two graphs G and H are
isomorphic and this is the notation if
and only if there exists a by Jackson
alpha from the vertex set of G to the
vertex set of H such that alpha of U
alpha V is an edge of H if and only if
UV is an edge of G this condition is
what's telling you that the by ejection
alpha preserves adjacency and non
adjacency quick question it seems like
you would be able to determine if two
graphs are isomorphic using their
adjacency matrices how would this work
all of the information in a graph is
contained in its adjacency matrix so it
definitely is possible to determine if
two graphs are isomorphic using just
their adjacency matrices and in this
video I'll show you how it turns out
that G is isomorphic to H if and only if
a G is equal to P times H times P
transpose for some permutation matrix P
and notice here that AG represents the
adjacency matrix of graph G and a H
represents the adjacency matrix of graph
H we're going to take a look at how this
works using an example so our graph G
will be a green graph on these five
vertices and I'll just label them our
graph H is going to be a red graph also
on five vertices because I chose such a
small example it should already be
pretty clear that these two graphs are
essentially the same in other words
isomorphic but it will be useful to work
through all of the steps in this example
anyways if we wanted to find an
isomorphism between these two graphs
let's consider what by ejection we might
use we'll take alpha to map from V of G
to V of H and we'll say that alpha can
map vertices 1 2 3 4 5 of G 2 vertices 5
4 1 2 3 respectively in H a different
notation for this is alpha equals in
brackets
one five three and then in brackets to
four
this tells us that one goes to five five
goes to three and then three goes back
to one and also tells us that two goes
to four and for respect to that's known
as cycle notation for this by Junction
alpha in order to prove that alpha is
indeed an isomorphism we would need to
check every pair of vertices in the
graph G and show that if they were
adjacent in the graph G then after the
mapping they get mapped to a pair of
vertices that are adjacent in the graph
H and also if they were not adjacent in
the graph G then they need to map to a
pair of vertices which are not adjacent
in the graph H to demonstrate this I'll
just go through two little examples we
notice that one two is an edge in the
graph G so alpha 1 alpha 2 ends up being
5 4 which is an edge in the graph H so
that worked next we notice that 1 4 is
not an edge in the graph G and alpha of
1 alpha 4 maps to 5 2 which is not an
edge in the graph H so those two
examples worked out if you want you can
check for yourself that alpha is indeed
an isomorphism but hopefully at this
point you're pretty convinced that it
will work to see how we would view this
in terms of matrices we'll start by
writing down the adjacency matrices of
the two graphs so we'll use green to
represent the adjacency matrix of the
graph G it's going to have 5 rows
corresponding to the 5 vertices and 5
columns also corresponding to the 5
vertices if we look at the first row
vertex 1 is adjacent only to vertex 2 so
that means we put a 1 in the 2 column
and zeros everywhere else similarly we
can fill in the rest of the adjacency
matrix if you'd like a review of the
details of how an adjacency matrix is
made click on this video or see the
links in the description below we build
the adjacency matrix of the graph H in
exactly the same way and we end up with
these two adjacency matrices our next
step is to determine if there is a
permute
matrix P such that P times the adjacency
matrix of H times P transpose will give
us the adjacency matrix of G this
problem of finding the permutation
matrix P is essentially equivalent to
finding a mapping alpha like we did
before if you find such a matrix P it
will be associated with a mapping alpha
and if you find a mapping alpha it will
be associated with a permutation matrix
P so since we already know that our
mapping alpha worked out let's use that
to try to build ourselves a nice
permutation matrix we have to remember
what alpha does and in particular alpha
maps one to five so in Row one we'll put
a one only in the five s column and
zeros everywhere else
similarly we fill in the rest of the
permutation matrix according to what
alpha tells us to map to to find P
transpose remember that the transpose of
a matrix is found just by swapping rows
four columns so if we look at our old
matrix P and we find the first row that
gives us our first column in P transpose
and we just finish off and write down P
transpose our next step is to take a
look at the product we get when we take
P times a H times P transpose okay so
let me copy and paste our matrix P and
copy and paste our matrix aah and also P
transpose now because multiplication of
matrices is associative I'm just going
to go ahead and multiply the first two
together you've probably seen matrix
multiplication before but let me just
remind you that if you're looking for
the entry in Row one column one of the
product what you need to do is to look
at Row one of the first matrix and
column one of the second Matrix and you
look along that row and along that
column and you take the dot product what
that means is that you just multiply
corresponding entries and keep doing
that multiplying corresponding entries
but you take the sum of all of that if
you do that in this particular example
you're going to get a zero here if I'm
looking for the next entry that's going
to go into the first row I still look at
the first row of the first
matrix but now I look into the second
column and I again take that dot product
again I get a zero and I'm going to get
a zero again until I get to the fourth
column I will end up getting a one there
so that tells me to put a 1 in the
product and the last entry is zero check
all of this for yourself now we're done
with the first row in the product to
figure out the second row we just repeat
this procedure but now looking at the
second row of the first matrix and again
looking into every individual column of
the second Matrix once we're finished
calculating the product of these two
matrices we are not done we still need
to multiply that product by P transpose
so I'll copy P transpose and now we just
have to run through all the matrix
multiplication again we work out the
product of these two matrices again
using matrix multiplication and after
you finish that you'll notice that the
corresponding matrix you get is exactly
the adjacency matrix of the graph G so
that's precisely what we were looking
for
we found a permutation matrix that
satisfied the property we were looking
for actually we did it in a little bit
of a roundabout way because we found
that permutation matrix by already
knowing an alpha mapping that would work
but again I'm reminding you that finding
this permutation matrix is as difficult
as finding the mapping alpha once you
know one you know the other if you have
any graph theory questions let us know
in the comments below click here for
related videos and keep having fun with
graph theory I'll see you next time
hi I'm Gail Locke McDowell author of
cracking the coding interview today I'm
going to solve the connected cell
problem so in this problem we have a
matrix of zeros and ones and we want to
find the largest region of connected
ones where that's to find it to find it
be ones that are adjacent to each other
either looking horizontally vertically
or diagonally so depth-first search is
perfect for this problem we could use
breadth-first search instead but
generally we find depth-first search to
be a little bit easier to implement and
it works just as well so we might as
well use it so we're going to do is
walks as a matrix and every time we see
a one go do depth-first search on that
region and get the size of it tracking
the biggest region as we go along so
pretty simple basic for loops by the way
I always find it's best to not use x and
y when we're dealing with matrices
because what I find is that people think
that X should be the row and Y should be
the column and that's actually backwards
so just take it for me don't use X and
Y's variable names row and column are
really better choices okay so if matrix
of row and column this one then do a
traversal here so do a depth first
search here get region size of matrix
row comma column and then max region
basically update the max necessary the
size of Max region okay so one thing we
want to be sensitive to is not that
we're not repeating work are necessarily
so if we come across a one in you know
the same region multiple times which
almost by definition we well we don't
want to repeat the same work for the
same region so there's different ways of
doing this one is we could track we
could have some sort of like boolean
visited matrix like this and every time
we search some into putting lengths
there of course but every time we you
know when we're doing get region size
pass in this visited list and make sure
that this is updated not just for this
row and column but for everything else
matrix or everything else in that region
and that will work but it's actually
kind of unnecessary if we're okay
destroying matrix then let's just reuse
that and every time we get to a value in
this region just update matrix and clear
that to make it a zero and that'll avoid
this issue if we're not okay with
destroying matrix then we can just clone
matrix it's ultimately it's kind of the
same thing in the end okay so now let's
turn to region size so get region size
is going to take in the matrix and the
row and column and then it's going to do
a depth first search so it's going to
search out recursively from each of
those areas so first thing I want to do
is my boundary checks so putting these
boundary checks here and returning zero
so the region size is zero so then what
I want to do is I also want to check to
make sure this is actually part of the
region so if matrix of row comma column
is zero return zero so now comes kind of
the interesting part so the size of this
region is going to be one for myself
plus the size of the region if I
traversed up-down left-right diagonal so
initial size is 1 and then Traverse so
there's different ways of doing this I'm
going to do it like this so I'm going to
search from row minus 1 except to go in
actually eight different directions so
all around so Rho is less than while row
so start off our with row minus 1 R is
less than or equal to Rho plus 1
our plus plus so go through all three
different rows all three different
columns here minus one column less than
or equal to C less than or equal to
column minus 1 C++
and then search so this is going to be
sighs so increased size by that area so
matrix of row comma column then return
size so here I did not have to put in
any boundary checks because I've already
done all of that here so it makes my
code a little bit shorter I could of
course instead we check the print a
check the bounds before I traversed or
before a curse but it's easier just to
do it up here and then I also want to
make sure that I don't go search myself
I mean I guess I could but it's you know
probably a little better to it that I
don't do that so I'm going to just skip
over myself so if yeah I'll do like this
if Road is not equal to this and column
or column value list so make sure that
one of them isn't equal so it's not
myself then do this search and then the
other thing I need to do is I need to
track some sort of weight I need to know
that I haven't repeated repeated this
search and seen the same cell before so
I'll do this right after I check to see
if this is zero I'll clear this out so
set row of column set your own column to
be 0 so it's interesting here is that
this will actually serve dual functions
it'll do a is visited check for this
depth-first search and make sure that I
haven't you know I'm not running some
sort of cycle nest search but it'll also
fulfill a value here on get region in
that it'll make sure I'm not searching
the same region multiple times now let's
just look through this oops this should
have been matrix that and this should be
actually plus one little typo there okay
now let's run this and see how we did
beautiful so this is you know not a it's
a pretty straightforward implementation
of depth-first search it's not verbatim
it's not you know go in depth first
search to do this but it builds off a
lot of the same
both the depth-first search and if
recursion general so one thing I'd like
you to take away here is not just think
about the applicable ative depth-first
search but also think about how I did
these boundary checks I've asked people
a lot of a lot of a syllabic and it's
questions that are very similar to this
and I'll often see that people do the
balanced checking before recursing and
it adds in some cases so much more
hassle to their code that's really
unnecessary so think about how you can
really drill the down really simplify
how your code works so keep that line
for your future problems and good luck
so in our previous lesson we talked
about adjacency matrix as a way to store
and represent graph and as we discussed
and analyzed this data structure we saw
that it's very efficient in terms of
time cost of operations with this data
structure it costs Big O of 1 that is
constant time to find if two nodes are
connected or not and it costs Big O of V
where V is number of vertices to find
all nodes adjacent to a given node but
we also saw that adjacency matrix is not
very efficient when it comes to space
consumption we consume space in order of
square of number of vertices in
adjacency matrix representation as you
know we store edges in a two-dimensional
array or matrix of size V cross V where
V is number of vertices in my example
graph here we have eight vertices that's
why I have an 8 cross 8 matrix here we
are consuming 8 square that is 64 units
of space here now what's basically
happening is that for each vertex for
each node we have a row in this matrix
where we are storing information about
all its connections this is the row for
the zeroth node that is a this is the
row for the one at node that is B this
is for C and we can go on like this so
each node has got a row and a row is
basically a one dimensional array of
size equal to number of vertices that is
V and what exactly are we storing in a
row let's just look at this first row in
which we are storing connections of node
a this two-dimensional matrix or array
that we have here is basically an array
of one-dimensional arrays so each row
has to be one dimensional array so how
are we storing the connections of node a
in these eight cells
this one-dimensional array of size 8/0
in the zeroeth position means that there
is no edge starting a and ending at zero
at node which again is a an edge
starting and ending at itself is called
a self loop and there is no self loop on
a of 1 in 1 its position here means that
there is an edge from a to 1 at node
that is B the way via storing
information here is that index or
position in this one-dimensional array
is being used to represent endpoint of
an edge for this complete row for this
complete one-dimensional array start is
always the same it's always the zero at
node that is a in general in the
adjacency matrix row index represents
the start point and column index
represents the end point now here when
we are looking only at the first row
start is always a and the indices 0 1 2
and so on are representing the endpoints
and the value at a particular index or
position tells us whether we have an
edge ending at that node or not one here
means that the edge exists 0 would have
meant that the edge does not exist now
when we are storing information like
this if you can see we are not just
storing that b c and d are connected to
a we are also storing the knot of it we
are also storing the information that a
e f g and h are not connected to a if we
are storing what all nodes are connected
through that we can also deduce what all
nodes are not connected these zeros in
my opinion are redundant information
causing extra consumption of memory most
real-world graphs are sparse that is
number of connections is really small
compared to total number of possible
connections so
so often there would be too many zeroes
and very few ones think about it let's
say we are trying to store connections
in a social network like Facebook in an
HSN C matrix which would be the most
impractical thing to do in my opinion
but anyway for the sake of argument
let's say we are trying to do it just to
store connections of one user I would
have a row or one dimensional matrix of
size 10 to the power 9 on an average in
a social network you would not have more
than thousand friends if I have thousand
friends then in the row used to store my
connections I would only have thousand
ones and rest that is 10 to the power 9
- thousand would be zeros and I'm not
trying to force you to agree but just
like me if you also think that these
zeros are storing redundant information
and our extra consumption of memory then
even if we are storing these ones and
zeros in just one byte as boolean values
these many zeros here is almost one
gigabyte of memory once are just 1
kilobyte so given this problem let's try
to do something different here let's
just try to keep the information that
these nodes are connected and get rid of
the information that these nodes are not
connected because it can be inferred it
can be deduced and there are a couple of
ways in which we can do this here to
store connections of a instead of using
an array such that index represents
endpoint of an edge and value at that
particular index represents whether we
have an edge ending there or not we can
simply keep a list of all the nodes to
which we are connected this is the list
or set of nodes to which a is connected
we can represent this list either using
the indices or
using the actual names for the nodes
let's just use indices because names can
be long and may consume more memory you
can always look at the vertex list and
find out the name in constant time now
in a machine we can store this set of
nodes which basically is a set of
integers in something as simple as an
array and this array as you can see is a
different arrangement from our previous
array in our earlier arrangement index
was representing index of a node in the
graph and value was representing whether
there was a connection to that node or
not here index does not represent
anything and the values are the actual
indices of the nodes to which we are
connected now instead of using an array
here to store this set of integers we
can also use a linked list and widest
array or linked list I would argue that
we can also use a true here in fact a
binary search tree is a good way to
store a set of values there are ways to
keep a binary search tree balanced and
if you always keep a binary search tree
balanced you can perform search
insertion and deletion all three
operations in order of log of number of
nodes we will discus cost of operations
for any of these possible ways in some
time right now all I want to say is that
there are a bunch of ways in which we
can store connections of a node for our
example graph that we started with
instead of an adjacency matrix we can
try to do something like this we are
still storing the same information we
are still saying that zero at node is
connected to one at two it and three at
node 1 at node is connected to 0 at 4th
and 5th node to ethno disconnected to 0
at and sixth node and so on but we are
consuming a lot less memory here
programmatically this adjacency matrix
here
is just a two-dimensional array of size
8 cross 8 so we are consuming 64 units
of space in total but this structure in
right does not have all the rules of
same size how do you think we can create
such a structure programmatically well
it depends in c or c++ if you understand
pointers then we can create an array of
pointers of size 8 and each pointer can
point to a 1 dimensional array of
different size 0 8 pointer can point to
an array of size 3 because 0 8th node
has 3 connections and we need an array
of size 3 one at pointer can point to an
array of size 3 because one it's node
also has 3 connections to it node
however has only 2 connections so 2 its
pointer should point to an array of size
2 and we can go on like this the 7th
node has four connections so 7th pointer
should should point to an array of size
4 if you do not understand any of this
point to think that I am doing right now
you can refer to my code schools lesson
titled pointers and arrays the link to
which you can find in the description of
this video but think about it the basic
idea is that each row can be a
one-dimensional array of different size
and you can implement this with whatever
tools you have in your favorite
programming language now let's quickly
see what are the pros and cons of this
structure in the write in comparison to
the matrix in the left
we are definitely consuming less memory
with the structure in right with
adjacency matrix our space consumption
is proportional to square of number of
vertices while
the second structure space consumption
is proportional to number of edges and
we know that most real-world graphs are
sparse that is the number of edges is
really small in comparison to square of
number of vertices square of number of
vertices is basically total number of
possible edges and for us to reach this
number every node should be connected to
every other node in most graphs a node
is connected to few other nodes and not
all other nodes in the second structure
we are avoiding this typical problem of
too much space consumption in an
adjacency matrix by only keeping the
ones and getting rid of the redundant
zeros here for an undirected graph like
this one we would consume exactly two
into number of edges units of memory and
for a directed graph we would consume
exactly ethat is number of edges units
of memory but all in all space
consumption will be proportional to
number of edges or in other words space
complexity would be Big O of e so the
second structure is definitely better in
terms of space consumption but let's now
also try to compare these two structures
for time cost of operations what do you
think would be the time cost of finding
if two nodes are connected or not we
know that it's constant time or Big O of
1 for an adjacency matrix because if we
know the start and end point we know the
cell in which to look for 0 or 1 but in
the second structure we cannot do this
we will have to scan through a row so if
I ask you something like can you tell me
if there is a connection from node 0 to
7 then you will have to scan this zero
at row you will have to perform a linear
search on this zero eighth row to find
seven right now all the rules in this
structure are sorted you can argue that
I can keep all the rules sorted and then
I can perform a binary search which
would be a lot less costlier that's fine
but if you just perform a linear search
then in worst case we can have exactly V
that is number of vertices cells in a
row so if we perform a linear search in
worst case we will take time
proportional to number of vertices and
of course the time cost would be big-oh
of log V if we would perform a binary
search logarithmic runtimes are really
good but to get this here we always need
to keep our rows sorted keeping an array
always sorted is costly in other ways
and I'll come back to it later for now
let's just say that this would cost us
big o of V now what do you think would
be the time cost of finding all nodes
adjacent to a given node that is finding
all neighbors of a node well even in
case of adjacency matrix we now have to
scan a complete row so it would be Big O
of V for the matrix as well as this
second structure here because here also
in worst case we can have V cells in a
row equivalent to having all ones in a
row in an adjacency matrix when we try
to see the time cost of an operation and
we mostly analyze the worst case so for
this operation we are Big O of V for
both so this is the picture that we are
getting looks like we are saving some
space with the second structure but we
are not saving much on time well I would
still argue that it's not true when we
analyze time
complexity we mostly analyze it for the
worst case but what if we already know
that we are not going to hit the worst
case if we can go back to our previous
assumption that we are dealing with a
sparse graph that we are dealing with a
graph in which a node would be connected
to few other nodes and not all other
nodes then the second structure will
definitely save us time things would
look better once again if we would
analyze them in context of a social
network I'll set some assumptions let's
say we have a billion users in our
social network and the maximum number of
friends that anybody has is 10,000 and
let's also assume computational power of
our machine let's say our machine or
system can scan or read 10 to the power
6 cells in a second and this is a
reasonable assumption because machines
often execute a couple of millions
instructions per second now what would
be the actual cost of finding all nodes
adjacent to a given node in adjacency
matrix well we will have to scan a
complete row in the matrix that would be
10 to the power 9 cells because in a
matrix we would always have cells equal
to number of vertices and if we would
divide this by a million we would get
the time in seconds to scan a row of 10
to the power 9 cells we would take
thousand seconds which is also sixteen
point six six minutes this is
unreasonably high but with the second
structure maximum number of cells in a
row would be 10,000 because the number
of cells would exactly be equal to
number of connections and this is the
maximum number of friends or connections
a person in the network has so here we
would take 10 to the power 4
10 to the power 6 that is 10 to the
power minus 2 seconds which is equal to
10 milliseconds 10 milliseconds is not
unreasonable now let's try to deduce the
cost for the second operation finding if
two nodes are connected or not
in case of adjacency matrix we would
know exactly what cell to read we would
know the memory location of that
specific cell and reading that one cell
would cost us 1 upon 10 to the power 6
seconds which is 1 microsecond in the
second structure we would not know the
exact cell we will have to scan a row so
once again maximum time taken would be
10 milliseconds just like finding
adjacent nodes so now given this
analysis if you would have to design a
social network
what structure would you choose
no-brainer
isn't it machine cannot make a user wait
for 16 minutes would you ever use such a
system milliseconds is fine but minutes
it's just too much so now we know that
for most real-world graphs this second
structure is better because it saves us
space as well as time remember I am
saying most and not all because for this
logic to be true for my reasoning to be
valid graph has to be sparse number of
edges has to be significantly lesser
than square of number of vertices so now
having analyzed space consumption and
time cost of at least two most
frequently performed operations looks
like this second structure would be
better for most graphs well there can be
a bunch of operations in a graph and we
should account for all kind of
operations so before making up my mind I
would analyze cost of few more
operations what if after us two
during this example graph in computer's
memory in any of these structures we
decide to add a new edge let's say we
got a new connection in the graph from A
to G then how do you think we can store
this new information this new edge in
both these structures the idea here is
to assess that once the structures are
created in computer's memory how would
we do if the graph changes how would we
do if a node or edge is inserted or
deleted if a new edge is inserted in
case of an adjacency matrix we just need
to go to a specific cell and flip the
zero at that cell to 1 in this case we
would go to 0-8 row and sixth column and
override it with value 1 and if it was a
deletion then we would go to a specific
cell and make the 1 0 now how about this
second structure how would you do it
here we need to add a 6 in the first row
and if you have followed this series on
data structures then you know that it's
not possible to dynamically increase
size of an existing array this would not
be so straightforward we will have to
create a new array of size 4 for the
zeroth row then we will have to copy
content off the old array write the new
value and then wipe off the old one from
the memory it's tricky implementing a
dynamic or changing list using arrays
this creation of new array and copying
of old data is costly and this is the
precise reason why we often use another
data structure to store dynamic or
changing
and this another data structure is
linked list so why not use a linked list
why can't eat Robi a linked list
something like this logically we still
have a list here but concrete
implementation wise we are no more using
an array that we need to change
dynamically we are using a linked list
it's a lot easier to do insertions and
deletions in a linked list now
programmatically to create this kind of
structure in computer's memory we need
to create a linked list for each node to
store its neighbors so what we can do is
we can create an array of pointers just
like what we had done when we were using
arrays the only difference would be that
this time each of these pointers would
point to head of a linked list that
would be a node I have defined node of a
linked list here node of a linked list
would have two fields one to store data
and another to store address of the next
node a zero would be a pointer to head
our first node of linked list for a a
one would be a pointer to head of linked
list for B and we will go on like a to
foresee a three for D and so on actually
I have drawn the linked lists here in
the left but I have not drawn the array
of pointers let's say this is my array
of pointers now a zero here this one is
a pointer to node and it points to the
head of linked list containing the
neighbors of a let's assume that head of
linked list for a has address 400 so in
a 0 we would have 400 it's really
important to understand what is what
here in this structure this one a zero
is a pointer to node and all up
winter does is store an address or
reference this one is a node and it has
two fields one to store data and another
a pointer to node to store the address
off next node let's assume that the
address of next node in this first
linked list is 450 then we should have
450 here and if the next one is at let's
say 500 then we should have 500 in
address part of the second node the
address and last one would be zero or
null now this kind of structure in which
we store information about neighbors of
a node in a linked list is what we
typically call an adjacency list what I
have here is an adjacency list for an
undirected unweighted graph to store a
weighted graph in an adjacency list I
would have one more field in node to
store weight I have written some random
weights next to the edges in this graph
and to store this extra information I
have added one extra field in node both
in logical structure and the code all
right now finally with this particular
structure that we are calling adjacency
list we should be fine with space
consumption space consumed will be
proportional to number of edges and not
to square of number of vertices most
graphs are sparse and number of edges in
most cases is significantly lesser than
square of number of vertices ideally for
space complexity I should say Big O of
number of edges plus number of vertices
because storing vertices will also
consume some memory but if we can assume
that number of vertices will be
significantly lesser in comparison to
number of edges then we can simply say
Big O of number of edges but it's always
good if we do the
right now for time cost of operations
the argument that we were earlier making
using a sparse graph like social network
is still true adjacency list would
overall be better than adjacency matrix
finally let's come back to the question
how flexible are we with this structure
if we need to add a new connection or
delete an existing connection and is
there any way we can improve upon it
well I leave this for you to think but
I'll give you a hint what if instead of
using a linked list to store information
about all the neighbors we use a binary
search tree do you think we would do
better for some of these operations I
think we would do better because the
time cost for searching inserting and
deleting a neighbor would reduce with
this part I'll sign off this is it for
this lesson thanks for watching
hi I'm Jonah in this video I'm going to
explain two different ways to implement
a graph and then I'm going to explain
some of the pros and cons of each and
I'll show you how to implement both of
these methods in Python so the first way
to implement a graph is using an
adjacency list so let's look at this
undirected graph it has five vertices
and some edges connecting them an
adjacency list actually is a set of
adjacency lists because each list is
stored in its own vertex so a keeps its
own list of directly connected neighbors
other vertices that it has an edge to so
a has neighbors B C and E node B has
neighbors a and C as we can see here
this is going to be stored within each
node or each vertex is going to store
its own adjacency list now the other way
is using an adjacency matrix and the
adjacency matrix is a two dimensional
array and it basically stores a zero
where there is no edge or a one where
there is an edge from A to B we can see
there is an edge there or from A to C
there is an edge as you'd expect since
this is an undirected graph this is
going to be symmetrical across this
diagonal so from A to B is a 1 from B to
a is also going to be a 1 then the
adjacency matrix like I said it's a 2d
array and is stored in the graph object
so there's one adjacency matrix
centrally located in the graph object
how about if you have weighted edges on
an undirected graph well it's much
easier to implement weighted edges with
an adjacency matrix instead of putting a
one for edges where there is a
connection you just put the weight of
that edge so it's very easy to do that
you already have the cell you can put
instead of a 1 you can just put the
number of the cost or the distance or
weight of that edge in the cell so
extremely easy to implement using
adjacency matrix you can also implement
weighted edges in an adjacency list but
it's a little bit trickier so if you
have a directed graph again very easy to
do this using an adjacency list so here
we would have
a has one outbound edge to see so we
list under a only C as a neighbor that's
the only neighbor we can get to from a
so we're going to list all the outbound
edges for that vertex so C has edges to
B D and E and we list all the outbound
edges from C here in C's a Jason C list
you know Jason C matrix the same thing
we're basically going to put ones where
we have an edge outbound from that
vertex so we have the from on the left
and the two is div columns so which is
better well before we can answer that
question let's look at some other
characteristics of graphs a dense graph
is a graph where this is not absolute
value this is the number or count of
edges and the count of vertices so a
dense graph is a graph where you have
the number of edges is about equal to 2
the number vertices squared in other
words almost every vertex is connected
to every other vertex in the graph so
you get a really large number of edges
relative to the number of vertices a
sparse graph is a graph where E is about
equal to V which is what we have here in
this picture so there are a lot of
possible edges that are not actually
there another thing we're going to look
at before we answer the question which
is better adjacency matrix takes up V
squared space right this is a big factor
the amount of space required for this
adjacency matrix is going to be V
squared or number of vertices squared
regardless of how dense the graph is so
very very sparse graph you still are
going to take up the same amount of
space so for our little 5x5 you know we
only have 5 vertices in this example who
cares right but if you can picture a
graph that has ten thousand or a hundred
thousand vertices that's going to take a
project gigantic amount of storage space
so with those things in mind an
adjacency list is better in cases where
you have a sparse graph because it's
going to be faster and it uses less
space but the disadvantage of an
adjacency list this is slower for very
dense graphs large dense graphs is going
to be slower and the adjacency matrix is
going to be better for dense graphs
it's going to be faster and the space
complexity is the same as it would be
thrown on dense graph and another
advantage is that is simpler to
implement for weighted edges but the
disadvantage of this adjacency matrix is
that it uses more space and especially
for large sparse graphs or perhaps to
have a lot of vertices but relatively
few edges the adjacency matrix is not a
good choice so depending on the nature
of your graph you have to decide which
one of these is a better implementation
to go with so I'll give a quick
explanation of the adjacency list
version of the graph implementation
first we have our vertex class which
basically has two variables as a name
and it has a neighbors list and as we
add neighbors we see we have an add
neighbor function that basically is just
appending that vertex to the list and
then sorting it in the graph itself we
only have one graph variable which is a
dictionary of vertices so that we can
find any vertex by its name so when we
add a vertex we basically just check
that that object that you passed in
actually is a vertex object and then it
doesn't exist in the vertices dictionary
yet and if those two conditions are met
then it goes in as the vertex to the
vertices dictionary and when you try to
add an edge with vertices U and V then
it's first going to check if u and V are
both actually in this vertices
dictionary before adds it so if there's
an invalid vertex and it's not going to
be able to add that edge then we iterate
through the vertices and we locate
vertex U and vertex V and we add the
other to its neighbors and that's pretty
much it then I have a print graph
function down here at the bottom so this
is a pretty straightforward
implementation of graph I think it's a
little bit simpler so I usually favor
this over the matrix version although
the matrix version is not too hard and
then down below I have some test code
that we can test our our code up here so
implementing a graph using an adjacency
matrix this version is actually going to
support both weighted and unweighted
edges for undirected graphs and you have
to do slight modifications to support
directed graphs
so our vertex class you'll notice only
has one variable and that's just the
name of the vertex we don't need
adjacency this stored locally in the
vertex that doesn't happen here they're
stored centrally under the graph so we
have the same vertices dictionary so
that we can locate any vertex given its
name we also have this edges list which
is going to be our two-dimensional array
of edges that's the matrix and then we
have edge indices so that we can quickly
locate the index of any edge given its
name so when we add a vertex first we're
gonna check if it's actually vertex and
it is not in the vertices list already
and if not we add to the dictionary and
then our for loop here and the statement
right after that basically we need to
add another row and column of all zeros
to our edges matrix so we're going to do
that here we're add another row of zeros
and in another column of zeros on to
that edges matrix because we have mapped
any edges to this new vertex yet but we
need to add it to this matrix with all
zeros and lastly we add the index for
this vertex name into our edge indices
dictionary so to add an edge we're first
going to verify that both vertices U and
V are in our vertices dictionary and if
they both are then recall that this
edges matrix is symmetrical along the
diagonal so we want to add this edge we
want to enter the weight in the matrix
in both the top right bar in the bottom
left part so we're going to add the edge
to both u comma V and to V comma u we'll
set the edge weight and that's it for
add edge if we achieve that and we'll
return true and if not the return false
then lastly I have a pretty pretty
simple print graph function that prints
a pretty crudely formatted edges matrix
for us so you can see what that looks
like and our interface is exactly the
same as for the adjacency list version I
have exactly the same test code down
here below where we we set up a graph we
add some vertices and some edges to it
and we print it out I posted all of my
Python code here in my github site and
you can download that pin you also have
access to the PowerPoint file posted
here Omega up site so I hope this video
was helpful for you if you liked it
please click like and subscribe to my
channel I'm Joe James thanks for
watching
welcome to the first in a series of
demonstrations on the graph data
structure what we're going to be
starting out with is a look at a graph
implementation specifically looking at a
graph implemented as an adjacency matrix
and trying to determine what kind of
graph that adjacency matrix represents
so we're going to draw out a graph
corresponding to this adjacency matrix
first thing that we're going to do is
we're going to try to figure out what
kind of graph we've got in the first
place now if we take a look at the
matrix the rows and columns are labeled
ABCD and E which means we have five
vertices which we're going to dry out
and label them a B C D and E now the
contents of the matrix itself are
numeric which means that there's going
to be some kind of weight associated
with the edges between each vertex now
if these have been boolean instead we
would say that it was an unweighted
graph but since we have numbers we're
going to associate those with the edges
the other thing that we can determine is
that by taking a look at the main
diagonal and the values on either side
the values on either side of the main
diagonal aren't identical so for example
evaluate Row one column two is not the
same as the value at Row two column one
what this means is the matrix is not
symmetric and therefore the graph is
bi-directional so we're going to have to
draw arrow heads as we go on each four
edges so let's start out with the first
row
and take a look at the edges that
originated a now there's two edges
originating at a one divert X B was
weight of three and another one to
vertex E with a weight of one now again
this is a directed graph so we're
drawing arrow heads on each edge as we
go there's only one edge originating a B
and that's an edge to D with wait to see
has three edges rigid a and they have
different weights we have one from C to
a with wait for one from C to B with
weight 2 and 1 from C to e with weight 5
there are two edges originating from d1
that goes to C with weight six and one
that goes to E with weight one
and then finally in the last row of our
matrix we have two edges originating at
row e1 back to a with weight one now
notice that we already have an edge from
A to E with weight one and the edge
going back will also have the same
weight so instead of drawing it in
another edge let's just draw in another
arrowhead indicating that this edge
happens to be bi-directional and the
other one is an edge from e to D with
weight three now although we already
have an edge from D to e we can't just
draw it in another arrowhead because
this new edge has a different weight so
I'll have to draw in another line with
an arrow going in the opposite direction
and label this one as having weight
three and that's our complete graph
based on that adjacency matrix for the
second demonstration we're going to take
a look at a different implementation of
a graph in this case a graph implemented
as an adjacency list there are six
vertices labeled a through F this will
start out by drawing our graph by
drawing those six vertices now we don't
know exactly where the best place to
draw these vertices are so we'll just
kind of take a guess and spread them
apart nicely so that we have lots room
to draw on edges the first item in our
adjacency list shows us all of the edges
originating at vertex a now a has an
edge going to see a soldier on that one
and in the absence of any evidence to
the contrary we're going to make this a
directed edge from A to C the second
item shows us the B has two edges
originating at B one to D and one to E
see has three edges one returning back
to a now in this case we don't have any
kinds weights so we'll just draw in an
arrow back to a 1/2 D and 1/2 e D has an
edge going to be well we already have an
edge from B to D so this is just now a
bi-directional edge and one back to C
again just another arrowhead on an
existing edge e has three edges one
returning back to be drawn another
arrowhead one back to C and one to F and
finally the last item in our Jason C
list shows us that there is an edge from
F returning back to e we take a careful
look at our graph we can see that all of
the edges that we've drawn in in fact
have arrowheads on both ends in other
words our graph is undirected now there
was no way for us to tell that from
actually looking at the original
adjacency list it's just something that
we had to discover as we went along
but that's our complete graph
hello everyone in our previous lessons
we introduced you to graphs and we also
looked at and talked about some of the
properties of graph but so far we have
not discussed how we can implement graph
how we can create a logical structure
like graph in computer's memory so let
us try to discuss this a graph as we
know contains a set of vertices and a
set of edges and this is how we define
graph in pure mathematical terms a graph
G is defined as an ordered pair of a set
V of vertices and a set of edges now to
create and store a graph in computer's
memory the simplest thing that we
probably can do is that we can create
two lists one to store all the vertices
and another to store all the edges for a
list we can use an array of appropriate
size or we can use an implementation of
a dynamic list in fact we can use a
dynamic list available to us in language
libraries something like vector in C++
or ArrayList in Java now a vertex is
identified by its name so the first list
the list of vertices would simply be a
list of names or strings I just filled
in names of all the vertices for this
example graph here now what should we
fill in this edge list here an edge is
identified by its two endpoints so what
we can do is we can create an edge as an
object with two fields we can define
edge as a structure or class with two
fields one to store the start vertex and
another to store the end vertex edge
list would basically be an array or list
of this type struct edge in these two
definitions of edge that I have written
here in the first one I have used
character pointers because in C we
typically use character pointers to
store or refer to strings we could use
character array
also in C++ or Java where we can create
classes we have string available to us
as a datatype so we can use tattles so
we can use any of these for the fields
we can use character pointer or
character array or string datatype if
it's available depends on how you want
to design your implementation now let's
fill this edge list here for this
example graph each row now here has two
boxes let's say the first one is to
store the start vertex and the second
one is to store the end vertex the graph
that we have here is an undirected graph
so any vertex can be called start vertex
and any vertex can be called end vertex
order of the vertices is not important
here we have 9 edges here 1 between a
and B another between a and C another
between a and D and then we have B E and
B F instead of having B F as an entry we
could also have F B but we just need one
of them and then we have CG D H E H and
F H actually there's one more we also
have G H we have 10 edges in total here
and not 9 now once again because this is
an undirected graph if we are saying
that there is an edge from F to H we are
also saying that there is an edge from H
to F there is no need to have another
entry as HF we will unnecessarily be
using extra memory if this was a
directed graph F H and H F would have
meant two different connections which is
the start vertex and which is the end
vertex would have mattered maybe in case
of undirected graphs we should name the
fields as first vertex and second vertex
and in case of directed graphs we should
name the fields as start vertex and end
vertex now our graph here could also be
a weighted graph we could have some cost
or weight associated with the edges as
you know in an unweighted graph
cost of all the connections is equal but
in a weighted craft different
connections would have different weight
or different cost now in this example
graph here I have associated some
weights to these edges now how do you
think we should store this data the
weight of edges well if the graph is
weighted we can have one more field in
the edge object to store the weight now
when entering my edge list has three
fields one to store the start vertex one
to store the end vertex and one more to
store the weight so this is one possible
way of storing the graph we can simply
create two lists one to store the
vertices and another to store the edges
but this is not very efficient for any
possible way of storing and organizing
data we must also see its cost and when
we say cost we mean two things time cost
of various operations and the memory
usage typically we measure the rate of
growth of time taken with size of input
or data what we also call time
complexity and we measure the rate of
growth of memory consumed with size of
input or data what we also call space
complexity time and space complexities
are most commonly expressed in terms of
what we call Big O notation for this
lesson I am assuming that you already
know about time and space complexity
analysis and Big O notation if you want
to revise some of these concepts then
you can check the description of this
video for link to some lessons we always
want to minimize the time cost of most
frequently performed operations and we
always want to make sure that we do not
consume unreasonably high memory okay so
let's now analyze this particular
structure that we are trying to use to
store our graph let's first discuss the
memory usage for the first list the
vertex list least number of rows needed
or consumed would be equal to number of
vertices now each row here in this water
list is a name or string and string can
be of any length right now all strings
have just one character because I simply
named the nodes a B C and so on but we
could have names with multiple
characters and because strings can be of
different lengths all rows may not be
consuming the same amount of memory like
here Here I am showing an intra-city
road network as a weighted graph cities
are my nodes and Road distances are my
weights now for this graph as you can
see names are of different lengths so
all rows in vertex list are all rows in
edge list would not cost the same more
characters will cost us more bytes but
we can safely assume that the names will
not be too long we can safely assume
that in almost all practical scenarios
average length of strings will be a
really small value if we assume it to be
always lesser than some constant then
the total space consumed in this vertex
list will be proportional to the number
of rows consumed that is the number of
vertices or in other words we can say
that space complexity here is Big O of
number of vertices this is how we write
number of vertices with two vertical
bars what we basically mean here is
number of elements in set V now for the
edge list once again we are storing
strings in first two fields of the edged
object so once again each row here will
not consume same amount of memory but if
we are just storing the reference or
pointer to a string like here in the
first row instead of having values
filled in these two fields we could have
references or pointers to the names in
the vertex list if we will design things
like this each row will consume same
memory this in fact is better because
references in most cases would cost us a
lot lesser than a copy of the name and
as reference we can have the actual
address of the string and that's what we
are doing when you are saying that start
and end vertex can be character pointers
or maybe a better design would be simply
having the index of the name word string
in vertex list let's say a is at index
zero in the vertex list and B is at
index 1 and C is at index 2 and I'll go
on like this now for start what X hand
end vertex we can have two integer
fields as you can see in both my
definitions of edge start vertex and end
vertex are of type int now and in each
row of edge list first and second field
are filled with integer values I have
filled in appropriate values of indices
this definitely is a better design and
if you can see now each row in edge list
would cost us the same amount of memory
so overall space consumed in edge list
would be proportional to number of edges
or in other words space complexity here
is Big O of number of edges okay so this
is analysis of our memory usage overall
space complexity of this design would be
Big O of number of vertices plus number
of edges is this memory usage
unreasonably high well we cannot do a
lot better than this if we want to store
a graph in computer's memory so we are
alright in terms of memory usage
now let's discuss time cost of
operations what do you think can be most
frequently performed operations while
working with graph one of the most
frequently performed operations while
working with graph would be finding all
nodes adjacent to a given node that is
finding all nodes directly connected to
a given node what do you think would be
time cost of finding all nodes directly
connected to a given node well we will
have to scan the whole edge list we will
have to perform a linear search we will
have to go through all the entries in
the list and see if the start or end
node in the entry is our given node for
a directed graph we would see
if the start node in the entry is our
given node or not and for an undirected
graph we would see both the start as
well as the end node running time would
be proportional to number of edges or in
other words time complexity of this
operation would be Big O of number of
edges okay now another frequently
performed operation can be finding if
two given nodes are connected or not in
this case also we will have to perform a
linear search on the edge list in worst
case we will have to look at all the
entries in the edge list so worst-case
running time would be proportional to
number of edges so for this operation to
time complexity is Big O of number of
edges now let's try to see how good or
bad this running time Big O of number of
edges is if you remember this discussion
from our previous lesson in a simple
graph in a graph with no self loop or
multi edge if number of vertices that is
the number of elements in set V is equal
to n then maximum number of edges would
be n into n minus 1 if the graph is
directed each node will be connected to
every other node and of course minimum
number of edges can be 0 we can have a
graph with no edge maximum number of
edges would be n into n minus 1 by 2 if
the graph is undirected but all in all
if you can see number of edges can go
almost up to square of number of
vertices number of edges can be of the
order of square of number of vertices
let's denote number of vertices here as
small V so number of edges can be of the
order of v square in a graph typically
any operation running in order of number
of edges would be considered very costly
we try to keep things in order of number
of vertices when we are comparing the
two running times this is very obvious
Big O of V is a lot better than Big O of
v square
all in all this what X list and edge
list kind of representation is not very
efficient in terms of time cost of
operations we should think of some other
efficient design we should think of
something better we will talk about
another possible way of storing and
representing graph in next lesson this
is it for this lesson thanks for
watching
okay so here we are with Dijkstra's
shortest path algorithm and we're going
to look at how we trace it as we need to
for the a-level computer science as
opposed to decision math or any other
time you may come across this so we've
got our graph in front of us here that
we're going to be finding the path for
and we're going to be moving from A
through to G and we want to find the
shortest path to do that so the first
thing you're going to need to do for
this is to produce an adjacency matrix
of your graph and you should know how to
do this so basically very simply you put
all the nodes or vertexes that you've
got across the top and across the bottom
of boards going horizontally and going
vertically and then you just show the
waiting's that there were between each
of the notes so for example if you have
a quick look here between a and B was
for between a and C is three and a and D
is seven so if we look at our chart you
will see that between a and B is for a
and C is three a and B is seven and we
have no links between e F and G with a
so we use this little infinity sign to
an infinite distance there is no
connection at all and the distance we
nee in itself is obviously zero and that
carries through for b c d e G so a trust
that you're able to produce those we're
not going to go into that right now what
we are going to go into how we work out
the shortest path so to do that we need
a new table we're going to call it
distances from a because we all start
from we're starting from a that's the
start of our path and we're trying to
work out the distances the shortest
distances for each of the potential node
from a so let's call that distances from
a so that we know what it is okay and
we're going to need to gently move it
over slightly and need a little bit more
space we need to have for every one of
the different vertices a little box so a
I'm going to leave a bit of space next
to actually be c d e f and g okay fill
in and we need to also write down maybe
what our current vertex is that we're
looking at so that's going to be the
vertex we're going to put here and step
the number in our trace table the way up
to so chording this off a little bit so
that we don't get distracted by it no
later than that let's try that again
thanks so okay we've got our distances
from a we're going to be filling those
in here and we've got the step that
we're currently on and the vertex of the
current e traversing so we need to now
work out we're going to start at a and
we want to work out the distances of all
the different nodes or vertex is from
vertices from a so step one we start
with a and we work up the distances from
a and this is really pretty easy because
we've already got that information in
that first row it's it's just a question
of copying these numbers over so this is
remaining zero and we went via vertex a
that's something we'll look at in a
minute but you have to sort of write
down what have we gone through to get to
this um that's in relation to our graph
from before so we've gone through kind
of a to get to itself which is it
this first instance that just keep going
with it okay
B is for away from a and we got there
via a C is three away from a and we got
there via a D is seven away and we got
there by a an EF and G there is no we
don't need to fill it out there is no
connection so we don't know yet how far
away from a they are okay how do we get
onto step two well we need to find the
smallest value oh by the way if you
think finish going through an A you kind
of bought a vertex you can then put a
ticket off say we're no longer going to
consider that one when we look for
shortest parks we've already got the
shortest part so we now look at our
remaining paths from a and we find the
lowest value which in this case is C so
it because then three away from a so
we're going to do vertex C and we've
already found us apart basically just
copy it down again now from see what's
the distance to be well there is no link
between B and C so we with still on for
a we just bring that down again we
haven't we haven't improves upon that C
well C has a business a zero from itself
so what we do is we get the distance
we've already got from a which is which
three away from a then we add how far
away we are from C which is zero to that
certain comes three still but now we've
got there via C okay D D is three away
from C so how far away is it from a well
it must be three plus the three that C
is away from a so C two a is 3 and B 2 C
is 3 so the Dixon can be
from a because that's what this table is
telling us businesses from a not
distances from see we just happen to be
looking at birth exceed businesses from
a is six and we got there via see care
to the e E is five away from C which
means it must be eight away from a
because again it took us three steps to
get to see from a so we've got five plus
three is eight and we've got there by IC
and we don't have any values yet for f
or g so we've done a and we've done C so
we can pick this one off so of our
numbers that remain B has the smallest
value is the nearest is the next nearest
one to a so let's look at that next so
step three is B and we copy down our
value for a and we look at C well B is
zero way from itself of course so and
itself is for away from a so it is now
four but via B and C we've already got
so we just put three C and again again
we don't need to check that one a
gangster you've already covered see
we've actually now covered B so you can
tick me off so it leads us to see e F
and G so B to D that's one but B to a is
four so via B A to B must be five which
is nearer and we write that in if it was
a bigger number than six or seven we
wouldn't we wouldn't write it it may be
node point because it's going to be a
longer distance but we've now improved
on D every time
originally D was seven away then we
found it to advice
C we can get there in six now we found
it's go buyer B we can get there in five
okay let's look now II
no relation so we just take the
information we already have which is 8
by C F is 5 away 5 away plus the
original four it took us to get there
means it's 9 away by B and we started to
have a route yet to G so let's look what
we got left 5 8 9 will 5 is clearly
smallest and five types of suit vertex D
so let's try that
step 4 vertex D well we can copy over
these values that we've already dropped
and we're on to D say C is 0 a from
itself and its nearest route a currently
is five prior B so we can now save it by
B B is in B 5 away e is two away from D
and B is five away from a so e by B is 7
5 plus 2 is 7 by D so we've improved
upon our 8 so we get rid of the 8 we
replace it with 7 F is 2 away from D and
again these 5 away from a so that means
that I think also something and we
finally got our first G as well G is 7
away from D and D is 5 away from a so 7
plus 5 is 12 D is 12 away from a via D
all right okay we've done David kick
deal so we're left with 7 7 and 12 not
this stage it doesn't really matter
which of these two sevens we take
they're equal but we might have to take
the first one so we're going to say our
next step 5 we're going to look at E and
we can copy all these initial values
over
because we know is cover those salon to
e now well e is obviously zero way from
itself and it's seven way from a so now
it's going to be seven away from a via e
F is where it's F there is no link so we
just pull down the seven B again and he
is now two away from G and E is seven
away from a so 7 plus 2 is 9 which beats
our 12 so we can pretend so we can
forget the 12 route the route via D that
takes 12 steps and we can now use just
route that is 9 steps by E that's pretty
good going going across what B now we've
got two different routes now to G so if
we just stopped it again how are our
we've reached G we would never find this
shorter route which is kind of the point
of the whole algorithm but we we may
have finished but we don't know for
certain so we're just going to finish it
off by doing the s row just for certain
so step six s try F well we can copy or
leave over and we know the 7 is 0 away
from its sorry F is 0 F F so it's
obviously 7 away and F has a distance
from G of 5 well it is self is 7 away
from a 7 plus 5 takes us back to the 12
again we had before so we could put in
12 via F but a wine earth would we have
replaced our distance our best distance
from for G from a with a greater
distance so we're not going to do that
so raise that it's not better so we just
put back the 9 either we had which is
indeed our shortest path so how do we
now actually where the path out well
except a little bit of backwards
reversal and that's where these letters
we've been putting in a really
useful so we know that we finish it G
because that's our end point so we
choose another nice color so going to
finish with G how did we get to G well
we got there via e so our next pass our
next node on the path is e how did we
get to e well e we got there via B how
did we get to D well the best way we got
D was via B and how did we get to B well
we got there via a so our shortest path
is a BD e G look at our graph again a B
D e G that's our shortest path and we
can verify that so it's 4 plus 1 5 2 7
plus 2 is 9 and indeed that's what we're
told hit it isn't the 9 away and that's
the shortest path we could have done if
we're taking any other routes it would
have been like maybe a B F G that have
been for 14 so that's longer and so on
so this is our shortest path so that's
how you go about finding and tracing
this here is our trace tables this shows
the steps we've taken and it shows the
vertex that we were looking at each time
and it shows how our distances from a
which is actually just a single
dimension array has updated its values
each step through
we always update it when we find a
shorter path if we don't find a shorter
path we don't update it and crucially
these values you get them by looking at
well what is the distance of let's in
this so in this case e from C plus the
distance that C was from a and that's
how those those values come out ok so I
hope that
make some sense my recommendation if you
do some practice and make sure that you
can do this by memory and by rates
because it's something you will need to
be able to do it could well commit an
exam it's a very it's a very meaty
question there's lots and lots they
could ask you they can easily ask you
for example they could show you a graph
and ask you to identify the algorithm
that you could use finest realist path
they could ask you to label different
parts of the graph they could ask you
then to draw your adjacent C matrix
based on the graph then they can ask you
to perform Dijkstra's shortest path
algorithm step tracing out all the steps
and showing what the ultimate path is
and what the shortest distance is so you
could ask like 20 mark question on this
so it's well worth knowing it off by
heart
welcome to our 27th video with data
structures and algorithms we're going to
continue with graphs probably should
have done this one before the last two
videos but that's okay let's do it now
we're going to do a jason see lists and
adjacency matrices so we let's start off
with an adjacency list we're going to
kind of go in a different direction here
now this is what this is a
representation of our graph so let's do
some practice with converting this into
an adjacency matrix so firstly with the
adjacency matrix what we're going to
write a 1 if there's an edge between the
two right and we're going to write zeros
otherwise right so we're going to start
from a left right this will be the nodes
that are in the actual array here and
these will be its adjacency list this is
top the columns ok you'll see what I
mean in a second so for a in its
adjacency list we have C D and G so
along this row we are going to write
ones at C oh let's say at C D and G now
everything else is going to be zeroes
we're going to write in zeroes later so
that we can kind of visualize this a
little better let's keep going so with B
it has a jason Siletz with e all right
so E is in its adjacency list it's
connected to visit there's an edge from
B to e C has an edge right it has a
self-loop D also has a self-loop it also
has an edge from D to E and there's also
an edge from D to F with e U has an edge
to G all right has a direct path to G F
has a path to B right an edge between F
and B and another edge there's another
edge between G are from G to B ok so
that's kind of what our matrix
looks like now this is a directed graph
and we know that because this is not
symmetrical okay that means there's not
an edge you can see this is an edge from
A to C but there is not an edge from C
to a okay so this is this is a directed
graph so now let me just pick a
different color and we're going to put
in zeros okay for the rest of this just
to be a little bit more complete okay
that's a lot of zeros I know just hang
with me for a second
zero zero all these zeros fun times
there we go here we go zero zero zero
zero okay and there we go so that's what
our adjacency matrix looks like for this
graph now let's do a little something
else let's translate this into the graph
like a visual representation that we are
used to so I'm kind of running out of
space here so we're going to have to
kind of go back and forth that's okay so
let's start with node a so we have a
node a here let's put it like this okay
and we know that there's an edge from A
to C so I'm going to put C up here okay
there's that there's also an edge from A
to D so let's draw a D node and we'll do
an edge there and then another one to G
so we're going to put G down here okay
there we go that's our first one you did
the same looking at this right so
looking at this we're going to show
another one but we'll do it from this
side so let's do B from this side so B
has an edge there's an edge from B to e
right here so let's do that
so let's do be down here and there's
another ed right there's a edge from B
to e so we're going to put e right here
okay
make that a little better well that's
not better at all that's okay
so next one is C right C has a self loop
you can see that right here if you'd
like to look at this one instead right
there's a one at C C so there is a self
loop on C for D D has an edge from D to
D so this also has a self loop there's
an edge from D to e okay so let's do
that here I've horrible arrows all right
let's just clean that one up a bit it's
a little better and there's also an edge
from D to F so f is not on here so let's
draw our F node okay so there's that he
has an edge to G so let's scroll down so
we can make a little loop here so we
have a edge from E to G and from F we
have an edge to be you know what I'm
going to redraw this to come over here
and F has an edge to be there we go you
don't have to cross lines and then G
also has an edge to be able to go that
works out good stuff okay so there is
our graph right now let's do some more
exercise while we're here and let's do
on line just a second here let's grab my
color I'll have the right color I lost
it so let's do this
okay let's do depth-first search on this
depth-first search just for some
practice and let's start from here
actually we can signify starting with
just this one oh wow that was not right
so we start here right have one now
we're going to take this we're going to
do this in this order the order of our
list so C is going to be the first place
that we go all right so let's go along
see we've discovered this at time two
and now let's do C right C has a
self-loop so it's already been
discovered so we're done with this one
three now back to a right so the next
one in a is d now you can see that here
so let's go that path okay and time for
this was discovered so let's look at D
the first one D is a self-loop so that's
already been discovered already gray he
is the next one so let's take that path
so time five so e down here has a path
from E to G alright so let's take this
path and it's been discovered at times
six G has a path to be right it has an
edge from G to B so now B has been
discovered at time seven let's go up to
B let's take the path to e except E has
already been discovered so we're done
with this one so it's been discovered a
time eight back to G this is done at
time nine there's nothing left and it's
list back to e
there's nothing left in its list right
so that's done at time 10 back to D the
next one in these lists is f so let's
take a path over to F and this has been
discovered at time 11 so f has be right
in its
adjacency list bees already been
discovered so we're done with this one
at time 12 and that means that we are
done with D at time 13 and then we are
done with a because G has already been
discovered so we were done with this at
time 14 all right that was kind of fun
let's do breadth-first search on this on
the same one let's just redraw this
alright let's just get some practice in
might as well so we got C over here
we've got G we put F over here whoops
it's kind of messed up
but F over here B is down here and E is
over here so we've got this kind of
crazy lines here okay there's a path
here so path here here and here I think
that's all of them yep okay
and let's do breadth-first search over
here breadth-first search now we have a
queue remember so here's our Q first
it's empty we're going to start at a
alright start here its distance is zero
so we put a right in the queue we take a
out of the queue and we put its
adjacency list on all right
all the distance of one so we have C D
and G we take C off right see points to
itself so we have we don't put anything
else on the queue next we take D off and
we put E and F on right who comes
first he comes first in the adjacency
list so that's we're going to put on
first so we've got G E and F all right
these are distance of two so next we
take G off and we put B on here all
right so now our cue looks like this
e F B okay next in the queue is e so you
take a off G has already been discovered
so we don't put anything else on so I'm
going to write this over here so f and B
are now on the queue we take F off the
cube B has already been discovered it's
already in the queue so we don't put
anything in there right B we would put
we take B off the queue now that would
be e right except E has already been
discovered so we don't put anything on
the queue and there's no nodes left
that's we've gone through all the nodes
and that's it so there's our depth-first
search or breadth-first search and our
adjacency matrix in our adjacency list
so there you have it
in our previous lesson we introduced you
to graphs we defined graph as a
mathematical or logical model and talked
about some of the properties and
applications of graph now in this lesson
we will discuss some more properties of
graph but first I want to do a quick
recap of what we have discussed in our
previous lesson a graph can be defined
as an ordered pair of a set of vertices
and a set of edges we use this formal
mathematical notation G equal V II to
define a graph here V is set of vertices
and E is set of edges ordered pair is
just a pair of mathematical objects in
which order of objects in the pair
matters it matters which element is
first and which element is second in the
pair now as we know to denote number of
elements in a set that we also call
cardinality of a set we use the same
notation that we use for modulus or
absolute value so this is how we can
denote number of vertices and number of
edges in a graph number of vertices
would be number of elements in set V and
number of edges would be number of
elements in set E moving forward this is
how I am going to denote number of
vertices and number of edges in all my
explanations now as we have discussed
earlier edges in a graph can either be
directed that is one-way connections or
undirected that is two-way connections a
graph with only directed edges is called
a directed graph or digraph and a graph
with only undirected edges is called an
undirected graph now sometimes all
connections in a graph cannot be treated
as equal so we label edges with some
weight or cost like what I'm showing
here and a graph in which some value is
associated to connections as cost or
weight is called a weighted graph a
graph is unweighted if there is no cost
distinction among edges okay now we can
also have some special kind of edges in
a graph these edges complicate
algorithms and make working with graphs
difficult but I'm going to talk about
them anyway an edge is called a self
loop or self edge if it involves only
one vertex
if both endpoints of energy are same
then it's called a self-loop we can have
a self-loop in both directed and
undirected graphs but the question is
why would we ever have a self-loop in a
graph well sometimes if edges are
depicting some relationship or
connection that's possible with the same
node as origin as well as destination
then we can have a self loop for example
as we have discussed in our previous
lesson interlinked web pages on the
internet or the world wide web can be it
presented as a directed graph a page
with a unique URL can be a node in the
graph and we can have a directed edge if
a page contains link to another page now
we can have a self loop in this graph
because it's very much possible for a
web page to have a link to itself have a
look at this web page my code school
comm / videos in the header we have
links for workouts page problems page
and read your age right now I'm already
on videos page but I can still click on
videos link and all that will happen
with the click is a refresh because I am
already on videos page my origin and
destination are same here so if I'm
representing world wide web as a
directed graph the way we just discussed
then we have a self loop here now the
next special type of edge that I want to
talk about is Multi edge and edge is
called a multi edge if it occurs more
than once in a graph once again we can
have a multi edge in both directed and
undirected graphs
first multi edge that I'm showing you
here is undirected and the second one is
directed now once again the question why
should we ever have a multi edge well
let's say we are representing flight
Network between cities as a graph a city
would be a node and we can have an edge
if there is a direct flight connection
between any two cities but then there
can be multiple flights between a pair
of cities these flights would have
different names and may have different
costs if I want to keep the information
about all the flights in my graph I can
draw multi edges I can draw one directed
edge for each flight and then I can
label
and edge with its cost or any other
property I just labeled edges here with
some random flight numbers now as we
were saying earlier selfloops and multi
edges often complicate working with
graphs the presence means we need to
take extra care while solving problems
if a graph contains no self-loop or
multi edge it's called a simple graph in
our lessons we will mostly be dealing
with simple graphs now I want you to
answer a very simple question given
number of vertices in a simple graph
that is a graph with no self loop or
multi-edge what would be maximum
possible number of edges well let's see
let's say we want to draw a directed
graph with four vertices I have drawn
forward DC's here I will name these
vertices v1 v2 v3 and v4 so this is my
set of vertices number of elements in
set V is 4 now it's perfectly fine if I
choose not to draw any edge here this
will still be a graph set of edges can
be empty nodes can be totally
disconnected so minimum possible number
of edges in a graph is 0 now if this is
a directed graph what do you think can
be maximum number of edges here well
each node can have directed edges to all
other nodes in this figure here each
node can have directed edges to 3 other
nodes we have 4 nodes in total so
maximum possible number of edges here is
4 into 3 that is 12 I have shown edges
originating from a vertex in same color
here this is the maximum that we can
draw if there is no self loop or
multi-edge in general if there are n
vertices then maximum number of edges in
a directed graph would be n into n minus
1 so in a simple directed graph number
of edges would be in this range 0 to n
into n minus 1 now what do you think
would be the maximum for an undirected
graph in an undirected graph we can have
only one bi-directional edge between a
pair of nodes we can't have two edges in
different directions so here the maximum
would be half of the maximum for
directed
so if the graph is simple and undirected
number of edges would be in the range 0
to n into n minus 1 by 2 remember this
is true only if there is no self loop or
multi-edge now if you can see number of
edges in a graph can be really really
large compared to number of vertices
for example if number of vertices in a
directed graph is equal to 10 maximum
number of edges would be 90 if number of
vertices is 100 maximum number of edges
would be 9900 maximum number of edges
would be close to square of number of
vertices a graph is called dense if
number of edges in the graph is close to
maximum possible number of edges that is
if the number of edges is of the order
of square of number of vertices and a
graph is called sparse if the number of
edges is really less typically close to
number of vertices and not more than
that there is no defined boundary for
what can be called dense and what can be
called sparse it all depends on context
but this is an important classification
while working with graphs a lot of
decisions are made based on whether the
graph is dense or sparse for example we
typically choose a different kind of
storage structure in computer's memory
for a dense graph we typically store a
dense graph in something called
adjacency matrix and for a sparse graph
we typically use something called
adjacency list I'll be talking about
adjacency matrix and adjacency lists in
next lesson ok now the next concept that
I want to talk about is concept of path
in a graph a part in a graph is a
sequence of vertices where each adjacent
pair in the sequence is connected by an
edge I'm highlighting a path here in
this example graph the sequence of
vertices a B F H is a path in this graph
now we have an undirected graph here
edges are bi-directional in a directed
graph all edges must also be aligned in
one direction the direction of the path
part is called simple path if no
vertices are repeated and if what
disease are not repeated then edges will
also not be repeated so in a simple path
both vertices and edges are not repeated
this path a bfh that I have highlighted
here is a simple path but we could also
have a path like this here start vertex
is a and end vertex is D in this path
one edge and two vertices are repeated
in graph theory there is some
inconsistency in use of this term path
most of the time when we say path we
mean a simple path and if repetition is
possible we use this term walk so a path
is basically a walk in which new
vertices or edges are repeated of walk
is called a trail if what disease can be
repeated but edges cannot be repeated I
am highlighting a trail here in this
example graph ok now I want to say this
once again walk and path are often used
as synonyms but most often when we say
path we mean simple path a path in which
vertices and edges are not repeated
between two different vertices if there
is a walk in which vertices or edges are
repeated like this walk that I am
showing you here in this example graph
then there must also be a path or simple
path that is a walk in which what
disease or edges would not be repeated
in this walk that I'm showing you here
we are starting at a and we are ending
our walk at C there is a simple path
from A to C with just one edge all we
need to do is we need to avoid going to
be e H D and then coming back again to a
so this is why we mostly talk about
simple path between two vertices because
if any other walk is possible simple
path is also possible and it makes most
sense to look for a simple path so this
is what I'm going to do throughout our
lessons I'm going to say path and by
path L mean simple path and if it's not
a simple path I will say it explicitly
our graph is called strongly connected
if in the graph there is a path from any
vertex to any other vertex if it's an
undirected graph we simply call it
connected and if it's a directed graph
we call it strongly connected in
leftmost and rightmost graphs that I'm
showing you here we have a path from any
vertex to any other vertex but in this
graph in the middle we do not have a
path from any vertex to any other vertex
we cannot go from vertex C to a we can
go from A to C but we cannot go from C
to a so this is not a strongly connected
graph remember if it's an undirected
graph we simply say connected and if
it's a directed graph we say strongly
connected if a directed graph is not
strongly connected but can be turned
into connected graph by treating all
ages as undirected then such a directed
graph is called weakly connected if we
just ignore the directions of the edges
here this is connected but I would
recommend that you just remember connect
it and strongly connected this leftmost
or undirected graph is connected I
removed one of the edges and now this is
not connected now we have two disjoint
connected components here but the graph
overall is not connected connectedness
of a graph is a really important
property if you remember intra-city road
network road network within a city that
would have a lot of one-ways can be
represented as a directed graph now an
intra-city road network should always be
strongly connected we should be able to
reach any street from any street any
intersection to any intersection ok now
that we understand concept of a path
next I want to talk about cycle in a
graph a walk is called a closed walk if
it starts and ends at same vertex like
what I'm showing here and there is one
more condition the length of the walk
must be greater than 0 length of a walk
or path is number of edges in the path
like for this closed walk
that I'm showing you here length is five
because we have five edges in this walk
so a closed walk is walk that starts and
ends at same vertex and the length of
which is greater than zero now some may
call closed walk a cycle but generally
we use the term cycle for a simple cycle
a simple cycle is a closed walk in which
other than start and end vertices no
other vertex or edge is repeated right
now what I'm showing you here in this
example graph is a simple cycle or we
can just say cycle a graph with no
cycles is called an acyclic graph a tree
if drawn with undirected edges would be
an example of an undirected acyclic
graph here in this tree we can have a
closed walk but we cannot have a simple
cycle in this closed walk that I'm
showing you here our edge is repeated
there would be no simple cycle in a tree
and apart from tree we can have other
kind of undirected acyclic graphs also a
tree also has to be connected now we can
also have a directed acyclic graph as
you can see here also we do not have any
cycle you cannot have a path of length
greater than 0 starting and ending at
the same vertex or directed acyclic
graph is often called a dag cycles in a
graph caused a lot of issues in
designing algorithms for problems like
finding shortest route from one vertex
to another and we will talk about cycles
a lot when we will study some of these
at one still go our thumbs and coming
lessons for this lesson I will stop here
now in our next lesson we will discuss
ways of creating and storing graph in
computer's memory this is it for this
lesson thanks for watching
hello guys you will be seeing a C code
for adjacency list representation of a
directed or undirected graphs in this
video so first of all we should have a
basic knowledge about graphs so what is
a graph so we would give a brief
introduction about graphs so graphs are
nothing but it has a data structure that
consists of two components first it
candy it contains a finite set of
vertices second it contains a finite set
of ordered pairs which are of the form
UE these are also called edges so what
does a graph consists of it consists of
two components which are number of
vertices which are set of vertices and
set of edges which comprises whose graph
so let's illustrate it with the pigs
ample so what a graph consists of set of
vertices and set of edges so let's say
these are the vertices 1 2 &amp; 3 &amp; 4 so
the lines which connect them forms and
edges of the graph so these are called
vertices of the graph and these are
called the edges of the graph so now we
have a
now we have a brief knowledge about
graphs so let's get to this so why we
said these are the ordered pairs ordered
pair because here the order patterns
because if you will see that 1 2 is an
age you can't say always a 2 1 is also
off will also form an edge so we will
see now in which graphs we can say that
1 1 2 is same as 2 1 where the order
does not matter there you can say that
if there is an edge from 1 to 2 there is
an edge from 2 to 1 also so these are
typically let's say we have two types of
graph for this first is undirected
graphs these have a pair of an ordered
vertices hey UV is same as we let's say
we can say in these type of graphs as 1
2 is same as 2 1 for example in this
graph 1 2 is an edge 2 1 is also an edge
because we aren't well we have we are
allowed to go anywhere in this graph so
1 2 is same as 2 1 in this graph so
these type of graph forms and undirected
graphs what we call that undirected
graphs so if we a lot directions to them
let's say if we are given these type of
directions here 1 2 is not same as 2 1
you are allowed to go from 1 to 2 1 2
phones an edge but to one not for the
rich let's not form the gauge white 2 1
does not form an edge because you are
not allowed to go from 2 to 1 but you
are allowed to go from 1 to 2 all right
so 1/2 is 1/8 but to what is not an inch
so these type of graphs where we are
allowed to go in one direction in the
direction which we are given we can we
are allowed to go in that direction only
we call that type of graph story
two drafts so if your Lord directions
with the a directed graph that becomes
directed graph so this was all about
graphs now you will see its
representation how we can represent it
represent a graph so we will be seen now
how we can represent a graph we can
revisit the graph using to the help of
two methods so first as with the help of
adjacency list and second one is with
the help of adjacency matrix so in this
video we will be seeing how we can
represent a graph using a distance a
list what we will do to represent a
graph using a distance a list so what we
will do so let's say if we have a graph
that I'll what theis is let's say it has
five vertices and this graph let's say
is an undirected one we are allowed to
go anywhere through the edges we can go
from one to two you can also go from two
to one also so this is an undirected
graph so let's say it's if this is a
graph so if we want to represent this
graph using adjacency list what we will
do is so we will create an array of
linked lists we will create an array of
linked list and that the size of the
array would be the number of vertices
that we have in a graph so in this graph
we have five vertices so our array size
would be five so this would be array and
this would this array would correspond
this array would be the array of linked
list so each entry in the array would
correspond to the linked list like this
this would be pointing to a linked list
this would also point to a linked list
this entry would also go into a linked
list this entry would also point to an
linked list so watched what would be
contained in that look list so each
entry in the array would be the set of
vertices let's say we have five vertices
so each entry in this would correspond
to the word linked list of vertices
which are adjacent to one so what are
the vertices that are adjacent to one
these are two and five right so this
entry would correspond to the linked
list which will contain what Isis -
inside that far
adjacent to one similarly for 2 what are
the vertices that are adjacent to two
these are 1 and 3 right so this entry
would correspond to the word Isis that
are adjacent to 2 these are 1 and 3 this
would point to null this will also point
to lunch similarly for 3 what are the
vertices that are adjacent to 3 these
are 4 and 2 right so this would be
forming a linked list correspond to
correspond corresponding to the edge s
is what our dices 2 3 so these word for
n 2 so we created a linked list with 4
and 2 3 a - just 2 3 similarly for 4
what are the adjacent toward Isis - for
these are 3 inside so we would attach we
will attach three in five think this
with that similarly 4 5 so what are the
adjacent what Isis - fine these are 1 &amp;
4 so they will be forming a linked list
that will contain vertices that are
adjacent to 5 so this is what a graph
will look like a favored trip
in the form of adjacency list now we'll
be seeing a seafood for representing a
graph using adjacency list
hi guys is video mohandro Janek a
decency matrix representation guevara
when the adjacent vertices of a graph is
represented in the form of matrix then
such type of representation is called
adjacency matrix representation of a
graph is named number of rows equal
within number of columns the number of
physically gravelly things example me
crappity kept his calm logo bow it is in
c matrix representation nikola autumn
locus in occulta belly-to-belly vodka
number of rows Disney okay number of
columns on get the number of cross or
number of forms my basket has six in
take a is hot I'm putting one two three
four five six to use 69 okay
how is cool represent gets a cut ends of
zip LFO diagonally up to one say two
mega octane or one six six nine take it
to once you do or one six six two
thousand eight one four one field that
night or baggage it may be a submit zero
which there is a tuba dect led not to up
they can to say up three me a sec there
to say up one mega set then take it to
one but three may up one finger thing or
baggy samba zero is whether three school
is called a attended three say to us at
the three step four we have seven three
seven is equal to 2 for 5 negative 2 for
5 May 1 1 1 he cut thing her back is sum
is 0
she dropped for say up three me for say
out 5 me as a head to force a three
sorry 43 over say 5 to 3 or 5 3 4 5 yeah
1 or e ah 1 dollar 1 1000 a pullback is
something 0 was you throw 5 me pipes is
6 5 0 5 C 3 a nigga 3 4 6 May 1 1
Pickering or bakasana 0 6 7 more 6fi
method 105 yen you keep one code 5 BM 1
min 1 / 5 new one
tell me one one filter in your bucket
sum is 0 0 0 the key here is graph
a decency matrix representation thanks
for watching
all right in this video I just want to
talk a little bit about some graph
theory and just some basic terminology
and ideas they get used so definitely
not going to be a you know a complete
version of everything you need to know
but definitely some basic ideas so graph
theory got started by really kind of I
think really came about by Leonardo and
what he did is he solved a problem the
famous bridge of coningsburgh problem
and that kind of a put graph theory sort
of out there for people to start
thinking about and for a while graph
theories kind of kind of poo-pooed on it
was kind of considered I think sort of a
recreational branch of math not really a
ton of uses but uh definitely with the
advent here of computer science that's
changed all that graph theory gets used
all the time in computer science lots of
other places as well
definitely become a very hot area to
research and I like it just because the
problems are easy to understand you can
draw pictures and visualize I definitely
enjoy it but let's see so the definition
of a graph that we're going to use and
these vary again from person to person
things still aren't really set in stone
a lot of the notation and definitions
but for us a graph is going to be a
non-empty finite set of vertices some
people will let it be infinite with a
set of two elements subsets of V we call
the elements of V vertices and the
elements of a are called edges so that
sounds may be a little more confusing
that it is all a graph is it's just dots
and lines connecting that's all a graph
is okay so we talked about graph theory
we're not talking about y equals x
squared
just just points and lines connecting
them so we would say the vertex set V
for this
graphs maybe we'll call it G are just v1
v2 v3 v4 v5 and v6 and you can think
really you know maybe these are just six
people at a party and v1 knows v2 v3 v4
you can see that v5 only knows person v4
and v6 maybe that's what an edge
represents is if they know each other
okay you know and you can make the edges
represent whatever you want to so maybe
we'll just think about the edges as
meaning there's a connection between
them and they know each other so the
edge set that's just going to be all two
elements subsets and basically we just
list all the vertices that have an edge
between them so v1 and v2 v1 and v3 v1
and v4
let's see v4 is connected to V 5 and
then vertex V 5 is connected to V 6 and
I think that's everything we need you
know we don't need to list V 6 is
connected to V 5 for example it's just
redundant already so if I had you know
again basically just this set in this
set e again it's just basically telling
me all the information in this original
graph so I still know that a couple
things the cardinality the cardinality
of a graph just represents the number of
vertices
the notation I've seen is they'll put an
absolute value so the absolute value of
G the cardinality of G is just the
number of vertices which in this case is
six
let's see another thing that we often
talk about is the degree of a vertex so
for example the degree of vertex v1
which will abbreviate little deg v1 all
that tells you is the number of edges
coming out from vertex v1 so there's one
two three edges leaving v1 so we would
say the degree of vertex v1 is three
again so vertex v1 knows three other
people is all that says another kind of
convention for a typical graph we don't
let a vertex have a loop back to itself
okay I mean definitely that certainly
happens in a lot of applications but
when we lao graphs to have loops back to
themselves typically people will call
those multi graphs so multi grass have
loops regular graphs don't have loops so
pretend that loops not there and we just
got the original the original matrix
that we are the original graph we
started with a couple other things to
the way that you draw the graph is
irrelevant
so here's V one here's V two here's V
three here's V 4 V 5 down there I want
to make it too crazy v 6 you know they
don't have to be straight lines they can
be whatever they want so okay so V 1 is
still connected to V 2 V 1 should still
be connected to V 3 V 1 is still
connected to V 4
we'll have v4 still connected to v5 and
hey v5 is still connected to vertex v6
so all the original connections are
still preserved and there's sort of no
new connections in there that weren't
there before
so when you have a graph where basically
all the original information is
preserved the original connections
there's no new connections there's
nothing missing and again this is very
kind of loose definition but we would
say that the original graph and this new
graph are isomorphic and all that means
is from a graph theory point of view
they're one in the same they're exactly
the same graph okay so typically tribuna
will try to draw them as a you know in
the least confusing manner as possible
but definitely an important idea the way
that you draw the graph in general
doesn't matter let's talk about a couple
other ideas just a way to describe a
graph one way is with what's called an
adjacency list and I don't know how
useful these are I never really saw them
much but again I didn't take a
tremendous amount of graph theory so
that doesn't mean that they don't get
used all the time and I just haven't ran
into it but all an adjacency list is
exactly what you think so all we do is
just list vertex that our vertices that
are adjacent so for v1 it's adjacent to
v1
excuse me fee one's adjacent to v2 v3
and v4
so we'll list those v2 v3 v4 vertex V 2
is only adjacent to v1 v3 is only
connected to v1 v4 is connected to V 1
and V 5
v5 is connected to v4 and v6 and v6 is
connected to v5 and again it's just
another way of summarizing you know so
this is Jason C list this set V in the
set E and this graph again are telling
me all the exact same information
another way that I know gets used all
the time is instead of doing an
adjacency list we'll make what's called
an adjacency matrix okay so I'm going to
imagine v1 v2 v3 typically people won't
even write these but you know this is
what makes sense to me so a lot of times
I used to always stick them in there v1
v2 v3 v4 v5 v6 all we do is if there's a
loop if there's a connection from a
vertex to another vertex we'll put a 1
and if there's not we'll put a 0 so
since there's not a loop from v1 to v1
we'll put a 0 there but v1 is connected
to v2 v3 and v4 so V once connected to
v2 v3 and v4 but it's not connected to
v5 or v6 there's not an edge present
likewise v2 is only connected to v1 so
we'll put a 1 there and then we'll put
zeros everywhere else
let's see v3 is also only connected to V
ones we'll put a 1 there and zeros
everywhere else v4 is connected to v1
and also to v5 so we'll put ones there
zeros everywhere else v5 is connected to
v4 and v6 so put ones there zeroes
everywhere else
lastly v6 is only connected to v5 so
we'll put a one there
and zeros everywhere else so this is
nice because you can do math of major
Z's ok so definitely there's a lot of
study done with you know matrix
representations of graphs you can do
stuff with them two less things just
maybe two last ideas notice for any
vertex here if you you know so imagine
maybe these are islands now and there's
a little bridge connecting the islands
notice in this this graph if you ever
were to leave an island suppose I was at
Island v1 and I went to Island v4 the
only way I can get back to Island v1 is
the sort of backtrack you know I could
go all the way to v5 and v6 but
eventually to get back I have to take
you know the bridges back so there's no
loops or what are called circuits if
there are no loops or circuits we say
that this is an example of a what's
called a tree and the idea with trees is
you can always sort of rewrite them and
the reason why we call them trees is we
sort of can rewrite them you know so
here's v1 it's connected to V 2 V 3 V 4
V 4 is connected to V 5 and V five is
connected to V 6 so again these would be
isomorphic graphs but now it's kind of
if you flip it over and maybe it had
some more branches the idea that starts
to look like a tree trees get used all
the time for example you know imagine a
chess algorithm you know it's the first
move you know maybe you've got one two
three reasonable reasonable moves that
you're disposable at your disposal not
disposable at your disposal
you know and then maybe you know once
you consider this move maybe there's
only one logical move from that and then
from that there's only one logical move
so trees can help sort of represent sort
of searches you know a computer search
so definitely one place I know for sure
that they get studied again if a graph
so maybe this is a whole separate little
graph over here this graph we would say
has a circuit and the idea is a circuit
you know for example if I met this
vertex I can leave that vertex and still
manage to get back to it without really
ever backtracking through through an
edge or a vertice I don't have to visit
the same place twice as all it says ok
so this would be an example of a graph
that does have a circuit so graph theory
I think is really interesting you know
there's tons of open problems if you're
a budding math person out there and what
some challenging problems
there's definitely tons of open graph
theory problems that are very simple to
understand you know definitely you've
got to learn some of the techniques to
be able to attack things but a lot of it
is very sort of intuitive and I think
open you know sort of it's very user
friendly because what I'm trying to say
there's still some reasonable open
problems out there for people to tackle
for sure so if you are interested in
kind of getting your hands wet and doing
some harder problems
I say graph theory is a great place to
start maybe I can even post some open
questions so all right I hope this
little introduction makes some sense you
get nothing too heavy I definitely plan
on doing some more you know detailed
stuff but again hopefully this is a good
little warm-up and just a good little
intro to some of the ideas
hello everyone so far in this series on
data structures we have talked about
some of the linear data structures like
array linked lists stack and queue in
all these structures data is arranged in
a linear or sequential manner so we can
call them linear data structures and
we've also talked about tree which is a
nonlinear data structure tree is a
hierarchical structure now as we
understand data structures are ways to
store and organize theta and for
different kinds of data we use different
kinds of data structures in this lesson
we are going to introduce you to another
nonlinear data structure and that has
got its application in a wide number of
scenarios in computer science it is used
to model and represent a variety of
systems and this data structure is graph
when we study data structures we often
first study them as mathematical or
logical models here also we will first
study graph as a mathematical or logical
model and we will go into implementation
details later okay so let's get started
a graph just like a tree is a collection
of objects or entities that we call
nodes or vertices connected to each
other through a set of edges but in a
tree connections are bound to be in a
certain way in a tree there are rules
dictating the connection among the nodes
in a tree with n nodes we must have
exactly n minus 1 edges one edge for
each parent-child relationship as we
know an edge in a tree is for a
parent-child relationship and all nodes
in a tree except the root node would
have a parent would have exactly one
parent and that's why if there are n
nodes there must be exactly n minus 1
edges in a tree all nodes must be
reachable from the root and there must
be exactly one possible path from root
to a node now in a graph there are no
rules dictating the connection among the
nodes a graph contains a set of nodes
and a set of edges and edges can be
connecting nodes in any possible way
tree is only a special
kind of graph now graph as a concept has
been studied extensively in mathematics
if you have taken a course on discrete
mathematics then you must be knowing
about crafts already in computer science
we basically study and implement the
same concept of graph from mathematics
the study of graphs is often referred to
as craft theory in pure mathematical
terms we can define graph something like
this a graph G is an ordered pair of a
set V of vertices and a set of edges now
I'm using some mathematical jargon here
an ordered pair is just a pair of
mathematical objects in which the order
of objects in the pair matters this is
how we write and represent an ordered
pair objects separated by comma put
within parentheses now because the order
here matters we can say that V is the
first object in the pair and E is the
second object an ordered pair a B is not
equal to B a unless a and B are equal in
our definition of graph here first
object in the pair must always be a set
of vertices and the second object must
be a set of edges that's why we are
calling the pair an ordered pair we also
have concept of an ordered pair an
unordered pair is simply a set of two
elements order is not important here we
write an unordered pair using curly
brackets or braces because the order is
not important here an ordered pair a B
is equal to B a it doesn't matter which
object is first and which object is
second okay coming back so a graph is an
ordered pair of a set of vertices and a
set of edges and G equal V E is a formal
mathematical notation that we use to
define a graph now I have a craft drawn
here in the write this graph has 8
vertices and 10 edges what I want to do
is I want to give some names to these
vertices because each node in a graph
must have some identification it can be
a name or it can be an
index I'm naming these vertices as V 1 V
2 V 3 V 4 V 5 and so on and this naming
is not indicative of any order there is
no first second and third node here I
could give any name to any node so my
set of what he sees here is this we have
eight elements in the set v1 v2 v3 v4 v5
v6 v7 and v8 so this is my set of
vertices for this graph now what's my
set of edges to answer this we first
need to know how to represent an edge an
edge is uniquely identified by its two
endpoints so we can just write the names
of the two endpoints of an edge as a
pair and it can be a representation for
the edge but edges can be of two types
we can have a directed edge in which
connection is one way or we can have an
undirected edge in which connection is
two way in this example graph that I'm
showing here edges are undirected but if
you remember the tree that I had shown
earlier then we have directed edges in
that free with this directed edge that
I'm showing you here we are saying that
there is a link or path from vertex u to
V but we cannot assume a path from V to
u this connection is one way for a
directed edge one of the endpoints would
be the origin and the other endpoint
would be the destination and we draw the
edge with an arrowhead pointing towards
the destination for our edge here origin
is U and destination is V a directed
edge can be represented as an ordered
pair first element in the pair can be
the origin and second element can be the
destination so with this directed edge
represented as ordered pair UV we have a
path from u to V if we want a path from
V to u we need to draw another directed
edge here with V as origin and u as
destination and this edge can be
represented as ordered pair V you
the upper one here is UV and the below
one is vu and they are not same
now if the edge is undirected the
connection is two-way an undirected edge
can be represented as an unordered pair
here because the edge is bi-directional
origin and destination are not fixed we
only need to know what two endpoints are
being connected by the edge so now that
we know how to represent edges we can
write the set of edges for this example
graph here we have an undirected edge
between v1 and v2 then we have one
between v1 and v3 and then we have v1 v4
this is really simple I'll just go ahead
and write all of them so this is my set
of edges typically in a graph all edges
would either be directed or undirected
it's possible for a graph to have both
directed and undirected edges but we are
not going to study such graphs we are
only going to study graphs in which all
edges would either be directed or
undirected a graph with all directed
edges is called a directed graph or
digraph and a graph with all undirected
edges is called an undirected graph
there is no special name for an
undirected graph usually if the graph is
directed we explicitly say that it's a
directed graph or digraph so these are
two types of graph directed graph or
digraph in which edges are
unidirectional or ordered pairs and
undirected graph in which edges are
bi-directional or unordered pairs now
many real-world systems and problems can
be modeled using a graph graphs can be
used to represent any collection of
objects having some kind of pairwise
relationship let's have a look at some
of the interesting examples a social
network like Facebook can be represented
as an undirected graph a user would be a
node in the graph and if two users are
French there would be an edge connecting
them a real social network would have
millions and billions of nodes I can
show only few in my diagram here because
I am short of space
now social network is an undirected
graph because friendship is a mutual
relationship if I am your friend you are
my friend too so connections have to be
two-way now once a system is modeled as
a graph a lot of problems can easily be
solved by applying standard algorithms
in graph theory like here in this social
network let's say we want to do
something like suggest friends to a user
let's say we want to suggest some
connections to Rama one possible
approach to do so can be suggesting
friends of friends who are not connected
already Rama has three friends Ella Bob
and Katie and Friends of these three
that are not connected to Rama already
can be suggested there is no friend of
Allah which is not connected to Rama
already Bob however has three friends
storm Sam and Lea that are not friends
with Rama so they can be suggested and
Katie has two friends Lee and Swati that
are not connected to Rama we have
counted Li already so in all we can
suggest these four users to Rama
now even though we described this
problem in context of a social network
this is a standard crafts problem the
problem here in pure graph terms is
finding all nodes having length of
shortest path from a given node equal to
two standard algorithms can be applied
to solve this problem we'll talk about
concepts like path in a graph in some
time for now just know that the problem
that we just described in context of a
social network is a standard crafts
problem okay so a social network like
Facebook is an undirected graph now
let's have a look at another example
interlinked web pages on the internet or
the world wide web can be represented as
a directed graph of web page that would
have a unique address or URL would be a
node in the graph and we can have a
directed edge if a page contains link to
another page now once again there are
billions of pages on the web but I can
show only few here the edges in this
graph are directed because
relationship is not mutual this time if
page a has a link to page B then it's
not necessary that page B will also have
a link to page a let's say one of the
pages on my code school comm has a
tutorial on craft and on this page I
have put a link to Wikipedia article on
graph let's assume that in this example
graph that I'm showing you here page B
is my my code school tutorial on graph
with this address or URL my code school
comm / videos / graph and let's say page
Q is the Wikipedia article on graph with
this URL wikipedia.org
/ wiki / graph now on my page that is
page P I have put a link to Wikipedia
page and graph if you are on page P you
can click on this link and go to page Q
but wikipedia has not reciprocated to my
favor by putting a link back to my page
so if you are on page Q you cannot click
on a link and come to page P connection
here is one way and that's why we have
drawn a directed edge here okay now once
again if we are able to represent web as
a directed graph we can apply standard
graph theory algorithms to solve
problems and perform tasks one of the
tasks that search engines like Google
perform very regularly is web crawling
search engines use a program called web
crawler that systematically browses the
worldwide web to collect and store data
about web pages search engines can then
use this data to provide quick and
accurate results against search queries
now even though in this context we are
using a nice and heavy term like web
crawling web crawling is basically draft
traversal or in simpler words act of
visiting all nodes in a graph and no
prizes for guessing that there are
standard algorithms for craft traversal
and we'll be studying graph traversal
algorithms in later lessons okay now the
next thing that I want to talk about is
concept of a weighted graph sometimes in
a graph all connections cannot be
treated as equal some connections can be
preferable to others like for example we
can represent intercity through a
network that is the network of highways
and freeways between cities as an
undirected graph I am assuming that all
highways would be bi-directional
intra-city road network that is road
network within a city would definitely
have one-way roads and so intra-city
road network must be represented as a
directed graph but intercity road
network in my opinion can be represented
as an undirected graph now clearly we
cannot treat all connections as equal
here roads would be of different lengths
and to perform a lot of tasks to solve a
lot of problems we need to take lengths
of roads into account in such cases we
associate some weight or cost with every
edge we label the edges with their
weights in this case weight can be
lengths off the roads so what I'll do
here is I'll just label these edges with
some values for their length and let's
say these values are in kilometers and
now edges in this graph are weighted and
this graph can be called a weighted
graph let's say in this graph we want to
pick the best route from City a to city
D have a look at these 4 possible routes
I'm showing them in different colors now
if I would treat all edges as equal then
I would say that the green route through
B and C and the red route through E and
F are equally good both these paths have
3 edges and this yellow route through E
is the best because we have only two
edges in this path but with different
weights assigned to the connections I
need to add up weights of edges in a
path to calculate total cost when I'm
taking weight into account
shortest route is through B and C
connections have different weights and
this is really important here in this
graph actually we can look at all the
graphs as weighted graphs and unweighted
graph can basically be seen as a
weighted graph in which weight of all
the edges is same and typically we
assume the weight as 1
okay so we have represented inter-cities
road network as a weighted undirected
graph social network was an unweighted
undirected graph and World Wide Web was
an unweighted directed graph and this
one is a weighted undirected graph now
this was anticipated what I think
intra-city road network that is road
network within a city can be modeled as
a weighted directed graph because in a
city there would be some one-ways
intersections in intra-city road network
would be nodes and Road segments would
be our edges and by the way we can also
draw an undirected graph as directed
it's just that for each undirected edge
we'll have two directed edges we may not
be able to redraw our directed graph as
undirected but we can always redraw an
undirected graph as directed okay I'll
stop here now this much is good for an
introductory lesson in next lesson we
will talk about some more properties of
graph this is it for this lesson thanks
for watching
they all this will end or indirectly in
and the class selection unsuccessful
degrees oral cancer in the xuxa recorded in
yesterday
top gun although it can not give a pike and
Sugar rate me thanks
graphic and the rate should fall in the seven
times is say who this person is that
makes it dated an unprecedented precision the
Team names and tags so the chart
diverted for the sound of the recording
hours as new snow at
s record it worsens
the series will be so alive miter me
for fire flex
perhaps the work indicates that there has
slave and goes from bras to be seen in 20
17
one of them is edson vieira 21 when the
team owner and day and ecad
if the second area has live
animal were going there
always want to say I do well
crashed the benghazi which has clean window
I would take care of my p
I knew they wanted for me a note saying
it would for me to follow us is 17 months
country to country as playing in seds
tasty black dick fact proves ivan
victim alive right will rise as homeland
binational headquarters of all internet
something to happen you will have to say
you have a live pilot was minc
fordu live under a paper and of good and
Modern bm a fact is a fact and ska and priest
otto standing right told me was the fact that
nobody talked about patents kombi
Fred left if this happened
SAICA master is expensive does not guard
in fact see only stella Mait s the
hello friends welcome back in this
tutorial we will study about the
adjacency matrix of a digraph the
adjacency matrix of a digraph having n
vertices is up and cross and binary
matrix in which entry at at row and jth
column is 1 if and only if there is an
arc from vertex a to vertex G each
diagonal entry in the adjacency matrix
of a digraph is 0 for example see this
diagraph this is the adjacency matrix of
this diagraph order of this matrix is 4
cross 4 because there are 4 vertices in
diagraph ndaya graph there is an arc
from vertex 1 to vertex 2 therefore in
adjacency matrix of this diagraph entry
at first row and second column is 1
similarly there is an arc from vertex 1
to vertex 4 therefore in adjacency
matrix the entry at first row and fourth
column is 1 there is an arc from vertex
2 to vertex 3 therefore in adjacency
matrix the entry at second row and third
column is 1 there is an arc from vertex
3 to what X 1 they
for in adjacent C matrix the ant react
third row and first column is one there
is an arc from vertex four to vertex 3
therefore in adjacency matrix the ant
react
fourth row and third column is one thank
you very much
hey good if you're here to discuss about
the adjacency list and multi nice
representation of graph and the sense a
list is one of the way in which graphs
can be represented in computer's memory
now let us begin with edges NC this
representation of graph so given
undirected graph let us construct
adjacency list for it
this structure consists of a list of all
nodes in graph since nobody has not been
and since accessing to it therefore it's
a sense a list of a contains B and C
similarly it isn't to be our C and E
because of which its adjacency list
contains C and E so every node is in
turn into its own list that contains the
names of one of the nodes that are
adjacent to it no.10 for the it graph
the sum of strengths of all adjacency
lists is equal to a number of edges in
graph now we have undirected graph and
its adjacency list here the sum of the
lengths of 1 in cessationists is equal
to twice and number of edges in graph
this is because an X a B means an X from
node a to b as well as an edge from B to
a because of which it is containing two
edges in lists it's a sense in this can
also be modified to store rating drops
we can see how weights on edges are
student education list here are some key
advantages of using it Edison seen list
first of them is it is easy to follow
and clearly shows
the Edison nodes of a particular node
second it is often used for storing
graphs that have small to moderate
number of edges that is an adjacency
list is preferred for representing space
drugs in the computer's memory third
adding new nodes in graph is easy and
straightforward when graph is
represented it using extensionists
now we come to my edges in C Michael is
representation of graph which can be
said to be modified version of adjacency
list adjacency multi list is in X based
rather than vortex based representation
of graph firstly you will understand it
with the end of example given an
undirected graph we will construct hsn.c
multi list for each of the edge the
information about an edge of an
undirected graph can be stored using the
five attributes positive note of each
adjacency list is intentionally left
blank for adjacency list of H 1 H 1 is
joining vertices 0 n 1
therefore 2nd main thought field
contains 0 &amp; 1
what is 0 is incident on edge 2
therefore X will contains in H 2 and
what X 1 is incident on FC so laughs
will contention H 3 now comes to
exercise a list of X 2 X 2 is connected
to vertex 0 &amp; 2 therefore it contains 0
n 2 vertex 0 is incident on H one whose
essential list we have already seen
therefore
we will contain single vortex two is
incident on x4 so is the fifth grade
similarly we can fill adjacency list of
remaining edges now when we have seen
construction of edges in selected list
let us look at copper and finishing
these attributes just try to link these
definitions with the example we have
seen M indicates whether the edge has
been excellent or not say contribute is
a vortex that is connected to VG by an
edge third it tribute is a vortex it is
connected to VI by an edge fourth a
tribute is a link that points to another
node catalyzing H instead on VJ final
attribute is a link it points to another
node that has an edge incident on VA now
given the Edison C multi list of edges
we can construct adjacency list four
vertices vertex zero is in adjacency
list for h1 and h2 therefore list of
edges for vertex 0 contains h1 and h2
list of edges for vertex 1 contains h1
and h3 similarly we can just get list of
edges for all other nodes thank you
welcome to our 27th video with data
structures and algorithms we're going to
continue with graphs probably should
have done this one before the last two
videos but that's okay let's do it now
we're going to do a jason see lists and
adjacency matrices so we let's start off
with an adjacency list we're going to
kind of go in a different direction here
now this is what this is a
representation of our graph so let's do
some practice with converting this into
an adjacency matrix so firstly with the
adjacency matrix what we're going to
write a 1 if there's an edge between the
two right and we're going to write zeros
otherwise right so we're going to start
from a left right this will be the nodes
that are in the actual array here and
these will be its adjacency list this is
top the columns ok you'll see what I
mean in a second so for a in its
adjacency list we have C D and G so
along this row we are going to write
ones at C oh let's say at C D and G now
everything else is going to be zeroes
we're going to write in zeroes later so
that we can kind of visualize this a
little better let's keep going so with B
it has a jason Siletz with e all right
so E is in its adjacency list it's
connected to visit there's an edge from
B to e C has an edge right it has a
self-loop D also has a self-loop it also
has an edge from D to E and there's also
an edge from D to F with e U has an edge
to G all right has a direct path to G F
has a path to B right an edge between F
and B and another edge there's another
edge between G are from G to B ok so
that's kind of what our matrix
looks like now this is a directed graph
and we know that because this is not
symmetrical okay that means there's not
an edge you can see this is an edge from
A to C but there is not an edge from C
to a okay so this is this is a directed
graph so now let me just pick a
different color and we're going to put
in zeros okay for the rest of this just
to be a little bit more complete okay
that's a lot of zeros I know just hang
with me for a second
zero zero all these zeros fun times
there we go here we go zero zero zero
zero okay and there we go so that's what
our adjacency matrix looks like for this
graph now let's do a little something
else let's translate this into the graph
like a visual representation that we are
used to so I'm kind of running out of
space here so we're going to have to
kind of go back and forth that's okay so
let's start with node a so we have a
node a here let's put it like this okay
and we know that there's an edge from A
to C so I'm going to put C up here okay
there's that there's also an edge from A
to D so let's draw a D node and we'll do
an edge there and then another one to G
so we're going to put G down here okay
there we go that's our first one you did
the same looking at this right so
looking at this we're going to show
another one but we'll do it from this
side so let's do B from this side so B
has an edge there's an edge from B to e
right here so let's do that
so let's do be down here and there's
another ed right there's a edge from B
to e so we're going to put e right here
okay
make that a little better well that's
not better at all that's okay
so next one is C right C has a self loop
you can see that right here if you'd
like to look at this one instead right
there's a one at C C so there is a self
loop on C for D D has an edge from D to
D so this also has a self loop there's
an edge from D to e okay so let's do
that here I've horrible arrows all right
let's just clean that one up a bit it's
a little better and there's also an edge
from D to F so f is not on here so let's
draw our F node okay so there's that he
has an edge to G so let's scroll down so
we can make a little loop here so we
have a edge from E to G and from F we
have an edge to be you know what I'm
going to redraw this to come over here
and F has an edge to be there we go you
don't have to cross lines and then G
also has an edge to be able to go that
works out good stuff okay so there is
our graph right now let's do some more
exercise while we're here and let's do
on line just a second here let's grab my
color I'll have the right color I lost
it so let's do this
okay let's do depth-first search on this
depth-first search just for some
practice and let's start from here
actually we can signify starting with
just this one oh wow that was not right
so we start here right have one now
we're going to take this we're going to
do this in this order the order of our
list so C is going to be the first place
that we go all right so let's go along
see we've discovered this at time two
and now let's do C right C has a
self-loop so it's already been
discovered so we're done with this one
three now back to a right so the next
one in a is d now you can see that here
so let's go that path okay and time for
this was discovered so let's look at D
the first one D is a self-loop so that's
already been discovered already gray he
is the next one so let's take that path
so time five so e down here has a path
from E to G alright so let's take this
path and it's been discovered at times
six G has a path to be right it has an
edge from G to B so now B has been
discovered at time seven let's go up to
B let's take the path to e except E has
already been discovered so we're done
with this one so it's been discovered a
time eight back to G this is done at
time nine there's nothing left and it's
list back to e
there's nothing left in its list right
so that's done at time 10 back to D the
next one in these lists is f so let's
take a path over to F and this has been
discovered at time 11 so f has be right
in its
adjacency list bees already been
discovered so we're done with this one
at time 12 and that means that we are
done with D at time 13 and then we are
done with a because G has already been
discovered so we were done with this at
time 14 all right that was kind of fun
let's do breadth-first search on this on
the same one let's just redraw this
alright let's just get some practice in
might as well so we got C over here
we've got G we put F over here whoops
it's kind of messed up
but F over here B is down here and E is
over here so we've got this kind of
crazy lines here okay there's a path
here so path here here and here I think
that's all of them yep okay
and let's do breadth-first search over
here breadth-first search now we have a
queue remember so here's our Q first
it's empty we're going to start at a
alright start here its distance is zero
so we put a right in the queue we take a
out of the queue and we put its
adjacency list on all right
all the distance of one so we have C D
and G we take C off right see points to
itself so we have we don't put anything
else on the queue next we take D off and
we put E and F on right who comes
first he comes first in the adjacency
list so that's we're going to put on
first so we've got G E and F all right
these are distance of two so next we
take G off and we put B on here all
right so now our cue looks like this
e F B okay next in the queue is e so you
take a off G has already been discovered
so we don't put anything else on so I'm
going to write this over here so f and B
are now on the queue we take F off the
cube B has already been discovered it's
already in the queue so we don't put
anything in there right B we would put
we take B off the queue now that would
be e right except E has already been
discovered so we don't put anything on
the queue and there's no nodes left
that's we've gone through all the nodes
and that's it so there's our depth-first
search or breadth-first search and our
adjacency matrix in our adjacency list
so there you have it
hello everyone in our previous lessons
we introduced you to graphs and we also
looked at and talked about some of the
properties of graph but so far we have
not discussed how we can implement graph
how we can create a logical structure
like graph in computer's memory so let
us try to discuss this a graph as we
know contains a set of vertices and a
set of edges and this is how we define
graph in pure mathematical terms a graph
G is defined as an ordered pair of a set
V of vertices and a set of edges now to
create and store a graph in computer's
memory the simplest thing that we
probably can do is that we can create
two lists one to store all the vertices
and another to store all the edges for a
list we can use an array of appropriate
size or we can use an implementation of
a dynamic list in fact we can use a
dynamic list available to us in language
libraries something like vector in C++
or ArrayList in Java now a vertex is
identified by its name so the first list
the list of vertices would simply be a
list of names or strings I just filled
in names of all the vertices for this
example graph here now what should we
fill in this edge list here an edge is
identified by its two endpoints so what
we can do is we can create an edge as an
object with two fields we can define
edge as a structure or class with two
fields one to store the start vertex and
another to store the end vertex edge
list would basically be an array or list
of this type struct edge in these two
definitions of edge that I have written
here in the first one I have used
character pointers because in C we
typically use character pointers to
store or refer to strings we could use
character array
also in C++ or Java where we can create
classes we have string available to us
as a datatype so we can use tattles so
we can use any of these for the fields
we can use character pointer or
character array or string datatype if
it's available depends on how you want
to design your implementation now let's
fill this edge list here for this
example graph each row now here has two
boxes let's say the first one is to
store the start vertex and the second
one is to store the end vertex the graph
that we have here is an undirected graph
so any vertex can be called start vertex
and any vertex can be called end vertex
order of the vertices is not important
here we have 9 edges here 1 between a
and B another between a and C another
between a and D and then we have B E and
B F instead of having B F as an entry we
could also have F B but we just need one
of them and then we have CG D H E H and
F H actually there's one more we also
have G H we have 10 edges in total here
and not 9 now once again because this is
an undirected graph if we are saying
that there is an edge from F to H we are
also saying that there is an edge from H
to F there is no need to have another
entry as HF we will unnecessarily be
using extra memory if this was a
directed graph F H and H F would have
meant two different connections which is
the start vertex and which is the end
vertex would have mattered maybe in case
of undirected graphs we should name the
fields as first vertex and second vertex
and in case of directed graphs we should
name the fields as start vertex and end
vertex now our graph here could also be
a weighted graph we could have some cost
or weight associated with the edges as
you know in an unweighted graph
cost of all the connections is equal but
in a weighted craft different
connections would have different weight
or different cost now in this example
graph here I have associated some
weights to these edges now how do you
think we should store this data the
weight of edges well if the graph is
weighted we can have one more field in
the edge object to store the weight now
when entering my edge list has three
fields one to store the start vertex one
to store the end vertex and one more to
store the weight so this is one possible
way of storing the graph we can simply
create two lists one to store the
vertices and another to store the edges
but this is not very efficient for any
possible way of storing and organizing
data we must also see its cost and when
we say cost we mean two things time cost
of various operations and the memory
usage typically we measure the rate of
growth of time taken with size of input
or data what we also call time
complexity and we measure the rate of
growth of memory consumed with size of
input or data what we also call space
complexity time and space complexities
are most commonly expressed in terms of
what we call Big O notation for this
lesson I am assuming that you already
know about time and space complexity
analysis and Big O notation if you want
to revise some of these concepts then
you can check the description of this
video for link to some lessons we always
want to minimize the time cost of most
frequently performed operations and we
always want to make sure that we do not
consume unreasonably high memory okay so
let's now analyze this particular
structure that we are trying to use to
store our graph let's first discuss the
memory usage for the first list the
vertex list least number of rows needed
or consumed would be equal to number of
vertices now each row here in this water
list is a name or string and string can
be of any length right now all strings
have just one character because I simply
named the nodes a B C and so on but we
could have names with multiple
characters and because strings can be of
different lengths all rows may not be
consuming the same amount of memory like
here Here I am showing an intra-city
road network as a weighted graph cities
are my nodes and Road distances are my
weights now for this graph as you can
see names are of different lengths so
all rows in vertex list are all rows in
edge list would not cost the same more
characters will cost us more bytes but
we can safely assume that the names will
not be too long we can safely assume
that in almost all practical scenarios
average length of strings will be a
really small value if we assume it to be
always lesser than some constant then
the total space consumed in this vertex
list will be proportional to the number
of rows consumed that is the number of
vertices or in other words we can say
that space complexity here is Big O of
number of vertices this is how we write
number of vertices with two vertical
bars what we basically mean here is
number of elements in set V now for the
edge list once again we are storing
strings in first two fields of the edged
object so once again each row here will
not consume same amount of memory but if
we are just storing the reference or
pointer to a string like here in the
first row instead of having values
filled in these two fields we could have
references or pointers to the names in
the vertex list if we will design things
like this each row will consume same
memory this in fact is better because
references in most cases would cost us a
lot lesser than a copy of the name and
as reference we can have the actual
address of the string and that's what we
are doing when you are saying that start
and end vertex can be character pointers
or maybe a better design would be simply
having the index of the name word string
in vertex list let's say a is at index
zero in the vertex list and B is at
index 1 and C is at index 2 and I'll go
on like this now for start what X hand
end vertex we can have two integer
fields as you can see in both my
definitions of edge start vertex and end
vertex are of type int now and in each
row of edge list first and second field
are filled with integer values I have
filled in appropriate values of indices
this definitely is a better design and
if you can see now each row in edge list
would cost us the same amount of memory
so overall space consumed in edge list
would be proportional to number of edges
or in other words space complexity here
is Big O of number of edges okay so this
is analysis of our memory usage overall
space complexity of this design would be
Big O of number of vertices plus number
of edges is this memory usage
unreasonably high well we cannot do a
lot better than this if we want to store
a graph in computer's memory so we are
alright in terms of memory usage
now let's discuss time cost of
operations what do you think can be most
frequently performed operations while
working with graph one of the most
frequently performed operations while
working with graph would be finding all
nodes adjacent to a given node that is
finding all nodes directly connected to
a given node what do you think would be
time cost of finding all nodes directly
connected to a given node well we will
have to scan the whole edge list we will
have to perform a linear search we will
have to go through all the entries in
the list and see if the start or end
node in the entry is our given node for
a directed graph we would see
if the start node in the entry is our
given node or not and for an undirected
graph we would see both the start as
well as the end node running time would
be proportional to number of edges or in
other words time complexity of this
operation would be Big O of number of
edges okay now another frequently
performed operation can be finding if
two given nodes are connected or not in
this case also we will have to perform a
linear search on the edge list in worst
case we will have to look at all the
entries in the edge list so worst-case
running time would be proportional to
number of edges so for this operation to
time complexity is Big O of number of
edges now let's try to see how good or
bad this running time Big O of number of
edges is if you remember this discussion
from our previous lesson in a simple
graph in a graph with no self loop or
multi edge if number of vertices that is
the number of elements in set V is equal
to n then maximum number of edges would
be n into n minus 1 if the graph is
directed each node will be connected to
every other node and of course minimum
number of edges can be 0 we can have a
graph with no edge maximum number of
edges would be n into n minus 1 by 2 if
the graph is undirected but all in all
if you can see number of edges can go
almost up to square of number of
vertices number of edges can be of the
order of square of number of vertices
let's denote number of vertices here as
small V so number of edges can be of the
order of v square in a graph typically
any operation running in order of number
of edges would be considered very costly
we try to keep things in order of number
of vertices when we are comparing the
two running times this is very obvious
Big O of V is a lot better than Big O of
v square
all in all this what X list and edge
list kind of representation is not very
efficient in terms of time cost of
operations we should think of some other
efficient design we should think of
something better we will talk about
another possible way of storing and
representing graph in next lesson this
is it for this lesson thanks for
watching
So in our previous lesson, we discussed
one possible way of
storing and representing a graph in
which
we used two list. One to store the
vertices and another to store the
edges. A record in vertex list here
is name of a node
and a record in edge list is an
object
containing references to the two endpoints
of an edge and also the weight of that edge
because this example graph that I am showing
you here is a
weighted graph. We called this kind of
representation
edge list representation but we realised
that this kind of storage is not very
efficient in terms of
time cost of most frequently performed
operations
like finding nodes adjacent to a given
node
or finding if two nodes are
connected are not.
To perform any of these operations, we
need to scan the whole
edge list. We need to perform a
linear search on the edge list.
So the time complexity is big oh of number
of
edges and we know that number of edges
in the graph
can be really really large. In worst case
it can be close to square of number of
vertices.
In a graph, anything running in order
of number of
edges is considered very costly. We
often want to keep the cost
in order of number of vertices. So we
should think of some other efficient
design.
We should think of something better than
this. One more possible design is that
we can store the edges in a
two-dimensional array
or matrix. We can have a
two-dimensional matrix
or array of size V*V
where V is number of vertices.
As you can see, I have drawn an 8*8
array here because number of vertices
in my sample graph here
is 8. Let's name this array A.
Now if we want to store a graph that is
unweighted. Let's just remove the weights
from this sample graph here
and now our graph is unweighted and if we
have
of value or index between 0 and V-1
for each vertex which we have here
if we are storing the vertices in a
vertex list
than we have an index between 0 and V-1
for each vertex. We can say that A
is zeroth node,
B is 1th node, C is
2th
node and so on. We are picking up
indices from vertex list. Okay
so if the graph
is unweighted and each vertex has an
index between 0 and
V-1, then in this matrix
or 2d array. We can set ith row
and jth column that is A[i][j]
as 1 or boolean value
true. if there is an edge from i to j
0 or false otherwise. If I have
to fill this matrix for this example
graph here then I'll go vertex by vertex.
Vertex 0 is connected to Vertex 1
2 and 3. Vertex 1
is connected to 0, 4 and 5.
This is an undirected graph so if we
have and edge from 0 to 1,
we also have an edge from 1 to 0
so
1th row and 0th column should also be
set as 1.
Now let's go to nodes 2, it's connected
to 0
and 6, 3 is connected to 0 and 7,
4 is connected to 1 and 7,
5 once again is connected to 1 and 7,
6 is connected to
2 and 7 and 7 is connected
to 3, 4, 5 and 6.
All the remaining positions in
this array should be set as 0.
Notice that this matrix
is symmetric. For an undirected graph,
this matrix would be symmetric
because A[i][j] would be equal to A[j][i].
We would have two positions filled for
each edge.
In fact to see all the edges in the graph,
we need to go through only one of these
two halves.
Now this would not be true for our
directed graph. Only one position will be
filled for each
edge and we will have to go through
the entire matrix
to see all the edges. Okay,
now this kind of representation of a
graph in which
edges or connections are stored in a
matrix
or 2D array is called adjacency matrix
representation. This particular matrix that
I have drawn here
is an adjacency matrix. Now with this
kind of storage or representation,
what do you think would be the time cost
of finding
all nodes adjacent to a given node. Let's say
given this vertex list
and adjacency matrix, we want to find
all nodes adjacent to node named F.
If we are given name of a node than
we first need to know it's
index and to know the index, we will have to
scan the vertex list.
There is no other way. Once we figured out
index
like for F index is 5 then
we can go to the row with that index
in the adjacency matrix
and we can scan this complete row to
find all the
adjacent nodes. Scanning the vertex
list
to figure it out the index in worst case
will cost us time proportional to the
number of vertices
because in worst case we may have to
scan the whole list,
and scanning a row
in the adjacency matrix would once again
cost us time proportional to number of
what vertices because
in a row we would have exactly
V columns where V is number of a
vertices.
So overall time cost of this operation
is big oh of V. Now most of the time
while performing operations,
we must pass indices to avoid
scanning the vertex list all the time.
If we know an index, we can figure out
the name in constant time,
because in an array we can access element at
any index in constant time but if we know
a name
want to figure out index then it will
cost us big oh of V.
We will have to scan the vertex list.
wWe will have to perform linear search
on it. Okay moving on.
Now what would be the time cost of
finding if 2 nodes
are connected or not. Now once again the
two nodes can be given to us
as indices or names. If the nodes
would be passed test as indices
then we simply need to look at value in
a particular row and
particular column. We simply need to look
at
A[I][J] for some values of I and J
and this will cost us constant time.
You can look at Value in any cell in
a two-dimensional array in constant time.
So if
indices are given time complexity of
this operation would be big oh of 1
which simply means that we will
take constant time
but if names are given then we also need
to do the scanning
to figure out the indices which will
cost us big oh of V.
Overall time complexity would be 
Big oh of V.
The constant time access would not mean
anything.
The scanning of vertex list all the
time to figure it out
indices can be avoided. We can use
some extra memory to create
a hash table with names and indices
as key value pairs and then the time
cost of finding
index from name would also be big oh
of 1 that is constant. Hash table is
a data structure
and I have not talked about it in any of
my lessons so far.
If you do not know about hash table, just
search online for
a basic idea of it. Okay, so as you can
see
with adjacency matrix representation
our time cost of some of the most
frequently performed operations
is in order of number of vertices
and not in order of number of
edges which can be as high as square of
number of vertices.
Okay now if we want to store
a weighted graph in adjacency matrix
representation
then A[i][j] in the matrix can be set as
weight of an edge. For non-existent ages we
can have
a default value like a really large
or maximum possible integer value
that is never expected to be an edge
weight. I have just filled in infinity
have to mean that
we can choose the default as infinity
minus infinity
or any other value that would never
ever be a valid
edge weight. Okay, now for further
discussion
I'll come back to an unweighted graph.
Ajacency matrix
looks really good so should we not use it
always.
Well, with this design we have improved
on
time, but we have gone really high on
memory usage
instead of using memory units exactly
equal to the number of edges
what we're doing with
edge list kind of storage.
Here we're using exactly V square
units of memory.
We are using big oh of V square space.
We are not just storing the information
that these two
nodes are connected, we are also storing not
of it
that is these two nodes side not connected
which probably is
redundant information. If a graph is
dense,
if the number of edges is really close
to V square
then this is good but if the graph is
sparse
that is if number of edges is lot lessser
than V square
then we are wasting a lot of
memory in storing the zeros.
Like for this example graph that I have
drawn here, in the edge list we were
consuming
10 units of memory we had ten rows
consumed in the edge list
but here we are consuming 64 unit.
Most graphs with
really large number of vertices would
not be very dense,
would not have number of edges anywhere
close to V sqaure
like for example, Let's say we are modeling
a social network like Facebook as a
graph such that a user in the network
is a node
and there is an undetected edge if two
users are friends.
Facebook has a billion users but I'm
showing only a few in my example graph
here because I'm short of space.
Let's just assume that we have a billion
users in our network,
so number of vertices in a graph is
10 to the power 9
which is billion. Now do you think number
of connections
in our social network can ever be close
to square of number of users
that will mean everyone in the network
is a friend of
everyone else. A user of our social
network will not be friend to all other
billion users.
We can safely assume that a user
on an average would not have more than
a thousand friends
with this assumption we would have
10 to the power 12
edges in our graph. Actually, this is an
undirected graph
so we should do a divide by 2 here. So
that we do not
count an edge twice. So if
average number of friends is 1000 then total
number of connections in my graph is
5 * 10 to power 11. Now this
is lot lesser than a square of number
of vertices.
So basically if you would use an adjacency
matrix for this kind of a graph,
we would waste a hell lot of space
and moreover
even if we are not looking in relative
terms 10 to the power 18
units of memory, even in absolute
sense
is alot. 10 to the power 18 bytes
would be about a 1000 petabytes.
Now this really is a lot of space. This
much data would never ever fit on one
physical disk.
5 into 10 to the power 11 byts on the other
hand
it's just 0.5 terabytes. A typical
personal computer these days would have this
much of storage.
So as you can see for something like a
large
social graph adjacency matrix
representation is not very efficient.
Agency matrix is good when a graph is
dense
that is when the number of edges is
close to square of number of vertices
or sometimes when total number of
possible connection that is V square
is so less that wasted space would not
even matter
but most real-world graphs would be
sparse
and adjacency matrix would not be a good
fit.
Let's think about another example. Let's
think about
world wide web as are directed graph.
If you can think of web pages as nodes
in a graph
and hyperlinks as directed edges
then a webpage would not have linked to
all other pages
and once again number of webpages
would be in order of millions.
A webpage would have link to only
the
a few other pages, so the graph would be
sparse.
Most real world graphs would be sparse
and adjacency matrix. Even though it's
giving us good running time for most
frequently performed
operations would not be a good fit
because it's not very efficient in terms
of space
so what should we do. Well there's
another
representation that gives us similar
or maybe even better running time than
adjacency matrix and does not consume so
much space
It's called adjacency list
representation and we will talk about it
in our next lesson.
This is it for this lesson. 
Thanks for watching
hi I'm Jonah in this video I'm going to
explain two different ways to implement
a graph and then I'm going to explain
some of the pros and cons of each and
I'll show you how to implement both of
these methods in Python so the first way
to implement a graph is using an
adjacency list so let's look at this
undirected graph it has five vertices
and some edges connecting them an
adjacency list actually is a set of
adjacency lists because each list is
stored in its own vertex so a keeps its
own list of directly connected neighbors
other vertices that it has an edge to so
a has neighbors B C and E node B has
neighbors a and C as we can see here
this is going to be stored within each
node or each vertex is going to store
its own adjacency list now the other way
is using an adjacency matrix and the
adjacency matrix is a two dimensional
array and it basically stores a zero
where there is no edge or a one where
there is an edge from A to B we can see
there is an edge there or from A to C
there is an edge as you'd expect since
this is an undirected graph this is
going to be symmetrical across this
diagonal so from A to B is a 1 from B to
a is also going to be a 1 then the
adjacency matrix like I said it's a 2d
array and is stored in the graph object
so there's one adjacency matrix
centrally located in the graph object
how about if you have weighted edges on
an undirected graph well it's much
easier to implement weighted edges with
an adjacency matrix instead of putting a
one for edges where there is a
connection you just put the weight of
that edge so it's very easy to do that
you already have the cell you can put
instead of a 1 you can just put the
number of the cost or the distance or
weight of that edge in the cell so
extremely easy to implement using
adjacency matrix you can also implement
weighted edges in an adjacency list but
it's a little bit trickier so if you
have a directed graph again very easy to
do this using an adjacency list so here
we would have
a has one outbound edge to see so we
list under a only C as a neighbor that's
the only neighbor we can get to from a
so we're going to list all the outbound
edges for that vertex so C has edges to
B D and E and we list all the outbound
edges from C here in C's a Jason C list
you know Jason C matrix the same thing
we're basically going to put ones where
we have an edge outbound from that
vertex so we have the from on the left
and the two is div columns so which is
better well before we can answer that
question let's look at some other
characteristics of graphs a dense graph
is a graph where this is not absolute
value this is the number or count of
edges and the count of vertices so a
dense graph is a graph where you have
the number of edges is about equal to 2
the number vertices squared in other
words almost every vertex is connected
to every other vertex in the graph so
you get a really large number of edges
relative to the number of vertices a
sparse graph is a graph where E is about
equal to V which is what we have here in
this picture so there are a lot of
possible edges that are not actually
there another thing we're going to look
at before we answer the question which
is better adjacency matrix takes up V
squared space right this is a big factor
the amount of space required for this
adjacency matrix is going to be V
squared or number of vertices squared
regardless of how dense the graph is so
very very sparse graph you still are
going to take up the same amount of
space so for our little 5x5 you know we
only have 5 vertices in this example who
cares right but if you can picture a
graph that has ten thousand or a hundred
thousand vertices that's going to take a
project gigantic amount of storage space
so with those things in mind an
adjacency list is better in cases where
you have a sparse graph because it's
going to be faster and it uses less
space but the disadvantage of an
adjacency list this is slower for very
dense graphs large dense graphs is going
to be slower and the adjacency matrix is
going to be better for dense graphs
it's going to be faster and the space
complexity is the same as it would be
thrown on dense graph and another
advantage is that is simpler to
implement for weighted edges but the
disadvantage of this adjacency matrix is
that it uses more space and especially
for large sparse graphs or perhaps to
have a lot of vertices but relatively
few edges the adjacency matrix is not a
good choice so depending on the nature
of your graph you have to decide which
one of these is a better implementation
to go with so I'll give a quick
explanation of the adjacency list
version of the graph implementation
first we have our vertex class which
basically has two variables as a name
and it has a neighbors list and as we
add neighbors we see we have an add
neighbor function that basically is just
appending that vertex to the list and
then sorting it in the graph itself we
only have one graph variable which is a
dictionary of vertices so that we can
find any vertex by its name so when we
add a vertex we basically just check
that that object that you passed in
actually is a vertex object and then it
doesn't exist in the vertices dictionary
yet and if those two conditions are met
then it goes in as the vertex to the
vertices dictionary and when you try to
add an edge with vertices U and V then
it's first going to check if u and V are
both actually in this vertices
dictionary before adds it so if there's
an invalid vertex and it's not going to
be able to add that edge then we iterate
through the vertices and we locate
vertex U and vertex V and we add the
other to its neighbors and that's pretty
much it then I have a print graph
function down here at the bottom so this
is a pretty straightforward
implementation of graph I think it's a
little bit simpler so I usually favor
this over the matrix version although
the matrix version is not too hard and
then down below I have some test code
that we can test our our code up here so
implementing a graph using an adjacency
matrix this version is actually going to
support both weighted and unweighted
edges for undirected graphs and you have
to do slight modifications to support
directed graphs
so our vertex class you'll notice only
has one variable and that's just the
name of the vertex we don't need
adjacency this stored locally in the
vertex that doesn't happen here they're
stored centrally under the graph so we
have the same vertices dictionary so
that we can locate any vertex given its
name we also have this edges list which
is going to be our two-dimensional array
of edges that's the matrix and then we
have edge indices so that we can quickly
locate the index of any edge given its
name so when we add a vertex first we're
gonna check if it's actually vertex and
it is not in the vertices list already
and if not we add to the dictionary and
then our for loop here and the statement
right after that basically we need to
add another row and column of all zeros
to our edges matrix so we're going to do
that here we're add another row of zeros
and in another column of zeros on to
that edges matrix because we have mapped
any edges to this new vertex yet but we
need to add it to this matrix with all
zeros and lastly we add the index for
this vertex name into our edge indices
dictionary so to add an edge we're first
going to verify that both vertices U and
V are in our vertices dictionary and if
they both are then recall that this
edges matrix is symmetrical along the
diagonal so we want to add this edge we
want to enter the weight in the matrix
in both the top right bar in the bottom
left part so we're going to add the edge
to both u comma V and to V comma u we'll
set the edge weight and that's it for
add edge if we achieve that and we'll
return true and if not the return false
then lastly I have a pretty pretty
simple print graph function that prints
a pretty crudely formatted edges matrix
for us so you can see what that looks
like and our interface is exactly the
same as for the adjacency list version I
have exactly the same test code down
here below where we we set up a graph we
add some vertices and some edges to it
and we print it out I posted all of my
Python code here in my github site and
you can download that pin you also have
access to the PowerPoint file posted
here Omega up site so I hope this video
was helpful for you if you liked it
please click like and subscribe to my
channel I'm Joe James thanks for
watching
okay so let me tell you just for fun
it's an example this pocket cube which
is 2 by 2 by 2 your rubik's cube what we
have in mind is it's called the
configuration graph or sometimes the
configuration space but it's a graph so
this graph has a vertex for each
possible state of the cube so this is a
state creaky here this is a state this
is a state this is a state now I'm
hopelessly lost
ok anyone want to work on this board
no one all right leave it I'm solving ok
so all those are vertices there's
actually a lot of vertices there are 264
million vertices or so if you want as an
aside here number vertices is something
like 8 factorial times 3 to the eighth
and one way to see that draw to bethe
veggie rubik's cube so these are these
guys are yeah these are what you might
call cubelets or cubies i think is
standard term in rubik's cube land and
so the there's eight of them and a 2 by
2 by 2 2 cubed you can essentially
permute those cubies within the cube
however you like that's 8 factorial and
then each of them has three possible
twists it could be like this it could be
like this or it could be like this ok so
you've got three for each and this is
actually an accurate count you're not
over
counting the number of configurations
all of those are at least in principle
conceivable if you take apart the cube
you can reassemble it in each of those
states and that number is about 264
million okay which is not so bad for
computers you could search that life is
a little bit easier you get two divided
by 24 because there's 24 symmetries of
the cube 8 times 3 you can divide by 3
also because only 1/3 of the
configuration space is actually
reachable if you're not allowed to take
the parts apart you have to get there by
emotion you can only get to 1/3 of the
two 2 by 2 by 2 so it's a little bit
smaller than that if you're actually
doing a breadth-first search which is
what you're going to be doing on your
problem set but in any case it's
feasible
okay that is vertices should talk about
edges for every move every move takes
you from one configuration to another
you could traverse it in one direction
I'll make that move you could also undo
that move because every move is undoable
in a rubik's cube this graph is
undirected or you can think of it as
every edge works in both directions so
so this is a move is called a quarter
twist some it's a controversy if you
will some people allow a whole half
twist as a single move whether you
define that as a single move or a double
move not that big a deal just changes
some of the answers but you're still
exploring essentially the same graph
so that's the graph and you'd like to
know some properties about it so let me
draw a picture of the graph I'm not
going to draw all 264 million vertices
but in particular there's the solved
state we kind of care about that one
where all the colors are aligned then
there's all of the configurations you
could reach by one move so these are the
possible moves from solve state and then
from those configurations there's more
places you can go
maybe there's multiple ways to get to
the same node
okay but these would be all of the
configurations you can reach in two
moves okay and so on and at some point
you run out of graph so there might be
some ways to get there might be a few
things
she knows out here these are kind of the
way I'm drawing this this is everything
you can reach in one move and two moves
and three moves at the end this would be
11 moves if you if you allow half twists
and I guess as puzzlers we're
particularly interested in this number
which you would call as a graph theorist
the diameter of the graph puzzlers call
it God's number if you were God or some
me something being you have the optimal
algorithm for solving the Rubik's Cube
how many moves do do you need if you
always follow the best path and the
answer is in the worst case 11 so we're
interested in the worst case of the best
algorithm for 2 by 2 by 2 the answer is
11 for 3 by 3 by 3 the answer is 20 that
was just proved last summer with a
couple years of computer time for a 4 by
4 by 4 I don't have one here I think
we'll never know the answer for 5 by 5
by 5 we'll never know the answer for 6 4
same deal but for 2 by 2 by 2 you can
you will compute it on your problem set
and it's kind of nice to know because it
says whatever configuration I'm in I can
solve it in 11 moves but the best known
way to compute it is basically to
construct this graph one layer at a time
until you're done and then you know what
the diameter is the trouble is in
between here this grows exponentially at
some point it decreases a little bit but
getting over that exponential hump is
really hard
good morning everyone this is your buddy
Keisha and today we are gonna discuss
graph theory and then later we'll
discuss that first search algorithm with
Java code so before talking about the
definition of the graph theory let's see
some more real life scenario
oh so for example in an airline route
okay in an airline route map if we need
to find that what is the fastest way or
the cheapest way to go from one station
to another one place to another is for
example so has about two New York so
what will be the cheapest and fastest
way to go from those okay to that
location so before answering this
question we should have some data for
example that you need information about
interconnections between objects so here
interconnections mean means Airlines
truth and objects means that towels are
so we are the graph or the data
structure are used for solving this kind
of problems so one my screen you can see
this diagram here which I have a few
notes like ABCD we call these loggers
vertex and the link which are joining
these nodes are called ages so link from
A to B your B to C are called the ages
so yeah I will here is the definition
like a graph is a pair V comma E where
we we denote V vertices to be and then
ages 2 is so where V is the set of nodes
called vertices and E is the collection
of pairs of vertices called ages so this
is the normal definition of graphs so
these are the application of graphs like
representing relationship between
components and electronic circuits or
the transportation network like highway
network or we just
to talk about this flight Network then
coming to a networks for example name
and not banner men but yet land and then
databases like in databases we have er
diagrams so er diagram is nothing but a
graph representation you can represent
yes I am using craft so we are
discussing about algorithm and Java code
yes we need to discuss that how we are
gonna represent our graph or we will
take data from the user and will store
and which form so here we can we can
store data or we can yeah we can store
data in graph using three wheels like
adjacency matrix adjacency list and a
distance is set so we'll give the basic
understanding about these three
representations and Addyson see this
I'll show you
like Lu that is contain lists for
storing my data for the graph data
structure so here is my adjacency matrix
representation on screen you can see
that I have four nodes called a B C and
D so what I did have created one array
of n plus n plus 1 Cross and plus 1 well
n plus 1 n is my number of load so yeah
so you can see that term what we need to
do is if there is a link or if there is
an edge between these two nodes then we
will put 1 as will give you a 0 so you
can see from a to a we don't have any
age okay we don't have any loop self
loop if it is a 2 it will be self loop
so we don't have any test looper I have
given here 0 then a to be let's check
from A to B now we have age so I gave
here 1 and so on so this is called my
identity matrix now let's see adjacent
to it so here is the adjacency list
representation what we are going to do
what we are doing here that you can see
this ABCD and so see I have created one
linked list
ABCD first and then for each node I have
created one new linked list so you can
he a is connected to B ending so as
given A to B then B to D soon B is
connected to C and nothing else
so B is connected to C then C is
connected to a and D so C is D and these
B I think yeah G is not connected with
anything so yeah we just gave the simple
link now addition C list sorry adjacent
is that said so I am NOT going into
detail about adjacency list that but it
is similar to add essentialist
but here instead of linkage we use
disjoint set now what is disjoint set
and what is add essential is that so I
will discuss all this think in future if
I create some video lecture then
definitely I'll and describe these
things into that but for the time being
you see the depth first search algorithm
and letter will see the Java code so
here on the screen you can see my graph
and I'm gonna use this graph to describe
my algorithm and the same graph I use
for my java code so as you can see you
guys are created one log graph on the
screen and in da face the concept is
very simple what we do we use here one
tag balrog sorry we use here one adding
so just call the array elements visited
so once I visited each one load I I just
gave the value one for that location so
I will create the visited array of the
side which is equivalent to the number
of nodes in this graph so in this graph
1 2 3 4 5 6 7 8 8 number of rules are H
so the size of my visited array will be
8 so initially I come to this node and
process this node so what I do I will
just print the data what whatever it
whatever is here
and then we'll give value one to this in
my visited array I later I'll come to
this node because it is depth-first
search so pulse will go into that and
then we'll come back we'll back
backtrack so second time this load will
be will get present third time will not
go here because this is not bread for
search I'll tell you in Bristow search
we do level order traversal and in that
first search we do preorder traversal so
next time we'll go here and then here so
because we covered each - okay and then
later we'll come so I will backtrack to
this route and then now we'll visit this
node now - first search suggests this
load now again it we need to go to - not
will cover the we are not traversing or
using level order so this load will get
visited and then this node so this is
the simple concept of depth-first search
now see me as let's see the algorithm so
while the screeners have algorithm order
the portion of my java code so what I am
doing here is I have graph DFS function
this caucus is nothing but my
constructor of dark leadership class DFS
class so what it is taking it is just
taking in to be the number of nodes okay
so this thing is they are using this
thing for the graph creation so number
of nodes in our case it is 4 because
initially I told you that I am going to
use one graph let me show you that graph
so yeah here is the gap so I'm using 4
node which is 0 1 2 3 and then 0 is
connected through 2 and 1 and then 2 is
again connected to 0 1 is connected to 2
and then 2 is connected to 3 and then 3
is
three has a self-loop surface connected
with train itself only so as you can see
that I am using here adjacent list I
showed you that in addition clear so I
have one list node which is linked list
whose size is equivalent to the number
of node and for each node and create a
new link list let me show you the that
picture once again so in here what I did
I have four cloves ABCD so as created
one linked list of sites for ABCD and
each load of the linked list is
connected or is is itself a linked list
okay so a is connected to B B is
connected to D D is and in connected to
a okay so I'm gonna use this
representation for my program so this
code graph DFS is doing nothing it is
taking number of nodes v and then it
will create one linked list of for size
B and then we'll iterate a loop to be
till V and then our each node of the
linked list builder will have one new
linked list itself now what the main
logic is this one BFS what we are doing
we have created one visited node with
the size of V V where V is the number of
vertices or number of nodes and then
this small V is my source node or the
first node for example in a graph if I
want to traverse from to lots of first
close but from the second node so we are
just give you two instead of one what I
do first I'll mark it mark that node to
true okay and then we'll simply print
the value of that we now will iterate
that we will iterate the linked list
associated to that
Vinod okay so that is adjacent we got
list iterator
so I hope you understand the concept of
for iterator
mr. crater basically traitor will
traverse in forward direction where is
this traitor we can traverse in backward
direction and forward as well now if I
dot has liked if we have learning then
do nothing just I dot next just get the
value in N and then if a visited n is
not marked then just recursively call
this DSS function if it is already
visited then we don't need to go into
that function once again so yeah this is
the counter plus C Java program so here
I have already created but a Java
program if you want to load down you can
not download it as completely scroll
down or the code so what I'm doing you
see this graph DFS is my classroom now
here I have declared two variables like
one is V where V is the number of
vortexes and then second is linked list
which is of type graduate and then this
is the constructor of for this graph DFS
class and what this constructor is doing
is just creating graph for us with the
size which has the number of vertices is
equivalent to this for me I already
covered this part that what we are going
to we are doing here that we are
creating one linked list and then called
off size B and then for that linked list
each node is associated with the new
linked list which is this at adjacent I
put two new linked list now so this add
inch function will do nothing it will
add ages into your row add edge into
your graph so from V to W so if it is
from V to W so definitely be will be my
first linked list and W will be the
associated linked list of is back the
first linkage I hope you understand like
the V will be the part of this adjacent
and then W will be the part of this new
linked list node and then this BFS
concept I have already explained that
term of
we'll mark the current flow to true
we'll print the value of that node and
then we'll iterate using the linked list
iterator for that node V if it is not
visited then called the FS function or
if it is visited then going to so this
is my main method what I am doing and
thus creating when the object G of graph
DSL adding ages into that so this graph
is similar to the graph which I was
loved
show them previously and then I have
created one visited node of Versailles
we will variable definitely because I am
assigning very true faucet rate or you
can we create this visited into in
others DFS class itself you don't need
to pause this visited well it depends on
your choice and then now here I solve
this DFS function so the thing which you
need to note here is that are given here
too okay so I need a depth first search
from the source node - not from 0 so I
am given here - so it will work
accordingly now let me run this program
and let's see what is the output so yes
it is giving me 2 0 1 3 which is
required so that's it guys I hope you
liked my video thank you for watching
thank you once again
welcome to our 28th video with data
structures and algorithms let's do an
example with disjoint sets so we have a
list of elements here a through H and
the first thing that we're going to do
is we're going to perform the mix set
operation on each one of these and that
is going to create a cell a list of or a
bunch of singleton sets out of each one
of these so let's do that so when we do
mix sets of a ok we're going to have a
by itself we're just going to represent
it like this ok so it's parent is itself
B is our next one right same thing so
we're going to do this for all of them
that's kind of crappy looking ok so c d
e f g and h okay now a couple things
here each one of these sets has a rank
right and so the rank starts off at 0 ok
so let's just write these ok there we go
and let's visualize this set in a more
in a different notation so this is the
set right of A and it is the
representative so we're just going to
mark it like that so same thing with all
of these we've got B and C D
you get better drawing these curly
braces F G and H just kind of getting
lazy here okay so we can see that each
of these is own set and its
representative is the underlined element
it's so far it's just the one now let's
do this little sequence here of union
operations so we are going to use union
by rank and find with path compression
and we'll explain what that means as we
go through so when we when we union a
and B for instance we are going to link
the representative of this out of this
set with the representative of this set
right so first thing we have to do is we
have to find the representative okay of
each set so far a is the representative
of its own set and B is the
representative of its own set now we
said we're going to union by rank that
means if they have whoever has the
higher rank will end up being the
representative of the Union set okay
that's a mouthful but rewind and listen
to that again to make it clear when they
have the same rank
the second element here right this this
guy over here will end up being the
representative of the Union set so it
will be the parent of this set let's see
that in action let's do all of these
kind of all in one so when we Union a
and B they both have their the same set
all of these will have the same or they
have the same rank I mean all these will
have the same rank so far so let's do
that a and B we said that B right we
said that the second element is going to
be the new representative of this set
okay so here's a
right a and B okay we Union to those two
and we'll show what the set looks like
in just a sec so we said that D will be
the representative of this one so C is
here we've said that e is going to be
the representative of this one and G
will be the representative okay of this
set and also when we union two elements
there are two sets I mean and they have
the same rank then the the rank of the
representative right will go up by one
okay when we have the same rank so now
the Reppert this rank will be 1 1 1 and
1 and we're not going to worry about the
rank of these ones down here because we
no longer really need that only the
representatives so let's draw the actual
sets and let's see what they kind of
look like now right and B is the
representative so you can see that we
Union these two sets up here okay they
are now in the same set and B is now the
representative of that Union set so we
have C D and we have E and F and we have
G and H okay so there's our
representatives and there we go so let's
go down to the next little sequence of
unions Union operations now we're going
to Union a and C so like we said first
thing we have to do is we have to find
the representative a and find the
representative of C the representative
of this set right is B so we are going
to link B and the representative of this
set is D so we're going to link B and
now they have the same rank so again the
second one okay is going to be the
parent of the group of the new
representative so let's see what that
looks like
so we have D up here and that is going
to be the representative of this set so
now we have B and a okay and again they
had the same rank right so this rank
goes up by one and we will do the same
for this next one H and E right so he
happens to be the representative of this
group and H is G is the representative
this one a is this second argument here
in the Union so it's going to be the the
new representative since the ranks are
the same so up here we have E and we
have F and then we have G and H over
here and again since they have the same
rank we will increment this rank up by
one so let's do draw out the new sets
here that we have B C D okay and D is
the representative and then we have e F
G and H in this new set and E is the
representative of that set let's go down
to this one how about a B now we said
we're doing find with path compression
so what's going to happen here when we
do an FYI Union a B well first thing
that we're going to do find with path
compression on a what that means is let
me just get a different color let's get
this color when we go through here we're
going to start here at a and we're going
to move up to B I don't know why I did
it like it
curved line there okay we're going to go
up to B and we find out that that is not
the representative right so we're going
to go up again and we're going to find
out that D is the representative now
when we do path compression every
element along this little path that we
went to will now point directly to D we
wanted to compress the path because as
we searched to find the representative
of this element down here we found out
that the representative of this element
and this element and every element in
this little path every node that we had
to skip over right or go through they
all can now point to this representative
so now we can make them closer to this
element by changing all their parent
pointers to D so let's do that and that
was just the find operation that did
that okay find with path compression we
still haven't unioned anything just yet
actually I want to do a over here so
let's do a B and C
okay again we have not unioned anything
we haven't linked anything yet so D
would be returned right here right when
we do find on B we find that it's part
it's representative is D so we're going
to Union D and D right but it's the same
it's the same element so we don't
actually link it together it's already
there now a good something we need to
mention is that this rank did not change
okay
let's remember that and also we're going
to draw our other sets just to show that
nothing changed in this set because we
didn't do anything to it so we're going
to have G and H okay and also it's just
right it's rank still - let's do one
more Union and see what happens here so
we're going to Union C and H now again
we're going to find the representative
of C which is D and we're going to find
the representative of H which is e and
remember that we do we did find with
path compression so this one's going to
kind of this set is going to kind of
look like this set up here and actually
I just forgot let's draw these sets
really quick so you can kind of see what
they look like so a B C and D and we
found that they just look the same right
use the representative okay just want to
have that for our reference down here so
let's do this all in one
okay so when we union this right we're
going to Union this set right DS set and
E's set now these set looks a little
different now remember because we did
find with path compression so I'm just
going to kind of draw that here
okay so H is now linked to e directly
and color there we go and we find that D
right when we found this and we find
this D and E have the same rank so ease
set E is going to be the representative
okay
so let's draw e up here kind of at the
top as the representative then we have D
no that's an a not a d D then we have F
G and remember H now points to e because
we did find with path compression so
let's draw the rest of these we have a
we have B and we have C and remember the
rank of this one goes up by one and
let's draw our final set here we have a
b c d e f g and h and e is the new
representative of our set
in our previous lesson we introduced you
to graphs we defined graph as a
mathematical or logical model and talked
about some of the properties and
applications of graph now in this lesson
we will discuss some more properties of
graph but first I want to do a quick
recap of what we have discussed in our
previous lesson a graph can be defined
as an ordered pair of a set of vertices
and a set of edges we use this formal
mathematical notation G equal V II to
define a graph here V is set of vertices
and E is set of edges ordered pair is
just a pair of mathematical objects in
which order of objects in the pair
matters it matters which element is
first and which element is second in the
pair now as we know to denote number of
elements in a set that we also call
cardinality of a set we use the same
notation that we use for modulus or
absolute value so this is how we can
denote number of vertices and number of
edges in a graph number of vertices
would be number of elements in set V and
number of edges would be number of
elements in set E moving forward this is
how I am going to denote number of
vertices and number of edges in all my
explanations now as we have discussed
earlier edges in a graph can either be
directed that is one-way connections or
undirected that is two-way connections a
graph with only directed edges is called
a directed graph or digraph and a graph
with only undirected edges is called an
undirected graph now sometimes all
connections in a graph cannot be treated
as equal so we label edges with some
weight or cost like what I'm showing
here and a graph in which some value is
associated to connections as cost or
weight is called a weighted graph a
graph is unweighted if there is no cost
distinction among edges okay now we can
also have some special kind of edges in
a graph these edges complicate
algorithms and make working with graphs
difficult but I'm going to talk about
them anyway an edge is called a self
loop or self edge if it involves only
one vertex
if both endpoints of energy are same
then it's called a self-loop we can have
a self-loop in both directed and
undirected graphs but the question is
why would we ever have a self-loop in a
graph well sometimes if edges are
depicting some relationship or
connection that's possible with the same
node as origin as well as destination
then we can have a self loop for example
as we have discussed in our previous
lesson interlinked web pages on the
internet or the world wide web can be it
presented as a directed graph a page
with a unique URL can be a node in the
graph and we can have a directed edge if
a page contains link to another page now
we can have a self loop in this graph
because it's very much possible for a
web page to have a link to itself have a
look at this web page my code school
comm / videos in the header we have
links for workouts page problems page
and read your age right now I'm already
on videos page but I can still click on
videos link and all that will happen
with the click is a refresh because I am
already on videos page my origin and
destination are same here so if I'm
representing world wide web as a
directed graph the way we just discussed
then we have a self loop here now the
next special type of edge that I want to
talk about is Multi edge and edge is
called a multi edge if it occurs more
than once in a graph once again we can
have a multi edge in both directed and
undirected graphs
first multi edge that I'm showing you
here is undirected and the second one is
directed now once again the question why
should we ever have a multi edge well
let's say we are representing flight
Network between cities as a graph a city
would be a node and we can have an edge
if there is a direct flight connection
between any two cities but then there
can be multiple flights between a pair
of cities these flights would have
different names and may have different
costs if I want to keep the information
about all the flights in my graph I can
draw multi edges I can draw one directed
edge for each flight and then I can
label
and edge with its cost or any other
property I just labeled edges here with
some random flight numbers now as we
were saying earlier selfloops and multi
edges often complicate working with
graphs the presence means we need to
take extra care while solving problems
if a graph contains no self-loop or
multi edge it's called a simple graph in
our lessons we will mostly be dealing
with simple graphs now I want you to
answer a very simple question given
number of vertices in a simple graph
that is a graph with no self loop or
multi-edge what would be maximum
possible number of edges well let's see
let's say we want to draw a directed
graph with four vertices I have drawn
forward DC's here I will name these
vertices v1 v2 v3 and v4 so this is my
set of vertices number of elements in
set V is 4 now it's perfectly fine if I
choose not to draw any edge here this
will still be a graph set of edges can
be empty nodes can be totally
disconnected so minimum possible number
of edges in a graph is 0 now if this is
a directed graph what do you think can
be maximum number of edges here well
each node can have directed edges to all
other nodes in this figure here each
node can have directed edges to 3 other
nodes we have 4 nodes in total so
maximum possible number of edges here is
4 into 3 that is 12 I have shown edges
originating from a vertex in same color
here this is the maximum that we can
draw if there is no self loop or
multi-edge in general if there are n
vertices then maximum number of edges in
a directed graph would be n into n minus
1 so in a simple directed graph number
of edges would be in this range 0 to n
into n minus 1 now what do you think
would be the maximum for an undirected
graph in an undirected graph we can have
only one bi-directional edge between a
pair of nodes we can't have two edges in
different directions so here the maximum
would be half of the maximum for
directed
so if the graph is simple and undirected
number of edges would be in the range 0
to n into n minus 1 by 2 remember this
is true only if there is no self loop or
multi-edge now if you can see number of
edges in a graph can be really really
large compared to number of vertices
for example if number of vertices in a
directed graph is equal to 10 maximum
number of edges would be 90 if number of
vertices is 100 maximum number of edges
would be 9900 maximum number of edges
would be close to square of number of
vertices a graph is called dense if
number of edges in the graph is close to
maximum possible number of edges that is
if the number of edges is of the order
of square of number of vertices and a
graph is called sparse if the number of
edges is really less typically close to
number of vertices and not more than
that there is no defined boundary for
what can be called dense and what can be
called sparse it all depends on context
but this is an important classification
while working with graphs a lot of
decisions are made based on whether the
graph is dense or sparse for example we
typically choose a different kind of
storage structure in computer's memory
for a dense graph we typically store a
dense graph in something called
adjacency matrix and for a sparse graph
we typically use something called
adjacency list I'll be talking about
adjacency matrix and adjacency lists in
next lesson ok now the next concept that
I want to talk about is concept of path
in a graph a part in a graph is a
sequence of vertices where each adjacent
pair in the sequence is connected by an
edge I'm highlighting a path here in
this example graph the sequence of
vertices a B F H is a path in this graph
now we have an undirected graph here
edges are bi-directional in a directed
graph all edges must also be aligned in
one direction the direction of the path
part is called simple path if no
vertices are repeated and if what
disease are not repeated then edges will
also not be repeated so in a simple path
both vertices and edges are not repeated
this path a bfh that I have highlighted
here is a simple path but we could also
have a path like this here start vertex
is a and end vertex is D in this path
one edge and two vertices are repeated
in graph theory there is some
inconsistency in use of this term path
most of the time when we say path we
mean a simple path and if repetition is
possible we use this term walk so a path
is basically a walk in which new
vertices or edges are repeated of walk
is called a trail if what disease can be
repeated but edges cannot be repeated I
am highlighting a trail here in this
example graph ok now I want to say this
once again walk and path are often used
as synonyms but most often when we say
path we mean simple path a path in which
vertices and edges are not repeated
between two different vertices if there
is a walk in which vertices or edges are
repeated like this walk that I am
showing you here in this example graph
then there must also be a path or simple
path that is a walk in which what
disease or edges would not be repeated
in this walk that I'm showing you here
we are starting at a and we are ending
our walk at C there is a simple path
from A to C with just one edge all we
need to do is we need to avoid going to
be e H D and then coming back again to a
so this is why we mostly talk about
simple path between two vertices because
if any other walk is possible simple
path is also possible and it makes most
sense to look for a simple path so this
is what I'm going to do throughout our
lessons I'm going to say path and by
path L mean simple path and if it's not
a simple path I will say it explicitly
our graph is called strongly connected
if in the graph there is a path from any
vertex to any other vertex if it's an
undirected graph we simply call it
connected and if it's a directed graph
we call it strongly connected in
leftmost and rightmost graphs that I'm
showing you here we have a path from any
vertex to any other vertex but in this
graph in the middle we do not have a
path from any vertex to any other vertex
we cannot go from vertex C to a we can
go from A to C but we cannot go from C
to a so this is not a strongly connected
graph remember if it's an undirected
graph we simply say connected and if
it's a directed graph we say strongly
connected if a directed graph is not
strongly connected but can be turned
into connected graph by treating all
ages as undirected then such a directed
graph is called weakly connected if we
just ignore the directions of the edges
here this is connected but I would
recommend that you just remember connect
it and strongly connected this leftmost
or undirected graph is connected I
removed one of the edges and now this is
not connected now we have two disjoint
connected components here but the graph
overall is not connected connectedness
of a graph is a really important
property if you remember intra-city road
network road network within a city that
would have a lot of one-ways can be
represented as a directed graph now an
intra-city road network should always be
strongly connected we should be able to
reach any street from any street any
intersection to any intersection ok now
that we understand concept of a path
next I want to talk about cycle in a
graph a walk is called a closed walk if
it starts and ends at same vertex like
what I'm showing here and there is one
more condition the length of the walk
must be greater than 0 length of a walk
or path is number of edges in the path
like for this closed walk
that I'm showing you here length is five
because we have five edges in this walk
so a closed walk is walk that starts and
ends at same vertex and the length of
which is greater than zero now some may
call closed walk a cycle but generally
we use the term cycle for a simple cycle
a simple cycle is a closed walk in which
other than start and end vertices no
other vertex or edge is repeated right
now what I'm showing you here in this
example graph is a simple cycle or we
can just say cycle a graph with no
cycles is called an acyclic graph a tree
if drawn with undirected edges would be
an example of an undirected acyclic
graph here in this tree we can have a
closed walk but we cannot have a simple
cycle in this closed walk that I'm
showing you here our edge is repeated
there would be no simple cycle in a tree
and apart from tree we can have other
kind of undirected acyclic graphs also a
tree also has to be connected now we can
also have a directed acyclic graph as
you can see here also we do not have any
cycle you cannot have a path of length
greater than 0 starting and ending at
the same vertex or directed acyclic
graph is often called a dag cycles in a
graph caused a lot of issues in
designing algorithms for problems like
finding shortest route from one vertex
to another and we will talk about cycles
a lot when we will study some of these
at one still go our thumbs and coming
lessons for this lesson I will stop here
now in our next lesson we will discuss
ways of creating and storing graph in
computer's memory this is it for this
lesson thanks for watching
hello guys you will be seeing a C code
for adjacency list representation of a
directed or undirected graphs in this
video so first of all we should have a
basic knowledge about graphs so what is
a graph so we would give a brief
introduction about graphs so graphs are
nothing but it has a data structure that
consists of two components first it
candy it contains a finite set of
vertices second it contains a finite set
of ordered pairs which are of the form
UE these are also called edges so what
does a graph consists of it consists of
two components which are number of
vertices which are set of vertices and
set of edges which comprises whose graph
so let's illustrate it with the pigs
ample so what a graph consists of set of
vertices and set of edges so let's say
these are the vertices 1 2 &amp; 3 &amp; 4 so
the lines which connect them forms and
edges of the graph so these are called
vertices of the graph and these are
called the edges of the graph so now we
have a
now we have a brief knowledge about
graphs so let's get to this so why we
said these are the ordered pairs ordered
pair because here the order patterns
because if you will see that 1 2 is an
age you can't say always a 2 1 is also
off will also form an edge so we will
see now in which graphs we can say that
1 1 2 is same as 2 1 where the order
does not matter there you can say that
if there is an edge from 1 to 2 there is
an edge from 2 to 1 also so these are
typically let's say we have two types of
graph for this first is undirected
graphs these have a pair of an ordered
vertices hey UV is same as we let's say
we can say in these type of graphs as 1
2 is same as 2 1 for example in this
graph 1 2 is an edge 2 1 is also an edge
because we aren't well we have we are
allowed to go anywhere in this graph so
1 2 is same as 2 1 in this graph so
these type of graph forms and undirected
graphs what we call that undirected
graphs so if we a lot directions to them
let's say if we are given these type of
directions here 1 2 is not same as 2 1
you are allowed to go from 1 to 2 1 2
phones an edge but to one not for the
rich let's not form the gauge white 2 1
does not form an edge because you are
not allowed to go from 2 to 1 but you
are allowed to go from 1 to 2 all right
so 1/2 is 1/8 but to what is not an inch
so these type of graphs where we are
allowed to go in one direction in the
direction which we are given we can we
are allowed to go in that direction only
we call that type of graph story
two drafts so if your Lord directions
with the a directed graph that becomes
directed graph so this was all about
graphs now you will see its
representation how we can represent it
represent a graph so we will be seen now
how we can represent a graph we can
revisit the graph using to the help of
two methods so first as with the help of
adjacency list and second one is with
the help of adjacency matrix so in this
video we will be seeing how we can
represent a graph using a distance a
list what we will do to represent a
graph using a distance a list so what we
will do so let's say if we have a graph
that I'll what theis is let's say it has
five vertices and this graph let's say
is an undirected one we are allowed to
go anywhere through the edges we can go
from one to two you can also go from two
to one also so this is an undirected
graph so let's say it's if this is a
graph so if we want to represent this
graph using adjacency list what we will
do is so we will create an array of
linked lists we will create an array of
linked list and that the size of the
array would be the number of vertices
that we have in a graph so in this graph
we have five vertices so our array size
would be five so this would be array and
this would this array would correspond
this array would be the array of linked
list so each entry in the array would
correspond to the linked list like this
this would be pointing to a linked list
this would also point to a linked list
this entry would also go into a linked
list this entry would also point to an
linked list so watched what would be
contained in that look list so each
entry in the array would be the set of
vertices let's say we have five vertices
so each entry in this would correspond
to the word linked list of vertices
which are adjacent to one so what are
the vertices that are adjacent to one
these are two and five right so this
entry would correspond to the linked
list which will contain what Isis -
inside that far
adjacent to one similarly for 2 what are
the vertices that are adjacent to two
these are 1 and 3 right so this entry
would correspond to the word Isis that
are adjacent to 2 these are 1 and 3 this
would point to null this will also point
to lunch similarly for 3 what are the
vertices that are adjacent to 3 these
are 4 and 2 right so this would be
forming a linked list correspond to
correspond corresponding to the edge s
is what our dices 2 3 so these word for
n 2 so we created a linked list with 4
and 2 3 a - just 2 3 similarly for 4
what are the adjacent toward Isis - for
these are 3 inside so we would attach we
will attach three in five think this
with that similarly 4 5 so what are the
adjacent what Isis - fine these are 1 &amp;
4 so they will be forming a linked list
that will contain vertices that are
adjacent to 5 so this is what a graph
will look like a favored trip
in the form of adjacency list now we'll
be seeing a seafood for representing a
graph using adjacency list
the graph data structure has a great
many applications in computer science
almost invariably to model some type of
network travel routes such as road links
shipping lanes or aircraft flight paths
can be represented including information
about distances speed limits wind speed
fuel requirements or just about anything
of relevance but it doesn't stop there a
search engine might model the links
between webpages on the internet using a
graph the routing of data packets during
transmission on a computer network can
be represented by a graph the
connections between people and groups in
social networks the speed and pressure
of liquids flowing inside pipes finding
the quickest time to complete a project
that includes several interdependent
steps for example in the field of
construction modeling objects in three
dimensions usually involves the creation
of a mesh which is really just another
type of graph the available moves in a
strategy game such as chest or the
possible scenarios in a computer
generated simulation arguably the graph
is one of the most versatile data
structures in the field of software
engineering here's a simple graph it's a
collection of interconnected nodes but
unlike a tree there are no rules about
how these nodes can be connected there's
no such thing as a root mode nor are
there such things as parent nodes or
child nodes in a graph a node is more
correctly known as a vertex and vertices
are connected by edges typically a graph
will have more edges than vertices a
graph with lots of edges in relation to
the number of vertices is said to be a
dense graph while a graph with few edges
in relation to the number of vertices is
said to be sparse in some graphs the
edges are directional this is known as
directed graph it's also known as a
digraph a graph in which all of the
edges are bi-directional is known as an
undirected graph or an unordered graph
or simply a graph by default a graph is
assumed to be unordered each edge in a
graph can have a weight associated with
it the weight of each edge is sometimes
referred to as the cost what each cost
represents depends of course on the
application for example each cost could
be a speed limit the diameter of a water
pipe the number of hours to complete a
phase of a project you name it a path is
a sequence of vertices in a graph a
graph is said to be connected if there
is a path from every vertex to every
other vertex a cycle is a path in which
the starting vertex is also the ending
vertex a tree is a special type of graph
which includes a path from some starting
node the root to every other node but a
tree has no cycles so how do we
represent a graph or to begin with a
graph can be described in mathematical
set notation a graph is said to be a set
of vertices V and a set of edges e we
can list the vertices inside curly
brackets and each edge can be listed as
a pair of vertices for a weighted graph
we can add the cost of each edge to this
notation now remember an undirected
graph is one in which all of the edges
are bi-directional so strictly speaking
we should do note each possible
direction of an edge separately so what
if we want to code up a graph and work
with the data it contains there are two
ways that a graph class could internally
maintain the vertices and edges of a
graph these are the adjacency list
and the adjacency matrix in essence with
an adjacency list system we have a
master list of vertices then for each
edge each starting vertex maintains a
list of ending vertices or to put in
another way each vertex maintains a list
of its neighbors there are several ways
this could be implemented but an
object-oriented approach is probably the
most suitable we could code up a vertex
class that each vertex object would be
instantiated from the vertex class would
have a property to hold information
about the vertex
such as the name of a city if we were
representing some kind of map
another property could be an identifier
for the vertex and another an array
containing the identifier of its
adjacent vertices the master list of
vertex objects can also be stored in a
simple one-dimensional array to
represent a weighted graph the cost of
each edge could be stored in the
adjacency list to using an adjacency
list is a very compact space efficient
representation of a graph particularly a
sparse graph you don't have to store any
more data than necessary
however determining if an edge exists
between two particular vertices would
require searching through the adjacency
list of one of them for a dense graph
the time taken will increase
proportionately with the density of the
graph
with an adjacency matrix every vertex is
written as a row heading and a column
heading in a grid if an edge exists
between a pair of vertices then its
weight can be indicated at the
intersection of the appropriate row and
column note that for an undirected graph
there is symmetry along the adjacency
matrix is diagonal if there's an edge
from A to B there must be a
corresponding edge from B to a this
symmetry wouldn't be present for a
directed graph for an unweighted graph
we can simply represent each edge with a
boolean value an adjacency matrix can be
implemented with a two-dimensional array
we would still have a vertex class from
which we would create each vertex object
but the actual connectivity of the graph
would be defined by this 2d array of
edges one of the advantages of an
adjacency matrix over an adjacency list
is that determining whether or not an
edge exists between two vertices
requires a simple array lookup this
takes the same amount of time to do
regardless of the edge in question
however an adjacency matrix is not
particularly efficient when it comes to
space for a sparse graph much of the
adjacency matrix will be empty
furthermore for an undirected graph half
of the information stored is just
duplication which method you use to
implement a graph will ultimately depend
on the nature of the information it will
represent and of course how you plan to
process it
could it be quickly seen what is an
articulation point or a cut vertex in a
graph so let's say we are given a graph
then articulation point or cut vertex is
a point is the vertex removing which
will disconnect the graph so in this
connected graph if we remove two then
the graph it is connected into this and
this two graphs so two is a cut vertex
one is not three is not because knowing
three will give us one connected with
two which is the connected graph now let
us see this example in this this one is
the connect is a red vertex because
removing this will give us this and this
so two connected components so this is a
cut vertex similarly this is also a cut
vertex and so on
so no more cut vertex for this
absolutely and if we are let us say
given a forest so this one let us say
this is the forest then in this forest
this one is the cut vertex because right
now there are two connected components
if we are removing this it will result
in three connected components one two
and one two and three so this is a cut
vertex there is no other cut vertex as
you can see it is so cut vertex this is
the definition of cut vertex or
articulation point a graph hope you
understood thank you friends please like
share and subscribe
so in our previous lesson we talked
about adjacency matrix as a way to store
and represent graph and as we discussed
and analyzed this data structure we saw
that it's very efficient in terms of
time cost of operations with this data
structure it costs Big O of 1 that is
constant time to find if two nodes are
connected or not and it costs Big O of V
where V is number of vertices to find
all nodes adjacent to a given node but
we also saw that adjacency matrix is not
very efficient when it comes to space
consumption we consume space in order of
square of number of vertices in
adjacency matrix representation as you
know we store edges in a two-dimensional
array or matrix of size V cross V where
V is number of vertices in my example
graph here we have eight vertices that's
why I have an 8 cross 8 matrix here we
are consuming 8 square that is 64 units
of space here now what's basically
happening is that for each vertex for
each node we have a row in this matrix
where we are storing information about
all its connections this is the row for
the zeroth node that is a this is the
row for the one at node that is B this
is for C and we can go on like this so
each node has got a row and a row is
basically a one dimensional array of
size equal to number of vertices that is
V and what exactly are we storing in a
row let's just look at this first row in
which we are storing connections of node
a this two-dimensional matrix or array
that we have here is basically an array
of one-dimensional arrays so each row
has to be one dimensional array so how
are we storing the connections of node a
in these eight cells
this one-dimensional array of size 8/0
in the zeroeth position means that there
is no edge starting a and ending at zero
at node which again is a an edge
starting and ending at itself is called
a self loop and there is no self loop on
a of 1 in 1 its position here means that
there is an edge from a to 1 at node
that is B the way via storing
information here is that index or
position in this one-dimensional array
is being used to represent endpoint of
an edge for this complete row for this
complete one-dimensional array start is
always the same it's always the zero at
node that is a in general in the
adjacency matrix row index represents
the start point and column index
represents the end point now here when
we are looking only at the first row
start is always a and the indices 0 1 2
and so on are representing the endpoints
and the value at a particular index or
position tells us whether we have an
edge ending at that node or not one here
means that the edge exists 0 would have
meant that the edge does not exist now
when we are storing information like
this if you can see we are not just
storing that b c and d are connected to
a we are also storing the knot of it we
are also storing the information that a
e f g and h are not connected to a if we
are storing what all nodes are connected
through that we can also deduce what all
nodes are not connected these zeros in
my opinion are redundant information
causing extra consumption of memory most
real-world graphs are sparse that is
number of connections is really small
compared to total number of possible
connections so
so often there would be too many zeroes
and very few ones think about it let's
say we are trying to store connections
in a social network like Facebook in an
HSN C matrix which would be the most
impractical thing to do in my opinion
but anyway for the sake of argument
let's say we are trying to do it just to
store connections of one user I would
have a row or one dimensional matrix of
size 10 to the power 9 on an average in
a social network you would not have more
than thousand friends if I have thousand
friends then in the row used to store my
connections I would only have thousand
ones and rest that is 10 to the power 9
- thousand would be zeros and I'm not
trying to force you to agree but just
like me if you also think that these
zeros are storing redundant information
and our extra consumption of memory then
even if we are storing these ones and
zeros in just one byte as boolean values
these many zeros here is almost one
gigabyte of memory once are just 1
kilobyte so given this problem let's try
to do something different here let's
just try to keep the information that
these nodes are connected and get rid of
the information that these nodes are not
connected because it can be inferred it
can be deduced and there are a couple of
ways in which we can do this here to
store connections of a instead of using
an array such that index represents
endpoint of an edge and value at that
particular index represents whether we
have an edge ending there or not we can
simply keep a list of all the nodes to
which we are connected this is the list
or set of nodes to which a is connected
we can represent this list either using
the indices or
using the actual names for the nodes
let's just use indices because names can
be long and may consume more memory you
can always look at the vertex list and
find out the name in constant time now
in a machine we can store this set of
nodes which basically is a set of
integers in something as simple as an
array and this array as you can see is a
different arrangement from our previous
array in our earlier arrangement index
was representing index of a node in the
graph and value was representing whether
there was a connection to that node or
not here index does not represent
anything and the values are the actual
indices of the nodes to which we are
connected now instead of using an array
here to store this set of integers we
can also use a linked list and widest
array or linked list I would argue that
we can also use a true here in fact a
binary search tree is a good way to
store a set of values there are ways to
keep a binary search tree balanced and
if you always keep a binary search tree
balanced you can perform search
insertion and deletion all three
operations in order of log of number of
nodes we will discus cost of operations
for any of these possible ways in some
time right now all I want to say is that
there are a bunch of ways in which we
can store connections of a node for our
example graph that we started with
instead of an adjacency matrix we can
try to do something like this we are
still storing the same information we
are still saying that zero at node is
connected to one at two it and three at
node 1 at node is connected to 0 at 4th
and 5th node to ethno disconnected to 0
at and sixth node and so on but we are
consuming a lot less memory here
programmatically this adjacency matrix
here
is just a two-dimensional array of size
8 cross 8 so we are consuming 64 units
of space in total but this structure in
right does not have all the rules of
same size how do you think we can create
such a structure programmatically well
it depends in c or c++ if you understand
pointers then we can create an array of
pointers of size 8 and each pointer can
point to a 1 dimensional array of
different size 0 8 pointer can point to
an array of size 3 because 0 8th node
has 3 connections and we need an array
of size 3 one at pointer can point to an
array of size 3 because one it's node
also has 3 connections to it node
however has only 2 connections so 2 its
pointer should point to an array of size
2 and we can go on like this the 7th
node has four connections so 7th pointer
should should point to an array of size
4 if you do not understand any of this
point to think that I am doing right now
you can refer to my code schools lesson
titled pointers and arrays the link to
which you can find in the description of
this video but think about it the basic
idea is that each row can be a
one-dimensional array of different size
and you can implement this with whatever
tools you have in your favorite
programming language now let's quickly
see what are the pros and cons of this
structure in the write in comparison to
the matrix in the left
we are definitely consuming less memory
with the structure in right with
adjacency matrix our space consumption
is proportional to square of number of
vertices while
the second structure space consumption
is proportional to number of edges and
we know that most real-world graphs are
sparse that is the number of edges is
really small in comparison to square of
number of vertices square of number of
vertices is basically total number of
possible edges and for us to reach this
number every node should be connected to
every other node in most graphs a node
is connected to few other nodes and not
all other nodes in the second structure
we are avoiding this typical problem of
too much space consumption in an
adjacency matrix by only keeping the
ones and getting rid of the redundant
zeros here for an undirected graph like
this one we would consume exactly two
into number of edges units of memory and
for a directed graph we would consume
exactly ethat is number of edges units
of memory but all in all space
consumption will be proportional to
number of edges or in other words space
complexity would be Big O of e so the
second structure is definitely better in
terms of space consumption but let's now
also try to compare these two structures
for time cost of operations what do you
think would be the time cost of finding
if two nodes are connected or not we
know that it's constant time or Big O of
1 for an adjacency matrix because if we
know the start and end point we know the
cell in which to look for 0 or 1 but in
the second structure we cannot do this
we will have to scan through a row so if
I ask you something like can you tell me
if there is a connection from node 0 to
7 then you will have to scan this zero
at row you will have to perform a linear
search on this zero eighth row to find
seven right now all the rules in this
structure are sorted you can argue that
I can keep all the rules sorted and then
I can perform a binary search which
would be a lot less costlier that's fine
but if you just perform a linear search
then in worst case we can have exactly V
that is number of vertices cells in a
row so if we perform a linear search in
worst case we will take time
proportional to number of vertices and
of course the time cost would be big-oh
of log V if we would perform a binary
search logarithmic runtimes are really
good but to get this here we always need
to keep our rows sorted keeping an array
always sorted is costly in other ways
and I'll come back to it later for now
let's just say that this would cost us
big o of V now what do you think would
be the time cost of finding all nodes
adjacent to a given node that is finding
all neighbors of a node well even in
case of adjacency matrix we now have to
scan a complete row so it would be Big O
of V for the matrix as well as this
second structure here because here also
in worst case we can have V cells in a
row equivalent to having all ones in a
row in an adjacency matrix when we try
to see the time cost of an operation and
we mostly analyze the worst case so for
this operation we are Big O of V for
both so this is the picture that we are
getting looks like we are saving some
space with the second structure but we
are not saving much on time well I would
still argue that it's not true when we
analyze time
complexity we mostly analyze it for the
worst case but what if we already know
that we are not going to hit the worst
case if we can go back to our previous
assumption that we are dealing with a
sparse graph that we are dealing with a
graph in which a node would be connected
to few other nodes and not all other
nodes then the second structure will
definitely save us time things would
look better once again if we would
analyze them in context of a social
network I'll set some assumptions let's
say we have a billion users in our
social network and the maximum number of
friends that anybody has is 10,000 and
let's also assume computational power of
our machine let's say our machine or
system can scan or read 10 to the power
6 cells in a second and this is a
reasonable assumption because machines
often execute a couple of millions
instructions per second now what would
be the actual cost of finding all nodes
adjacent to a given node in adjacency
matrix well we will have to scan a
complete row in the matrix that would be
10 to the power 9 cells because in a
matrix we would always have cells equal
to number of vertices and if we would
divide this by a million we would get
the time in seconds to scan a row of 10
to the power 9 cells we would take
thousand seconds which is also sixteen
point six six minutes this is
unreasonably high but with the second
structure maximum number of cells in a
row would be 10,000 because the number
of cells would exactly be equal to
number of connections and this is the
maximum number of friends or connections
a person in the network has so here we
would take 10 to the power 4
10 to the power 6 that is 10 to the
power minus 2 seconds which is equal to
10 milliseconds 10 milliseconds is not
unreasonable now let's try to deduce the
cost for the second operation finding if
two nodes are connected or not
in case of adjacency matrix we would
know exactly what cell to read we would
know the memory location of that
specific cell and reading that one cell
would cost us 1 upon 10 to the power 6
seconds which is 1 microsecond in the
second structure we would not know the
exact cell we will have to scan a row so
once again maximum time taken would be
10 milliseconds just like finding
adjacent nodes so now given this
analysis if you would have to design a
social network
what structure would you choose
no-brainer
isn't it machine cannot make a user wait
for 16 minutes would you ever use such a
system milliseconds is fine but minutes
it's just too much so now we know that
for most real-world graphs this second
structure is better because it saves us
space as well as time remember I am
saying most and not all because for this
logic to be true for my reasoning to be
valid graph has to be sparse number of
edges has to be significantly lesser
than square of number of vertices so now
having analyzed space consumption and
time cost of at least two most
frequently performed operations looks
like this second structure would be
better for most graphs well there can be
a bunch of operations in a graph and we
should account for all kind of
operations so before making up my mind I
would analyze cost of few more
operations what if after us two
during this example graph in computer's
memory in any of these structures we
decide to add a new edge let's say we
got a new connection in the graph from A
to G then how do you think we can store
this new information this new edge in
both these structures the idea here is
to assess that once the structures are
created in computer's memory how would
we do if the graph changes how would we
do if a node or edge is inserted or
deleted if a new edge is inserted in
case of an adjacency matrix we just need
to go to a specific cell and flip the
zero at that cell to 1 in this case we
would go to 0-8 row and sixth column and
override it with value 1 and if it was a
deletion then we would go to a specific
cell and make the 1 0 now how about this
second structure how would you do it
here we need to add a 6 in the first row
and if you have followed this series on
data structures then you know that it's
not possible to dynamically increase
size of an existing array this would not
be so straightforward we will have to
create a new array of size 4 for the
zeroth row then we will have to copy
content off the old array write the new
value and then wipe off the old one from
the memory it's tricky implementing a
dynamic or changing list using arrays
this creation of new array and copying
of old data is costly and this is the
precise reason why we often use another
data structure to store dynamic or
changing
and this another data structure is
linked list so why not use a linked list
why can't eat Robi a linked list
something like this logically we still
have a list here but concrete
implementation wise we are no more using
an array that we need to change
dynamically we are using a linked list
it's a lot easier to do insertions and
deletions in a linked list now
programmatically to create this kind of
structure in computer's memory we need
to create a linked list for each node to
store its neighbors so what we can do is
we can create an array of pointers just
like what we had done when we were using
arrays the only difference would be that
this time each of these pointers would
point to head of a linked list that
would be a node I have defined node of a
linked list here node of a linked list
would have two fields one to store data
and another to store address of the next
node a zero would be a pointer to head
our first node of linked list for a a
one would be a pointer to head of linked
list for B and we will go on like a to
foresee a three for D and so on actually
I have drawn the linked lists here in
the left but I have not drawn the array
of pointers let's say this is my array
of pointers now a zero here this one is
a pointer to node and it points to the
head of linked list containing the
neighbors of a let's assume that head of
linked list for a has address 400 so in
a 0 we would have 400 it's really
important to understand what is what
here in this structure this one a zero
is a pointer to node and all up
winter does is store an address or
reference this one is a node and it has
two fields one to store data and another
a pointer to node to store the address
off next node let's assume that the
address of next node in this first
linked list is 450 then we should have
450 here and if the next one is at let's
say 500 then we should have 500 in
address part of the second node the
address and last one would be zero or
null now this kind of structure in which
we store information about neighbors of
a node in a linked list is what we
typically call an adjacency list what I
have here is an adjacency list for an
undirected unweighted graph to store a
weighted graph in an adjacency list I
would have one more field in node to
store weight I have written some random
weights next to the edges in this graph
and to store this extra information I
have added one extra field in node both
in logical structure and the code all
right now finally with this particular
structure that we are calling adjacency
list we should be fine with space
consumption space consumed will be
proportional to number of edges and not
to square of number of vertices most
graphs are sparse and number of edges in
most cases is significantly lesser than
square of number of vertices ideally for
space complexity I should say Big O of
number of edges plus number of vertices
because storing vertices will also
consume some memory but if we can assume
that number of vertices will be
significantly lesser in comparison to
number of edges then we can simply say
Big O of number of edges but it's always
good if we do the
right now for time cost of operations
the argument that we were earlier making
using a sparse graph like social network
is still true adjacency list would
overall be better than adjacency matrix
finally let's come back to the question
how flexible are we with this structure
if we need to add a new connection or
delete an existing connection and is
there any way we can improve upon it
well I leave this for you to think but
I'll give you a hint what if instead of
using a linked list to store information
about all the neighbors we use a binary
search tree do you think we would do
better for some of these operations I
think we would do better because the
time cost for searching inserting and
deleting a neighbor would reduce with
this part I'll sign off this is it for
this lesson thanks for watching
welcome to the first in a series of
demonstrations on the graph data
structure what we're going to be
starting out with is a look at a graph
implementation specifically looking at a
graph implemented as an adjacency matrix
and trying to determine what kind of
graph that adjacency matrix represents
so we're going to draw out a graph
corresponding to this adjacency matrix
first thing that we're going to do is
we're going to try to figure out what
kind of graph we've got in the first
place now if we take a look at the
matrix the rows and columns are labeled
ABCD and E which means we have five
vertices which we're going to dry out
and label them a B C D and E now the
contents of the matrix itself are
numeric which means that there's going
to be some kind of weight associated
with the edges between each vertex now
if these have been boolean instead we
would say that it was an unweighted
graph but since we have numbers we're
going to associate those with the edges
the other thing that we can determine is
that by taking a look at the main
diagonal and the values on either side
the values on either side of the main
diagonal aren't identical so for example
evaluate Row one column two is not the
same as the value at Row two column one
what this means is the matrix is not
symmetric and therefore the graph is
bi-directional so we're going to have to
draw arrow heads as we go on each four
edges so let's start out with the first
row
and take a look at the edges that
originated a now there's two edges
originating at a one divert X B was
weight of three and another one to
vertex E with a weight of one now again
this is a directed graph so we're
drawing arrow heads on each edge as we
go there's only one edge originating a B
and that's an edge to D with wait to see
has three edges rigid a and they have
different weights we have one from C to
a with wait for one from C to B with
weight 2 and 1 from C to e with weight 5
there are two edges originating from d1
that goes to C with weight six and one
that goes to E with weight one
and then finally in the last row of our
matrix we have two edges originating at
row e1 back to a with weight one now
notice that we already have an edge from
A to E with weight one and the edge
going back will also have the same
weight so instead of drawing it in
another edge let's just draw in another
arrowhead indicating that this edge
happens to be bi-directional and the
other one is an edge from e to D with
weight three now although we already
have an edge from D to e we can't just
draw it in another arrowhead because
this new edge has a different weight so
I'll have to draw in another line with
an arrow going in the opposite direction
and label this one as having weight
three and that's our complete graph
based on that adjacency matrix for the
second demonstration we're going to take
a look at a different implementation of
a graph in this case a graph implemented
as an adjacency list there are six
vertices labeled a through F this will
start out by drawing our graph by
drawing those six vertices now we don't
know exactly where the best place to
draw these vertices are so we'll just
kind of take a guess and spread them
apart nicely so that we have lots room
to draw on edges the first item in our
adjacency list shows us all of the edges
originating at vertex a now a has an
edge going to see a soldier on that one
and in the absence of any evidence to
the contrary we're going to make this a
directed edge from A to C the second
item shows us the B has two edges
originating at B one to D and one to E
see has three edges one returning back
to a now in this case we don't have any
kinds weights so we'll just draw in an
arrow back to a 1/2 D and 1/2 e D has an
edge going to be well we already have an
edge from B to D so this is just now a
bi-directional edge and one back to C
again just another arrowhead on an
existing edge e has three edges one
returning back to be drawn another
arrowhead one back to C and one to F and
finally the last item in our Jason C
list shows us that there is an edge from
F returning back to e we take a careful
look at our graph we can see that all of
the edges that we've drawn in in fact
have arrowheads on both ends in other
words our graph is undirected now there
was no way for us to tell that from
actually looking at the original
adjacency list it's just something that
we had to discover as we went along
but that's our complete graph
hey this is sesh welcome to another
lesson in data structures and algorithms
this one is on graphs in which I will
introduce you to the kinds or types of
graphs we often deal with in computing
applications and although there are
different kinds of graphs they can all
be represented and stored in a program
in one of two standard formats which we
will study okay then let's begin by
looking at a graph that underpins
perhaps the most well-known application
in recent times namely Facebook Sarah is
friends with Sam who was friends with
Mira who's friends with Jane who was
friends with Maria Sarah is also friends
with AJ and Sam is also friends with
Shawn there is another group of people
that's not connected to the first here
Rahul is friends with Sapna who is
friends with Rohit what we've drawn is a
graph that represents friendships in
Facebook of course the real Facebook
graph is huge with hundreds of millions
of people and friendships but this
representation holds true no matter the
size in formal terms this graph models a
symmetric relationship if Sapna is Rajas
friend then Rahul is topknot friend as
well the relationship applies in both
directions we will see shortly that this
has an implication in how the graph is
stored in a program in graph terminology
each person in the Facebook graph is
represented by what's called a vertex
vertices plural and a friendship is
represented by an edge so the graph is a
collection of vertices that describe the
entities and edges that describe the
relationships between them here's
another example a graph that represents
a website a website has pages and pages
have links that connect them with other
pages page a links to pages B D and E
page B links to page D page see links to
a D links to be a links to F and
Flinx 2d the pages are the vertices and
each link is an edge from one page to
another page in other words each edge is
unidirectional
unlike the facebook graph where the
edges are implicitly bi-directional
since friendship works both ways the
edges in the website graph have
direction because the linking
relationship is asymmetric for example
my personal webpage points to an Amazon
page but that Amazon page doesn't point
back to mine graphs in which edges are
directional or directed are called
directed graphs those in which edges are
not directional are called undirected
graphs an undirected graph is actually a
special kind of directed graph since
every undirected edge represents a
relationship going both ways it is
equivalent to having two edges going in
opposite directions again this
observation will be useful when we get
to storing a graph in a program
sometimes edges will carry what are call
weights as in this graph weights are
numbers and in this case there are
distances in miles this is an example of
a weighted undirected graph in general
edge weights in graphs are typically
positive integers or real numbers and
here's the earlier web graph where the
edges are now marked with the number of
times the corresponding links were
clicked in the period for which the data
was collected this is a weighted
directed graph to recap there are four
kinds of graphs undirected graphs
without edge weights weighted undirected
graphs directed graphs without edge
weights and weighted to write to graphs
next up graph storage in programs this
Dora Graf in a program we need to
account for all the vertices and all the
edges every vertex will have a name such
as a person's name as in the Facebook
graph or a webpage URL as in a website
graph or a city name or whatever we can
store the set of verdict vertex names in
one of many ways for instance we can
store them in an array or if an
efficient search by name is needed say
in a hash table but how to store the
edges the edges are in fact what make
the graph because a graph is really
about the connections between vertices
we need to be able to show which pairs
of vertices are connected by edges one
way to do this is by means of a matrix
which in a program would be a
two-dimensional array the rows and
columns would both stand for vertices
each vertex has an integer number
assigned to it if the vertex names are
stored in an array then the vertex
number is implicitly its index in the
array since there are ten vertices we
have a 10 by 10 matrix in this example
Sara is number zero
Sam is number one and so forth the order
in which the vertices are stored and
therefore the sequence in which they are
numbered is irrelevant the matrix
accounts for all possible pairs of
vertices and each cell would show
whether a particular pair of vertices
has an edge between them or not there is
an edge between Sara and Sam so the cell
for row 0 column 1 should be turned on
but since the edge applies both ways the
cell for Row 1 and column 0 should also
be turned on in the same way all other
cells in the matrix corresponding to
edges will be turned on whether a cell
is turned on or off can be indicated by
a true or false boolean values stored in
the cell so the matrix would have truths
in all the cells that correspond to
edges
Graaff all the other cells would be
false the false values are not shown
here so let's not cloud the matrix
observed the pattern of true values is
symmetric about the main diagonal since
if row I column J is true then so is row
J column I the symmetry is also true of
all the false values hence this is a
symmetric matrix which is in keeping
with the graph representing a symmetric
relationship
now let's tour the website graph without
edge weights in matrix form since there
are 6 vertices we need to set up a 6 by
6 matrix let's take a look at the edges
page a has an edge to page B so we fill
in a true in row 0 column 1 but because
the edge is directed there will not be a
true in row 1 column 0 filling in the
rest of the matrix gives us this the
matrix is not symmetric as expected
because the graph represents an
asymmetric relationship in these two
examples we've used the boolean matrix
since the edges don't have any weights
on them however if the edges do carry
weights we can use the edge weight
numbers in place of the true values for
the false values we can use any number
that is not a legal edge weight so for
instance a value of negative 1 could be
used to show the absence of an edge for
any graph whose edge weights are
positive earlier we saw the graph of
cities and distances between them again
since there are 6 vertices you would
need a 6 by 6 matrix to store this graph
this matrix is then filled in with the
distances add the appropriate cells the
cells for the pairs of vertices that
don't have edges between them carry
negative 1 values observe that this
matrix is symmetric
because the distance relationship
between a pair of cities is a symmetric
relationship it works both ways
in graph vernacular this matrix is
called the adjacency matrix because it
lists all the vertices that are adjacent
to any vertex for instance Chicago and
Atlanta are adjacent to Newark because
they are one edge away the term neighbor
is alternatively used to refer to
vertices that are one edge away in the
adjacency matrix in row zero for Newark
the distances to Chicago and Atlanta
appear in columns one and five row zero
is set to hold the adjacency list of
vertices from the work with negative one
for the holes or absence of edges the
columns also hold adjacency lists so for
instance column indexed two for San
Francisco shows that Chicago and Los
Angeles are adjacent to it since the
matrix is symmetric the information
below the main diagonal is the same as
the information above it so if you
wanted to run through the entire set of
edges you could either scan the lower
triangle or the upper triangle but not
both if you scan the entire matrix you
would hit each edge twice so say you
wanted to count the number of edges in
an undirected weighted graph off is
adjacency matrix say the matrix is
stored in a two dimensional array a of
integers then the edge counting code
would look like this the nested
for-loops can still lower triangle of
the matrix in this example n the number
of vertices is six the first row is not
scan at all since the inner loop four
columns goes up to row minus one and
since the first row index zero the inner
loop does not run in the second row the
first column is checked and counted
in the third row the first column is
checked and skipped the second column is
counted and so on until the last row you
may have noticed in the matrices we have
seen up to this point that there are
very few cells that are filled in for
the edges but a lot of empty no edge
cells in the facebook friendship graph
there are eight edges as seen in the
lower triangle of the array the other
eight rows in the upper triangle is the
same information so it doesn't count the
total number of cells in the array is a
hundred so the proportion of actual
information to space used is eight
divided by 100 or eight percent in the
website graph which is directed there is
a total of eight truths or eight edges
while the total number of cells is 36 so
the space utilization is eight divided
by 36 or twenty-two percent and in the
city's graph there are again six edges
while there are 36 cells for a space
utilization of six divided by 36 or
sixteen percent it's clear that when the
number of edges is small the space
utilization is extremely low in order
for the adjacency matrix to use space
effectively there has to be a large
number of edges let's look at the
extreme possibilities for number of
edges in a graph this line is the
spectrum of number of possible edges in
all graphs that have n vertices at the
left extreme is the least possible
number of edges which is 0 the other
right extreme would be the most possible
number of edges what would the number be
let's look at a few examples of this
extreme to see if we can arrive at a
formula for maximum edges in terms of
number of vertices if there's a single
vertex there can't be any edges with two
vertices there
me a maximum of one edge with three
vertices we can have at most three edges
and with four vertices we can have up to
six edges four connections between every
pair of vertices one way to get at the
formula is to think of the maximum
possible edges that can emanate from a
vertex if the number of vertices is n
then each vertex can connect to all the
other vertices or n minus 1 so the
maximum total number of emanations is
the product of n the number of vertices
in n minus 1 the maximum emanations per
vertex however this figure counts each
edge twice in an undirected graph first
from one endpoint vertex and then from
the other endpoint as well
so for the four vertex graph plugging
four for n in this formula gives us four
times four minus one which is 12 by the
number of edges is six so we need to
divide this figure by two for the
correct formula in a directed graph the
maximum number of edges would simply be
n times n minus one since each emanation
counts for only one edge these extremes
basically set up a gradation on the left
end of which we have what are called
sparser graphs and at the right end of
which we have what are called denser
graphs if the graph tends to be denser
there is increased space utilization
with the adjacency matrix and it is a
good storage scheme but the graph tends
to be sparse or there is decreased
utilization of space in practice most
graphs tend to be sparse for instance
Facebook has about 1 billion members on
the average say each person has about
300 friends this means Cindy decency
matrix there would be 300 truths in each
of the 1 billion rows for the members
for a total of 300 times 1 billion
whereas the matrix would need 1 billion
squared amount of space the space
utilization is therefore 300 over a
billion which is miniscule actually as
we saw before it's really 150 over a
billion since each friendship edge gets
counted twice which makes the
utilization even worse if you think
about the graph for the world wide web
you run into a similar situation there
are billions of web pages but any single
page points to a few hundred other pages
if so what this means is for most
real-world applications the adjacency
matrix is not a good choice however
there are some niche applications where
the matrix is in fact useful typically
when memory is not an issue
and when operations result in random
access into the array happen very often
in a follow up video we'll look at a
much more space efficient alternative to
store graphs see you then
hello in this video we are going to have
a very quick tour through the tool
Gaffey that we are going to use for
social network analysis before we start
the exercise explained in this video I
would like to ask you that you first
download Kaffee and follow the
instruction for the installation of
caffeine some of you depending on the
operating system the type of computer
you may have and the type of Java
version may have different requirements
and needs to update or check that you
check the Java version that your machine
has there are also some
incompatibilities between different
versions of Java and Kaffee well that's
one of the joys of having open source
software while while the this piece of
technology we are going to use for
social network analysis is open source
and publicly available to anybody there
are certain issues that we always need
to deal when we are installed installing
so I hope you have already overcome that
problem and that you can now continue
with the exercise that we are going to
have in this video so for this exercise
I suggest that first we are following
the examples that are provided in their
course resources so those examples are
available in the course readings so for
the EDX users you can easily locate them
in your EDX platform and they are also
available in the pro solo credential
available for this week so in these two
examples you will see that there are two
separate files each of these files can
be imported and loaded into Gaffey for
further analysis so all you need to do
is to say open and go located the folder
in which these two examples are and then
import it so let's go first with example
1 and import it into Gaffey both of
these examples are created in such a way
to be undirected of course you can also
import them as directed but the overall
size of the network and the types of
results that I am going to show in your
analysis would be different so let's
assume that these two networks are
undirected in the same
manner as they are shown in the slides
that we followed throughout the
presentation so the first thing that you
are going to notice is although I using
the identical example that is provided
in the slides and the video
presentations that we use for the
interaction of social network analysis
in this video you can see that the first
basic layout of this visualization is
not the same so what I am suggesting you
to first to check out is to go to this
component which is called layout and
India layout you can experiment with
different types of visualization of
graphs through my experimentation with
this example I found that Yin Phan you
hue was the probably best example of the
layout that could be applied for our
network you can also see that this
network visual as visualized as now is
probably the most similar to the
representation to be used in the slides
of course there are many other of these
different visualizations and depends on
the data set and depends on what respect
you want to show some of these different
layouts may work better in some other
cases in some cases where you are
dealing with bigger data sets this
particular data set this particular
layout can be best for you and I'm
typically using however for this
particular data set that we are using
now for this small example its eternal
that Union fan who proportional Lorene
fun food is the basic algorithm work
equally well all right so once you have
visualized that the next thing that I'm
sure you would like to do is that you
actually zoom bit this whole example n
so that let's go there you can identify
here on this lower button right corner
this small icon when you open this
saikhan you will see that the first tab
here is global so just try to play there
with this slider and you can zoom it in
and zoom it out this icon this whole
network
and the second thing is then here you
can also change the shape of this
diagram the next thing is you can also
play with the color and the shape of
different edges that you have in the
network so you can also play there and
final thing that might be interested in
this case is that you can also turn on
the labels or the name so the actors in
this network that we are presently
experimenting with they are of course
situations like this one where this
labeling may be useful and may be still
visible however when you are dealing
with networks of several hundreds or
even several thousand of actors in your
network they may not be that's durable
too to be shown in the network but let's
for time being turn them off and let's
continue to experiment with the some of
the network analysis that we learn in
this course so the first network
analysis that I'm going to introduce
here is available through these
statistics so when you open this the tab
on the right hand side of your window
statistics you can first compute degree
so it says average degree but the moment
you say average degree it will also
compute the value of every single node
in your network so it will also show the
distribution of the degrees and finally
it will also show what is the average
degree for the network in this case we
can see that the average degree is 3.6
and so this is the value that means that
each node in the network on average has
3.6 connections but of course different
nodes may have different degrees so how
we can actually become aware or see what
is the value of degree for each of these
different nodes well there are few
strategies how you can do that one
strategy is that you go to the data
laboratory tab here and in that tab you
will then see each of these nodes as
well as each nodes degree so you can see
that for each nodes degree that we are
having this network we can see what was
the value of the
three okay so let us now return back to
the visualization that is done by
clicking or pressing this button which
is called overview so how we can now
visualize some of these network measures
and see that we can for example
differently color our nodes in the
network or maybe even size based on the
values of their degree so to do so you
need to go to this now tab on the left
hand side which is called partition so
the first thing is you will see there is
a drop-down box here which is empty so
the first thing we need to do is we need
to refresh it all right so once we
refresh that box we can see that they
are there is the value degree so for
partitioning generally you can do this
and based on that the nodes with the
same number of degree values they will
be colored differently so you can follow
these different colors and their
representation here so this is one way
to do that so in this way for example
the nodes with red color meaning that
they have three to the value three they
will be shown here on the diagram and
the similar based on these degree values
those are the discrete value items for
each of these values are shown and
visualized differently in the diagram
there is another way to do and visualize
your network is if you go into the
ranking part and select nodes once you
have selected nodes you can then choose
degree and then once you have chosen
degree and say apply you will see that
these nodes will be colored differently
in the darkness of the color of the node
will represent the higher value of
degree that is to say the measure that
we use to color our nodes of course you
can also experiment with different types
of splines and the different ways how
that can be colored but nevertheless
it's important to remember that this is
the way how you can visualize based on
the color
before we continue the visualization I
would suggest that we first do something
else I first suggest that we go return
back to our network and to compute
betweenness centrality so between us and
round is computed when we are computing
diameter this is actually not surprising
given that the in the computation of
between a centrality closeness
centrality and few other measures that
were diameter the measure that we also
introduced in our slides and videos is
introduced so I'm suggesting you that
just you run network diameter once you
are asked here network diameter you will
be by default selected undirected graph
and you can choose whether you would
like to normalize it or not
thermalization means whether you would
like that between a centrality and all
these other three measures are presented
in the on the scale 0 to 1 or you would
like to just simply have them all
represent them with the values as they
are this normalization 0 to 1 means that
there will be found the maximal value of
between a centrality and then all these
other values will be scale that is to
say they will be divided by that maximum
value have been doing us and travel to
your father of a node in the network and
that's how we are getting this
normalized centrality measures so let's
not go now with these normalized let's
go with the actual values of the
centrality measures and see what we can
get all right again similar as done
before we are getting between a
centrality and closing centrality has
done for degree centrality there's
another measure here it's just cause a
centricity we haven't introduced it but
it's quite similar to close the
centrality except it's a discrete value
it's always an integer number and means
basically what is the highest number of
hops that a node needs to have to reach
to any other node meaning that's a
geographic center of the network
so once we computed these three measures
if you return back to the data
laboratory tab you will see that three
new columns were added a centricity
closeness and betweenness centrality all
right
so let's go now back to the overview of
our network and for that overview let's
now click on this like a small diamond
in the ranking tab of the network when
you ask who over that small diamond you
will see the size weight will be
something that will be shown as the
value so what I'm suggesting you here
let's now choose between a sensuality is
used to size the nodes in the network
and I'm suggesting you that you can play
with different numbers Max signs but I'm
suggesting you to say enter value like
100 here to see what will happen so it
means basically that the based on the
values of between a centrality the
maximum size of some of these nodes will
be hundred between one and hundred
points and they'll be depending on the
values so between a centrality alright
so once we apply this between a
centrality you can see that we visualize
these nodes and they were sized based on
between a centrality but you can see
that this network presented this this
way is really not that helpful so let's
try with some smaller number like 30
perhaps and you can see now that there
are differences in the size of our nodes
the node which has the largest value or
betweenness centrality is in principle
the highest node here and the question
becomes well how do we know which node
is that there's one possibility
you can right-click on that node and you
can go select in detail laboratory that
means the following once we have done
this so select indeed a laboratory and
you return back to data laboratory that
particular node will be selected and for
a good reason because this node had the
highest between a centrality as we also
showed in our video presentation
before so this is Liz and Liz has this
betweenness centrality as the highest
number let's return back again here
there's another possibility how you can
see which node was that one with the
highest centrality we can again turn on
the labels back so once we turn the
labels back on we can again see that
slays with the highest number of degree
of between a centrality so this is the
way how you analyze networks and
especially how you analyze networks when
you are interested to compute some of
these major measures of course we can
also compute grab density as we also
introduced and again it's fairly simple
it tells us the same number as we also
saw in our presentation it's point for
the value that is to say 40 percent of
the entire potential death Network to be
connected there's one more thing we
computed these measures that are at the
level of nodes and at the level of the
entire network like a dual internal
network was natural diameter and grab
density and in there are level of
individual nodes we had degree we have
also closeness in between a centrality
someone may ask okay this is cool we all
computed but then how we can now
experiment with some of these measures
and connected say with the tool for data
analysis such as a tableau that we
introduced in weeks one and two or rapid
miner that Ryan Baker is going to
introduce in weeks five and six so
that's also fairly simple you can now
export this entire table from the data
laboratory in comma separated value
files or some other separated files and
then you can import this file into
tableau you can have be imported into
any tool that deals with spreadsheets or
you can import into different
statistical analysis tools such as our
SPSS SAS or some other tool that you may
have access to use R for example is open
source and it can be easily accessed at
this point we finished some basic
introduction into getting how to compute
these basic measures I would encourage
you now to go into the hands-on
activities that are provided in the
course materials to import these
examples and review start performing
these types analysis as shown in this
video I would also then encourage you to
perform further hands-on activities on a
bigger data set that we've provided in
the study and more importantly to share
your experience with others in addition
to my video here that I recorded with
Jaffe I'm also going to refer you and
you can find that in the resources
available in the course materials to
some other YouTube videos which can
allow you for additional insights under
ways how Jeffie can be used for
visualization and performing some of
these types of analysis from of those
examples are all suffering opportunities
for you to for example download your
Facebook network or your Twitter network
based on that we also created some
assignments that you can perform but in
a nutshell these types of analysis and
the functionality that I showed in this
video will get you going very far of
course for those who would like to have
something more advanced they are welcome
to explore additional functionalities
and even better they are more than
welcome to share it with everybody else
through EDX discussion forums through
Pro solo or other social media that is
used in this course thanks very much
hello friends in this lecture we will
look at graph representation using
adjacency lists and we will use C++
STL's to do accomplish this task so we
will just look at a very simple graph
here
and let's see that this one is the graph
0 1 2 3 so we have 4 nodes in our graph
and this is how they are connected with
the edges so now what we want is we want
the adjacency list representation and
what does adjacency list do is that for
each node the case of we have node 0
node 1 node 2 and node 3 ok so we have
these in a vector okay so we have them
like this so this is a vector where we
store all the nodes and we also have
what is known as a list for all these
nodes okay
so node 0 it is connected to node 1 2
okay so we will have here node 1 and
node 2 ok so these are the nodes that
are connected to node 0 then for node 1
we again see 0 and 2 are the nodes that
are connected to node 1 for node 2 we
see that node 0 node 1 and node 3 are
connected and for node 3 it's just
connected to node 2 so this is the
adjacency list representation and what
happens is that it saves storage for us
okay it saves memory and how because
each now if there are mod e number of
edges so all these nodes just we have
the list of nodes for each node which
are connected to it ok so this
is the basic idea but here the important
another important thing is how to
represent it in C++ so in C++ our most
important thing that we need to know is
that we have what we have set of nodes
okay our set of vertices and each
vertices each vertex is connected to a
set of other nodes through edges okay
and this is what we have to represent so
how we do that thing so we will use what
is known as so a vector we will use for
all the nodes we have vector where we
will store all the nodes but each node
now has a list so we have vector or a
list of int okay so this is what we will
have so if you see here so we have and
if there are n nodes okay so what it
becomes is that we have a vector of list
of nodes okay and which we will call it
adjacency list and what happens in the
vector you have each node okay and in
each node you have a list which tells
you that which other nodes it that
particular node is connected to so now
we will look at the C++ code that
implements this graph representation
using adjacency matrix so of course the
first most important thing here is so we
are using STL where we use vector and
list okay so these are the two
representations the data structures that
we use and the most important thing is
here so this piece of code so standard
vectors we have a vector of what the
vector is also upset basically indexed
set and in that what we have in each
vector item we have a list okay so we
have a list
of all the nodes it is connected to so
this is the basic idea and now what
happens let's see how we have done so we
have a simple graph here and what that
graph looks like is we have four nodes
okay so 0 1 2 &amp; 3 and let's see how are
they connected so we do because this is
a vector so it is like an array very
much similar to an array where we can
indexed items we can use to adjacency
list 0 that is the first node dot push
back 1 ok so now let's try to see this
thing so when we do adjacency list 0 dot
push back 1 it means that our graph is
basically 0 is connected to 1 so let us
first draw the graph then 1 is connected
to 2 and 0 2 is connected to 0 1 and 3
so this is our graph and now let's look
so this is an unweighted graph so and
what happens and undirected ok so here
what happens is this is adjacency list 0
means the node 0 and when we do dot push
backs of this item adjacent see list 0
this represents in list ok list and a
list for basically or you should remove
list for node 0 similarly adjacency list
1 is the list of nodes that are
connected to 1 so this is basically of
type standard list ok this is the type
of the adjacency list I now what happens
is so we have a if napi okay push
underscore
back where we just pushed the note
number which it is connected to so
adjacency list 0 dot push back 1
adjacency list 0 dot push back to so we
push in this creates for us now we have
here 1 &amp; 2 similarly what happens
adjacency list 1 so for node 1 the
vector and this is the list so we have 2
and 0 here for - we have a list 0 1 &amp; 3
so this is the list and for 3 we have
just got two so this is the your
adjacent see list and your graph is here
and this is how you create the graph
okay now the thing is we want to print
the graph okay how the nodes are
connected and so on and which is a
little bit complicated because of STL
that we are using and in fact STL makes
your life very simple because you don't
need to have your linked list maintain
your own linked list it's and resize
everything will be done by your vector
and list STL classes okay so this is the
part where we construct our graph now we
would look at how we Traverse so how we
will Traverse so let's see so for
traversing we have this piece of code
okay and let's try to see how it is done
so we have what we have one is vector so
if let's say I want to print for all the
vertices I want to print their neighbors
so first thing is I need a kind of for
loop which will iterate through all the
nodes so for all the nodes and a nested
for again for
each of its neighbor so print their name
so these are the two things that you
need to do so how we do so there is a
concept of iterator in C++ STL where
what happens when we want to I trait
through some STL class so if we have a
vector so we are making a vector I
traitor so you need to have the same
kind of hydrator through the type of
class you want to I take I trait through
so we have standard vector and that
vector is of what so it consists of
vector of standard list of ends so it's
I traitor by scope resolution I gave I
traitor I we have a see count is zero
initially we start so standard vector
standard list int i traitor i so i
traitor now it starts at adjacency list
dot begin and till it goes till
adjacency list dot end and i plus plus
happens okay so what happens it's just
like a for loop okay where i is equal to
0 to some maximum size so here we are
going because we don't know the size of
the the list or the vector so we keep on
iterating and this adjacency list dot
begins show me the beginning of the
vector and adjacency list dot n j--
shows me the end of the vector okay so i
is your eye traitor that is ight rating
through your vector of 0 1 2 3 those
objects so this is the vertical i
traitor i am going through
i but each time i also need to traverse
the list for each of the nodes ok so
this is again one i traitor so when i am
traversing here so this vector gives me
what inside the each vector object there
is a list of int okay and that list of
int vivant so what happens so we do
so in this a traitor I we will always
have a pointer to the list
okay so standard list of int okay so we
have in star I we get the list so let's
see so we have now the pointer to the
list for that particular vector item so
for standard list I traitor ITER Li dot
begin I traitor so now we are iterating
through this list using this for loop so
a standard list int so we have no I
traitor of type list of integers
it starts with Li dot begin so this is
the from here we take for this first
node what is the list I get from here
get the list for this node so we get it
here Li dot big ni traitor is not equal
to Li dot n plus plus ITER we do and we
what we do print the neighbors okay we
print which are the neighbors of this
particular node so what is has connected
to node C which is here and then we just
give one end line and C++ so that we are
printing the nodes okay which we are
traversing so this is the simple idea
where we are creating up for undirected
graph and with novated edges so this is
how we represent it using a vector of
list of int okay so the main thing is
how you implement this the concept of
adjacency list is simple but how you
implement using STL is a bit tricky and
I hope you understand this now so thanks
a lot
okay so one thing I forgot is that I
need to show you that it runs really
okay so that is important which I did
not do so let's try to see so vertices
connected to node 0 or 1 &amp; 2 vertices
connected to node 1 or 2 and 0 vertices
connected to node 2 are 0 1 &amp; 3 vertices
connected to node 3 are 2 just one node
that it is connected to so this brings
for us that how wonderfully in a compact
way we are representing a graph using
adjacency lists okay
so I hope you understand this thanks a
lot
hi in the first class we have learned
that how we can represent a sparse
matrix in three column form only and
second-world linked list form the first
three column form we have seen in the
first class of his past matrix where the
forecast for matrix is there and the C
programming there is indexing zero a
zero row and the zero one two three
column and we have represented in three
column form the first row in this three
column represent total row total column
and total nonzero values similarly when
we are going to represent linked list we
require three nodes and three nodes has
a different structure the first head
node has four places where first place
is total row second total column third
total nonzero values in that matrix and
last is a pointer that point the next
row similar to your previous after one
two three place one pointer is required
that could point next row okay next is
row node row node first is row number
next pointer for next row because in any
matrix you have to up a scanning all the
columns you have to move next row so
there is a one pointer that will put you
on next true and third is column node in
the column node first is column number
second the value that exists in that
column a next pointer for next value is
same room for example this is the matrix
in zero column value is four in the same
row two column value is 3 so we can we
require a node that could move right
side okay so let's take same example and
we are going to make its linked list
representation so for linked list
representation of this matrix
first head node this head node contains
four row four column and six nonzero
values okay next is pointer that will
point first row the first row is mean a
zero and its next pointer point next row
mean one
this next pointer point row two and it's
next point a point last Row Row three
now in each oath there would be a column
moment so for column moment this point
this is his own ode and column this will
go to the value is in first column so in
the first column value is two and is
there any another value in same row no
so it's last pointer is null now in Row
one this pointer points to in column
zero value is four then again it points
to next column where column value is 2
and value is three and the point there
is not any other value in the same rule
so it is none second row
- values are there so I have related to
loads the first in row 2 column 1 value
is 1 and it points to next column values
column number 3 column number is 3 value
is 1 and it does not point to next row
it is none in 3 the column node in
column 1 we got value - it is not point
any other value in non zero value in
same row so it is none so it is a linked
list representation of sparse matrix and
I have created linked list
representation for this matrix thank you
sighs welcome to this tutorial and this
video is about graphs and its
representation using edges in G lists
let's quickly have a look what a graph
is really is so graph is basically a
collection of nodes and edges between
those nodes so zero connects to one one
connects to two and three and four zero
connects to four fourth and X to 0 1 and
three graphs could be of two types one
is the undirected graph and one is the
director graph that undirected graph
basically means if one to two is the
neighbor then to the one is also enable
directed graphs on the other hand if one
to do is a neighbor two to one is not
enabled so if two to one had had been a
neighbor then there would have been an
arrow pointing from two to one now that
we know what a graph basically is we can
get to putting this in Eclipse we
quickly over hand create a new Java
project
let's call this graph wait for it to
build path let Kelso's create a new
class and we call this graph graph hsn.c
list pretty cool name big one though
okay first let's import java.util u2
tour so then we create a private
instance of a map at a list and list and
in teacher so this air LS it should be
array list it's provided was by Java dot
util and it lists and let's call this
adjacency list map
alright now we create the constructor
for this class it's called public graph
HSMC
list and it will take an input and
square this is so we give an input as
the number of vertices then we create
and a big off with those vertices and
edges and see list map is basically a
new hash map which will take input as an
integer and then add a list of type
integer so it should be captive I okay
then we say for the number of vertices
start the user input we create an empty
graph with it so and I equals 1 I less
than equal to the number of vertices I
plus plus we create an array list of
integers in teacher and let us call this
as neighbors this will be a new
ArrayList of integer
Edge's until s map is now we just put
four ayat element we put in the
neighbors so what we just did was for
supports a node zero we created an
ArrayList which will which we are
calling as neighbors so for zero there's
a list for one this list for two and so
on for the number of what it is that the
user input we have created an empty list
of neighbors now we basically need a
function to add n8 so let's call this
public void add edge and this will take
as input the voltage and the neighbors
that we want to add the neighboring word
is that we want to add first we check if
the world is start with input that the
user input is actually a part of the
nodes that we initially defined so
suppose our graph is for node 0 1 &amp; 2
but the user wants to access the node
say 7 so that is not in the range in the
scope and so we need to check that case
and W belongs is greater than adjacency
list list map node size then we simply
return so this should be W create a pan
ok and if that is not the case then we
use the inbuilt function it's in C list
map dot get B first get the word test V
and then we basically add W as its
neighbor we should put brackets over
here to make clear
we get the list but we get vertex we and
then we add W as its neighbor so this if
we add only this line that means that
graph we are talking about is an
undirected graph is a directed graph
sorry and if we add this line as well
adjacent c-list map dot get W and then
dot add we so now the graph we're
talking about becomes an undirected
graph so what we basically mean over
here is that we get V and add W of its
neighbor and then we get W and add V as
its neighbor okay
now we need to add neighbors as well so
we create a new function which we call
as let's call it get neighbors so this
function basically returns us the list
of neighbors to a particular node that
they input
okay so what seems to be there okay so
okay let's say let's again check our
base case which is if we is actually a
part of a cross
in this case we simply return a null as
we return an ArrayList of integer should
be capital I of individual which will be
agency list math dot get we so this
returns us the list of neighbors to the
vertex we all right now we write down
the main code public static void main
string argument let's create an integer
and count and get initiated to one and
then we need the source vertex and we
need a destination vertex then we can
create a line on that synthesis enter
the number of vertices and edges
and we use scanner to get the input and
we call some dot n then we create a new
variable let's call it number of
vertices number of vertices and we take
input from the user
next int then we take input as the
number of edges and we take input again
from the user extent okay now what we
need we create a new we need to enter
semicolon over here then we take we
create a new instance of the class graph
adjacency list it sealers and let's call
this adjacency list new graph hsn.c it
sends C in C list and the input will be
the number of vertices that we just took
input from the user seems fine till now
then we need the user to enter the edges
so like zero to one is an edge we need
the user to develop start so again we
tell the user one here we told a friend
in line
say enter edges in format source space
edge toast space destination alright now
we create a loop and we say while count
is less than equal to number of edges we
just simply take input source is scan
dot next int destination is scan dot mix
end and we add the edge edge SNC list
dot add edge between source and
destination and we done and now we just
increment count consciousness okay now
let's tell the user that the given
adjacency list for the graph and then
[Music]
let's give a line after this and then we
simply create an Impala we say int I
equals 1 I less than equal to the number
of vertices i plus plus system dot out
dot print print how do we print so
there's a node followed by the neighbors
so let's do it like this I and then you
say plus followed by an arrow this
should be double bracket okay now let's
say let's create an array list of type
which is integer let's call it edge list
jason see list dot should be a jason
seed yes so we're talking about this
edges in serious adjacency list or gate
neighbors so we created get neighbors
function over here now we're just using
it to get the list of neighbors and the
input to this will be our vertex I and
now we simply need to print this in J
equals 1 semicolon semicolon j + s we do
this ok now we say if J not equals edge
list dot size
then we output turns out dot print edge
list dot get J minus one plus again we
give an air over here else let's do this
system dot out dot print edge list H
list dot get J minus one and and then
break so this this statement is just to
take whether the node whether the
neighbor we are talking about it's the
last neighbor or it's an end with me
neighbor so if it's the last neighbor
then we simply do this if it's not the
last neighbor then we do this because we
want to keep like putting arrows after
each neighbor so let's just give this
space over here like this okay seems
pretty nice till now now just give a new
line over here system dot out dot print
line just to make it look up a little
better think we done over here we can
run this enter the number of vertices
and edges so number of vertices is say
four and edges are five five and of the
edges in format source and destination
so we say one
has an edge with to one has an edge with
three to as an edge with or with three
and let's say one is an edge with four
and one okay - as an edge with four
pretty cool so one as neighbors two
three and four to have neighbors one
three and four three has neighbors one
and two and four s neighbors one and two
seems to be working fine
in this presentation we are going to
look at using adjacency lists in graph
theory so let G be a simple graph at the
vertex set v1 v2 v3 v4 v5 so value for
five vertices and that is the adjacency
list there v1 is a neighbor of is
adjacent to v2 v3 v4 v2 is adjacent to
v1 v3 v4 v5 and so on what we have to do
here is answer the two following
questions first off list the degree
sequence of G so let's see that one
first so v1 is connected to three
vertices so three and v2 is connected to
four so there's four three three and one
so how do we write at the degree
sequence we write it out as follows for
in descending order there you have it
there and descending order at four three
three three and one so now let's look at
drawing the graph here so I'm going to
sort of set it up here as follows
so we have five vertices this is v1 v2
v3 v4 and v 5 and let's see how they
connect up to one another so v1 is
connected to v2 v3 and v4 so that
connects there there and down there v2
is connected to all of the other four
vertices so it's already connected to
one there so it's connected to be three
let's connect it to be five and it
connects to vie for v3 and v4 so we've
already connected to v1 and v2 so all
that remains is just connected to be
four down there just going to color the
vertices back in here plus a v4 is
connected to v1 v2 and v3 so we've
actually have taken care of all of those
already lastly v5 is connected to v2 and
again that has also been connected
already 2v2 so that there is the graph G
and that ends our presentation thank you
hey guys welcome to this video in this
video we are coding agency lists and
Python very quickly let's look at the
path that we want to plot so we got six
vertices 0 1 2 3 4 5 0 if connected to
neighbor as 1 &amp; 2 2 is connected to
neighbor 4 1 is connected to 2 &amp; 3 and
so on so we can actually use 2 ways to
implement this infighting so the first
way for list of list methods so what we
want to do is we want to create a list
let's call it edge until this and this
will basically be a list of list
so the 0th index will contain all the
neighbors of vertex 0 so we got 1 &amp; 2 1
&amp; 2 so we done we just implemented the
neighbors of vertex 0 now we want to put
in the neighbors of vertex 1 which are 2
&amp; 3 so we create another list we say 2 &amp;
3 and similarly the neighbor 4 3 which
is 4 neighbor 4 2 which is 4 then
neighbor 4 3 is 4 &amp; 5 and the neighbor 4
5 so this would be 5 and then we or non
point 5 so this will be an empty list
all right so we just specified what are
the neighbors of each vertex 1 &amp; 2 for
vertex 0 2 &amp; 3 for vertex 1 and so on
now we we just created the structure we
can simply loop through the structure
and print the neighbors of each so what
we'll say is we created on your variable
n which is basically the length of this
so edges until s and now we want to
implement a for loop and we say for we
end range the 0 to n 0 comma N and
now we just want a friend so friend and
this should be V space in and we want to
print and we should give a space between
this and then we say HSN seal is base we
actually let's do it do it like this so
this should be a space okay so let me
open the terminal and try to run this is
a item which is in say list or py okay
very neat
so one into neighbors of zero two and
three neighbors of one and so on so this
was a list of lists method the other
method that we want to use the
dictionary method so let me write down
dictionary okay so what we want to do is
a dictionary will basically cut there a
contain a pair of vertex and list so
great a dictionary let's call it agency
list for system is collected and
implemented as an empty dictionary now
we simply can insert the nodes so
adjacent village dip and for 0 we'd
specify the neighbors and this will
basically be a list so this would be 1 M
2 and similarly you can you can copy
this but we'll see we now we can go 1 2
3 4 4 5 so this will be an empty list
for has neighbors 5 3 has neighbor 4
comma 5 2 as neighbors for and this
court neighbor 20 okay so we just
specify the gradient structure we
specified what are the neighbors of each
four days and now we can again create a
loop like this so we copy this again and
we say for be in range at this time this
should be and let's create another
variable let's call it and two and this
should be length of edges and he left
stick and should be Co like this it
should be picked and pretty cool we can
try to run this so go over there again
run my code I should probably give a
line over here so let's just write this
print mm backslash in okay now we run
this
okay pretty cool we can see the code is
working fine we got neighbors for all
the six vertices so that's how we
implement adjacency list in Python or
using these two methods if you got any
queries you cannot ask me in the comment
section I'll be posting this code in the
description and if you liked the video
to it the like button and thanks for
watching
hello everyone so far in this series on
data structures we have talked about
some of the linear data structures like
array linked lists stack and queue in
all these structures data is arranged in
a linear or sequential manner so we can
call them linear data structures and
we've also talked about tree which is a
nonlinear data structure tree is a
hierarchical structure now as we
understand data structures are ways to
store and organize theta and for
different kinds of data we use different
kinds of data structures in this lesson
we are going to introduce you to another
nonlinear data structure and that has
got its application in a wide number of
scenarios in computer science it is used
to model and represent a variety of
systems and this data structure is graph
when we study data structures we often
first study them as mathematical or
logical models here also we will first
study graph as a mathematical or logical
model and we will go into implementation
details later okay so let's get started
a graph just like a tree is a collection
of objects or entities that we call
nodes or vertices connected to each
other through a set of edges but in a
tree connections are bound to be in a
certain way in a tree there are rules
dictating the connection among the nodes
in a tree with n nodes we must have
exactly n minus 1 edges one edge for
each parent-child relationship as we
know an edge in a tree is for a
parent-child relationship and all nodes
in a tree except the root node would
have a parent would have exactly one
parent and that's why if there are n
nodes there must be exactly n minus 1
edges in a tree all nodes must be
reachable from the root and there must
be exactly one possible path from root
to a node now in a graph there are no
rules dictating the connection among the
nodes a graph contains a set of nodes
and a set of edges and edges can be
connecting nodes in any possible way
tree is only a special
kind of graph now graph as a concept has
been studied extensively in mathematics
if you have taken a course on discrete
mathematics then you must be knowing
about crafts already in computer science
we basically study and implement the
same concept of graph from mathematics
the study of graphs is often referred to
as craft theory in pure mathematical
terms we can define graph something like
this a graph G is an ordered pair of a
set V of vertices and a set of edges now
I'm using some mathematical jargon here
an ordered pair is just a pair of
mathematical objects in which the order
of objects in the pair matters this is
how we write and represent an ordered
pair objects separated by comma put
within parentheses now because the order
here matters we can say that V is the
first object in the pair and E is the
second object an ordered pair a B is not
equal to B a unless a and B are equal in
our definition of graph here first
object in the pair must always be a set
of vertices and the second object must
be a set of edges that's why we are
calling the pair an ordered pair we also
have concept of an ordered pair an
unordered pair is simply a set of two
elements order is not important here we
write an unordered pair using curly
brackets or braces because the order is
not important here an ordered pair a B
is equal to B a it doesn't matter which
object is first and which object is
second okay coming back so a graph is an
ordered pair of a set of vertices and a
set of edges and G equal V E is a formal
mathematical notation that we use to
define a graph now I have a craft drawn
here in the write this graph has 8
vertices and 10 edges what I want to do
is I want to give some names to these
vertices because each node in a graph
must have some identification it can be
a name or it can be an
index I'm naming these vertices as V 1 V
2 V 3 V 4 V 5 and so on and this naming
is not indicative of any order there is
no first second and third node here I
could give any name to any node so my
set of what he sees here is this we have
eight elements in the set v1 v2 v3 v4 v5
v6 v7 and v8 so this is my set of
vertices for this graph now what's my
set of edges to answer this we first
need to know how to represent an edge an
edge is uniquely identified by its two
endpoints so we can just write the names
of the two endpoints of an edge as a
pair and it can be a representation for
the edge but edges can be of two types
we can have a directed edge in which
connection is one way or we can have an
undirected edge in which connection is
two way in this example graph that I'm
showing here edges are undirected but if
you remember the tree that I had shown
earlier then we have directed edges in
that free with this directed edge that
I'm showing you here we are saying that
there is a link or path from vertex u to
V but we cannot assume a path from V to
u this connection is one way for a
directed edge one of the endpoints would
be the origin and the other endpoint
would be the destination and we draw the
edge with an arrowhead pointing towards
the destination for our edge here origin
is U and destination is V a directed
edge can be represented as an ordered
pair first element in the pair can be
the origin and second element can be the
destination so with this directed edge
represented as ordered pair UV we have a
path from u to V if we want a path from
V to u we need to draw another directed
edge here with V as origin and u as
destination and this edge can be
represented as ordered pair V you
the upper one here is UV and the below
one is vu and they are not same
now if the edge is undirected the
connection is two-way an undirected edge
can be represented as an unordered pair
here because the edge is bi-directional
origin and destination are not fixed we
only need to know what two endpoints are
being connected by the edge so now that
we know how to represent edges we can
write the set of edges for this example
graph here we have an undirected edge
between v1 and v2 then we have one
between v1 and v3 and then we have v1 v4
this is really simple I'll just go ahead
and write all of them so this is my set
of edges typically in a graph all edges
would either be directed or undirected
it's possible for a graph to have both
directed and undirected edges but we are
not going to study such graphs we are
only going to study graphs in which all
edges would either be directed or
undirected a graph with all directed
edges is called a directed graph or
digraph and a graph with all undirected
edges is called an undirected graph
there is no special name for an
undirected graph usually if the graph is
directed we explicitly say that it's a
directed graph or digraph so these are
two types of graph directed graph or
digraph in which edges are
unidirectional or ordered pairs and
undirected graph in which edges are
bi-directional or unordered pairs now
many real-world systems and problems can
be modeled using a graph graphs can be
used to represent any collection of
objects having some kind of pairwise
relationship let's have a look at some
of the interesting examples a social
network like Facebook can be represented
as an undirected graph a user would be a
node in the graph and if two users are
French there would be an edge connecting
them a real social network would have
millions and billions of nodes I can
show only few in my diagram here because
I am short of space
now social network is an undirected
graph because friendship is a mutual
relationship if I am your friend you are
my friend too so connections have to be
two-way now once a system is modeled as
a graph a lot of problems can easily be
solved by applying standard algorithms
in graph theory like here in this social
network let's say we want to do
something like suggest friends to a user
let's say we want to suggest some
connections to Rama one possible
approach to do so can be suggesting
friends of friends who are not connected
already Rama has three friends Ella Bob
and Katie and Friends of these three
that are not connected to Rama already
can be suggested there is no friend of
Allah which is not connected to Rama
already Bob however has three friends
storm Sam and Lea that are not friends
with Rama so they can be suggested and
Katie has two friends Lee and Swati that
are not connected to Rama we have
counted Li already so in all we can
suggest these four users to Rama
now even though we described this
problem in context of a social network
this is a standard crafts problem the
problem here in pure graph terms is
finding all nodes having length of
shortest path from a given node equal to
two standard algorithms can be applied
to solve this problem we'll talk about
concepts like path in a graph in some
time for now just know that the problem
that we just described in context of a
social network is a standard crafts
problem okay so a social network like
Facebook is an undirected graph now
let's have a look at another example
interlinked web pages on the internet or
the world wide web can be represented as
a directed graph of web page that would
have a unique address or URL would be a
node in the graph and we can have a
directed edge if a page contains link to
another page now once again there are
billions of pages on the web but I can
show only few here the edges in this
graph are directed because
relationship is not mutual this time if
page a has a link to page B then it's
not necessary that page B will also have
a link to page a let's say one of the
pages on my code school comm has a
tutorial on craft and on this page I
have put a link to Wikipedia article on
graph let's assume that in this example
graph that I'm showing you here page B
is my my code school tutorial on graph
with this address or URL my code school
comm / videos / graph and let's say page
Q is the Wikipedia article on graph with
this URL wikipedia.org
/ wiki / graph now on my page that is
page P I have put a link to Wikipedia
page and graph if you are on page P you
can click on this link and go to page Q
but wikipedia has not reciprocated to my
favor by putting a link back to my page
so if you are on page Q you cannot click
on a link and come to page P connection
here is one way and that's why we have
drawn a directed edge here okay now once
again if we are able to represent web as
a directed graph we can apply standard
graph theory algorithms to solve
problems and perform tasks one of the
tasks that search engines like Google
perform very regularly is web crawling
search engines use a program called web
crawler that systematically browses the
worldwide web to collect and store data
about web pages search engines can then
use this data to provide quick and
accurate results against search queries
now even though in this context we are
using a nice and heavy term like web
crawling web crawling is basically draft
traversal or in simpler words act of
visiting all nodes in a graph and no
prizes for guessing that there are
standard algorithms for craft traversal
and we'll be studying graph traversal
algorithms in later lessons okay now the
next thing that I want to talk about is
concept of a weighted graph sometimes in
a graph all connections cannot be
treated as equal some connections can be
preferable to others like for example we
can represent intercity through a
network that is the network of highways
and freeways between cities as an
undirected graph I am assuming that all
highways would be bi-directional
intra-city road network that is road
network within a city would definitely
have one-way roads and so intra-city
road network must be represented as a
directed graph but intercity road
network in my opinion can be represented
as an undirected graph now clearly we
cannot treat all connections as equal
here roads would be of different lengths
and to perform a lot of tasks to solve a
lot of problems we need to take lengths
of roads into account in such cases we
associate some weight or cost with every
edge we label the edges with their
weights in this case weight can be
lengths off the roads so what I'll do
here is I'll just label these edges with
some values for their length and let's
say these values are in kilometers and
now edges in this graph are weighted and
this graph can be called a weighted
graph let's say in this graph we want to
pick the best route from City a to city
D have a look at these 4 possible routes
I'm showing them in different colors now
if I would treat all edges as equal then
I would say that the green route through
B and C and the red route through E and
F are equally good both these paths have
3 edges and this yellow route through E
is the best because we have only two
edges in this path but with different
weights assigned to the connections I
need to add up weights of edges in a
path to calculate total cost when I'm
taking weight into account
shortest route is through B and C
connections have different weights and
this is really important here in this
graph actually we can look at all the
graphs as weighted graphs and unweighted
graph can basically be seen as a
weighted graph in which weight of all
the edges is same and typically we
assume the weight as 1
okay so we have represented inter-cities
road network as a weighted undirected
graph social network was an unweighted
undirected graph and World Wide Web was
an unweighted directed graph and this
one is a weighted undirected graph now
this was anticipated what I think
intra-city road network that is road
network within a city can be modeled as
a weighted directed graph because in a
city there would be some one-ways
intersections in intra-city road network
would be nodes and Road segments would
be our edges and by the way we can also
draw an undirected graph as directed
it's just that for each undirected edge
we'll have two directed edges we may not
be able to redraw our directed graph as
undirected but we can always redraw an
undirected graph as directed okay I'll
stop here now this much is good for an
introductory lesson in next lesson we
will talk about some more properties of
graph this is it for this lesson thanks
for watching
all right in this video I just want to
talk a little bit about some graph
theory and just some basic terminology
and ideas they get used so definitely
not going to be a you know a complete
version of everything you need to know
but definitely some basic ideas so graph
theory got started by really kind of I
think really came about by Leonardo and
what he did is he solved a problem the
famous bridge of coningsburgh problem
and that kind of a put graph theory sort
of out there for people to start
thinking about and for a while graph
theories kind of kind of poo-pooed on it
was kind of considered I think sort of a
recreational branch of math not really a
ton of uses but uh definitely with the
advent here of computer science that's
changed all that graph theory gets used
all the time in computer science lots of
other places as well
definitely become a very hot area to
research and I like it just because the
problems are easy to understand you can
draw pictures and visualize I definitely
enjoy it but let's see so the definition
of a graph that we're going to use and
these vary again from person to person
things still aren't really set in stone
a lot of the notation and definitions
but for us a graph is going to be a
non-empty finite set of vertices some
people will let it be infinite with a
set of two elements subsets of V we call
the elements of V vertices and the
elements of a are called edges so that
sounds may be a little more confusing
that it is all a graph is it's just dots
and lines connecting that's all a graph
is okay so we talked about graph theory
we're not talking about y equals x
squared
just just points and lines connecting
them so we would say the vertex set V
for this
graphs maybe we'll call it G are just v1
v2 v3 v4 v5 and v6 and you can think
really you know maybe these are just six
people at a party and v1 knows v2 v3 v4
you can see that v5 only knows person v4
and v6 maybe that's what an edge
represents is if they know each other
okay you know and you can make the edges
represent whatever you want to so maybe
we'll just think about the edges as
meaning there's a connection between
them and they know each other so the
edge set that's just going to be all two
elements subsets and basically we just
list all the vertices that have an edge
between them so v1 and v2 v1 and v3 v1
and v4
let's see v4 is connected to V 5 and
then vertex V 5 is connected to V 6 and
I think that's everything we need you
know we don't need to list V 6 is
connected to V 5 for example it's just
redundant already so if I had you know
again basically just this set in this
set e again it's just basically telling
me all the information in this original
graph so I still know that a couple
things the cardinality the cardinality
of a graph just represents the number of
vertices
the notation I've seen is they'll put an
absolute value so the absolute value of
G the cardinality of G is just the
number of vertices which in this case is
six
let's see another thing that we often
talk about is the degree of a vertex so
for example the degree of vertex v1
which will abbreviate little deg v1 all
that tells you is the number of edges
coming out from vertex v1 so there's one
two three edges leaving v1 so we would
say the degree of vertex v1 is three
again so vertex v1 knows three other
people is all that says another kind of
convention for a typical graph we don't
let a vertex have a loop back to itself
okay I mean definitely that certainly
happens in a lot of applications but
when we lao graphs to have loops back to
themselves typically people will call
those multi graphs so multi grass have
loops regular graphs don't have loops so
pretend that loops not there and we just
got the original the original matrix
that we are the original graph we
started with a couple other things to
the way that you draw the graph is
irrelevant
so here's V one here's V two here's V
three here's V 4 V 5 down there I want
to make it too crazy v 6 you know they
don't have to be straight lines they can
be whatever they want so okay so V 1 is
still connected to V 2 V 1 should still
be connected to V 3 V 1 is still
connected to V 4
we'll have v4 still connected to v5 and
hey v5 is still connected to vertex v6
so all the original connections are
still preserved and there's sort of no
new connections in there that weren't
there before
so when you have a graph where basically
all the original information is
preserved the original connections
there's no new connections there's
nothing missing and again this is very
kind of loose definition but we would
say that the original graph and this new
graph are isomorphic and all that means
is from a graph theory point of view
they're one in the same they're exactly
the same graph okay so typically tribuna
will try to draw them as a you know in
the least confusing manner as possible
but definitely an important idea the way
that you draw the graph in general
doesn't matter let's talk about a couple
other ideas just a way to describe a
graph one way is with what's called an
adjacency list and I don't know how
useful these are I never really saw them
much but again I didn't take a
tremendous amount of graph theory so
that doesn't mean that they don't get
used all the time and I just haven't ran
into it but all an adjacency list is
exactly what you think so all we do is
just list vertex that our vertices that
are adjacent so for v1 it's adjacent to
v1
excuse me fee one's adjacent to v2 v3
and v4
so we'll list those v2 v3 v4 vertex V 2
is only adjacent to v1 v3 is only
connected to v1 v4 is connected to V 1
and V 5
v5 is connected to v4 and v6 and v6 is
connected to v5 and again it's just
another way of summarizing you know so
this is Jason C list this set V in the
set E and this graph again are telling
me all the exact same information
another way that I know gets used all
the time is instead of doing an
adjacency list we'll make what's called
an adjacency matrix okay so I'm going to
imagine v1 v2 v3 typically people won't
even write these but you know this is
what makes sense to me so a lot of times
I used to always stick them in there v1
v2 v3 v4 v5 v6 all we do is if there's a
loop if there's a connection from a
vertex to another vertex we'll put a 1
and if there's not we'll put a 0 so
since there's not a loop from v1 to v1
we'll put a 0 there but v1 is connected
to v2 v3 and v4 so V once connected to
v2 v3 and v4 but it's not connected to
v5 or v6 there's not an edge present
likewise v2 is only connected to v1 so
we'll put a 1 there and then we'll put
zeros everywhere else
let's see v3 is also only connected to V
ones we'll put a 1 there and zeros
everywhere else v4 is connected to v1
and also to v5 so we'll put ones there
zeros everywhere else v5 is connected to
v4 and v6 so put ones there zeroes
everywhere else
lastly v6 is only connected to v5 so
we'll put a one there
and zeros everywhere else so this is
nice because you can do math of major
Z's ok so definitely there's a lot of
study done with you know matrix
representations of graphs you can do
stuff with them two less things just
maybe two last ideas notice for any
vertex here if you you know so imagine
maybe these are islands now and there's
a little bridge connecting the islands
notice in this this graph if you ever
were to leave an island suppose I was at
Island v1 and I went to Island v4 the
only way I can get back to Island v1 is
the sort of backtrack you know I could
go all the way to v5 and v6 but
eventually to get back I have to take
you know the bridges back so there's no
loops or what are called circuits if
there are no loops or circuits we say
that this is an example of a what's
called a tree and the idea with trees is
you can always sort of rewrite them and
the reason why we call them trees is we
sort of can rewrite them you know so
here's v1 it's connected to V 2 V 3 V 4
V 4 is connected to V 5 and V five is
connected to V 6 so again these would be
isomorphic graphs but now it's kind of
if you flip it over and maybe it had
some more branches the idea that starts
to look like a tree trees get used all
the time for example you know imagine a
chess algorithm you know it's the first
move you know maybe you've got one two
three reasonable reasonable moves that
you're disposable at your disposal not
disposable at your disposal
you know and then maybe you know once
you consider this move maybe there's
only one logical move from that and then
from that there's only one logical move
so trees can help sort of represent sort
of searches you know a computer search
so definitely one place I know for sure
that they get studied again if a graph
so maybe this is a whole separate little
graph over here this graph we would say
has a circuit and the idea is a circuit
you know for example if I met this
vertex I can leave that vertex and still
manage to get back to it without really
ever backtracking through through an
edge or a vertice I don't have to visit
the same place twice as all it says ok
so this would be an example of a graph
that does have a circuit so graph theory
I think is really interesting you know
there's tons of open problems if you're
a budding math person out there and what
some challenging problems
there's definitely tons of open graph
theory problems that are very simple to
understand you know definitely you've
got to learn some of the techniques to
be able to attack things but a lot of it
is very sort of intuitive and I think
open you know sort of it's very user
friendly because what I'm trying to say
there's still some reasonable open
problems out there for people to tackle
for sure so if you are interested in
kind of getting your hands wet and doing
some harder problems
I say graph theory is a great place to
start maybe I can even post some open
questions so all right I hope this
little introduction makes some sense you
get nothing too heavy I definitely plan
on doing some more you know detailed
stuff but again hopefully this is a good
little warm-up and just a good little
intro to some of the ideas
alright so again good afternoon and
welcome to the second part of the second
mini course which will focus on
introduction of subspace segmentation
problem first I'm going to state what
the problem is I'm going to spend a
little bit time on providing a
mathematical proof that motion
segmentation problem is is actually a
special case of subspace segmentation
problem tomorrow you can expect that
some of the presenters will provide
experimental results on the air on a
data set that they come under the title
for face recognition or for motion
segmentation so so you can get a head
start with the tomorrow's presentation
with this after them going to talk about
principal component analysis principal
component analysis is used to reduce
dimensionality of data set for example
instead of working even very high
dimension data set first you can project
your data in a lower dimensional space
and then you can do all the analysis in
the moment fashion space I'm going to
show that with principal component
analysis we do nothing but least square
estimation on least square approximation
of a subspace so and I'm going to try to
link it to the singular value
decomposition analysis attack the bar
just presented and then I hope it will
be linked to the use of single well so
I'm going to provide another route
instead of just single decomposition I
will try to explain it to another
approach which uses the covariance
matrix of your denim attics so that's
also an approach as I said spec to the
class right like magic it works so it is
a very modern a clustering technique
that some of the presenters tomorrow
will be using I'm expecting so here in
many engineering and in many engineering
science and mathematics problems actual
data leaves the union of low-dimensional
subspaces I'm expecting that you know
what union of subspace means now from
the first part so for example face face
facial expression recognition
problem we can't consider so to get
those faces we have six phases of the
same person right and the same person
the same facial expression under
different illumination conditions of
different lighting conditions we can
show that all of those six phases
actually lies in a multinational
subspace approximately lies in a non
dimensional subspace of a very high
dimensional space another example will
be motion segmentation I'm not talking
about it as well most of the actually
this area of future subspace clustering
has attracted a lot of interest from
computer science mathematics and
engineering and most of the notable
research has been done in recent years
so this is a very finely ailea
especially if you're a PhD she looking
for a dissertation I can tell you that
this is a very fun area to work with and
as this as other possible dissertation
area here is the face you can issue
problem assume that we have this image
one face of a person assume that is like
25-30 pizza that means that are like 600
pixels here let's say in other words we
can take the first image the first phase
and you can convert it to x 600 x 1
vector right assume that this vector is
used to represent that image similarly
the second leg to represent the second
phase third fourth fifth and sixth so
that means each phase is nothing but a
data point in a 600 dimensional space
right in our six hundred and we can
experimentally show that those vector
goes data point six data points
approximately lie in a mind dimensional
subspace of our 600 so those fake legs
are face a face recognition problem is
nothing but in this I mean I'm kind of
exaggerating things but it is kind of
you know finding this for my
international subspace out of our 600
right
so that's the subspace segmentation from
so what is our problem here is the
problem we have assume that getting our
three we have a bunch of data points the
special thing about this is that those
data points are not random data points
some of them for example here comes from
what a two dimensional subspace of our
three some of them comes from one
dimensional subspace of our three
another view look at this be a bunch of
data and we our data lives in our three
that means all the data points are in
our three but some of those data points
come from a plane which is what two
dimensional subspace of our three some
of those data points comes from a line
which is what the national subspace of
our three and some of them comes from
another line which is also another one
dimensional subspace of what are three
in fact those all of those data points
comes from union of s1 s2 s3 isn't it so
the problem becomes what the problem is
given data so basically in this case we
have data points that comes from reading
of three subspaces so that's all what we
know we don't know those subspaces what
all we know is that we have data points
somehow they comes from reading of three
substrate greening of subspaces what are
the possible problems that we need to
solve first pletely determine how many
subspaces right so subspace clustering
problem deals with given the data points
without knowing anything about subspaces
all you know is that they come from enid
of certain subspaces the first thing
that you need to answer is what are the
number of subspaces have a sub spaces
that we have second problem is how do we
determine each sub space and dirt after
we determine the subspaces how do we
cluster the data for example all those
data points come from the same subspace
how I
Master them how could I say that these
are the data point that comes from the
same subspace how do I say that these
are the other data points that comes
from the same subspace and and these are
the other data pointers confirm so
subspace class in problem you are giving
it data set that comes from you know
subspaces that's all what you know then
you try to determine the number of
subspaces and then you try to determine
what those sub spaces are and then you
want to go back and cluster the data
points or group the data points that
blown to the same subspace that clear so
here is a little bit more formal
definition or the statement of the
problem here is the data set we are
giving a data set that's it we are
giving all the data set what we know
about this data set is that they are
drawn from a union of subspaces so here
a bunch of data points all you know is
they are coming from a union of certain
subspace then we don't know low
subspaces so our problem is to find a
model for this Union and then use that
model go back and classify our data into
clusters that is subspace segmentation
problem and here is more mathematical
definition and it uses Hilbert and
Banach space concepts let me discuss in
the first part so what we have is assume
that we are in a panic or hilbert space
be ok so we are dealing with a bonnet or
Hilbert space V and we have added
subspaces of this Banach space b or
hilbert space v
okay so what the assume is we are
working on my next space or invest base
B and we have end sub spaces of this
Banach space and a suit that we are
given and data points w1 w2 all the way
to WF n we are given n data points and
all what we know is that those data
points are drawn from union of and union
off some subspaces so the problem is how
do we determine the number of subspace
then how do we determine its subspace
determining a subspace means finding an
orthonormal basis for the subspace and
then once we determine the subspaces how
do we group the data points that loan to
the same subspace into the same cluster
so that is more formal definition of or
statement of the problem so what we have
we have different approaches to solve
this problem first of all is the problem
clear I want to make sure that the
problem is clear to do to the audience
are there any questions about the
problem yes what kind of conditions do
we have they guarantee that this should
cost during the subspaces as a
to something that maybe doesn't include
zero like some some plane that's away
from the origin Oh approach is that I
mean it depends on the approach right i
mean the data the assumption is that
your data comes from union of subspaces
of course that will be noise for example
your data is going to deviate from that
subspace so algorithms that are down
below should be handled the noise or
there will be some hardliners for
example certain points will go really
far far away from what from your
subspace but the algorithms should be
also able to take care of those kind of
cases so so it transform algorithm to
taking care but there are certain cases
I mean the day that will be so deviated
from a subspace it is no longer subspace
clustering problem so then you can
assume the data leaves knit one big
springs and then you can for examples
pca and things like that for like a
general class and problem is that answer
to a question okay so some of the
approaches that i categorize them as
like sparsely methods this is very
recent and tomorrow we will have dr.
Renee doll he is going to our first
keynote speaker he's going to talk about
sparse than algebraic methods so the
first keynote speaker will give and
overly off and actually that a doctor in
every now is the is work on something
called generalized principal component
analysis which is algebraic technique
and I am assuming that he's going to
talk about it and also recently we have
recent techniques like more rank
approximations who have to dr. V Donnell
and also we're going to have another
presented from China he's going to talk
about more rank approximations for some
space cluster then we will have
iterative and statistical methods actual
our second keynote speaker tomorrow
background really is going to mainly
talk about those methods that's what I'm
assuming and there are of course other
methods and the invited speakers I'm
expecting that they're going to provide
different views of different approaches
so by the end of tomorrow I expect that
you understand what subspace clustering
problem is and you know what is the
state of the art
in subspace clustering okay so first I'm
going to now introduce or provide
mathematical proof that motion
segmentation is a subspace segmentation
problem by motion segmentation what I
mean is motion segmentation problem is
identifying independently moving rigid
objects in the video so we are giving a
video file what's the video one everyday
file is nothing but bunch of frames they
can consequently right for example you
may have like hundreds frames altogether
if you play them back to back you have a
video right so in suit that we have two
cars this is our first frame and we have
two cars and in each car we have some
feature points when I say featured forms
it may be very clear to some computer
scientist it may not be clear to
mathematicians but pigeon point is
nothing but for example a corner might
be a featured point on the car okay
maybe the door might be featured point
on the car assume that there are certain
feature points that we can extract on
those rigid bodies okay now this is
second frame third frame for frame so
watch the segmentation simply deals with
determining the number of rigid objects
in a video file number of moving rigid
objects on a video file okay so that's
what you're going to show hmm I had some
animations here but I think it's messed
up so here is the car when I say for
example I have four feature points on
the car right look at this this x1 y1
one means x and y assume that the camera
is really far far away from the car so
it seemed that you know we are looking
from the sky or from really far away so
everything is in 2d so now x1 y1 what
means the coordinates x and y
coordinates of the first feature point
in frame number 1 x 2 y 2 11 means the x
and y coordinates of the second feature
point in frame 1 similarly the x and y
coordinates of the fourth feature point
in friend number one ranked number two
car moved here so this feature point
move from here to here right so this x1
y1 two names XM white fulness of the
first feature point in frame 2 similarly
x and y coordinates of the fourth
feature point in frame too and we move a
lot and then assume that we have f
frames like 200 frames on f frames and
this feature point move from here here
all the way here x1 y1 f means x and y
coordinates of the future point one in
frame f that clear so these are the just
representation of the coordinates so
what does this vector representing x 1 y
1 1 x1 y1 to all the way x1 y1 f I want
an answer from the audience what does
this vector represents if they presented
trajectory exactly so basically it
represents the trajectory of what first
featured point or a pact right so this
is nothing but the pad or trajectory of
the first feature point across all the
frames and similarly what does this
represent this represents the trajectory
of the second future point across all
what frames and we have dots right so
what am I going to show what I'm going
to show is that do you see the dimension
of this vector what is the dimension of
this vector or where does it leave it
leaves in r2f right because we have x1
y1 x and we have x1 y1 f x that means
this data is actually this is one data
point in our to F what we are going to
show that all the treasure
therese of the old featured points on
the same rigid body why in a four
dimensional subspace of r2f so instead
of three clustering on our 2f i am going
to determine those four dimensional sub
spaces so all the future points in the
first car are going to lie in a 14
dimensional subspace and all the
features on the other car or the
trajectories of the futures on the
second car rely on another four
dimensional subspace so motion
segmentation problem became what a
subspace segmentation fault is it clear
so now I'm going to show really this is
the case and I'm going to show is since
it is very difficult to write I will go
little with some animations but you can
stop me and ask me questions if they are
not if the sort of the points are not
clear so assume that we have a frame
which is called world Frank capital z
capital X captain why this is the world
frame wall frame is what that is the
frame that does not change that's our
reference point ok so we start with a
word frame anything is going to be with
respect to what this won't bring any
motion will be with respect to what this
more prey ok initially it shouldn't be a
car car and this is we have work frame
and you have an object frame but object
frame will change as the car moves
object frame moves with the car but the
world's rain stays stupid right so we
have to coordinate systems warframe that
doesn't change and the object frame
that's going to be moving with the car
and assume that this is once featured
point on the car and also assume that
little are one little are two little are
three are the basis vectors for this
world frame
now what happens if the car rotates
can't rotates does the world frame
change no world frames stay still but as
you see the object frame X little lower
case explore caves in lower case Y just
rotated right so this is basically what
happened to our car p is p was here now
it moved there now my question is this
with respect to object frame with let's
take the object frame does or does the
coordinate or do the coordinates of this
feature point does that do they change
as the object rotates for example this
point p with respect object frame and
the car rotated the speed they speak the
object frame does it change how many of
you say changes
right how's my change so the P that the
point p which they expect Arctic frame
does might change it is still for
example here it was this much distance
from object frame it is still the same
distance from the object well this is
our three because this much distance
from our three it's still the same
distance so it is the view of it so I
just moved it here let's look at this
let's forget the point P let's consider
just this point what is the coordinates
of this point with respect to object
frame the coordinates of this point with
respect the object frame will be 100 do
you agree with them but the coordinates
of this point with respect the world
frame will be one simply are one isn't
it the coordinates of this point with
respect object frame is what 011 but
with respect the world frame it is what
are 2 similarly the coordinates of this
point with respect to out geek frame
will be 001 but with less take the world
frame is what are 3 will agree with that
then what can I say about this point
this point let's say with respect the
optic frame let's say it is a be a be be
PCP and with respect the world frame it
is nothing but AP times r1 plus B P
times r2 plus CP times r3 we agree with
them okay so p0 a be a PvP CP is the
coordinates of this point with respect
to object frame and pw is the
coordinates of this point with respect
the world frame ok that is physically
what it is
so what can I do can I rewrite this as a
matrix whose columns are r1 r2 r3 and
point p dot p 0 which is this vector
this statement is equivalent to this
right and if you look at this matrix it
is nothing but a rotation matrix so i
can say corn is so filled with respect
the work frame is a rotated version of
the coordinates of the point with
respect object ring ok I want to give
you like 10 seconds so because I'm gonna
build on this
alright
so this slide simply says what I
explained I'm just going to skip it but
whenever you have time after we put on
the internet you can you know read it
and then it's exactly what I am saying
now it soon that the optic does not only
rotate but it also translate so what
happens to coordinate of this point P
betrays take the world ring before
translation it was just rotation it was
rotation of the point into aspect object
frame right now we will all say what a
translational turn so P with respect the
world frame is a rotation matrix times P
with respect the object frame plus TW TW
is the coordinate of the center of the
object with respect one world frame
thank you to
now assume that we have you know an
image plane that's the camera plane what
does it means is that your camera is
really far far far far away and the
optical zoom of the you know the the
axis of your camera is your z-axis okay
and see this is X this is y this is e
your camera exit is also in this
connection assume that the this is
Freight number K so we have one two
three four javiel in frame number K and
in Frank number k I had a future point p
0 p 0 is the cord ends of this pigeon
point with respect the object frame
which is a be vp hcv right this never
changes this coordinate never changes
when i go to for example later the
second frame this coordinate will be
still the same because the coordinates
with respect object frame of a feature
point does not change from one frame to
another one only with respect the world
frame changes ok so r 1 r 2 r 3 k are
the basis vectors for the object frame
in frame number k so what i am doing is
I am going to project because when I
take an image with a camera what happens
I just project that feature point on the
image exit right or image plane and here
is the projection of this point in the
image plane let's call it XP YP chain
that means x and y coordinates of the
future point p in frame number check
okay
and of course this is pw t w that means
the coordinates of future point P with
respect to work frame for frame number
what okay okay so let's check this do we
know that pw k is equal to a rotation
matrix p 0 plus a translational vector
so this is what you know right and and
the coordinates of this sky this point
with respect the world frame will have
actually three components XYZ right that
means X Y Z with respect the word frame
is nothing but this matrix multiplied by
this and then then another vector x y&amp;z
coordinates of what the the center of
the object frame the right but since we
assume that the camera axis is in line
with the z-axis I am NOT interested in
the Z component so I only considered x
and y coordinates in other words instead
of having a three-dimensional are one I
truncate the last element of our one and
I obtain r 1 tilde so r 1 tilde is the
same as our one just you know you
truncate the third element of our one
okay so basically XP YP k is nothing but
x and y coordinates of this feature
point p with respect to work print that
clear okay good so here's the first
thing now in this this was frame k now
i'm in frame k plus 1 whatever sin frame
k plus 1 does the coordinates of this
widget point p with respect to object
frame does it change it does not right
with respect object frame it was ABC it
is still ABC but what happened to do to
to to r 1 r 2 r
we have different basis vectors ok
because object rotates and when I
project this feature point to the image
plane now I have XP YP I say k plus 1
that means x and y coordinates of this
Richard point with respect the wall
frame in frame number k plus 1 similarly
now the future point is here I project
it and I have that so what does tragic
that of features point means on the
image plane isn't it just this one right
for example the object was here now the
object is here mount objects in here
when I say that rejected off a future
point on the image plane it is nothing
but you know linking those points
together so now here is my data matrix
for motion segmentation let's forget
this what is the first column first
column it is is the trajectory of the
first feature point across all the
frames x and y coordinates of the first
feature point in the first frame all the
way x and y coordinate so first feature
poet in frame number left for example
this one x and y coordinates of the
feature number s in your first frame and
the same thing x and y course of future
as in what frame number n so each column
is nothing but trajectory of one feature
point for example if this is our car we
have n feature points and the track all
those and future points across how many
frames f frames is it clear so far ok
now let's take this trajectory ok let's
take this trajectory let's go back to
this we know that XP YP k is a b c and
linear combinations of our 1 tilde are 2
tilde are three tilde and then what t
tilde that right and we know that a
bc they do not change for the same
feature point all right now let's go
back to that here consider this this
feature point x and y-coordinate of the
future point as in frame number one will
be a as x this BS times this CS times
only the first two and then this first
two similarly if i say x s ys in frame
number two the coefficients a b c they
don't change the only thing that changes
is the vectors are 1 tilde instead of r
1 tilde r 2 tilde are three days i will
have different r1 r2 and r3 basically
trajectory as can be written linear
combination of one two three and four
vectors so what does it mean it means
that that trajectory has is little
linear combination of three vectors and
if i take another feature point another
feature point for example i take this
feature point this will be this field is
also linear combination of what leave
another linear combination of the same
basis vectors instead of asp SCSI will
have a2 b2 c2 for example right but the
feature vectors i'm sorry the basis
vectors will be the same for all the
future points that are coming from the
same rigid object in other words all the
trajectories that belong to the featured
points or the same rigid body leaves the
four dimensional subspace of our to
death because we can represent each
trajectory as linear combination of four
vectors in our freedom is it clear
yes so for this you knew before you
started this analysis that you had full
essentially four dimensions that you're
going to be actually we didn't I mean
the first mathematical proof that was
provided they they derive this so they
didn't know but they mathematically dry
they mathematically proved that you know
that it comes from four dimensional
subspace so I start with no assumption
that it comes from four dimensions of
space I don't have that assumption but
finally I have that conclusion yes
well that's a good question in this in
this in this analysis we assume that we
can track all the future points in every
frame okay let's say that there are
certain future points that you can laugh
track okay they are called missing data
points for example some of those
mattresses let's say this your data
metrics right according to what you are
saying sometimes you may not have
certain entries you may not know so
subspace clustering algorithm some
algorithms can deal with that they can
say hey I have missing data points but I
can still go subspace cluster sometimes
we may have outliers that means while I
was taking one feature points from one
frame to another one I did something
wrong and instead of get real
coordinates I did a mistake and now that
feature present a off then let's go out
like and in that case against subspace
clustering algorithm should be able to
handle those cases or sometimes due to
measurement error instead of real XY
coordinates I may have an order and in
that case this will be noisy matrix and
that should be still there via Twitter
on subspace class about it and why am i
right back a little be an expert sir
okay yes
to me
too many frames okay exactly this
doesn't matter the number of frames as
long as you can track the same feature
across all the frames it doesn't matter
but of course if you have too many
frames one feature will not exist in you
know so the assumption is all the future
points or a future point can be tracked
across all those frames yes provided
that you're viewing for instance house
I'll go to distinguish between having
like glossy multiple cars having the
same physical features movement
altogether so so it does not matter you
have multiple cars but that's the
feature extraction and feature tracking
is a different problem so we assume that
we don't have that problem so we assume
that we can detect features and we can
track the features across the frames
that's our assumption but otherwise
that's another computer vision problem
which has nothing to do itself is
clustering for example there are things
like corner Morse measures so that's a
good feature to track but our assumption
is these are given to you you have the
features and you can track them
any other questions yes all the features
are off same man all the features are of
the same length actually it makes a not
much sense in this context because all
the interest is the coordinates of the
future points I have XYZ coordinates of
the switching point here and now the
switcher point is here in this other XYZ
coordinates if I may say the lengths i
know all the pictures it may be like an
early or finally on the plane so
featured points1 feature point exists
across all frames and somehow you can
track this feature point from one frame
to another frame in terms of coordinates
of the future point yes
don't think about the perspective
formation prospective information so
deformation camera lens well in this
assumption we have a fine projection
model in other words camera is really
far far away so and yeah that we have
that assumption thank youuu okay look i
hope this problem is clear because in
the talks tomorrow they may not have
time to go in this death to the
description of the problem okay so now
i'm going to jump to another important
topic principal component analysis iming
of you have used pca before okay yeah so
PCA is is a very fundamental tool that
you know is commonly using data
clustering so the goal of PCA is to
reduce dimension of a data set with
minimal loss of information so you are
in a very high dimension space but you
don't want to work in that hydrogen
because of computational complex these
or you know the the cost of computation
and for many reasons you want are going
to load the management space but you
don't want to lose a lot of information
when you project your data from a
high-dimensional space tail or domestic
venues for example if two points we are
separated in high dimension you still
want them to be separated in the lower
dimension you don't want to lose that
information use the phone information so
basically you go from high dimensional
space to elude the national space
without losing much push I don't do
something but you don't want to lose
much you still want to be able to
separate data in the lower dimension is
it yeah so we project the feature space
on to a smaller subspace that represent
a toga the plot the data well means if
the points were separated in the high
dimension they are still separated to
some extent to an acceptable extent that
they are still separated in the
in the whole dimension so actually so
what we are trying to do is we are
trying to search for a subspace that
will maximize the variance of the
projected points so we project them in a
lowest mass appeal but you want to
maximize the variance of beta in that
subspace we can project at the beta sub
spaces right but beach for me a config
we are going to pick the one that will
keep the variance of the data maximum in
that subspace this is a fuel problem of
the linear least squares fitting I am
sure some of you are familiar with it by
basically finding a sub space that is
the the best in list square
approximation is actually that subspace
that we are looking forward okay and
Rico okay so let me go pca i will show
that can be done by SVD of a data matrix
or via an icon value decomposition of
data covariance matrix so I'm going to
talk about but I want to give you first
and understand look at look at this
these are my data points in our two I
don't want to work it out so I want
working on one what am I going to do I'm
going to measure subspace to that right
but beach subspace the subspace that
will when I project it onto this
subspace we see the separation between
this two point these two point is to
point this took what they are high so it
is not any line but a line that is going
to be the best match so that the
variance is still high and that best
match happens to be the least square
approximation in other words the square
distance is the distance here this point
to the projected point this point of the
projected point if you get the square of
the square of all those distances they
are maximized if you take any other one
dimensional space and if you find the
square of those distances it's going to
be less than this or if you think in our
to as you see these are also in r3 these
are my points so I want to match it
playing to those points but when I miss
the plane I don't match any plane I
wanted to play that when I projected
those date on the plane the variance of
that will be maximum or in the least
square approximation sense the squared
distances this square of the on the sum
of the square of the distances is gonna
be one maximum in this case so basically
PCA finds and subspace that match data
in a lower dimension but the separation
of data is maximum or the variance of
theta is maximum in that subscript okay
so what are we trying to do okay I say
another view assume that this is our
data metrics what does that mean each
column is a data point for you in other
words we are working in an n-dimensional
space we have P data points want to all
the way to pee and each data point is in
on em let's say okay they're clear each
column is a data point so my data matrix
is n by P i have p data points and each
data point is in RN okay but what I know
is that even though each data point is
in our end actually there is some
redundancy because I know that some of
those components are somehow related
okay so I don't want to keep the related
conference I want to say hey I don't
meet the related things let me get rid
of the related things I just want to
have unrelated things right so basically
from these bad legs I want to go to
another matrix w hat or w bar okay and
which is still consisting of people and
so instead of this x1 x2 all the way to
xn my first data point I want to convert
my first data point to another data y 1
y 2 y que but this time this data point
lives in bed in R K and K is less than n
so instead of working in our end now I'm
going to work in R K so the problem
became what having these data matrix n
by P and converting it into another data
matrix K Y P and K
less than n so I'm going to deal with
data clustering instead of our end now
I'm gonna deal by data clustering in
there in RK right so we don't know how
to do it but that's the problem I mean
that's the thing that I want to do I
don't want to work by N by P our work
with k by P and K is less than n okay so
i want to get peed off the related
things within my data so that i did get
rid of redundancy in my data and he is
there how we do it with pca dr. Bob
describe what PCA what singular value
decomposition is right so we have
datamatics and might be this is my data
metrics nyp this is the data metrics so
any matrix regardless of it is rank
regardless of invertible or not any data
that is can be decomposed into three
matrices u sigma and v transpose so
assume that this is my data matrix what
i do i take my data metrics and do SVD
single all decomposition and if the rank
of the matrix is our we will have our
independent columns of you okay so
assume that I want to project into K
dimension I want to project a dimension
what'll be the best subspace what do I
mean by best something I mean what will
be a basis for the best up space isn't
it because a subspace is defined by a
basis so determining the best subspace
means determining a basis for the best
up space here it is you are you to UK in
other words the eigenvalues after I ghen
the first k principal eigenvectors of w
will be a basis for the best sub space
that is or that in the least square
approximation sauce that's it
that's my subspace all you need to do
get the data metrics do SVD you Sigma V
transpose and then get the first k
principal eigenvectors that's going to
be a basis for the best of space but of
course finding the best subspace is not
the whole story after you find the best
subspace you read the project onto that
subspace right and dr. bharat showed you
that a projection is so basically what i
do i project my data k dimension
subspace spent by first k principal I
know makers and if you recall from our
earlier lecture projection of a data
matrix on a subspace is nothing but you
you've transpose W and your w bar is
going to be on with this we get this U
is k by P dimensions that right yeah I'm
sorry it is and by let's see you is and
by K dimensional right what does you
transpose u transpose this k x and the
national and w @ n times P that means u
transpose ee is k times p that is your w
bar so you will replace your w your
original data matrix with this data
matrix if you want to have more deeper
understanding this is nothing but the
coordinates with respect to new basis
this is your basis for the subspace and
this is each column of this matrix is
going to be the coordinates with respect
to this new basis of your original data
and since we have K basis vectors your
data will be K dimensional
so I repeat I know or maybe i'm working
too much and just trying to make sure we
have w and x p and i get the single roll
the composition i do single value
decomposition then I get the first k
principle I convectors right there okay
and then i project my data matrix onto
the subspace fell by those eigenvectors
and then i get the coordinates or the
the new coordinates of each data point
in the new basis and this is nothing but
u tilde transpose W and W was n by P now
w bar is going to be K times ok here is
an example well even before I mean okay
so let me go back a little bit after I
explained those already but I want to
give you an idea about what other that
mean assume that this son team centered
this ex my ex is centimeters and why is
inches in other words i have two routes
with one ruler which is centimeter based
and made in my height then i'm taking
the second ruler which is inch base
inches based and I amazing my height
again okay and this point is my height
as in centimeters and inches okay then i
get a phony and then i do exactly the
same thing i have two rulers i measure
his height in centimeters and then his
eyes in inches here is that data point
there and similarly these are one two
three seven people we measure their
height in centimeters and inches in fact
this is supposed to be linear right
because I mean Santa Mira conversion
from Sunday meter 1 inches always 2.42
points54 centimeters it's supposed to be
linear but during the invasion
whatever's or due to noise it is not but
i know that this data is really curly
right i mean i don't want a keyboard
inches and centimeters
makes no sense I want to get rid off
instead of having two data points 1
centimeter 1 inches I want to get rid of
that and I represent each data with a
single number in other words I want to
reduce my dimension instead of working
in our two I want to work in on one okay
so what can I do I'm going to find a
vector you saw that let me project those
data points in that direction the
variance will be as much as possible
here it is assume that C we have this
and we have that if I project all of my
data in the blue vector the separation
between the points will be this much
right what what if I I bet if I project
i'm in the red vector as you see the
data will not be separated there is this
much right so you don't want to project
your data on the raft you want to
project your data on the book which will
maximize the separation in fact our
problem is how do you find the direction
of you that is what principal component
analysis deals with so we want to
determine you so that then project in
the direction of view data will be as
separate as possible yeah and and I'll
let me go it turns out that it is
actually our datamatics this is inches
centimeters I know they don't have
people like them in those very short for
me
it's okay so this is the first data
point 10 inches 28 centimeters 12 inches
19 son and so on so we have one to
actually six data points okay so I want
to convert this 2 by 6 matrix 2 1 by 6
matrix because I know that the data it
is correlated instead of representing by
two numbers I want to represent it by
100 and so on so that is now banette
principal component analysis how am I
gonna do it by I can do it in different
ways let's do it singular value
decomposition I just explained right
it's singular value decomposition all
you need to do is have a video of your
data metrics and since you want to
convert it from two dimension to
one-dimensional how many principal I
connectors that I might have only one
right only one because we are if we want
to project into the cave national space
we have K Prince verizon vectors by the
regular project into one dimension space
i will only one single I don't Tector in
this case yeah it is but well before I
take anything I want to normalize it
normalization means having zero means
and unit variance of data okay basically
instead of 10 28 what I do first I get
the average of all those numbers I get
the average of all those numbers and i
subtract the average from each one of
them that's going to convert my data to
zero mean and then I do something else
and also I've been zero absolutely unit
variance but I'm just skipping this for
the sake of time so assume that this
data is converted first or normalized
first two so that each column I'm sorry
each as you see each row is unit the
average of each rob is going to what 0
and the variance of each job is what one
then I do SVD my data messages to buy
six you Sigma V transpose my you will be
actually two vectors but which one am I
going to take I'm going to take the
first one that corresponds to the
highest ideal involving that means the
eigenvector that corresponds to the
highest eigen value which is this one
right that is mine this is a basis for a
line it's a basis for a line that's
going to be the best match for my
subspace do you see that this is just a
45-degree angle right so that's just a
line so then what do I do this is my new
tilde and then all I have to do is you
till the transpose W and bump here it is
so instead of working with 2 by 6 matrix
I can work with this matrix in
formulation yes
take the variations you me that same
okay let's let me show right here
because I do it also another way which
will which would answer your question it
is the problem now i'm going to do not
with SPD what I'm going to do it with
what covariance matrix okay which will
have more explicit analysis so these are
my data points x 12 x 6 actually here
are my data but after i calculate see I
first compute what mean of those six
data 10 12 15 20 22 26 I calculate the
mean of it and subtract that mean from
each data point that is the mean right
but for Damian's after that assuming
that now my data is 0 mean I calculate
the variance but I don't work with the
original data anymore I work with what
the the normalize in terms of me Dana
and then I get the variance of this data
by getting the square of each number
adding them up and whiting by six and
then replacing each data point by the
data point divided by the square root of
the variance exactly I've been expected
to see t-virus right right of course you
do that yes yes I know me station so I
need to be really careful I know okay so
so that's the pre-processing so we first
normalize our data okay once I realize
my data my goal is what my goal is
you so I want to maximize the
separations i right I want to maximize
the separation you can data points but
i'll try normalize my data will be will
not be like this my data will be somehow
centered around origin right because I
normalize it so they they will be
centered around origin in other words
maximizing separation is going to be an
equivalent problem of maximizing
distance from the origin for example the
distance of this point from religion is
that if I get the sum of all those
distances from the red line if I get the
sum of all these dances for the blue
line obviously the blue line will have a
figure sum of distances from the origin
so my problem right now is it maximizing
separation or variance is equivalent to
maximizing distance from origin ok so
here it is but if you remember is that
clear about our previous presenter show
if you maintain the point X and if you
want to project it on you projection is
nothing but an inner product isn't it so
if you want to project this all a unit
vector u it is nothing but the inner
product of X with that unit vector u so
this size I mean this point is projected
here this left here is equal to the
inner product of X I with you here it is
X I with you and for our specific cases
we have six data points X I in and for
that you is going to be the distance
from origin to the first data point that
x2 inner product you move with the
distance from origin to the second data
point and so on I'm adding them up but I
want to find a you that will maximize
this son right in other words Pike a
little bit more I can show that the you
that will maximize this separation is
nothing but
and the principal eigenvector of this
madness we call it covariance matrix so
instead of SVD you can solve the same
problem why first called creating a
careerist matrix like this and then
finding it is first principle
eigenvector that's your you so now I do
it in that way and after that of course
we have to after you find you what do we
do we project data right and then get
the coordinates in the projected space
it is my i'm using the same w ok the
same datamatics and this is the
covariance matrix basically this matrix
is right here and then I get the
principal eigenvector of this covariance
matrix is this now this looks similar to
the same matrix the same eigen vector
that we have been SVD right the problem
became exactly the same then I'm going
to replace my original data with project
with data points which is this does this
look similar to this is exactly the same
result if I obtained at work sweetie so
you can do principal component analysis
either with SVD or you want to do with
regular covariance matrix and here are
the by the way and I change the colors
blue red but this is the direction and
these are the projected points in one
dimension so general PCA algorithm if
you don't want to be the SVD here it is
given a data set let's say that we have
n data points and each data point the
least in our end we want to reduce the
date of the K dimensional data set in
other words we will ever and data points
but each each one of them will live in
our chain this time first you normalize
data to 0 mean and unit covariance and
you complete the Kuwaitis matrix and
then find the top k eigenvectors of the
covariance matrix and replace each X I x
y IX
r &amp; but why I has 12 all the AK has K
components in other words why is in our
chain so a data point XK I'm so X in RN
is replaced by another data point which
is in our care okay so that is principal
component analysis I hope it was clear
so we cannot solve subspace classes pro
problems with PCA can somebody tell me
why not can I saw subspace clustering
problem with PCA I cannot why because a
subspace clustering problem what we are
doing is we are trying to find you need
of subspaces right so that means for
each subspace I must have one pca not
too thin but I really don't know which
data phones comes from which subspace so
when I do pca I find only single
subspace that matches the best of the
best of the older data point but that's
not what I meant is a subspace closely I
want to say that hey boldly the points
are coming from one subspace I want to
find that subspace the only person from
another sub so I when I write that
subspace but if I do pca I will find a
single subspace that will match all the
data points so that means that is not
subspace clustering algorithm so
specular cross spectral clustering is a
very modern and been a powerful
clustering algorithm it's very easy to
implement any outperform traditional
clustering algorithms like k-means i'm
assuming that you know what he means is
what king is a very fundamental
clustering algorithms given a number of
data points you can somehow cluster them
based on the center of the clusters of
theta I'm not going to go over it but
with it is not easy to understand why it
works which is not easy but
implementation is very easy okay
basically given a set of data points
what you do is you have given bunch of
data points right what do you want to do
is you want to develop similarity
between all the pairs of the data points
so although most of the subspace
clustering algorithms boiled down to
determining that similarity
once they determine the similarity
between the data points the rest is the
same most of the spectral class and
yogurt I'm sorry most of the substrate
has an algorithms in the last stage it
says now let's apply expect a little
cluster yes okay I will define now good
questions so I will define for example
similarity may be based on distance if
two points are close to each other they
are similar or more similar than two
data points that are not close but they
may not work in subspace clustering
because on a line we may have a data
point right there another data point
here they are really far far away from
each other right but they are very
similar because they are on the same
line so this tues base similarity may
not work in subspace clustering right so
here for example assume that this is
your data if use k means there is no way
that you can cluster this right but if
you expected a class thing you can do it
k means you cannot cluster this but if
we inspect to the class ring you can
come up with a way that this is one
cluster this is another cluster here is
answer to your question actually we have
the data points this is Olivia five data
points between each data points pairs of
data points you somehow determinate
similarity okay but that is the key for
subspace clustering algorithms how do
you determine that similarity sparsely
methods use a certain approaches to
determine the similarity low-rank
approximation is another and so
everybody uses different ways to
determine once you determine that
similar to the proudest fault anyway
okay the problem is so once you turn
that similarity and assume that as 13
means the similarity between X 1 and
point x1 and x3 and this is the
significant point estrella as you see
there is no similarity between 4 &amp; 4 &amp; 4
&amp; 5
okay so what do we do what is the
starting point of specular clustering
specular clustering assumes that you
have the similar to somehow okay assume
that we have n data points and each data
point is in our end is similarity matrix
it's also called infinity 0 matrix is
provided as input this graphics s is
provided for example this is a very
naive way of developing or determining a
similarity and this is like Gaussian
function for example if X I and XJ are
very close to each other the difference
the norm of the difference will be what
small small and that means since we have
the e to the inverse that means similar
twill be high so the points are the more
separated the points the less similar
the points are right so but but this
will not work what for example this will
not work with the examples that I just I
mean well I don't want to say that but
this will not work for me subspace
classroom from but assume that somehow
you have the similarity matrix and look
your data leaves in RN are maybe this
thing like let's say are two thousand
assume that we have 50 data points and
each one lives in our 2,000 regardless
our 2,000 or mod our similarity matrix
will be what 50 by 50 because
similarities between the points so here
one point in our two thousand and other
point in our two thousand somehow we are
developing similarity and you obtain one
number so similarity is simply one
number that represent how similar two
points are regardless of their
innovation ok so my similarity matrix is
what and by n but we also seen inspector
glassing oh there's a way to estimate
not a reliable way to estimate how many
classes that we should have we assume
that also we know the number of clusters
so by the spectacle by the subspace
class and algorithms by before you use
this you should be
similarity and you should have a good
guest about the number of subspaces by
this time yes you do an example of how
you do a similarity metric for something
along the line okay oh yeah I think it
may be at the base right in that case
see if if the angle is you know the
angle base at all of them are I mean
very similar so you can develop
different similarities instead playing I
mean yeah so I think angle base similar
to be more suitable for for a line so
you're not clear I mean I haven't
discussed anything yet but you must know
that similarity matrix is the input to
spectral clusters and the number of
clusters is also provided we know that
there are three clusters two classes and
so on I am just extremely mechanics of
spectral class I'm going to explain that
the idea and why it works it is not
possible for me to explain in 10-15
minutes it's impossible so the first
step is the similarity from the
similarity matrix you are going to
develop a diagonal degree mattox d
diagonal degree matrix is a diagonal
matrix that means all the diagonal
elements are nonzero and each diagonal
element for example the first diagonal
element is nothing but sum of all
similarities on the first row second
diagonal element is the sum of the
similarities on the second row and the
last diagonal element is the sum of the
similarities in other words the sum of
similarity of point n with point one
with point two point three and so on
okay so that is a diagonal matrix so
that was our input now step on using the
similarity matrix I have a diagonal TD
matrix T then step two we compute a
normalized graph laplacian matrix
graph laplacian matrix is nothing but I
mean do you may have different laplacian
matrix but in this specific case i use
this so it is d to the power minus 1
over 2 and my similarity matrix digital
power minus 1 of 2 since these as the
diagonal matrix getting the square root
of diagonal matrix is trivial right get
the squares of the diagonals right so
the third step after you have the
laplacian ethics what you're going to do
is you are going to compute if there are
K clusters if you know that there are K
clusters you are going to compute first
k principle icon vectors of app first
similar to ethics then diagonal degree
matrix then they are not classy emetics
now I'm going to find first k principle
lights vectors of what laplacian matrix
ok step 4 I generate a matrix W which
consists of the whose columns are just
the first k principle I can make use of
what laplacian matrix ok so let's go
back to this what was the dimension of
similarity matrix and buy em right the
dimension of degree matrix is n by n the
laplacian matrix is n by n however this
w is what and by k because we have K
principle eigenvectors and each
eigenvector they said eigenvector of el
L was n by n that means this is n by 1
eigen vector so that means double is
what and by K now last step acquired
traditional clustering techniques such
as k-means in RK to the rows of company
now I corded the problem instead of
crossing my original data points for
example x1 is going to correspond to the
first row of this Dana extremely
correspond to the second row of the
state
next and so on and xn is going to
correspond to the last row of this data
matrix but each row is how each row
lives in RK right let's say if there are
two classes will be in r2 so clustering
in our 2,000 is converted to clustering
in r2 or in RK now i can apply k means
to my problem i know it is not intuitive
but this is what it is ok ok these are
from the lecture notes of this this this
is very well known person in spectral
clustering and I borrow that instead of
generating i generate in my own but
these are really good assume that it's
an example it soon as our data set is
not too and we use very naive similarity
measure just like this ok and we use
completely connected similarity graph
completely connected means somehow you
define the symmetric with all pairs so
every pair is related to each other
because artists are similarity measure
right as long as there is distance
between two points there is a positive
similar to be ok now assume that you
want to look at the classes for two
clusters three four five clusters here
is our L ok since we are looking for up
to five clusters I want to get 25 I can
make theirs of what laplacian matrix L
so if I assume there are five clusters I
will do clustering in what are five that
means my first data point will be this
second at appointment with that third
and so on what if I assume that there
are three clusters instead of five
eigenvectors I'm going to get one the
first what three eigen vector
okay for example here it is this was my
original data assume that this is x1
right this is next one if I say that
there are three clusters I can convert
this problem to this that data point x1
will be one of those red points here
because i am taking the three eigen
vectors that means each data from this
time from r2 i go back to our three I
know this looks a little bad but so I'm
going from our 2 2 R 3 because in r3 I
can separate them better you see in our
three I see three clusters very clearly
right here and then I can apply k-means
to this better than K means to this K
means they apply to this those points
will be you know we don't know but if
you apply k-means to this it will be
more separable right okay and these are
the eigenvalues so we don't know how
many i mean bv say that there are three
classes right but if you don't know how
many clusters by looking at eigen values
for example that laplacian matrix has
three eigen modules which are really
slow and then the other fourth fifth and
so on are bigger so maybe you can have
an estimated based on the eigenvalues
this master this should have three
clusters but that's not always true so I
can't rely on it your assumption is you
know the number of clusters here are
some other examples that I created using
matlab this is a high rolla MO generated
data and then I find the I developed the
similarity based on you know the
Gaussian function very naive similarity
and then I convert that I find and I
know that there are two clusters I find
vectors first two principal eigenvectors
of L and then converted it to k-means
and hear what I get with liquor k-means
you may not get this but with after that
I get that this had better example I
generated this data that I converted it
into two dimensional I said this is the
this is the eigenvectors the coordinate
the rows of the of my w you see how
separable it is here instead of a plane
came instead I applied here this is
better example this one I generated this
data and after i coordinate all of the
points are either dead or there see how
easy an artist to separate into this
with regular K&amp;C cannot be that's
basically what I handful today any
questions
I hope it was useful and I'm around to
hear any questions let's go thank you
and we are going to put those
presentations on workshop website
hopefully tonight so that you know
whenever we have time have a better
about some of those lives
hello everyone in our previous lessons
we introduced you to graphs and we also
looked at and talked about some of the
properties of graph but so far we have
not discussed how we can implement graph
how we can create a logical structure
like graph in computer's memory so let
us try to discuss this a graph as we
know contains a set of vertices and a
set of edges and this is how we define
graph in pure mathematical terms a graph
G is defined as an ordered pair of a set
V of vertices and a set of edges now to
create and store a graph in computer's
memory the simplest thing that we
probably can do is that we can create
two lists one to store all the vertices
and another to store all the edges for a
list we can use an array of appropriate
size or we can use an implementation of
a dynamic list in fact we can use a
dynamic list available to us in language
libraries something like vector in C++
or ArrayList in Java now a vertex is
identified by its name so the first list
the list of vertices would simply be a
list of names or strings I just filled
in names of all the vertices for this
example graph here now what should we
fill in this edge list here an edge is
identified by its two endpoints so what
we can do is we can create an edge as an
object with two fields we can define
edge as a structure or class with two
fields one to store the start vertex and
another to store the end vertex edge
list would basically be an array or list
of this type struct edge in these two
definitions of edge that I have written
here in the first one I have used
character pointers because in C we
typically use character pointers to
store or refer to strings we could use
character array
also in C++ or Java where we can create
classes we have string available to us
as a datatype so we can use tattles so
we can use any of these for the fields
we can use character pointer or
character array or string datatype if
it's available depends on how you want
to design your implementation now let's
fill this edge list here for this
example graph each row now here has two
boxes let's say the first one is to
store the start vertex and the second
one is to store the end vertex the graph
that we have here is an undirected graph
so any vertex can be called start vertex
and any vertex can be called end vertex
order of the vertices is not important
here we have 9 edges here 1 between a
and B another between a and C another
between a and D and then we have B E and
B F instead of having B F as an entry we
could also have F B but we just need one
of them and then we have CG D H E H and
F H actually there's one more we also
have G H we have 10 edges in total here
and not 9 now once again because this is
an undirected graph if we are saying
that there is an edge from F to H we are
also saying that there is an edge from H
to F there is no need to have another
entry as HF we will unnecessarily be
using extra memory if this was a
directed graph F H and H F would have
meant two different connections which is
the start vertex and which is the end
vertex would have mattered maybe in case
of undirected graphs we should name the
fields as first vertex and second vertex
and in case of directed graphs we should
name the fields as start vertex and end
vertex now our graph here could also be
a weighted graph we could have some cost
or weight associated with the edges as
you know in an unweighted graph
cost of all the connections is equal but
in a weighted craft different
connections would have different weight
or different cost now in this example
graph here I have associated some
weights to these edges now how do you
think we should store this data the
weight of edges well if the graph is
weighted we can have one more field in
the edge object to store the weight now
when entering my edge list has three
fields one to store the start vertex one
to store the end vertex and one more to
store the weight so this is one possible
way of storing the graph we can simply
create two lists one to store the
vertices and another to store the edges
but this is not very efficient for any
possible way of storing and organizing
data we must also see its cost and when
we say cost we mean two things time cost
of various operations and the memory
usage typically we measure the rate of
growth of time taken with size of input
or data what we also call time
complexity and we measure the rate of
growth of memory consumed with size of
input or data what we also call space
complexity time and space complexities
are most commonly expressed in terms of
what we call Big O notation for this
lesson I am assuming that you already
know about time and space complexity
analysis and Big O notation if you want
to revise some of these concepts then
you can check the description of this
video for link to some lessons we always
want to minimize the time cost of most
frequently performed operations and we
always want to make sure that we do not
consume unreasonably high memory okay so
let's now analyze this particular
structure that we are trying to use to
store our graph let's first discuss the
memory usage for the first list the
vertex list least number of rows needed
or consumed would be equal to number of
vertices now each row here in this water
list is a name or string and string can
be of any length right now all strings
have just one character because I simply
named the nodes a B C and so on but we
could have names with multiple
characters and because strings can be of
different lengths all rows may not be
consuming the same amount of memory like
here Here I am showing an intra-city
road network as a weighted graph cities
are my nodes and Road distances are my
weights now for this graph as you can
see names are of different lengths so
all rows in vertex list are all rows in
edge list would not cost the same more
characters will cost us more bytes but
we can safely assume that the names will
not be too long we can safely assume
that in almost all practical scenarios
average length of strings will be a
really small value if we assume it to be
always lesser than some constant then
the total space consumed in this vertex
list will be proportional to the number
of rows consumed that is the number of
vertices or in other words we can say
that space complexity here is Big O of
number of vertices this is how we write
number of vertices with two vertical
bars what we basically mean here is
number of elements in set V now for the
edge list once again we are storing
strings in first two fields of the edged
object so once again each row here will
not consume same amount of memory but if
we are just storing the reference or
pointer to a string like here in the
first row instead of having values
filled in these two fields we could have
references or pointers to the names in
the vertex list if we will design things
like this each row will consume same
memory this in fact is better because
references in most cases would cost us a
lot lesser than a copy of the name and
as reference we can have the actual
address of the string and that's what we
are doing when you are saying that start
and end vertex can be character pointers
or maybe a better design would be simply
having the index of the name word string
in vertex list let's say a is at index
zero in the vertex list and B is at
index 1 and C is at index 2 and I'll go
on like this now for start what X hand
end vertex we can have two integer
fields as you can see in both my
definitions of edge start vertex and end
vertex are of type int now and in each
row of edge list first and second field
are filled with integer values I have
filled in appropriate values of indices
this definitely is a better design and
if you can see now each row in edge list
would cost us the same amount of memory
so overall space consumed in edge list
would be proportional to number of edges
or in other words space complexity here
is Big O of number of edges okay so this
is analysis of our memory usage overall
space complexity of this design would be
Big O of number of vertices plus number
of edges is this memory usage
unreasonably high well we cannot do a
lot better than this if we want to store
a graph in computer's memory so we are
alright in terms of memory usage
now let's discuss time cost of
operations what do you think can be most
frequently performed operations while
working with graph one of the most
frequently performed operations while
working with graph would be finding all
nodes adjacent to a given node that is
finding all nodes directly connected to
a given node what do you think would be
time cost of finding all nodes directly
connected to a given node well we will
have to scan the whole edge list we will
have to perform a linear search we will
have to go through all the entries in
the list and see if the start or end
node in the entry is our given node for
a directed graph we would see
if the start node in the entry is our
given node or not and for an undirected
graph we would see both the start as
well as the end node running time would
be proportional to number of edges or in
other words time complexity of this
operation would be Big O of number of
edges okay now another frequently
performed operation can be finding if
two given nodes are connected or not in
this case also we will have to perform a
linear search on the edge list in worst
case we will have to look at all the
entries in the edge list so worst-case
running time would be proportional to
number of edges so for this operation to
time complexity is Big O of number of
edges now let's try to see how good or
bad this running time Big O of number of
edges is if you remember this discussion
from our previous lesson in a simple
graph in a graph with no self loop or
multi edge if number of vertices that is
the number of elements in set V is equal
to n then maximum number of edges would
be n into n minus 1 if the graph is
directed each node will be connected to
every other node and of course minimum
number of edges can be 0 we can have a
graph with no edge maximum number of
edges would be n into n minus 1 by 2 if
the graph is undirected but all in all
if you can see number of edges can go
almost up to square of number of
vertices number of edges can be of the
order of square of number of vertices
let's denote number of vertices here as
small V so number of edges can be of the
order of v square in a graph typically
any operation running in order of number
of edges would be considered very costly
we try to keep things in order of number
of vertices when we are comparing the
two running times this is very obvious
Big O of V is a lot better than Big O of
v square
all in all this what X list and edge
list kind of representation is not very
efficient in terms of time cost of
operations we should think of some other
efficient design we should think of
something better we will talk about
another possible way of storing and
representing graph in next lesson this
is it for this lesson thanks for
watching
So in our previous lesson, we discussed
one possible way of
storing and representing a graph in
which
we used two list. One to store the
vertices and another to store the
edges. A record in vertex list here
is name of a node
and a record in edge list is an
object
containing references to the two endpoints
of an edge and also the weight of that edge
because this example graph that I am showing
you here is a
weighted graph. We called this kind of
representation
edge list representation but we realised
that this kind of storage is not very
efficient in terms of
time cost of most frequently performed
operations
like finding nodes adjacent to a given
node
or finding if two nodes are
connected are not.
To perform any of these operations, we
need to scan the whole
edge list. We need to perform a
linear search on the edge list.
So the time complexity is big oh of number
of
edges and we know that number of edges
in the graph
can be really really large. In worst case
it can be close to square of number of
vertices.
In a graph, anything running in order
of number of
edges is considered very costly. We
often want to keep the cost
in order of number of vertices. So we
should think of some other efficient
design.
We should think of something better than
this. One more possible design is that
we can store the edges in a
two-dimensional array
or matrix. We can have a
two-dimensional matrix
or array of size V*V
where V is number of vertices.
As you can see, I have drawn an 8*8
array here because number of vertices
in my sample graph here
is 8. Let's name this array A.
Now if we want to store a graph that is
unweighted. Let's just remove the weights
from this sample graph here
and now our graph is unweighted and if we
have
of value or index between 0 and V-1
for each vertex which we have here
if we are storing the vertices in a
vertex list
than we have an index between 0 and V-1
for each vertex. We can say that A
is zeroth node,
B is 1th node, C is
2th
node and so on. We are picking up
indices from vertex list. Okay
so if the graph
is unweighted and each vertex has an
index between 0 and
V-1, then in this matrix
or 2d array. We can set ith row
and jth column that is A[i][j]
as 1 or boolean value
true. if there is an edge from i to j
0 or false otherwise. If I have
to fill this matrix for this example
graph here then I'll go vertex by vertex.
Vertex 0 is connected to Vertex 1
2 and 3. Vertex 1
is connected to 0, 4 and 5.
This is an undirected graph so if we
have and edge from 0 to 1,
we also have an edge from 1 to 0
so
1th row and 0th column should also be
set as 1.
Now let's go to nodes 2, it's connected
to 0
and 6, 3 is connected to 0 and 7,
4 is connected to 1 and 7,
5 once again is connected to 1 and 7,
6 is connected to
2 and 7 and 7 is connected
to 3, 4, 5 and 6.
All the remaining positions in
this array should be set as 0.
Notice that this matrix
is symmetric. For an undirected graph,
this matrix would be symmetric
because A[i][j] would be equal to A[j][i].
We would have two positions filled for
each edge.
In fact to see all the edges in the graph,
we need to go through only one of these
two halves.
Now this would not be true for our
directed graph. Only one position will be
filled for each
edge and we will have to go through
the entire matrix
to see all the edges. Okay,
now this kind of representation of a
graph in which
edges or connections are stored in a
matrix
or 2D array is called adjacency matrix
representation. This particular matrix that
I have drawn here
is an adjacency matrix. Now with this
kind of storage or representation,
what do you think would be the time cost
of finding
all nodes adjacent to a given node. Let's say
given this vertex list
and adjacency matrix, we want to find
all nodes adjacent to node named F.
If we are given name of a node than
we first need to know it's
index and to know the index, we will have to
scan the vertex list.
There is no other way. Once we figured out
index
like for F index is 5 then
we can go to the row with that index
in the adjacency matrix
and we can scan this complete row to
find all the
adjacent nodes. Scanning the vertex
list
to figure it out the index in worst case
will cost us time proportional to the
number of vertices
because in worst case we may have to
scan the whole list,
and scanning a row
in the adjacency matrix would once again
cost us time proportional to number of
what vertices because
in a row we would have exactly
V columns where V is number of a
vertices.
So overall time cost of this operation
is big oh of V. Now most of the time
while performing operations,
we must pass indices to avoid
scanning the vertex list all the time.
If we know an index, we can figure out
the name in constant time,
because in an array we can access element at
any index in constant time but if we know
a name
want to figure out index then it will
cost us big oh of V.
We will have to scan the vertex list.
wWe will have to perform linear search
on it. Okay moving on.
Now what would be the time cost of
finding if 2 nodes
are connected or not. Now once again the
two nodes can be given to us
as indices or names. If the nodes
would be passed test as indices
then we simply need to look at value in
a particular row and
particular column. We simply need to look
at
A[I][J] for some values of I and J
and this will cost us constant time.
You can look at Value in any cell in
a two-dimensional array in constant time.
So if
indices are given time complexity of
this operation would be big oh of 1
which simply means that we will
take constant time
but if names are given then we also need
to do the scanning
to figure out the indices which will
cost us big oh of V.
Overall time complexity would be 
Big oh of V.
The constant time access would not mean
anything.
The scanning of vertex list all the
time to figure it out
indices can be avoided. We can use
some extra memory to create
a hash table with names and indices
as key value pairs and then the time
cost of finding
index from name would also be big oh
of 1 that is constant. Hash table is
a data structure
and I have not talked about it in any of
my lessons so far.
If you do not know about hash table, just
search online for
a basic idea of it. Okay, so as you can
see
with adjacency matrix representation
our time cost of some of the most
frequently performed operations
is in order of number of vertices
and not in order of number of
edges which can be as high as square of
number of vertices.
Okay now if we want to store
a weighted graph in adjacency matrix
representation
then A[i][j] in the matrix can be set as
weight of an edge. For non-existent ages we
can have
a default value like a really large
or maximum possible integer value
that is never expected to be an edge
weight. I have just filled in infinity
have to mean that
we can choose the default as infinity
minus infinity
or any other value that would never
ever be a valid
edge weight. Okay, now for further
discussion
I'll come back to an unweighted graph.
Ajacency matrix
looks really good so should we not use it
always.
Well, with this design we have improved
on
time, but we have gone really high on
memory usage
instead of using memory units exactly
equal to the number of edges
what we're doing with
edge list kind of storage.
Here we're using exactly V square
units of memory.
We are using big oh of V square space.
We are not just storing the information
that these two
nodes are connected, we are also storing not
of it
that is these two nodes side not connected
which probably is
redundant information. If a graph is
dense,
if the number of edges is really close
to V square
then this is good but if the graph is
sparse
that is if number of edges is lot lessser
than V square
then we are wasting a lot of
memory in storing the zeros.
Like for this example graph that I have
drawn here, in the edge list we were
consuming
10 units of memory we had ten rows
consumed in the edge list
but here we are consuming 64 unit.
Most graphs with
really large number of vertices would
not be very dense,
would not have number of edges anywhere
close to V sqaure
like for example, Let's say we are modeling
a social network like Facebook as a
graph such that a user in the network
is a node
and there is an undetected edge if two
users are friends.
Facebook has a billion users but I'm
showing only a few in my example graph
here because I'm short of space.
Let's just assume that we have a billion
users in our network,
so number of vertices in a graph is
10 to the power 9
which is billion. Now do you think number
of connections
in our social network can ever be close
to square of number of users
that will mean everyone in the network
is a friend of
everyone else. A user of our social
network will not be friend to all other
billion users.
We can safely assume that a user
on an average would not have more than
a thousand friends
with this assumption we would have
10 to the power 12
edges in our graph. Actually, this is an
undirected graph
so we should do a divide by 2 here. So
that we do not
count an edge twice. So if
average number of friends is 1000 then total
number of connections in my graph is
5 * 10 to power 11. Now this
is lot lesser than a square of number
of vertices.
So basically if you would use an adjacency
matrix for this kind of a graph,
we would waste a hell lot of space
and moreover
even if we are not looking in relative
terms 10 to the power 18
units of memory, even in absolute
sense
is alot. 10 to the power 18 bytes
would be about a 1000 petabytes.
Now this really is a lot of space. This
much data would never ever fit on one
physical disk.
5 into 10 to the power 11 byts on the other
hand
it's just 0.5 terabytes. A typical
personal computer these days would have this
much of storage.
So as you can see for something like a
large
social graph adjacency matrix
representation is not very efficient.
Agency matrix is good when a graph is
dense
that is when the number of edges is
close to square of number of vertices
or sometimes when total number of
possible connection that is V square
is so less that wasted space would not
even matter
but most real-world graphs would be
sparse
and adjacency matrix would not be a good
fit.
Let's think about another example. Let's
think about
world wide web as are directed graph.
If you can think of web pages as nodes
in a graph
and hyperlinks as directed edges
then a webpage would not have linked to
all other pages
and once again number of webpages
would be in order of millions.
A webpage would have link to only
the
a few other pages, so the graph would be
sparse.
Most real world graphs would be sparse
and adjacency matrix. Even though it's
giving us good running time for most
frequently performed
operations would not be a good fit
because it's not very efficient in terms
of space
so what should we do. Well there's
another
representation that gives us similar
or maybe even better running time than
adjacency matrix and does not consume so
much space
It's called adjacency list
representation and we will talk about it
in our next lesson.
This is it for this lesson. 
Thanks for watching
hi I'm Jonah in this video I'm going to
explain two different ways to implement
a graph and then I'm going to explain
some of the pros and cons of each and
I'll show you how to implement both of
these methods in Python so the first way
to implement a graph is using an
adjacency list so let's look at this
undirected graph it has five vertices
and some edges connecting them an
adjacency list actually is a set of
adjacency lists because each list is
stored in its own vertex so a keeps its
own list of directly connected neighbors
other vertices that it has an edge to so
a has neighbors B C and E node B has
neighbors a and C as we can see here
this is going to be stored within each
node or each vertex is going to store
its own adjacency list now the other way
is using an adjacency matrix and the
adjacency matrix is a two dimensional
array and it basically stores a zero
where there is no edge or a one where
there is an edge from A to B we can see
there is an edge there or from A to C
there is an edge as you'd expect since
this is an undirected graph this is
going to be symmetrical across this
diagonal so from A to B is a 1 from B to
a is also going to be a 1 then the
adjacency matrix like I said it's a 2d
array and is stored in the graph object
so there's one adjacency matrix
centrally located in the graph object
how about if you have weighted edges on
an undirected graph well it's much
easier to implement weighted edges with
an adjacency matrix instead of putting a
one for edges where there is a
connection you just put the weight of
that edge so it's very easy to do that
you already have the cell you can put
instead of a 1 you can just put the
number of the cost or the distance or
weight of that edge in the cell so
extremely easy to implement using
adjacency matrix you can also implement
weighted edges in an adjacency list but
it's a little bit trickier so if you
have a directed graph again very easy to
do this using an adjacency list so here
we would have
a has one outbound edge to see so we
list under a only C as a neighbor that's
the only neighbor we can get to from a
so we're going to list all the outbound
edges for that vertex so C has edges to
B D and E and we list all the outbound
edges from C here in C's a Jason C list
you know Jason C matrix the same thing
we're basically going to put ones where
we have an edge outbound from that
vertex so we have the from on the left
and the two is div columns so which is
better well before we can answer that
question let's look at some other
characteristics of graphs a dense graph
is a graph where this is not absolute
value this is the number or count of
edges and the count of vertices so a
dense graph is a graph where you have
the number of edges is about equal to 2
the number vertices squared in other
words almost every vertex is connected
to every other vertex in the graph so
you get a really large number of edges
relative to the number of vertices a
sparse graph is a graph where E is about
equal to V which is what we have here in
this picture so there are a lot of
possible edges that are not actually
there another thing we're going to look
at before we answer the question which
is better adjacency matrix takes up V
squared space right this is a big factor
the amount of space required for this
adjacency matrix is going to be V
squared or number of vertices squared
regardless of how dense the graph is so
very very sparse graph you still are
going to take up the same amount of
space so for our little 5x5 you know we
only have 5 vertices in this example who
cares right but if you can picture a
graph that has ten thousand or a hundred
thousand vertices that's going to take a
project gigantic amount of storage space
so with those things in mind an
adjacency list is better in cases where
you have a sparse graph because it's
going to be faster and it uses less
space but the disadvantage of an
adjacency list this is slower for very
dense graphs large dense graphs is going
to be slower and the adjacency matrix is
going to be better for dense graphs
it's going to be faster and the space
complexity is the same as it would be
thrown on dense graph and another
advantage is that is simpler to
implement for weighted edges but the
disadvantage of this adjacency matrix is
that it uses more space and especially
for large sparse graphs or perhaps to
have a lot of vertices but relatively
few edges the adjacency matrix is not a
good choice so depending on the nature
of your graph you have to decide which
one of these is a better implementation
to go with so I'll give a quick
explanation of the adjacency list
version of the graph implementation
first we have our vertex class which
basically has two variables as a name
and it has a neighbors list and as we
add neighbors we see we have an add
neighbor function that basically is just
appending that vertex to the list and
then sorting it in the graph itself we
only have one graph variable which is a
dictionary of vertices so that we can
find any vertex by its name so when we
add a vertex we basically just check
that that object that you passed in
actually is a vertex object and then it
doesn't exist in the vertices dictionary
yet and if those two conditions are met
then it goes in as the vertex to the
vertices dictionary and when you try to
add an edge with vertices U and V then
it's first going to check if u and V are
both actually in this vertices
dictionary before adds it so if there's
an invalid vertex and it's not going to
be able to add that edge then we iterate
through the vertices and we locate
vertex U and vertex V and we add the
other to its neighbors and that's pretty
much it then I have a print graph
function down here at the bottom so this
is a pretty straightforward
implementation of graph I think it's a
little bit simpler so I usually favor
this over the matrix version although
the matrix version is not too hard and
then down below I have some test code
that we can test our our code up here so
implementing a graph using an adjacency
matrix this version is actually going to
support both weighted and unweighted
edges for undirected graphs and you have
to do slight modifications to support
directed graphs
so our vertex class you'll notice only
has one variable and that's just the
name of the vertex we don't need
adjacency this stored locally in the
vertex that doesn't happen here they're
stored centrally under the graph so we
have the same vertices dictionary so
that we can locate any vertex given its
name we also have this edges list which
is going to be our two-dimensional array
of edges that's the matrix and then we
have edge indices so that we can quickly
locate the index of any edge given its
name so when we add a vertex first we're
gonna check if it's actually vertex and
it is not in the vertices list already
and if not we add to the dictionary and
then our for loop here and the statement
right after that basically we need to
add another row and column of all zeros
to our edges matrix so we're going to do
that here we're add another row of zeros
and in another column of zeros on to
that edges matrix because we have mapped
any edges to this new vertex yet but we
need to add it to this matrix with all
zeros and lastly we add the index for
this vertex name into our edge indices
dictionary so to add an edge we're first
going to verify that both vertices U and
V are in our vertices dictionary and if
they both are then recall that this
edges matrix is symmetrical along the
diagonal so we want to add this edge we
want to enter the weight in the matrix
in both the top right bar in the bottom
left part so we're going to add the edge
to both u comma V and to V comma u we'll
set the edge weight and that's it for
add edge if we achieve that and we'll
return true and if not the return false
then lastly I have a pretty pretty
simple print graph function that prints
a pretty crudely formatted edges matrix
for us so you can see what that looks
like and our interface is exactly the
same as for the adjacency list version I
have exactly the same test code down
here below where we we set up a graph we
add some vertices and some edges to it
and we print it out I posted all of my
Python code here in my github site and
you can download that pin you also have
access to the PowerPoint file posted
here Omega up site so I hope this video
was helpful for you if you liked it
please click like and subscribe to my
channel I'm Joe James thanks for
watching
okay so let me tell you just for fun
it's an example this pocket cube which
is 2 by 2 by 2 your rubik's cube what we
have in mind is it's called the
configuration graph or sometimes the
configuration space but it's a graph so
this graph has a vertex for each
possible state of the cube so this is a
state creaky here this is a state this
is a state this is a state now I'm
hopelessly lost
ok anyone want to work on this board
no one all right leave it I'm solving ok
so all those are vertices there's
actually a lot of vertices there are 264
million vertices or so if you want as an
aside here number vertices is something
like 8 factorial times 3 to the eighth
and one way to see that draw to bethe
veggie rubik's cube so these are these
guys are yeah these are what you might
call cubelets or cubies i think is
standard term in rubik's cube land and
so the there's eight of them and a 2 by
2 by 2 2 cubed you can essentially
permute those cubies within the cube
however you like that's 8 factorial and
then each of them has three possible
twists it could be like this it could be
like this or it could be like this ok so
you've got three for each and this is
actually an accurate count you're not
over
counting the number of configurations
all of those are at least in principle
conceivable if you take apart the cube
you can reassemble it in each of those
states and that number is about 264
million okay which is not so bad for
computers you could search that life is
a little bit easier you get two divided
by 24 because there's 24 symmetries of
the cube 8 times 3 you can divide by 3
also because only 1/3 of the
configuration space is actually
reachable if you're not allowed to take
the parts apart you have to get there by
emotion you can only get to 1/3 of the
two 2 by 2 by 2 so it's a little bit
smaller than that if you're actually
doing a breadth-first search which is
what you're going to be doing on your
problem set but in any case it's
feasible
okay that is vertices should talk about
edges for every move every move takes
you from one configuration to another
you could traverse it in one direction
I'll make that move you could also undo
that move because every move is undoable
in a rubik's cube this graph is
undirected or you can think of it as
every edge works in both directions so
so this is a move is called a quarter
twist some it's a controversy if you
will some people allow a whole half
twist as a single move whether you
define that as a single move or a double
move not that big a deal just changes
some of the answers but you're still
exploring essentially the same graph
so that's the graph and you'd like to
know some properties about it so let me
draw a picture of the graph I'm not
going to draw all 264 million vertices
but in particular there's the solved
state we kind of care about that one
where all the colors are aligned then
there's all of the configurations you
could reach by one move so these are the
possible moves from solve state and then
from those configurations there's more
places you can go
maybe there's multiple ways to get to
the same node
okay but these would be all of the
configurations you can reach in two
moves okay and so on and at some point
you run out of graph so there might be
some ways to get there might be a few
things
she knows out here these are kind of the
way I'm drawing this this is everything
you can reach in one move and two moves
and three moves at the end this would be
11 moves if you if you allow half twists
and I guess as puzzlers we're
particularly interested in this number
which you would call as a graph theorist
the diameter of the graph puzzlers call
it God's number if you were God or some
me something being you have the optimal
algorithm for solving the Rubik's Cube
how many moves do do you need if you
always follow the best path and the
answer is in the worst case 11 so we're
interested in the worst case of the best
algorithm for 2 by 2 by 2 the answer is
11 for 3 by 3 by 3 the answer is 20 that
was just proved last summer with a
couple years of computer time for a 4 by
4 by 4 I don't have one here I think
we'll never know the answer for 5 by 5
by 5 we'll never know the answer for 6 4
same deal but for 2 by 2 by 2 you can
you will compute it on your problem set
and it's kind of nice to know because it
says whatever configuration I'm in I can
solve it in 11 moves but the best known
way to compute it is basically to
construct this graph one layer at a time
until you're done and then you know what
the diameter is the trouble is in
between here this grows exponentially at
some point it decreases a little bit but
getting over that exponential hump is
really hard
good morning everyone this is your buddy
Keisha and today we are gonna discuss
graph theory and then later we'll
discuss that first search algorithm with
Java code so before talking about the
definition of the graph theory let's see
some more real life scenario
oh so for example in an airline route
okay in an airline route map if we need
to find that what is the fastest way or
the cheapest way to go from one station
to another one place to another is for
example so has about two New York so
what will be the cheapest and fastest
way to go from those okay to that
location so before answering this
question we should have some data for
example that you need information about
interconnections between objects so here
interconnections mean means Airlines
truth and objects means that towels are
so we are the graph or the data
structure are used for solving this kind
of problems so one my screen you can see
this diagram here which I have a few
notes like ABCD we call these loggers
vertex and the link which are joining
these nodes are called ages so link from
A to B your B to C are called the ages
so yeah I will here is the definition
like a graph is a pair V comma E where
we we denote V vertices to be and then
ages 2 is so where V is the set of nodes
called vertices and E is the collection
of pairs of vertices called ages so this
is the normal definition of graphs so
these are the application of graphs like
representing relationship between
components and electronic circuits or
the transportation network like highway
network or we just
to talk about this flight Network then
coming to a networks for example name
and not banner men but yet land and then
databases like in databases we have er
diagrams so er diagram is nothing but a
graph representation you can represent
yes I am using craft so we are
discussing about algorithm and Java code
yes we need to discuss that how we are
gonna represent our graph or we will
take data from the user and will store
and which form so here we can we can
store data or we can yeah we can store
data in graph using three wheels like
adjacency matrix adjacency list and a
distance is set so we'll give the basic
understanding about these three
representations and Addyson see this
I'll show you
like Lu that is contain lists for
storing my data for the graph data
structure so here is my adjacency matrix
representation on screen you can see
that I have four nodes called a B C and
D so what I did have created one array
of n plus n plus 1 Cross and plus 1 well
n plus 1 n is my number of load so yeah
so you can see that term what we need to
do is if there is a link or if there is
an edge between these two nodes then we
will put 1 as will give you a 0 so you
can see from a to a we don't have any
age okay we don't have any loop self
loop if it is a 2 it will be self loop
so we don't have any test looper I have
given here 0 then a to be let's check
from A to B now we have age so I gave
here 1 and so on so this is called my
identity matrix now let's see adjacent
to it so here is the adjacency list
representation what we are going to do
what we are doing here that you can see
this ABCD and so see I have created one
linked list
ABCD first and then for each node I have
created one new linked list so you can
he a is connected to B ending so as
given A to B then B to D soon B is
connected to C and nothing else
so B is connected to C then C is
connected to a and D so C is D and these
B I think yeah G is not connected with
anything so yeah we just gave the simple
link now addition C list sorry adjacent
is that said so I am NOT going into
detail about adjacency list that but it
is similar to add essentialist
but here instead of linkage we use
disjoint set now what is disjoint set
and what is add essential is that so I
will discuss all this think in future if
I create some video lecture then
definitely I'll and describe these
things into that but for the time being
you see the depth first search algorithm
and letter will see the Java code so
here on the screen you can see my graph
and I'm gonna use this graph to describe
my algorithm and the same graph I use
for my java code so as you can see you
guys are created one log graph on the
screen and in da face the concept is
very simple what we do we use here one
tag balrog sorry we use here one adding
so just call the array elements visited
so once I visited each one load I I just
gave the value one for that location so
I will create the visited array of the
side which is equivalent to the number
of nodes in this graph so in this graph
1 2 3 4 5 6 7 8 8 number of rules are H
so the size of my visited array will be
8 so initially I come to this node and
process this node so what I do I will
just print the data what whatever it
whatever is here
and then we'll give value one to this in
my visited array I later I'll come to
this node because it is depth-first
search so pulse will go into that and
then we'll come back we'll back
backtrack so second time this load will
be will get present third time will not
go here because this is not bread for
search I'll tell you in Bristow search
we do level order traversal and in that
first search we do preorder traversal so
next time we'll go here and then here so
because we covered each - okay and then
later we'll come so I will backtrack to
this route and then now we'll visit this
node now - first search suggests this
load now again it we need to go to - not
will cover the we are not traversing or
using level order so this load will get
visited and then this node so this is
the simple concept of depth-first search
now see me as let's see the algorithm so
while the screeners have algorithm order
the portion of my java code so what I am
doing here is I have graph DFS function
this caucus is nothing but my
constructor of dark leadership class DFS
class so what it is taking it is just
taking in to be the number of nodes okay
so this thing is they are using this
thing for the graph creation so number
of nodes in our case it is 4 because
initially I told you that I am going to
use one graph let me show you that graph
so yeah here is the gap so I'm using 4
node which is 0 1 2 3 and then 0 is
connected through 2 and 1 and then 2 is
again connected to 0 1 is connected to 2
and then 2 is connected to 3 and then 3
is
three has a self-loop surface connected
with train itself only so as you can see
that I am using here adjacent list I
showed you that in addition clear so I
have one list node which is linked list
whose size is equivalent to the number
of node and for each node and create a
new link list let me show you the that
picture once again so in here what I did
I have four cloves ABCD so as created
one linked list of sites for ABCD and
each load of the linked list is
connected or is is itself a linked list
okay so a is connected to B B is
connected to D D is and in connected to
a okay so I'm gonna use this
representation for my program so this
code graph DFS is doing nothing it is
taking number of nodes v and then it
will create one linked list of for size
B and then we'll iterate a loop to be
till V and then our each node of the
linked list builder will have one new
linked list itself now what the main
logic is this one BFS what we are doing
we have created one visited node with
the size of V V where V is the number of
vertices or number of nodes and then
this small V is my source node or the
first node for example in a graph if I
want to traverse from to lots of first
close but from the second node so we are
just give you two instead of one what I
do first I'll mark it mark that node to
true okay and then we'll simply print
the value of that we now will iterate
that we will iterate the linked list
associated to that
Vinod okay so that is adjacent we got
list iterator
so I hope you understand the concept of
for iterator
mr. crater basically traitor will
traverse in forward direction where is
this traitor we can traverse in backward
direction and forward as well now if I
dot has liked if we have learning then
do nothing just I dot next just get the
value in N and then if a visited n is
not marked then just recursively call
this DSS function if it is already
visited then we don't need to go into
that function once again so yeah this is
the counter plus C Java program so here
I have already created but a Java
program if you want to load down you can
not download it as completely scroll
down or the code so what I'm doing you
see this graph DFS is my classroom now
here I have declared two variables like
one is V where V is the number of
vortexes and then second is linked list
which is of type graduate and then this
is the constructor of for this graph DFS
class and what this constructor is doing
is just creating graph for us with the
size which has the number of vertices is
equivalent to this for me I already
covered this part that what we are going
to we are doing here that we are
creating one linked list and then called
off size B and then for that linked list
each node is associated with the new
linked list which is this at adjacent I
put two new linked list now so this add
inch function will do nothing it will
add ages into your row add edge into
your graph so from V to W so if it is
from V to W so definitely be will be my
first linked list and W will be the
associated linked list of is back the
first linkage I hope you understand like
the V will be the part of this adjacent
and then W will be the part of this new
linked list node and then this BFS
concept I have already explained that
term of
we'll mark the current flow to true
we'll print the value of that node and
then we'll iterate using the linked list
iterator for that node V if it is not
visited then called the FS function or
if it is visited then going to so this
is my main method what I am doing and
thus creating when the object G of graph
DSL adding ages into that so this graph
is similar to the graph which I was
loved
show them previously and then I have
created one visited node of Versailles
we will variable definitely because I am
assigning very true faucet rate or you
can we create this visited into in
others DFS class itself you don't need
to pause this visited well it depends on
your choice and then now here I solve
this DFS function so the thing which you
need to note here is that are given here
too okay so I need a depth first search
from the source node - not from 0 so I
am given here - so it will work
accordingly now let me run this program
and let's see what is the output so yes
it is giving me 2 0 1 3 which is
required so that's it guys I hope you
liked my video thank you for watching
thank you once again
welcome to our 28th video with data
structures and algorithms let's do an
example with disjoint sets so we have a
list of elements here a through H and
the first thing that we're going to do
is we're going to perform the mix set
operation on each one of these and that
is going to create a cell a list of or a
bunch of singleton sets out of each one
of these so let's do that so when we do
mix sets of a ok we're going to have a
by itself we're just going to represent
it like this ok so it's parent is itself
B is our next one right same thing so
we're going to do this for all of them
that's kind of crappy looking ok so c d
e f g and h okay now a couple things
here each one of these sets has a rank
right and so the rank starts off at 0 ok
so let's just write these ok there we go
and let's visualize this set in a more
in a different notation so this is the
set right of A and it is the
representative so we're just going to
mark it like that so same thing with all
of these we've got B and C D
you get better drawing these curly
braces F G and H just kind of getting
lazy here okay so we can see that each
of these is own set and its
representative is the underlined element
it's so far it's just the one now let's
do this little sequence here of union
operations so we are going to use union
by rank and find with path compression
and we'll explain what that means as we
go through so when we when we union a
and B for instance we are going to link
the representative of this out of this
set with the representative of this set
right so first thing we have to do is we
have to find the representative okay of
each set so far a is the representative
of its own set and B is the
representative of its own set now we
said we're going to union by rank that
means if they have whoever has the
higher rank will end up being the
representative of the Union set okay
that's a mouthful but rewind and listen
to that again to make it clear when they
have the same rank
the second element here right this this
guy over here will end up being the
representative of the Union set so it
will be the parent of this set let's see
that in action let's do all of these
kind of all in one so when we Union a
and B they both have their the same set
all of these will have the same or they
have the same rank I mean all these will
have the same rank so far so let's do
that a and B we said that B right we
said that the second element is going to
be the new representative of this set
okay so here's a
right a and B okay we Union to those two
and we'll show what the set looks like
in just a sec so we said that D will be
the representative of this one so C is
here we've said that e is going to be
the representative of this one and G
will be the representative okay of this
set and also when we union two elements
there are two sets I mean and they have
the same rank then the the rank of the
representative right will go up by one
okay when we have the same rank so now
the Reppert this rank will be 1 1 1 and
1 and we're not going to worry about the
rank of these ones down here because we
no longer really need that only the
representatives so let's draw the actual
sets and let's see what they kind of
look like now right and B is the
representative so you can see that we
Union these two sets up here okay they
are now in the same set and B is now the
representative of that Union set so we
have C D and we have E and F and we have
G and H okay so there's our
representatives and there we go so let's
go down to the next little sequence of
unions Union operations now we're going
to Union a and C so like we said first
thing we have to do is we have to find
the representative a and find the
representative of C the representative
of this set right is B so we are going
to link B and the representative of this
set is D so we're going to link B and
now they have the same rank so again the
second one okay is going to be the
parent of the group of the new
representative so let's see what that
looks like
so we have D up here and that is going
to be the representative of this set so
now we have B and a okay and again they
had the same rank right so this rank
goes up by one and we will do the same
for this next one H and E right so he
happens to be the representative of this
group and H is G is the representative
this one a is this second argument here
in the Union so it's going to be the the
new representative since the ranks are
the same so up here we have E and we
have F and then we have G and H over
here and again since they have the same
rank we will increment this rank up by
one so let's do draw out the new sets
here that we have B C D okay and D is
the representative and then we have e F
G and H in this new set and E is the
representative of that set let's go down
to this one how about a B now we said
we're doing find with path compression
so what's going to happen here when we
do an FYI Union a B well first thing
that we're going to do find with path
compression on a what that means is let
me just get a different color let's get
this color when we go through here we're
going to start here at a and we're going
to move up to B I don't know why I did
it like it
curved line there okay we're going to go
up to B and we find out that that is not
the representative right so we're going
to go up again and we're going to find
out that D is the representative now
when we do path compression every
element along this little path that we
went to will now point directly to D we
wanted to compress the path because as
we searched to find the representative
of this element down here we found out
that the representative of this element
and this element and every element in
this little path every node that we had
to skip over right or go through they
all can now point to this representative
so now we can make them closer to this
element by changing all their parent
pointers to D so let's do that and that
was just the find operation that did
that okay find with path compression we
still haven't unioned anything just yet
actually I want to do a over here so
let's do a B and C
okay again we have not unioned anything
we haven't linked anything yet so D
would be returned right here right when
we do find on B we find that it's part
it's representative is D so we're going
to Union D and D right but it's the same
it's the same element so we don't
actually link it together it's already
there now a good something we need to
mention is that this rank did not change
okay
let's remember that and also we're going
to draw our other sets just to show that
nothing changed in this set because we
didn't do anything to it so we're going
to have G and H okay and also it's just
right it's rank still - let's do one
more Union and see what happens here so
we're going to Union C and H now again
we're going to find the representative
of C which is D and we're going to find
the representative of H which is e and
remember that we do we did find with
path compression so this one's going to
kind of this set is going to kind of
look like this set up here and actually
I just forgot let's draw these sets
really quick so you can kind of see what
they look like so a B C and D and we
found that they just look the same right
use the representative okay just want to
have that for our reference down here so
let's do this all in one
okay so when we union this right we're
going to Union this set right DS set and
E's set now these set looks a little
different now remember because we did
find with path compression so I'm just
going to kind of draw that here
okay so H is now linked to e directly
and color there we go and we find that D
right when we found this and we find
this D and E have the same rank so ease
set E is going to be the representative
okay
so let's draw e up here kind of at the
top as the representative then we have D
no that's an a not a d D then we have F
G and remember H now points to e because
we did find with path compression so
let's draw the rest of these we have a
we have B and we have C and remember the
rank of this one goes up by one and
let's draw our final set here we have a
b c d e f g and h and e is the new
representative of our set
in our previous lesson we introduced you
to graphs we defined graph as a
mathematical or logical model and talked
about some of the properties and
applications of graph now in this lesson
we will discuss some more properties of
graph but first I want to do a quick
recap of what we have discussed in our
previous lesson a graph can be defined
as an ordered pair of a set of vertices
and a set of edges we use this formal
mathematical notation G equal V II to
define a graph here V is set of vertices
and E is set of edges ordered pair is
just a pair of mathematical objects in
which order of objects in the pair
matters it matters which element is
first and which element is second in the
pair now as we know to denote number of
elements in a set that we also call
cardinality of a set we use the same
notation that we use for modulus or
absolute value so this is how we can
denote number of vertices and number of
edges in a graph number of vertices
would be number of elements in set V and
number of edges would be number of
elements in set E moving forward this is
how I am going to denote number of
vertices and number of edges in all my
explanations now as we have discussed
earlier edges in a graph can either be
directed that is one-way connections or
undirected that is two-way connections a
graph with only directed edges is called
a directed graph or digraph and a graph
with only undirected edges is called an
undirected graph now sometimes all
connections in a graph cannot be treated
as equal so we label edges with some
weight or cost like what I'm showing
here and a graph in which some value is
associated to connections as cost or
weight is called a weighted graph a
graph is unweighted if there is no cost
distinction among edges okay now we can
also have some special kind of edges in
a graph these edges complicate
algorithms and make working with graphs
difficult but I'm going to talk about
them anyway an edge is called a self
loop or self edge if it involves only
one vertex
if both endpoints of energy are same
then it's called a self-loop we can have
a self-loop in both directed and
undirected graphs but the question is
why would we ever have a self-loop in a
graph well sometimes if edges are
depicting some relationship or
connection that's possible with the same
node as origin as well as destination
then we can have a self loop for example
as we have discussed in our previous
lesson interlinked web pages on the
internet or the world wide web can be it
presented as a directed graph a page
with a unique URL can be a node in the
graph and we can have a directed edge if
a page contains link to another page now
we can have a self loop in this graph
because it's very much possible for a
web page to have a link to itself have a
look at this web page my code school
comm / videos in the header we have
links for workouts page problems page
and read your age right now I'm already
on videos page but I can still click on
videos link and all that will happen
with the click is a refresh because I am
already on videos page my origin and
destination are same here so if I'm
representing world wide web as a
directed graph the way we just discussed
then we have a self loop here now the
next special type of edge that I want to
talk about is Multi edge and edge is
called a multi edge if it occurs more
than once in a graph once again we can
have a multi edge in both directed and
undirected graphs
first multi edge that I'm showing you
here is undirected and the second one is
directed now once again the question why
should we ever have a multi edge well
let's say we are representing flight
Network between cities as a graph a city
would be a node and we can have an edge
if there is a direct flight connection
between any two cities but then there
can be multiple flights between a pair
of cities these flights would have
different names and may have different
costs if I want to keep the information
about all the flights in my graph I can
draw multi edges I can draw one directed
edge for each flight and then I can
label
and edge with its cost or any other
property I just labeled edges here with
some random flight numbers now as we
were saying earlier selfloops and multi
edges often complicate working with
graphs the presence means we need to
take extra care while solving problems
if a graph contains no self-loop or
multi edge it's called a simple graph in
our lessons we will mostly be dealing
with simple graphs now I want you to
answer a very simple question given
number of vertices in a simple graph
that is a graph with no self loop or
multi-edge what would be maximum
possible number of edges well let's see
let's say we want to draw a directed
graph with four vertices I have drawn
forward DC's here I will name these
vertices v1 v2 v3 and v4 so this is my
set of vertices number of elements in
set V is 4 now it's perfectly fine if I
choose not to draw any edge here this
will still be a graph set of edges can
be empty nodes can be totally
disconnected so minimum possible number
of edges in a graph is 0 now if this is
a directed graph what do you think can
be maximum number of edges here well
each node can have directed edges to all
other nodes in this figure here each
node can have directed edges to 3 other
nodes we have 4 nodes in total so
maximum possible number of edges here is
4 into 3 that is 12 I have shown edges
originating from a vertex in same color
here this is the maximum that we can
draw if there is no self loop or
multi-edge in general if there are n
vertices then maximum number of edges in
a directed graph would be n into n minus
1 so in a simple directed graph number
of edges would be in this range 0 to n
into n minus 1 now what do you think
would be the maximum for an undirected
graph in an undirected graph we can have
only one bi-directional edge between a
pair of nodes we can't have two edges in
different directions so here the maximum
would be half of the maximum for
directed
so if the graph is simple and undirected
number of edges would be in the range 0
to n into n minus 1 by 2 remember this
is true only if there is no self loop or
multi-edge now if you can see number of
edges in a graph can be really really
large compared to number of vertices
for example if number of vertices in a
directed graph is equal to 10 maximum
number of edges would be 90 if number of
vertices is 100 maximum number of edges
would be 9900 maximum number of edges
would be close to square of number of
vertices a graph is called dense if
number of edges in the graph is close to
maximum possible number of edges that is
if the number of edges is of the order
of square of number of vertices and a
graph is called sparse if the number of
edges is really less typically close to
number of vertices and not more than
that there is no defined boundary for
what can be called dense and what can be
called sparse it all depends on context
but this is an important classification
while working with graphs a lot of
decisions are made based on whether the
graph is dense or sparse for example we
typically choose a different kind of
storage structure in computer's memory
for a dense graph we typically store a
dense graph in something called
adjacency matrix and for a sparse graph
we typically use something called
adjacency list I'll be talking about
adjacency matrix and adjacency lists in
next lesson ok now the next concept that
I want to talk about is concept of path
in a graph a part in a graph is a
sequence of vertices where each adjacent
pair in the sequence is connected by an
edge I'm highlighting a path here in
this example graph the sequence of
vertices a B F H is a path in this graph
now we have an undirected graph here
edges are bi-directional in a directed
graph all edges must also be aligned in
one direction the direction of the path
part is called simple path if no
vertices are repeated and if what
disease are not repeated then edges will
also not be repeated so in a simple path
both vertices and edges are not repeated
this path a bfh that I have highlighted
here is a simple path but we could also
have a path like this here start vertex
is a and end vertex is D in this path
one edge and two vertices are repeated
in graph theory there is some
inconsistency in use of this term path
most of the time when we say path we
mean a simple path and if repetition is
possible we use this term walk so a path
is basically a walk in which new
vertices or edges are repeated of walk
is called a trail if what disease can be
repeated but edges cannot be repeated I
am highlighting a trail here in this
example graph ok now I want to say this
once again walk and path are often used
as synonyms but most often when we say
path we mean simple path a path in which
vertices and edges are not repeated
between two different vertices if there
is a walk in which vertices or edges are
repeated like this walk that I am
showing you here in this example graph
then there must also be a path or simple
path that is a walk in which what
disease or edges would not be repeated
in this walk that I'm showing you here
we are starting at a and we are ending
our walk at C there is a simple path
from A to C with just one edge all we
need to do is we need to avoid going to
be e H D and then coming back again to a
so this is why we mostly talk about
simple path between two vertices because
if any other walk is possible simple
path is also possible and it makes most
sense to look for a simple path so this
is what I'm going to do throughout our
lessons I'm going to say path and by
path L mean simple path and if it's not
a simple path I will say it explicitly
our graph is called strongly connected
if in the graph there is a path from any
vertex to any other vertex if it's an
undirected graph we simply call it
connected and if it's a directed graph
we call it strongly connected in
leftmost and rightmost graphs that I'm
showing you here we have a path from any
vertex to any other vertex but in this
graph in the middle we do not have a
path from any vertex to any other vertex
we cannot go from vertex C to a we can
go from A to C but we cannot go from C
to a so this is not a strongly connected
graph remember if it's an undirected
graph we simply say connected and if
it's a directed graph we say strongly
connected if a directed graph is not
strongly connected but can be turned
into connected graph by treating all
ages as undirected then such a directed
graph is called weakly connected if we
just ignore the directions of the edges
here this is connected but I would
recommend that you just remember connect
it and strongly connected this leftmost
or undirected graph is connected I
removed one of the edges and now this is
not connected now we have two disjoint
connected components here but the graph
overall is not connected connectedness
of a graph is a really important
property if you remember intra-city road
network road network within a city that
would have a lot of one-ways can be
represented as a directed graph now an
intra-city road network should always be
strongly connected we should be able to
reach any street from any street any
intersection to any intersection ok now
that we understand concept of a path
next I want to talk about cycle in a
graph a walk is called a closed walk if
it starts and ends at same vertex like
what I'm showing here and there is one
more condition the length of the walk
must be greater than 0 length of a walk
or path is number of edges in the path
like for this closed walk
that I'm showing you here length is five
because we have five edges in this walk
so a closed walk is walk that starts and
ends at same vertex and the length of
which is greater than zero now some may
call closed walk a cycle but generally
we use the term cycle for a simple cycle
a simple cycle is a closed walk in which
other than start and end vertices no
other vertex or edge is repeated right
now what I'm showing you here in this
example graph is a simple cycle or we
can just say cycle a graph with no
cycles is called an acyclic graph a tree
if drawn with undirected edges would be
an example of an undirected acyclic
graph here in this tree we can have a
closed walk but we cannot have a simple
cycle in this closed walk that I'm
showing you here our edge is repeated
there would be no simple cycle in a tree
and apart from tree we can have other
kind of undirected acyclic graphs also a
tree also has to be connected now we can
also have a directed acyclic graph as
you can see here also we do not have any
cycle you cannot have a path of length
greater than 0 starting and ending at
the same vertex or directed acyclic
graph is often called a dag cycles in a
graph caused a lot of issues in
designing algorithms for problems like
finding shortest route from one vertex
to another and we will talk about cycles
a lot when we will study some of these
at one still go our thumbs and coming
lessons for this lesson I will stop here
now in our next lesson we will discuss
ways of creating and storing graph in
computer's memory this is it for this
lesson thanks for watching
hello guys you will be seeing a C code
for adjacency list representation of a
directed or undirected graphs in this
video so first of all we should have a
basic knowledge about graphs so what is
a graph so we would give a brief
introduction about graphs so graphs are
nothing but it has a data structure that
consists of two components first it
candy it contains a finite set of
vertices second it contains a finite set
of ordered pairs which are of the form
UE these are also called edges so what
does a graph consists of it consists of
two components which are number of
vertices which are set of vertices and
set of edges which comprises whose graph
so let's illustrate it with the pigs
ample so what a graph consists of set of
vertices and set of edges so let's say
these are the vertices 1 2 &amp; 3 &amp; 4 so
the lines which connect them forms and
edges of the graph so these are called
vertices of the graph and these are
called the edges of the graph so now we
have a
now we have a brief knowledge about
graphs so let's get to this so why we
said these are the ordered pairs ordered
pair because here the order patterns
because if you will see that 1 2 is an
age you can't say always a 2 1 is also
off will also form an edge so we will
see now in which graphs we can say that
1 1 2 is same as 2 1 where the order
does not matter there you can say that
if there is an edge from 1 to 2 there is
an edge from 2 to 1 also so these are
typically let's say we have two types of
graph for this first is undirected
graphs these have a pair of an ordered
vertices hey UV is same as we let's say
we can say in these type of graphs as 1
2 is same as 2 1 for example in this
graph 1 2 is an edge 2 1 is also an edge
because we aren't well we have we are
allowed to go anywhere in this graph so
1 2 is same as 2 1 in this graph so
these type of graph forms and undirected
graphs what we call that undirected
graphs so if we a lot directions to them
let's say if we are given these type of
directions here 1 2 is not same as 2 1
you are allowed to go from 1 to 2 1 2
phones an edge but to one not for the
rich let's not form the gauge white 2 1
does not form an edge because you are
not allowed to go from 2 to 1 but you
are allowed to go from 1 to 2 all right
so 1/2 is 1/8 but to what is not an inch
so these type of graphs where we are
allowed to go in one direction in the
direction which we are given we can we
are allowed to go in that direction only
we call that type of graph story
two drafts so if your Lord directions
with the a directed graph that becomes
directed graph so this was all about
graphs now you will see its
representation how we can represent it
represent a graph so we will be seen now
how we can represent a graph we can
revisit the graph using to the help of
two methods so first as with the help of
adjacency list and second one is with
the help of adjacency matrix so in this
video we will be seeing how we can
represent a graph using a distance a
list what we will do to represent a
graph using a distance a list so what we
will do so let's say if we have a graph
that I'll what theis is let's say it has
five vertices and this graph let's say
is an undirected one we are allowed to
go anywhere through the edges we can go
from one to two you can also go from two
to one also so this is an undirected
graph so let's say it's if this is a
graph so if we want to represent this
graph using adjacency list what we will
do is so we will create an array of
linked lists we will create an array of
linked list and that the size of the
array would be the number of vertices
that we have in a graph so in this graph
we have five vertices so our array size
would be five so this would be array and
this would this array would correspond
this array would be the array of linked
list so each entry in the array would
correspond to the linked list like this
this would be pointing to a linked list
this would also point to a linked list
this entry would also go into a linked
list this entry would also point to an
linked list so watched what would be
contained in that look list so each
entry in the array would be the set of
vertices let's say we have five vertices
so each entry in this would correspond
to the word linked list of vertices
which are adjacent to one so what are
the vertices that are adjacent to one
these are two and five right so this
entry would correspond to the linked
list which will contain what Isis -
inside that far
adjacent to one similarly for 2 what are
the vertices that are adjacent to two
these are 1 and 3 right so this entry
would correspond to the word Isis that
are adjacent to 2 these are 1 and 3 this
would point to null this will also point
to lunch similarly for 3 what are the
vertices that are adjacent to 3 these
are 4 and 2 right so this would be
forming a linked list correspond to
correspond corresponding to the edge s
is what our dices 2 3 so these word for
n 2 so we created a linked list with 4
and 2 3 a - just 2 3 similarly for 4
what are the adjacent toward Isis - for
these are 3 inside so we would attach we
will attach three in five think this
with that similarly 4 5 so what are the
adjacent what Isis - fine these are 1 &amp;
4 so they will be forming a linked list
that will contain vertices that are
adjacent to 5 so this is what a graph
will look like a favored trip
in the form of adjacency list now we'll
be seeing a seafood for representing a
graph using adjacency list
could it be quickly seen what is an
articulation point or a cut vertex in a
graph so let's say we are given a graph
then articulation point or cut vertex is
a point is the vertex removing which
will disconnect the graph so in this
connected graph if we remove two then
the graph it is connected into this and
this two graphs so two is a cut vertex
one is not three is not because knowing
three will give us one connected with
two which is the connected graph now let
us see this example in this this one is
the connect is a red vertex because
removing this will give us this and this
so two connected components so this is a
cut vertex similarly this is also a cut
vertex and so on
so no more cut vertex for this
absolutely and if we are let us say
given a forest so this one let us say
this is the forest then in this forest
this one is the cut vertex because right
now there are two connected components
if we are removing this it will result
in three connected components one two
and one two and three so this is a cut
vertex there is no other cut vertex as
you can see it is so cut vertex this is
the definition of cut vertex or
articulation point a graph hope you
understood thank you friends please like
share and subscribe
the problem we're going to talk about
today is surface matching and I would
like to place it in kind of a more
global context and first of all what is
surface matching so surfaces are what we
call a two dimensional manifolds as
mathematicians but also can simply
intuitively explain as outer shells of
solids in the three-dimensional world
around us so there are two-dimensional
objects that folded in some interesting
shapes and basically they could
comparison comparing those comparing
surfaces is a core element in many in
many scientific fields and this is by no
means an exhaustive list but just few
interesting applications of confer of
comparing surfaces one is related to
data mining so we think you have a
database of shapes you want to do a
shape retrieval based on on the on
shapes that's a problem people working
on in medical imaging obviously many
people are comparing surfaces whether
it's internal organs or the cortex
surface face matching is again
comparison of surfaces the surface the
describe the faces of people and you
want to kind of be able to recognize
people to be invariant to expressions
and so on another application which is
kind of slightly less explored is
related to biology and that's something
I'm going to emphasize on this talk I
apologize to whoever heard this talk
before that's a lot of it is from last
year so what what what is the business
of pelant ology so they are interested
in shapes and they basically look at
shapes of bones and they kind of
understood very early in their evolution
that shapes have a lot of biological
meaning not just purely functional and
basically they look at the same shape
from different species is the one I want
to extract the maximum information from
the shape in a sense they're the kind of
meta goal is to extract something like a
geometric DNA of a shape and be able to
really say something concrete about
about evolution to kind of understand
little bit what is the problem in
surface comparison when we talk about
biological forms I show you here three
of the same bone it's called the distal
radius bone from three related species
there's a gorilla human
Arango town and i rendered them
especially in this direction so you can
see there is kind of a global similarity
between them but locally it's very hard
to say something and basically when
biologists now come in nowadays to
compare those two surfaces the first
kind of notion that comes into mind is
to basically reduce the problem to maybe
a bunch of numbers or the describe each
of the surfaces then compare the numbers
in some in some reasonable way so
basically they choose points on the
surfaces measure the distance between
them and maybe compare those distances
however these methods are kind of
problematic because there's a lot of
arbitrariness in the process some one
has to choose those points in a
relatively stable weight stable to
natural deformations and it's not clear
how many points you should choose and
whether your choice is already kind of
dictating the answer and so on so this
is really a process which is very a user
dependent and it's not something what
they like to do is to be more like the
DNA colleagues where they have kind of a
way to compare strings without ambiguity
I'll show you an application which is
kind of a recent thing that we tried
which there is no other way to solve it
except using geometry so there are two
groups of species that lived on earth
and according to the current theory it
is believed that there has been a 20
million years gap between when this
species lived in this piece of you so
these by the way are teeth of certain
primates so people believe that there is
20 million years gap between them my
colleague which actually collects this
data his name is Doug Boyer he recently
found two other fossils he actually digs
in certain spots in the world and in
fine fossils and the fact that he digs
them in the same place means that
whoever owned those teeth belong to the
same era and he conjectured that one of
them belonged to one of the groups and
the other belonged to the other but in
order to convince his friends he has no
know kind of a precise way to do that
except kind of reasoning about the
geometry of the stuff and if you look at
it it's pretty hard to say something
decisive about the shapes and my goal in
this talk is to say that we can take
this discussion one level further and
to find something like a common grew up
geometric common ground on which we can
start arguing about so we can I'll
actually show you that there is a pretty
clear answer which belongs to which
group by the way the group contains more
elements I just chose represented
represent two represented representative
of each okay so now I'm going to leave
biology I'm gonna describe the
mathematical machinery that we've used
and at the end of the of the talk I'm
going to go back to this problem and I
will show you a solution okay well not
our not so a solution but let's say one
step toward the formalization of this
question so in surface matching
basically one is given two surfaces so a
surface could could be is basically
virginal think this dog here is the
surface and there are two kind of
products that people expect to get when
they matching surfaces the first product
is a correspondence which can be a map
but not necessarily as we will see which
basically means that for every point on
one surface we want to get a
corresponding point on the other surface
or more than one point and the second
product that people expect is something
which is a scholar which we will have
the natural kind of structure of a
metric which kind of encapsulate the
difference between the two surfaces in
one number this is very useful if you
think about the that like a segmentation
of shapes and so on and the first thing
that comes into mind when you want to
define a metric on this space of
surfaces is you have to choose what is
your notion of equivalence so what do
you call - when do you call two surfaces
the same so the most classical way to
say that to sums of the same is if there
is some kind of a group that will aid
them so for example congruence if there
a rigid motion one of another we
obviously don't want to consider them
different and you want a metric to be
zero the distance between them is zero a
slightly more modern point of view is
the Romanian metric which basically says
okay so this surface has an induced
Romanian matrix form its embedding and
basically all the isometric deformation
the deformations that don't change
distances on the surface do the
existences are basically all the same
the same appearances of the same object
now there is there is really vast amount
of works that try to saw
the matching problem in in very
different fields starting from
structural biology through engineering
fields the computer vision computer
graphics and I don't want to go through
and this is also not exhaustive live but
I want to kind of give the feeling that
there is a strong there is a big gap in
algorithm either there is algorithm
which are more you ristic and provide
good results on certain subclass of the
problem but have no guarantees and
indeed do poorly on other subclasses or
there are very rigorous type of
algorithms like algorithm that directly
discretize notions like home of house of
distance but then they basically boiled
down to np-hard problem when you near
it-- it down and you have to do
something like finding some global
minima based on initial conditions and
so on and it's really hard to find a
global minimum of those problems so this
space this gap is basically a very very
something that people try always to to
narrow down and and basically what what
I'll try to convince that it's actually
it can't be Nirvana little bit I don't
know to what extent but there's
definitely things that can be done in
the future to to to make it smaller so
basically there are few so from looking
at previous work the few basic questions
that comes into mind the first question
is a very simple ones if I'm giving you
two surfaces and I'm just going to ask
you a simple question can you decide
quickly
if those two surfaces are isometric yeah
so obviously if I would ask if they are
congruent if there's really motion
between them everybody going to come up
with lot of suggestions but if I ask you
whether that isometric is there a simple
algorithm when it says simple I mean
reasonable time complexity algorithm if
you can answer these questions once we
can answer this question we can go the
next step and the next step said okay so
we know to figure out when two surfaces
are symmetric that's our kind of
equivalence relation now maybe you can
use this idea to define distances
between surfaces which which have this
kernel but the distance is kind of
extend to any pair of surfaces that we
can compare not just say yes or no
whether there is no metric and maybe the
last question which is extremely big and
definitely contains the the first two
but contains much more is in general if
we take a surface comparison functional
so I want to measure distances between
surfaces can we say something about its
global optimum in a reasonable time
and what I try to convince you by the
end of the talk which is not that far
away is that for surface comparison this
the structure of the problem do often
implies that you can say something about
the global solution and I will get to
that so the main a kind of tool that
we're going to use is the notion of
conformal geometry and I'll give a kind
of a quick introduction to that so
conformal maps are a maps that are
preserving angles here's just a kind of
visualization of a map defined on this
square basically mathematically we can
answer the differential is the
similarity writing down in coordinates
it's basically the Cauchy Riemann
equations
more generally confirmed maps can be
defined between two dimensional domains
not embedded in the plane that is
differentiable surfaces and the
definition is basically the same thing
we just ask that the map the
differential of the map which is defined
between those two tangent planes at
every point is a similarity and we have
a definition of conformal Maps between
surfaces now our goal will be to compute
conformers between surfaces and use them
for something so the first part of the
talk I'm going to I'm going to quickly
say how do we compute conformance
between surfaces so for certain surfaces
everything is known so for example if we
talk about the unit sphere the entire
group of bijective conformal maps that
take the sphere to itself is the
well-known mobius group and if we part
right the sphere with the extended plane
using this famous telegraphic projection
then we have a very nice formula which
we all kind of seen before which is the
fractional in transformation of the
mobius group another canonical surface
is the unit disk and the set of all
bijective conformal mappings self
conformed maps equal to this to itself
are a subgroup of the general mobius
group and it can be parameterized in
this way the really important thing
which we're actually going to build on
in all this thing is the fact that the
dimensionality the dimensionality of
those groups is relatively small
relatively small in comparison to all
the form of physics and we know for
example that to set a memories group on
the sphere type surfaces we need this
six real degrees of freedom or three
complex degrees of freedom and for this
type surface
three real degrees of freedom which is
basically we know that also for women
mapping theorem of simply connected
surfaces a planar domains okay so what
do we need to do in order to complete to
compute all the conformal Maps so be
able to compute all the conformal
between two general surfaces so we have
these two surfaces desire again teeth
and these are homomorphic to disks so
the component that we're missing is the
uniformization theorem which is
basically a celebrated theorem that says
that if we have a simply connected
surface let's say homomorphic to disk
then we can map it globally by ejective
Lee and conformally to the disk once
we've done that we basically now can
explore all the conformal maps between
the surfaces by exploring Mobius
transformation from the disk to itself
so for example here I just pick one
Mobius transformation between the disks
and I compose them with the with the
uniformization in this way and basically
I'm showing you now the conformal map
that that this Mobius element represents
so you can appreciate this conformal
because the grid is orthogonal here and
orthogonal there okay I mean that the
intersection is always 90 degrees so it
means that the angles are preserved it's
not a proof but it's kind it gives the
feeling so it's it's it's basically
approximating an elliptic partial
differential equation finite element
linear but we I can I have slide about
that we can talk about it later let's
say that for this thing you do it once
and then once you do it there is a
closed form formula for the Mobius
transformations and you can basically
explore them in an efficient way how do
you say anything about our multi metric
so far just confirmed mappings something
more general I didn't say anything about
metric now I'm going to say something
about metric so the first problem we're
going to ask is where the two surfaces
are isometric okay so we want to answer
that quickly I want it I want to contact
I want to I want to say that confer maps
can help us to do it very quickly
and the reason it's kind of obvious let
me explain so what what do you mean
again by a dormitory for let me remind
quickly so we have a surface we
basically want to define a metric on it
and we define a metric by taking two
points on the surface and defining their
distance the geodesic this
to be the length of the shortest curve
the class on the surface between the two
points this kind of make this a metric
space which we can call a Romanian
metric we call two surfaces isometric if
there is a map between them which
preserve all those pairwise distances so
that's eye geometry and now given two
surfaces how do we decide or and if
there are symmetric so the really simple
observation here is that isometry is in
particular a projective conformal map
one way to see it from the way I defined
a geometry is that if we take a very
small geodesic triangles they behave
very similar to cleveland triangles and
we all know from high school that
setting three lengths of a triangle also
makes the triangles congruent right so
the angles are also preserved so that
that would mean if we take this
interface female point of view that
isometry is a conformal map so what so
which means that if there is an isometry
it lies in a very small space relatively
to all possible D formalism it lies in
the conformal group which we only said
his six or three degrees of freedom so
it's only enough to look in that space
and we also have an efficient way to
search that space so here's an algorithm
for finding a symmetry we take a surface
we map it to numerical approximation to
the disk conformally we take another
surface we do the same thing by the way
what is this landscape here when we map
something conformally we preserved
angles perfectly but but obviously we
didn't preserve the scaling right we
cannot this is not a flat metric we
cannot flatten it without an arrow so
the information said we can make sure
that angles are preserved but the scales
will be significant so here basically
now it's we can save a positive scholar
function which define how much scale
happens so we can imagine that this peak
it kind of correlates to places with
high Gaussian curvature yeah so
basically the simple observation says
that if those two isometrics there's a
Mobius transformations that takes this
landscape I would call it a density
that's the conformal factors by the way
take this conformal density to this
conformal density so we can just if you
want random of information and see if we
can get from this image to that image
that we mean the two surfaces isometric
here's a an experiment so here's a tooth
versus these are the approximation that
we do for an information I don't want to
talk too much about the actual way how
we do it all I want to say is that we
can kind of expect that these two
surfaces are near isometric why because
when cat moves we can expect that its
skin doesn't stretch too much which
means that the distances intrinsic to
the car do not stretch too much that
that's a vague argument but it means
that if we take that three points three
points again that's exactly six degrees
of freedoms of the Moriscos formation if
we take three points which are kind of
corresponding and we align those three
points in the uniformization space by
aligning the by Morris transformation we
can expect that if we took points from
an isometry or near isometry
then everything else would be rearranged
and we kind of explore pilate's the we
reconstruct the this asymmetry
everywhere so let's do that so I'm just
gonna apply a Mobius transformation here
and what you see happen is that those
black spots here arranged similarly to
the black spots here these black spots
basically could correspond to the
different limbs of the cat so the leg
hand so this is probably the front leg
this is maybe the head node head the leg
and this is the tainment you see that
the image looks very similar so it kind
of gives the sense that you can think
about polynomial algorithm in complexity
of n2 the cube in the number of points
to find a geometries if they exist so
that's the first proof of concept and
now we can move to the real problem of
how to define in AI geometry invariant
distances between general surfaces not
just isometric ones or near the metric
ones in in a which are also efficient so
the point of view is like in including
geometry when you were present
quantities we always like to represent
them in a way which is a rigid motion
invariant why because we don't want to
bother a circle things we don't care
about so we don't care about orientation
of stuff so let's represent it in
environment way the same thing a the
same kind of concept should apply also
to other geometries so if we have a
surface the last thing that we want to
do is remember the surface in
coordinates right a so the formal
discussion kind of gives a natural way
to represent a surface which is
basically an orbit of the conformal
densities up to a Mobius transformation
so this is kind of an object I'm not
suggesting to keep that in a computer
yeah but that'sthat's
conceptually a good thing to think about
why so here's a good reason let's say
that we want to define a metric between
between surfaces and we have a good
metric between measures or between
densities and that we all know that
there are many good measures distance
metrics between measures say let's say
probability measures then there is a
canonical way to connect whatever we got
there to surfaces and how do we do that
we take some metric between probability
measures and then we basically just do
metric quotient thing so we place here
the orbits of of the confirm factors up
to the mobis group and we automatically
would get a metric between surfaces so
basically this kind of a simple idea
connects between general metrics and
measures two metrics on surfaces and the
question now is what kind of metric to
use a choice of metric which is
favorable for this problem is what is
called the vasa style metric and the
vastest time metric is basically a kind
of a metric between distribution or
probability measures which has kind of a
physical intuition basically it says
that it basically looks at things of the
two densities as pile of dirt or a pile
of some pile of some material of mass
one and you want to rearrange this to be
in this configuration you want to do it
as efficient as you can so what is mean
is efficient it means that whatever you
move this is the distance you multiply
but how much you move that's kind of a
cost that takes you from this to there
and obviously there are many ways to
rearrange basically how many ways other
to rearrange these two probability
measures basically you can look at all
measures on the product space which have
a marginal of this density on the left
and this density on the right and this
we can call this is a huge space right
and we we want to choose over this space
the one which does the best so we use
this concept for generalization and you
get you get an algorithm to define
decisions between surfaces and the
bottom line is that is the convex
algorithm because this thing boils down
to linear programming I'm not going to
get too much too details because I want
to talk about the third part on the
biological applications so I'm going to
say whatever I said so far in different
words and
with just images so what did we do you
know what how did we define distances on
surfaces so we had this huge space of
air preserving by measures it means that
measures on the product space of the two
surfaces with the marginals and what we
did is looked for a minimum on the space
up to some functional this is a huge
space however luckily when you
discretize it use explaining some points
on the surfaces and so on this space
comes it becomes a convex polytope right
that's basically those linear
programming constraints we want the sum
of the matrix to to equal one density
and the rows sorry the columns would
sound to the second density and the rows
would summon to the first density and we
get a very nice convex polytope and we
can optimize it in linear in in
polynomial time and then what what do
you do with it we said basically now if
you only use that framework to define
distances between surfaces then they're
not all we did is basically said a
distance between surfaces is basically a
distance between the conformal group
between those two surfaces and the area
preserving by measure the two surfaces
that's that's basically the same way to
say it because what we did is apply the
Mobius transformation on a density and
ask what is the mass transportation
distance between them what is the
vastest and distance between them and
you can imagine that if we had a mobile
source formation which is area
preserving that is an isometry then we
had we wouldn't have a perfect area
preserving and these two would intersect
so in a sense the the distance that were
measuring is the distance between the
conformal group and their area
preserving by measures now the problem
with that is the biologists don't like
by measures and the reason is that by
measures are not necessarily Maps so
they can take piece of mass here and in
in distributed to several points on the
other so a seven point here would
correspond to many points on the other
surface that's not unlikely right right
but so the many people also for many
applications it is important that you
produce map at the end of the day so in
a sense in order to produce map all you
have to do is something that may seem
simple is to change this
with whatever you you want to preserve
so instead of air preserving by measures
we can take air preserving d4 morphisms
yeah so smooth maps that preserve area
and actually we get even a smaller space
the problem is that this space is much
less nice than the than the by measures
right because it's it's nonlinear and we
maybe we know how to flow in it with
divergence free vector fields but we
don't in any way know how to optimize
globally over this space this is the
unity formally it's infinite dimensional
manifold it even took a non-trivial
amount of of Mathematica and ice to
prove that it's not empty although
people understand with infant
dimensional right that's a famous paper
by Moser few years back so how so so we
in this setting we have an air
preserving the formalism with some
functional over it and we want to
implement to to globally optimize it so
how can we achieve that
so obviously the general setting when
the function we can't assume we don't
assume anything on the functional that's
we cannot really say anything however in
our problem where we comparing surfaces
there a very strong kind of another
assumption on the functional that we use
we use the fact that if the distance
between two surfaces is zero the two
surfaces are isometric or congruent
depending on what choice of equivalence
we made and and that's something we're
actually going to use so here's how
we're going to use it in case the two
surfaces are isometric the image looks
like this the group of air preserving
deform of either between the surfaces
and the conformal map actually intersect
why because we know there is an element
which is there isometry which belongs
both to angle preserving conformal maps
and to air preserving rights that's the
definition of a geometry so if we want
to optimize globally this functional dmn
in the case it's zero we can do that why
because we don't need to consider this
human in space we just consider the
conformal Maps that's what we said
before when the surfaces are not
isometric so the distance is greater
than zero then the kind of situation is
something like this the conformal group
is kind of disjoint from the air
preserving so what we're going to do
we're going to do a general kind of
thing which we're actually going to
define in there a preserving the
formalism
a very small set of candidates why do I
mean small set because we're going to
act
going to do something like projection of
the conformed apps on their episode 84
physics so we get a three dimensional
manifold inside the infinite dimensional
manifold so that's very small and we're
only going to work in that space and
what I'm going to claim to you is that
in many cases we can prove that the
global minimum on this group actually
belong to this extremely small set so
let me actually instantiate this idea to
a particular geometric functional that
biologists care about and show you an
algorithm and results so the so let me
explain the functions that we take so we
start for something which is well-known
which is called the Procrustes distance
that's the functional this is how they
compare surfaces you take a bunch of
point on one surface a bunch of point
out the surface defined by the user the
user marked corresponding points here
you can see them by colors and then the
distance is defined factor out the best
rigid motion between those two sets and
take the sum of squared distances that's
the proquest is distance obviously the
user has a very influential role on the
on the distance right he decides the
course the points and the
correspondences so we first of all you
want to get rid of the user so what do
we do we replace the correspondent says
with continuous maps between the two
surfaces we put here an integral on the
first surface and then we also put here
the correspondence inside the search
yeah ignore this minimum let's say that
we didn't prove at this point that there
is a minimum later maybe I'll talk about
that but anyway there is a minimum so we
want to search both for those space of
maps and the rigid motions now the first
question that arises is what class of
transformations do we want three minutes
okay so I'll just two minutes in this
and one minute okay so it turns out that
air preserving deform physics the right
thing I'm not gonna say over here all I
want to say is that now we have this we
call this a continuous proquest is
functional it is defiled area preserving
different morphisms and the theorem that
kind of ties this thing together says
that if we have an area preserving
deform of films that gives small
procrastinates not far from a conformal
map ok so that's kind of continue to
result but why is it important it means
that if the distance is small we can say
something global about this functional
over infinite dimensional group which is
something
particularly interesting because the way
people people can approach this problem
is start with some initial guess that
comes from another place and do gradient
descent but if for small distancing you
could say something global it means it
means that you can do well for these
short distances
so the algorithm okay I'm not talking
about too much the algorithm basically
take the conformal Maps randomize the
conform map project it on this space in
certain way and now we just test all of
them kind of sample the conformal group
test all of them and take the best one
very simple algorithm let me answer just
this thing you know I'll be done so back
to this at 20 million years gap thing so
there are two groups we got 36 models
all of them scanned by our collaborators
these are three-dimensional meshes
achieved by micro CT these things are
actually very small and we there's three
surfaces that have been found in this
special occasion which is me which means
that they both from the same area era
the same the same time in history and
these two groups are believed to be
twenty millions apart so we ran we take
this group of meshes and we just compute
the distances between all pairs so we
get a matrix of 36 by 36 with the
distances between every pair and now in
order to visualize it I'm just going to
show you kind of an embedding with
relatively low distortion of those
points what what you can clearly see is
that the Blue Point is one group the
light blue point is the other group and
the three the three interesting ones
that were found in the same place in the
digging site actually two of them belong
pretty clearly to one group and only one
of them we don't create to the clearly
to the other group which might imply
that these two groups exist is together
in history and they're not really twenty
millions apart they think I want to
highlight here isn't it it's not that
this is a historical proof but what it
means is that there is some objective
measure which did not involve human in
any part of the process and was able to
provide any representation of the data
which gives a clear separation between
the two groups and and I think in that's
kind of my take my kind of my main kind
of
message is that we might want to develop
such algorithms that are able to provide
to provide information on our data which
is kind of more conclusive than it was
originally originally was I know if it
makes sense but that that's that okay
thank you
welcome to the first in a series of
demonstrations on the graph data
structure what we're going to be
starting out with is a look at a graph
implementation specifically looking at a
graph implemented as an adjacency matrix
and trying to determine what kind of
graph that adjacency matrix represents
so we're going to draw out a graph
corresponding to this adjacency matrix
first thing that we're going to do is
we're going to try to figure out what
kind of graph we've got in the first
place now if we take a look at the
matrix the rows and columns are labeled
ABCD and E which means we have five
vertices which we're going to dry out
and label them a B C D and E now the
contents of the matrix itself are
numeric which means that there's going
to be some kind of weight associated
with the edges between each vertex now
if these have been boolean instead we
would say that it was an unweighted
graph but since we have numbers we're
going to associate those with the edges
the other thing that we can determine is
that by taking a look at the main
diagonal and the values on either side
the values on either side of the main
diagonal aren't identical so for example
evaluate Row one column two is not the
same as the value at Row two column one
what this means is the matrix is not
symmetric and therefore the graph is
bi-directional so we're going to have to
draw arrow heads as we go on each four
edges so let's start out with the first
row
and take a look at the edges that
originated a now there's two edges
originating at a one divert X B was
weight of three and another one to
vertex E with a weight of one now again
this is a directed graph so we're
drawing arrow heads on each edge as we
go there's only one edge originating a B
and that's an edge to D with wait to see
has three edges rigid a and they have
different weights we have one from C to
a with wait for one from C to B with
weight 2 and 1 from C to e with weight 5
there are two edges originating from d1
that goes to C with weight six and one
that goes to E with weight one
and then finally in the last row of our
matrix we have two edges originating at
row e1 back to a with weight one now
notice that we already have an edge from
A to E with weight one and the edge
going back will also have the same
weight so instead of drawing it in
another edge let's just draw in another
arrowhead indicating that this edge
happens to be bi-directional and the
other one is an edge from e to D with
weight three now although we already
have an edge from D to e we can't just
draw it in another arrowhead because
this new edge has a different weight so
I'll have to draw in another line with
an arrow going in the opposite direction
and label this one as having weight
three and that's our complete graph
based on that adjacency matrix for the
second demonstration we're going to take
a look at a different implementation of
a graph in this case a graph implemented
as an adjacency list there are six
vertices labeled a through F this will
start out by drawing our graph by
drawing those six vertices now we don't
know exactly where the best place to
draw these vertices are so we'll just
kind of take a guess and spread them
apart nicely so that we have lots room
to draw on edges the first item in our
adjacency list shows us all of the edges
originating at vertex a now a has an
edge going to see a soldier on that one
and in the absence of any evidence to
the contrary we're going to make this a
directed edge from A to C the second
item shows us the B has two edges
originating at B one to D and one to E
see has three edges one returning back
to a now in this case we don't have any
kinds weights so we'll just draw in an
arrow back to a 1/2 D and 1/2 e D has an
edge going to be well we already have an
edge from B to D so this is just now a
bi-directional edge and one back to C
again just another arrowhead on an
existing edge e has three edges one
returning back to be drawn another
arrowhead one back to C and one to F and
finally the last item in our Jason C
list shows us that there is an edge from
F returning back to e we take a careful
look at our graph we can see that all of
the edges that we've drawn in in fact
have arrowheads on both ends in other
words our graph is undirected now there
was no way for us to tell that from
actually looking at the original
adjacency list it's just something that
we had to discover as we went along
but that's our complete graph
hey this is sesh welcome to another
lesson in data structures and algorithms
this one is on graphs in which I will
introduce you to the kinds or types of
graphs we often deal with in computing
applications and although there are
different kinds of graphs they can all
be represented and stored in a program
in one of two standard formats which we
will study okay then let's begin by
looking at a graph that underpins
perhaps the most well-known application
in recent times namely Facebook Sarah is
friends with Sam who was friends with
Mira who's friends with Jane who was
friends with Maria Sarah is also friends
with AJ and Sam is also friends with
Shawn there is another group of people
that's not connected to the first here
Rahul is friends with Sapna who is
friends with Rohit what we've drawn is a
graph that represents friendships in
Facebook of course the real Facebook
graph is huge with hundreds of millions
of people and friendships but this
representation holds true no matter the
size in formal terms this graph models a
symmetric relationship if Sapna is Rajas
friend then Rahul is topknot friend as
well the relationship applies in both
directions we will see shortly that this
has an implication in how the graph is
stored in a program in graph terminology
each person in the Facebook graph is
represented by what's called a vertex
vertices plural and a friendship is
represented by an edge so the graph is a
collection of vertices that describe the
entities and edges that describe the
relationships between them here's
another example a graph that represents
a website a website has pages and pages
have links that connect them with other
pages page a links to pages B D and E
page B links to page D page see links to
a D links to be a links to F and
Flinx 2d the pages are the vertices and
each link is an edge from one page to
another page in other words each edge is
unidirectional
unlike the facebook graph where the
edges are implicitly bi-directional
since friendship works both ways the
edges in the website graph have
direction because the linking
relationship is asymmetric for example
my personal webpage points to an Amazon
page but that Amazon page doesn't point
back to mine graphs in which edges are
directional or directed are called
directed graphs those in which edges are
not directional are called undirected
graphs an undirected graph is actually a
special kind of directed graph since
every undirected edge represents a
relationship going both ways it is
equivalent to having two edges going in
opposite directions again this
observation will be useful when we get
to storing a graph in a program
sometimes edges will carry what are call
weights as in this graph weights are
numbers and in this case there are
distances in miles this is an example of
a weighted undirected graph in general
edge weights in graphs are typically
positive integers or real numbers and
here's the earlier web graph where the
edges are now marked with the number of
times the corresponding links were
clicked in the period for which the data
was collected this is a weighted
directed graph to recap there are four
kinds of graphs undirected graphs
without edge weights weighted undirected
graphs directed graphs without edge
weights and weighted to write to graphs
next up graph storage in programs this
Dora Graf in a program we need to
account for all the vertices and all the
edges every vertex will have a name such
as a person's name as in the Facebook
graph or a webpage URL as in a website
graph or a city name or whatever we can
store the set of verdict vertex names in
one of many ways for instance we can
store them in an array or if an
efficient search by name is needed say
in a hash table but how to store the
edges the edges are in fact what make
the graph because a graph is really
about the connections between vertices
we need to be able to show which pairs
of vertices are connected by edges one
way to do this is by means of a matrix
which in a program would be a
two-dimensional array the rows and
columns would both stand for vertices
each vertex has an integer number
assigned to it if the vertex names are
stored in an array then the vertex
number is implicitly its index in the
array since there are ten vertices we
have a 10 by 10 matrix in this example
Sara is number zero
Sam is number one and so forth the order
in which the vertices are stored and
therefore the sequence in which they are
numbered is irrelevant the matrix
accounts for all possible pairs of
vertices and each cell would show
whether a particular pair of vertices
has an edge between them or not there is
an edge between Sara and Sam so the cell
for row 0 column 1 should be turned on
but since the edge applies both ways the
cell for Row 1 and column 0 should also
be turned on in the same way all other
cells in the matrix corresponding to
edges will be turned on whether a cell
is turned on or off can be indicated by
a true or false boolean values stored in
the cell so the matrix would have truths
in all the cells that correspond to
edges
Graaff all the other cells would be
false the false values are not shown
here so let's not cloud the matrix
observed the pattern of true values is
symmetric about the main diagonal since
if row I column J is true then so is row
J column I the symmetry is also true of
all the false values hence this is a
symmetric matrix which is in keeping
with the graph representing a symmetric
relationship
now let's tour the website graph without
edge weights in matrix form since there
are 6 vertices we need to set up a 6 by
6 matrix let's take a look at the edges
page a has an edge to page B so we fill
in a true in row 0 column 1 but because
the edge is directed there will not be a
true in row 1 column 0 filling in the
rest of the matrix gives us this the
matrix is not symmetric as expected
because the graph represents an
asymmetric relationship in these two
examples we've used the boolean matrix
since the edges don't have any weights
on them however if the edges do carry
weights we can use the edge weight
numbers in place of the true values for
the false values we can use any number
that is not a legal edge weight so for
instance a value of negative 1 could be
used to show the absence of an edge for
any graph whose edge weights are
positive earlier we saw the graph of
cities and distances between them again
since there are 6 vertices you would
need a 6 by 6 matrix to store this graph
this matrix is then filled in with the
distances add the appropriate cells the
cells for the pairs of vertices that
don't have edges between them carry
negative 1 values observe that this
matrix is symmetric
because the distance relationship
between a pair of cities is a symmetric
relationship it works both ways
in graph vernacular this matrix is
called the adjacency matrix because it
lists all the vertices that are adjacent
to any vertex for instance Chicago and
Atlanta are adjacent to Newark because
they are one edge away the term neighbor
is alternatively used to refer to
vertices that are one edge away in the
adjacency matrix in row zero for Newark
the distances to Chicago and Atlanta
appear in columns one and five row zero
is set to hold the adjacency list of
vertices from the work with negative one
for the holes or absence of edges the
columns also hold adjacency lists so for
instance column indexed two for San
Francisco shows that Chicago and Los
Angeles are adjacent to it since the
matrix is symmetric the information
below the main diagonal is the same as
the information above it so if you
wanted to run through the entire set of
edges you could either scan the lower
triangle or the upper triangle but not
both if you scan the entire matrix you
would hit each edge twice so say you
wanted to count the number of edges in
an undirected weighted graph off is
adjacency matrix say the matrix is
stored in a two dimensional array a of
integers then the edge counting code
would look like this the nested
for-loops can still lower triangle of
the matrix in this example n the number
of vertices is six the first row is not
scan at all since the inner loop four
columns goes up to row minus one and
since the first row index zero the inner
loop does not run in the second row the
first column is checked and counted
in the third row the first column is
checked and skipped the second column is
counted and so on until the last row you
may have noticed in the matrices we have
seen up to this point that there are
very few cells that are filled in for
the edges but a lot of empty no edge
cells in the facebook friendship graph
there are eight edges as seen in the
lower triangle of the array the other
eight rows in the upper triangle is the
same information so it doesn't count the
total number of cells in the array is a
hundred so the proportion of actual
information to space used is eight
divided by 100 or eight percent in the
website graph which is directed there is
a total of eight truths or eight edges
while the total number of cells is 36 so
the space utilization is eight divided
by 36 or twenty-two percent and in the
city's graph there are again six edges
while there are 36 cells for a space
utilization of six divided by 36 or
sixteen percent it's clear that when the
number of edges is small the space
utilization is extremely low in order
for the adjacency matrix to use space
effectively there has to be a large
number of edges let's look at the
extreme possibilities for number of
edges in a graph this line is the
spectrum of number of possible edges in
all graphs that have n vertices at the
left extreme is the least possible
number of edges which is 0 the other
right extreme would be the most possible
number of edges what would the number be
let's look at a few examples of this
extreme to see if we can arrive at a
formula for maximum edges in terms of
number of vertices if there's a single
vertex there can't be any edges with two
vertices there
me a maximum of one edge with three
vertices we can have at most three edges
and with four vertices we can have up to
six edges four connections between every
pair of vertices one way to get at the
formula is to think of the maximum
possible edges that can emanate from a
vertex if the number of vertices is n
then each vertex can connect to all the
other vertices or n minus 1 so the
maximum total number of emanations is
the product of n the number of vertices
in n minus 1 the maximum emanations per
vertex however this figure counts each
edge twice in an undirected graph first
from one endpoint vertex and then from
the other endpoint as well
so for the four vertex graph plugging
four for n in this formula gives us four
times four minus one which is 12 by the
number of edges is six so we need to
divide this figure by two for the
correct formula in a directed graph the
maximum number of edges would simply be
n times n minus one since each emanation
counts for only one edge these extremes
basically set up a gradation on the left
end of which we have what are called
sparser graphs and at the right end of
which we have what are called denser
graphs if the graph tends to be denser
there is increased space utilization
with the adjacency matrix and it is a
good storage scheme but the graph tends
to be sparse or there is decreased
utilization of space in practice most
graphs tend to be sparse for instance
Facebook has about 1 billion members on
the average say each person has about
300 friends this means Cindy decency
matrix there would be 300 truths in each
of the 1 billion rows for the members
for a total of 300 times 1 billion
whereas the matrix would need 1 billion
squared amount of space the space
utilization is therefore 300 over a
billion which is miniscule actually as
we saw before it's really 150 over a
billion since each friendship edge gets
counted twice which makes the
utilization even worse if you think
about the graph for the world wide web
you run into a similar situation there
are billions of web pages but any single
page points to a few hundred other pages
if so what this means is for most
real-world applications the adjacency
matrix is not a good choice however
there are some niche applications where
the matrix is in fact useful typically
when memory is not an issue
and when operations result in random
access into the array happen very often
in a follow up video we'll look at a
much more space efficient alternative to
store graphs see you then
hello in this video we are going to have
a very quick tour through the tool
Gaffey that we are going to use for
social network analysis before we start
the exercise explained in this video I
would like to ask you that you first
download Kaffee and follow the
instruction for the installation of
caffeine some of you depending on the
operating system the type of computer
you may have and the type of Java
version may have different requirements
and needs to update or check that you
check the Java version that your machine
has there are also some
incompatibilities between different
versions of Java and Kaffee well that's
one of the joys of having open source
software while while the this piece of
technology we are going to use for
social network analysis is open source
and publicly available to anybody there
are certain issues that we always need
to deal when we are installed installing
so I hope you have already overcome that
problem and that you can now continue
with the exercise that we are going to
have in this video so for this exercise
I suggest that first we are following
the examples that are provided in their
course resources so those examples are
available in the course readings so for
the EDX users you can easily locate them
in your EDX platform and they are also
available in the pro solo credential
available for this week so in these two
examples you will see that there are two
separate files each of these files can
be imported and loaded into Gaffey for
further analysis so all you need to do
is to say open and go located the folder
in which these two examples are and then
import it so let's go first with example
1 and import it into Gaffey both of
these examples are created in such a way
to be undirected of course you can also
import them as directed but the overall
size of the network and the types of
results that I am going to show in your
analysis would be different so let's
assume that these two networks are
undirected in the same
manner as they are shown in the slides
that we followed throughout the
presentation so the first thing that you
are going to notice is although I using
the identical example that is provided
in the slides and the video
presentations that we use for the
interaction of social network analysis
in this video you can see that the first
basic layout of this visualization is
not the same so what I am suggesting you
to first to check out is to go to this
component which is called layout and
India layout you can experiment with
different types of visualization of
graphs through my experimentation with
this example I found that Yin Phan you
hue was the probably best example of the
layout that could be applied for our
network you can also see that this
network visual as visualized as now is
probably the most similar to the
representation to be used in the slides
of course there are many other of these
different visualizations and depends on
the data set and depends on what respect
you want to show some of these different
layouts may work better in some other
cases in some cases where you are
dealing with bigger data sets this
particular data set this particular
layout can be best for you and I'm
typically using however for this
particular data set that we are using
now for this small example its eternal
that Union fan who proportional Lorene
fun food is the basic algorithm work
equally well all right so once you have
visualized that the next thing that I'm
sure you would like to do is that you
actually zoom bit this whole example n
so that let's go there you can identify
here on this lower button right corner
this small icon when you open this
saikhan you will see that the first tab
here is global so just try to play there
with this slider and you can zoom it in
and zoom it out this icon this whole
network
and the second thing is then here you
can also change the shape of this
diagram the next thing is you can also
play with the color and the shape of
different edges that you have in the
network so you can also play there and
final thing that might be interested in
this case is that you can also turn on
the labels or the name so the actors in
this network that we are presently
experimenting with they are of course
situations like this one where this
labeling may be useful and may be still
visible however when you are dealing
with networks of several hundreds or
even several thousand of actors in your
network they may not be that's durable
too to be shown in the network but let's
for time being turn them off and let's
continue to experiment with the some of
the network analysis that we learn in
this course so the first network
analysis that I'm going to introduce
here is available through these
statistics so when you open this the tab
on the right hand side of your window
statistics you can first compute degree
so it says average degree but the moment
you say average degree it will also
compute the value of every single node
in your network so it will also show the
distribution of the degrees and finally
it will also show what is the average
degree for the network in this case we
can see that the average degree is 3.6
and so this is the value that means that
each node in the network on average has
3.6 connections but of course different
nodes may have different degrees so how
we can actually become aware or see what
is the value of degree for each of these
different nodes well there are few
strategies how you can do that one
strategy is that you go to the data
laboratory tab here and in that tab you
will then see each of these nodes as
well as each nodes degree so you can see
that for each nodes degree that we are
having this network we can see what was
the value of the
three okay so let us now return back to
the visualization that is done by
clicking or pressing this button which
is called overview so how we can now
visualize some of these network measures
and see that we can for example
differently color our nodes in the
network or maybe even size based on the
values of their degree so to do so you
need to go to this now tab on the left
hand side which is called partition so
the first thing is you will see there is
a drop-down box here which is empty so
the first thing we need to do is we need
to refresh it all right so once we
refresh that box we can see that they
are there is the value degree so for
partitioning generally you can do this
and based on that the nodes with the
same number of degree values they will
be colored differently so you can follow
these different colors and their
representation here so this is one way
to do that so in this way for example
the nodes with red color meaning that
they have three to the value three they
will be shown here on the diagram and
the similar based on these degree values
those are the discrete value items for
each of these values are shown and
visualized differently in the diagram
there is another way to do and visualize
your network is if you go into the
ranking part and select nodes once you
have selected nodes you can then choose
degree and then once you have chosen
degree and say apply you will see that
these nodes will be colored differently
in the darkness of the color of the node
will represent the higher value of
degree that is to say the measure that
we use to color our nodes of course you
can also experiment with different types
of splines and the different ways how
that can be colored but nevertheless
it's important to remember that this is
the way how you can visualize based on
the color
before we continue the visualization I
would suggest that we first do something
else I first suggest that we go return
back to our network and to compute
betweenness centrality so between us and
round is computed when we are computing
diameter this is actually not surprising
given that the in the computation of
between a centrality closeness
centrality and few other measures that
were diameter the measure that we also
introduced in our slides and videos is
introduced so I'm suggesting you that
just you run network diameter once you
are asked here network diameter you will
be by default selected undirected graph
and you can choose whether you would
like to normalize it or not
thermalization means whether you would
like that between a centrality and all
these other three measures are presented
in the on the scale 0 to 1 or you would
like to just simply have them all
represent them with the values as they
are this normalization 0 to 1 means that
there will be found the maximal value of
between a centrality and then all these
other values will be scale that is to
say they will be divided by that maximum
value have been doing us and travel to
your father of a node in the network and
that's how we are getting this
normalized centrality measures so let's
not go now with these normalized let's
go with the actual values of the
centrality measures and see what we can
get all right again similar as done
before we are getting between a
centrality and closing centrality has
done for degree centrality there's
another measure here it's just cause a
centricity we haven't introduced it but
it's quite similar to close the
centrality except it's a discrete value
it's always an integer number and means
basically what is the highest number of
hops that a node needs to have to reach
to any other node meaning that's a
geographic center of the network
so once we computed these three measures
if you return back to the data
laboratory tab you will see that three
new columns were added a centricity
closeness and betweenness centrality all
right
so let's go now back to the overview of
our network and for that overview let's
now click on this like a small diamond
in the ranking tab of the network when
you ask who over that small diamond you
will see the size weight will be
something that will be shown as the
value so what I'm suggesting you here
let's now choose between a sensuality is
used to size the nodes in the network
and I'm suggesting you that you can play
with different numbers Max signs but I'm
suggesting you to say enter value like
100 here to see what will happen so it
means basically that the based on the
values of between a centrality the
maximum size of some of these nodes will
be hundred between one and hundred
points and they'll be depending on the
values so between a centrality alright
so once we apply this between a
centrality you can see that we visualize
these nodes and they were sized based on
between a centrality but you can see
that this network presented this this
way is really not that helpful so let's
try with some smaller number like 30
perhaps and you can see now that there
are differences in the size of our nodes
the node which has the largest value or
betweenness centrality is in principle
the highest node here and the question
becomes well how do we know which node
is that there's one possibility
you can right-click on that node and you
can go select in detail laboratory that
means the following once we have done
this so select indeed a laboratory and
you return back to data laboratory that
particular node will be selected and for
a good reason because this node had the
highest between a centrality as we also
showed in our video presentation
before so this is Liz and Liz has this
betweenness centrality as the highest
number let's return back again here
there's another possibility how you can
see which node was that one with the
highest centrality we can again turn on
the labels back so once we turn the
labels back on we can again see that
slays with the highest number of degree
of between a centrality so this is the
way how you analyze networks and
especially how you analyze networks when
you are interested to compute some of
these major measures of course we can
also compute grab density as we also
introduced and again it's fairly simple
it tells us the same number as we also
saw in our presentation it's point for
the value that is to say 40 percent of
the entire potential death Network to be
connected there's one more thing we
computed these measures that are at the
level of nodes and at the level of the
entire network like a dual internal
network was natural diameter and grab
density and in there are level of
individual nodes we had degree we have
also closeness in between a centrality
someone may ask okay this is cool we all
computed but then how we can now
experiment with some of these measures
and connected say with the tool for data
analysis such as a tableau that we
introduced in weeks one and two or rapid
miner that Ryan Baker is going to
introduce in weeks five and six so
that's also fairly simple you can now
export this entire table from the data
laboratory in comma separated value
files or some other separated files and
then you can import this file into
tableau you can have be imported into
any tool that deals with spreadsheets or
you can import into different
statistical analysis tools such as our
SPSS SAS or some other tool that you may
have access to use R for example is open
source and it can be easily accessed at
this point we finished some basic
introduction into getting how to compute
these basic measures I would encourage
you now to go into the hands-on
activities that are provided in the
course materials to import these
examples and review start performing
these types analysis as shown in this
video I would also then encourage you to
perform further hands-on activities on a
bigger data set that we've provided in
the study and more importantly to share
your experience with others in addition
to my video here that I recorded with
Jaffe I'm also going to refer you and
you can find that in the resources
available in the course materials to
some other YouTube videos which can
allow you for additional insights under
ways how Jeffie can be used for
visualization and performing some of
these types of analysis from of those
examples are all suffering opportunities
for you to for example download your
Facebook network or your Twitter network
based on that we also created some
assignments that you can perform but in
a nutshell these types of analysis and
the functionality that I showed in this
video will get you going very far of
course for those who would like to have
something more advanced they are welcome
to explore additional functionalities
and even better they are more than
welcome to share it with everybody else
through EDX discussion forums through
Pro solo or other social media that is
used in this course thanks very much
hi in the first class we have learned
that how we can represent a sparse
matrix in three column form only and
second-world linked list form the first
three column form we have seen in the
first class of his past matrix where the
forecast for matrix is there and the C
programming there is indexing zero a
zero row and the zero one two three
column and we have represented in three
column form the first row in this three
column represent total row total column
and total nonzero values similarly when
we are going to represent linked list we
require three nodes and three nodes has
a different structure the first head
node has four places where first place
is total row second total column third
total nonzero values in that matrix and
last is a pointer that point the next
row similar to your previous after one
two three place one pointer is required
that could point next row okay next is
row node row node first is row number
next pointer for next row because in any
matrix you have to up a scanning all the
columns you have to move next row so
there is a one pointer that will put you
on next true and third is column node in
the column node first is column number
second the value that exists in that
column a next pointer for next value is
same room for example this is the matrix
in zero column value is four in the same
row two column value is 3 so we can we
require a node that could move right
side okay so let's take same example and
we are going to make its linked list
representation so for linked list
representation of this matrix
first head node this head node contains
four row four column and six nonzero
values okay next is pointer that will
point first row the first row is mean a
zero and its next pointer point next row
mean one
this next pointer point row two and it's
next point a point last Row Row three
now in each oath there would be a column
moment so for column moment this point
this is his own ode and column this will
go to the value is in first column so in
the first column value is two and is
there any another value in same row no
so it's last pointer is null now in Row
one this pointer points to in column
zero value is four then again it points
to next column where column value is 2
and value is three and the point there
is not any other value in the same rule
so it is none second row
- values are there so I have related to
loads the first in row 2 column 1 value
is 1 and it points to next column values
column number 3 column number is 3 value
is 1 and it does not point to next row
it is none in 3 the column node in
column 1 we got value - it is not point
any other value in non zero value in
same row so it is none so it is a linked
list representation of sparse matrix and
I have created linked list
representation for this matrix thank you
bismillah ar-rahman ar-rahim nobelium
inshallah be just a Fenny Weiler seen
the fast America volatile oils me at the
Magna carpa father mukada me in in
packet rocking always somebody in
introduction to Beckett Rajan he had a
list of a Java file a general method was
Angelica problem formulation volcanic
even halma skeletal iniquity problem
vamos with the Hamiltonian cycles this
dish Grameen Bank is rocking Pedrosa so
the cartographer holodeck terminus of
the hamon mache kilobit well jigna he
hired 911 a year welcome to Emily and
oil zubatov a friend who a sequential
mean method hananim script sorting
distilled and selection will pop in
while insertion rather the Catawbas not
a scuba wah-wah divide-and-conquer
method mahalia nobility Mia is sorting
the spectrum in merge were a liquid sort
algorithms Bala delicate have
acknowledged to be degree limited
O'Hanlon armed planning on skipping
minimum spanning III were in knapsack
problems but they can I know knapsack
problem screaming ha million to virgins
ilium again the fraction and knapsack
were I bond again zero-one knapsack
politically Demeter darling a partner
Allah diffraction and knapsack come on
rather cat about knowledge tube jadid
what what dynamic programming method
while I'm in Janeiro
Helena Muscatine multistage graphs were
cave allocated by traveling salesperson
mean a problem in the Omaha Dhammapada
Scoobies did what many some have
impacted tracking method while I'm 34
Helena mechanical and McQueen a problem
working dedicated on how many other hand
held on 34 Muscatine hamiltonian mean
cycles a heavenly camino problems are
harmony and booking poon mocha Queen
eight Queenie problems
Aram again for the Queenie problems has
available Queens emoji in indeed come on
you don't have a fan of stupid packet
rocking what happen if mo be cooled
Basava in 30 fucking method warming it
is a general algorithm for finding all
or some solution to some computation and
mean a problem I'm going a national
Imperial backtracking in the world
occasion in the harmony and notable
harmony and mooska that in Turkey
tracking the program
I mean come on we couldn't pass up a hot
animal packet working method
I'm an idiot here and how that again
mean in the graph how many things we had
a chicken in go up ducky how many Yankee
fish turning back is rocking lucky
fucking galactic dominant look for my
get him I'm gonna get a husband peony
multi-tone IVF process why adventuregirl
any problem problem energy the problems
let me at him held her back
Emily young you know it didn't look well
in a village it mean here in the X term
in bath botella nominee el mohammed
abdel fattah who I am
tamam whether I can hammer Amin in a
chicken in my level baffle in condition
LAPD and Haley problem it again yes the
parameter phenomena million mean
recursive namin the math about coming
hiding in mosquito victim in again if I
can how many young and the cantle Eric
Harris the rajala true victory nominee
invest in an emergency who are many and
mean Sofia the mom the mom okaybut a the
Campbells we had in bath or victory huh
committee hata is Italian the problem a
million means inhale the mommy the
cannibal puffs called affirming of
harmony meaning undo a homonym again
taraji arm no potato harmful in about me
in Kearney battalion Emil Halabja near
death emoji t90 had a hell mean had any
problem either Java Virginia had in past
well lists any problems from a newly my
victory American had any problems or
have the journey Falls Road victory
there is no solution any problems with
aromatic aldehyde mean in a problem
happy M onion thicken compacted working
me method in fact it working method our
data tracking algorithms what estimate
Alice systematic search data Madonna is
systematic search
less solutions face bommana in an
American of Ken and Yanina problem or
Haldane the problems here in the are ba
are bajalia the problem come on we
recognize our bajalia Thomas theorem
again optimal solution
the man named jihad from October ha
victory solution space lacunae harmony
and mean our path victory I mean in
practical congrat Amidala in hate carry
our said Amanda chicken has a solution
space hello I'm again three
organizations and warming in depth fears
no the generation our harming
intersecting bounding funk
happy I'm a limitation the search come
on how many in the camp I became that as
in the Caballero of hub or the telly a
TDR meet again later Paula Hockey League
on her fanny half-a-million be shaken
over hand but it means empty neva
respecting her Armenian like instead of
emptiness to the dirty fucking captain
friend happy mean had a friend in
Michigan in between Jenna come on an
American engineer license technically
had impacted working have been held had
in Michigan
okay Taylor had cool American higher
yield or more lava orbit active in
pounding the function and German army
and limitation let's search come on come
on now at any chemical engineering
problem for me a Chanel jacket tracking
ammonium method victory harmony and
novelty and economy I mean a problem
returning as a mahaki trend ahead
hello Lucas aha so mom was and again the
top two Shukla Haley problem come on and
I'm gonna change the problem had a
health issue rules come on no fee then
no can't render me an auto Baha'u'llah
Baha'u'llah money and half of a that he
should be telling semi I may be a
desired solution had a desired solution
came imagine how a piranha and
ejaculation trouble coddled Emily gave
the height methylamine okay and x1 x2 x3
all right XM demand in harmony and
harmony and ok Nanami and the are bar
solution Madonna Finnegan condemning any
other boroughs of a million or four
couples multi demon having a meal and D
happy
solutions our desired solutions
occurring a hectare windy simcha the
Kennedys solution space our culinary
insist the nominee Shekinah as one again
as I tighten a bit metal American
economy Double L mowjood mean Emily and
Andy come on okay and a million on
paternity Emily in the world wahad raha
metal a Meganium Victor what attorney
Rahim economic and halwa had married
appropriate vemana locate any immediate
problems within a two solution matter
nominee Ava - Jamie a-come bro
reclamation and the two row either Road
oh one 1 million mean had a row ten
after
intended to tuples having in the
worldwide right Otaniemi victor Nashua
high meth-addicted wahad or Victoria
libel macadamia in halwa had had about
Danny Mahesh Sharma DNA and evict
attorney Rania Mohammed Amin health any
London and now I mean I'm highly
publicly on the two big stories man
Konami and the two solution
come on behind the problem come on make
an Italian whatever an optimal mean
solution Konami in the double eyelid
have a clean objective led problems
differently they can tell a parent about
done maximize or minimize over time
making technical a perfect condition me
why I am come on
ok bharanam again turned am again mean
um but Eddie lost aradhna
in no pnw mean solution space Armenian
hedge Marbury and um I
tamam lahat a solution in space Victor a
million and her work on the m1 and to
the right mmm
turning economic and I'm the end minute
levels in moji be mean Andy what in hey
I had met anomaly and desired solution
or candidates solution Lahaina problem -
mom I'm in the last nominee Wendy I did
Nina problems with him Hal dad system in
package rocking the Republican
nomination up have got much more mainly
minute constraints how much one should
come on and it constraints phenomenal
you mean you are in the n-dimensional
except missive and M conceived
constraints exclusive constraint
spreading and harmony and divested rule
rule what harm had the day how to hide
this father it means solution come on we
met Alan hello be judgmental added a
layer Emily and outdated rather than
Mujib it the mom or rather the rear self
in Lackey another demodulate we enabled
our million in positive numbers Victor
aha Mia had cool X the item X with
material added its of I be heightened
Noemi I have connected offered to sell
me and set up whatever chicky lanyard
shit data we had a dad emoji B are
non-negative me numbers like in ins
chakra in Germany and zero or one
Ketchikan Amin Amin said Fanny not Rami
in the Buddha again mean Wawa had
enormous a meeting except this across
trance the mom Randy not anymore myself
in implicit consonants when new army
the solution vemana an event amiami no
problems who had held any problem
spending much more maninsuit the telly
had reported issue of metonymy and
hassle vana troubles
al-hasakah again alanine other solutions
return hey here an absurd to somebody
implicit mean constraints with any Amir
hoc Academy and conditions or the
criterion for functions or constraints
American vicuna had a hard worker had a
hand Heidi is in the problem okay okay
and thanks for listening and have a
great day
okay so i'll continue about not into
since now and the first one I want to
show you is a non-interactive
zero-knowledge proof for circuit
satisfiability it will have perfect
completeness perfect soundness and the
zero knowledge property will be
computational okay and what we'll see is
that we could get a very small common
reference during it will just be a small
constant number of group elements and
then will the proof will be also a
number of group elements this time one
that grows linearly in the size of the
circle okay i'm going to use composite
order groups to construct these proofs
okay so just a reminder that composite
order groups so we have n which is a
product of two primes p and q and these
groups here they have order n and what
we're going to assume is a subgroup
decision problem is hard so given n in
the description of the groups and
elements G and H it's hard to
distinguish whether H has order Q or H
has order n so a brief reminder here so
then talked about how you could build
encryption schemes based on the subgroup
decision problem and that's exactly what
we're going to use as a fundamental tool
to construct these non-interactive
zero-knowledge proves so the public key
here is again this description of the
groups and elements G and H the G is a
generator flu group has order n + H has
order q ok and the secret key is a
factorization of n and to encrypt
something with a BG encryption scheme so
to encrypt a we take G to the a and then
multiplied with h to the r and we can
decrypt this by raising ciphertext to q
that gives us g to the aah to the r
raise to q and if you do the math you
see that this is the H just cancels out
and we're left with G to the q raise to
a and if a is a small number then we can
compute the discrete logarithm and the
and as then argued this is an
indistinguishable on the chosen
plaintext attack I'm going to extend
that a little bit so what is called a
commitment scheme ok so the commitment
scheme works exactly the same way so
still have the same public key and a
commitment to an element a is G today
and H times H to the are ok now at this
stage though I'm not restricting it
doesn't have to be a small number this
works for any value a modulo P because a
commitment uniquely determines a modulo
P right so we have this age which has
autocue that can cancel out and and do
bad things of anything in the order q
sub group but in your P sub group we
have a is uniquely determined so
therefore we know a modulo P given this
commitment and just as for the
encryption scheme we can argue this is
computationally hiding that just seeing
equipment and doesn't let you decide
whether is equal to 0 or 1 or something
else now this commitment scheme has
these nice properties of just like the
encryption scheme that if you multiply
two commitments together you get a
commitment to the sum of the elements
that you have committed to and if you
pair two commitments you get a canoe
commitment this time in the target group
which encodes a times B okay so I'll
just leave this slide on for a short
while so you can do the math yourself
and convince you that I'm not cheating
okay so okay so using this as a tool i'm
not going to construct a non-interactive
zero-knowledge proof for circular
satisfiability so just to remind you so
the goal is to argue that we have a
circuit and without loss of generality
we can assume that it just consists of
NAND gates okay so what I want to argue
is that that has some input to the
circuit that will make it output 1 okay
so in other words we have okay so we
have some some input we can give to the
circuit which will lead to this
intermediate and wire well use and the
output will be 1 and the provo has a
witness the proven knows some some
assignment to these input why's that
will make the circuit output 1 now the
provo wants to convince the verify that
yes indeed this circuit is satisfiable
so what the provo will do is to commit
to these values of the input wires and
also the intermediate wires in the
circuit okay and all these commitments
approval send to the verifier and for
the output of the circuit the prove we
will also make a commitment this is a
commitment but here a random is our is 0
right so this is something the verify
can say yes the output commitment yes
that's a commitment to one that's easy
to verify so what remains now is to
prove that all these commitments
actually have our commitments to wire
values that satisfy the circuit and we
need to show two things first of all we
need to show that these wires near their
commitments 201 by all the verify sees
is some commitment it could be any value
modulo P but so the first step for the
program is to prove to the verify that
the program has committed to two values
which are either 0 or 1 for these wires
and the second step then is to show that
all these committed values actually
respect the NAND gates okay so in other
words the committed w-4 should be the
land of the committed w1 and w2 so i'll
show you how these proofs work okay so
the goal here here is we have a
commitment and we want to prove that it
contains zero or one okay and without
loss of generality we can write it as G
to the W for some W which is unique
modulo P okay and we're going to use
here this multiplicative property of the
encryption scheme of the bgm encryption
scheme so what we're going to do is
we're going to take the commitment and
then the commitment multiplies while G
inverse ok and pair these two
commitments together and while the
commitment see has w inside right and
the commitment C times G inverse has w
minus one inside so when we pair these
two commitments together what we get is
a new commitment that contained w times
W minus one and then something that has
order q
okay and the interesting thing is here
if w is 0 then this is a commitment to 0
right and if w is 1 then this is a
commitment to 0 and if w is anything
else modulo P then this is a commitment
to something non zero so what do we want
to convince now the verify prove one's
convince the verify that this is a
commitment to 0 so how do we do that
well the proof is very simple is one
group element it's this part over here
that's the proof and to verify this
proof here the verify will check that CP
it will see that times G inverse is the
same as the pairing of age with a proof
pie ok so it's easy to see it's complete
right because we just took it from here
so let me argue white sound ok so what
what the verifier can deduce is well
that the sum w some some are such that
this pairing here is the same as this
value here and that's apparently the
same as h paired with the proof pie ok
and this thing here has autocue right
because H has autocue and this thing
over here well h-has autocue so this is
also something that has order q the only
thing that has some some order modulo P
possibly is over here right and while if
it has to have order Q as we have over
here then the only way that's possible
if is this thing here is 0 modulo P
so the verified concludes that w times W
minus 1 is 0 modulo P and therefore that
W is 0 modulo P or w is equal to 1
modulo fee okay so this is an extremely
simple proof that a commitment contains
zero one right it's just one group
element that we need to convince the
verifier okay and that's the first step
right now we can use this proof to all
the wires and prove that that contains
zero or ones just as we want it to so
the next step we need now is to prove
that the NAND gates are respected as
well and for that purpose on make this
observation here okay that if we have
bits p naught b1 and b2 then be too is
an and of p naught and be one if and
only if this linear equation here is
either 0 or 1
okay so we're going to use that
observation in a moment so now I'm doing
this for NAND gate without any loss of
generality because you can with with
only linear overhead reduce any circuit
two to one that consists just of NAND
gates but you could do this also if you
had other gates of fan in too so you can
find similar tables for all possible
gates and have two inputs okay so so now
we have these commitments c naught c 1
and c 2 we know that they contain bits
because that's what we proved before and
the remaining question is is it true
that let's see two contains the land of
c naught and c 1 and here we use the
homomorphic property of the commitment
scheme right we take c naught multiplied
with c 1 multiplied with c 2 squared
multiplied with g inverse to okay and by
the homomorphic property that gets as a
commitment to be naught plus b1 plus 2 v
2 minus 2 and well if b 2 is then and
then you speak then this value here is a
0 or 1 right but that we already know
how to do we just use the proof before
we prove that this commitment heat
product here contains 01 and we're done
this is a proof of knowledge yes as well
right I mean so so all these commitments
because it just contains bit 0 a 1 you
could use the BGN decryption mechanism
to get out the bit 0 1 yes so i'll show
you zero knowledge in a moment so so
right now I'm just arguing that we have
soundness okay and then I'll get to the
zero knowledge part later on okay so so
that's it okay now we have we commit to
all the wires for each of them proved
that to contain zero one and for each
NAND gate we take this product here and
prove that contains 0 0 1 and we have
proved everything so now we know that
the circuit with these committed values
will output 1 okay and this is very nice
so the crs is the BGN doubled BGN key
okay so it contains so it contains an
RSA modules and then there's not much
overhead in describing the rest here and
then it contains these two group
elements so so we ended up with
something that's roughly three times
then and Aras a modulus in size and the
proof size while we are committing to
every wire and for every why we're
making one proof okay and each proof is
one group element so that gives us 2
times the wire number of wires sighs
okay of group elements and then for each
NAND gate we have to make a proof so
that's plus the size of the circuit in
the number of NAND gates so constant
size crs and and linear size proof
ok so now I'm getting to the zero
knowledge part why is this Sarah
knowledge so we're going to use the
subgroup decision assumption right here
right it's hard to distinguish whether H
has order Q or each has order any okay
so when we set up a simulated common
reference string we are going to instead
of having H that has auto cube we are
going to have h that has order N and
this is something by the subgroup
decision assumption the adversary has no
clue that we have changed and simulated
the common reference string okay so so
i'm going to choose H that has all right
now I'm actually going to choose such as
there are no value towel such as g is
equal to h raise to the towel okay and
this towel here is a simulation trapdoor
and what the this value here gives us is
that now the commitments are perfectly
hiding trapdoor commitments what this
means is that i can create a commitment
which I can open both as a zero and as a
one whichever way I choose right so I
could commit to 21 as G to the 1 times
h2 they are but that's the same as G to
the 0 and H to the r plus towel ok so
now I have commitments that I can
pretend are either 0 or contain ones and
the verify has no clue what's inside
ok so the simulation what I'm going to
do this how well now I have this new
common reference drink with H has order
n again going to i'm just going to
commit to all the ones now when i'm
simulating i don't know what the
witnesses right so i'll just commit to
one's all over the place then I'll give
the proves that the commitment contains
zero ones that's fine because they
contain ones and then when it comes to
the NAND gates well I can just tweak it
i can just cheat right because I know
how to commit to both the commitments
are both of zeros and ones at the same
time so I'll just pretend that some of
them to contain zeros and now they also
respect the NAND gates and I can give
proofs for the NAND gates so that's how
the simulation works
so so what did you say simulation sound
were that while simulation soundness
says that if you see simulations of
statements you would not be able to
approve a new statement and you've falls
in a false statement right that I don't
think you know I don't think you would
get that from here I mean the ways you
can you can modify these proofs are
malleable and you would be able to cheat
that way so so so you don't get advanced
soundless properties that but no no
that's that's known on and you can you
can get to get that kind of kind of
thing I'm not planning to talk about it
here but I'm I'm happy to go to talk
about it later okay okay so what do we
actually get from these proofs okay so
each of these individuals 01 proves they
actually not zero knowledge it's just
witness indistinguishable okay so let me
show you why they are witnessing
distinct roots so we have some
commitment okay and we want to run this
proof that it's 01 okay and it could be
you know both have one and A zero at the
same time because H has order end and
what I want to argue is that whether you
give a proof where I have the opening 21
or a give a proof with a half the
opening 20 well there's no way you can
tell what I started with a 0 or a 1 okay
it's witness indistinguishable okay so
so depending on what I use the one and
an R or the 0 &amp; applause towel opening I
will get a proof of this form or proof
of this form here okay and then the
verifier will check that the pairing of
C and C times G inverse is the same as a
pairing of age with the proof pot pie
okay and just as before I mean we have
perfect completeness these proofs will
you know we just give the exact same
process before and they verify for the
same reasons that is that it
early on where each had order q okay so
why is this witness indistinct why are
these two exactly the same well because
H has order n so there's only one unique
value pie that fits into this equation
here okay so whether you are using this
proof this proof it's going to be the
same value so this is a bit of a
shortcut to show that I mean you can of
course also do the computations on these
values and see that they are actually
identical these proofs here but this is
a shortcut there's only one possible
proof that fits into the verification
equation and therefore its witness in
this region but all witnesses map to the
same proof so now we know that all these
01 proof our witness indistinguishable
okay now witness in distinguish with
none is not enough what we really want
for the entire proof for circuit
sensibility is of course that it's zero
knowledge so let me show you why that's
the case okay and it works a little like
this okay so we're starting starting
let's say with a real proof okay so we
have an an adversary that's trying to
distinguish am I seeing a real CRS and
the real proof or am I seeing a
simulated series and a simulated proof
right so we start out with the adversary
see is a real proof okay and i'll put
some guess 1 or 0 depending on whether
elise it's a real true for simulated
proof okay and we modify this okay so
let's compare that to an experiment
where we're running a real proof one
other simulated semi TRS okay so that's
kind of in an intermediate situation
where we use a common reference during
where H has order n but where the provo
actually knows the witness and gives a
real proof on this combo referenced ring
okay the only difference between these
two experiments is whether H has autocue
or each has order n
okay and by the subgroup decision
assumption the adversary cannot
distinguish between those two cases so
we know that here that the adversary
would not really be able to distinguish
whether whether we've seen a real
serious or simulated crs now I'm going
to look at another modification of this
game here I'm looking to add a hybrid
where H has order N and where we first
make commitments to one all over the
place instead of committing to the
witness okay but then later on when I
have to prove something I use the track
door to open all the commitment to the
witness and then give the proof okay and
that's actually no modification at all
right because all these commitments well
they are commitment to 0 and 1 at the
same time so I'm not really doing
anything different here I'm just picking
commitments which are really random
group element and giving them okay so
that's exactly the same thing and
there's no way the episode can can see
anything these things are perfectly
indistinct result to that Missouri okay
so so now I'm going to do another
modification so instead of giving so
first we commit to one so all over the
place but instead of using the trap door
to open to a real witness now i'm just
going to use the trap door to open some
commitment to zero and then give the
proofs ok so in other words whenever I
have to prove that a why I'm a your 01
well then I just give the true for that
because it is a commitment to one
whenever have to prove an and gate then
I tweak one of the inputs and then I can
prove the nand gate ok
and the claim is that these two
experiments here also completely
indistinguishable to the adversary and
the reason for this is well because we
have perfect witness
indistinguishability so there's no way
the adversary can tell whether we are
using a real witness for any of these
NAND gates all we're using simulated
witness plenty of the gates okay and now
what are we doing well we're giving a
proof where we start with giving H of
order n then we commit to ones and then
we use the trap door to open some
commitments to 0 to give the nand proofs
oh so you're thinking ok so you if i'll
try to reformulate your questions so
your question is so we have what we're
trying to do is a global proof that this
circuit is satisfiable and your concern
is what we have witnessed in this room
for these individual proves ok but does
that mean we have global witness
indistinguishability for the entire
circuit ok and the answer is yes because
we just need we only need this local
witness indistinguishability so what you
can do is you can take essentially one
of these proofs at a time for commitment
having 0 or 1 and you can show that it's
witness indistinguishable whether we use
in openings to 20 on opening to a one ok
and then you can flip one of these
proofs at a time and then you end up in
this situation here where they all a
what they all use trap door openings for
the commitments good ok so what we have
now is now we have h has order in we're
making commitments to ones and then the
simulator uses a trapped or two of them
some commitments in the nand cruise and
this is exactly what we do in the
simulation so yes
yes so your question is can we sing if
we have a simulator can we prove their
circuit is unsatisfiable and the answer
to that is yes we can do that okay and
and and well there's simply nothing in
the zero knowledge property of the sound
is that guarantees we cannot simulate
things on false statements okay so you
could pick friends in the circuit where
it's put where it's hard to decide
whether it's satisfiable or not right so
it looks like a real satisfiable
circuses I don't know some something
with a one-way function or something
like that so it's not distinguishable
from satisfiable circuit and you could
run the simulator and the simulator have
to be okay on this this one here so so
yeah you could do that yes
yes and I'm going to get back to that
little later yes
okay so what we have here actually this
is a strong form of zero knowledge what
I call composable zero knowledge okay
what it says is that we have on one hand
we could have a real common reference
drink or a signal ated common reference
drink and these are computationally
indistinguishable once we get to have a
simulated common reference during
actually have perfect zero knowledge
right it's perfectly indistinguishable
whether we are simulating or giving a
real proof okay so this is a stronger
notion than the standard zero knowledge
definition that just says combine these
two a indistinguishable from your cruise
okay so to summarize what we have now is
we have this construction of a
non-interactive zero knowledge proof
where we commit to all the wires prove
that each commitment contains zero or
one for each NAND gate we also make a 01
proof to show that it's respected by the
committed values and the total cost is
is a linear in the circuit okay and it
has perfect completes the perfect
soundness and this nice composable
zero-knowledge property and it's also a
proof of knowledge because if we have
this factorization of n if we know Q
then we can simply for all of these
commitments take CI to the q and what we
get out is due to the q raise to wi and
since all the wires are 01 it's easy to
figure out what the wire values are okay
so now i'm going to get to two pennies
that's correct yes it's true it
previously non-interactive xenon spruce
were typically statistically sound and
the reason was you you were sampling
these bits here and you had to have some
structure in the remaining bits but of
course I mean there's some extremely
small probability that you end up with
these hidden bits that don't have that
structure and then the provo could cheat
okay so that was also a tricky thing to
get and we get perfect soundness here we
do pay a little cost in that that in the
sense that we have a special common
reference drink we don't have a uniform
random common reference ring and you can
actually show that for a uniform common
reference ring you cannot have perfect
soundness as and the reason is simply I
mean there must be some common reference
string for which you can actually which
is a simulation string where you can
cheat right and if it's uniformly random
sample there's some probability that you
end up with this simulating camera first
ring and you can cheat so so you cannot
put a uniform random string get perfect
sounds but with a special common
reference during such as the one we use
here you can get perfect soundness yes
yes that's that's true i mean it would
it could be a explain and actually it
would be an exponentially small
probability and you can also have this
kind of mix so what you would have I
mean this is exponentially small
probability that you pick a bad common
reference string for which you do not
have something but if you were lucky
which happens with most probability then
you would actually have perfect
soundness on those common reference
things yes
hmm
perfect yeah that's possible I haven't
thought about that but yeah that's good
observation it very well be so ok ok so
now now I want to switch a live around
and I want to to talk about perfect zero
knowledge ok so just to give you a
little bit of history what was known
about zero knowledge proof so so
interactive truth it was pretty quick
that we got that for all languages in NP
ok computational zero knowledge and
pretty quickly we also figured out how
to do perfect zero knowledge for
interactive proofs and and of course
bloom felt McCauley they came along and
found on how to do nun interactive
proves with computational zero knowledge
and what remained was this the problem
of how to get perfect sara knowledge and
it seems like then this sampling
technique where we have hidden bits and
so forth in its inherently it's very
hard to get perfect serenity and I
certainly don't know any way that that
you can do that okay but with pairings
this is something we can do okay and I
think actually this was essentially what
what betty was just suggesting that
instead of using agent has order q we
use H so that has order n okay so we
simply start with a simulation come a
reference string and use that as a real
common reference string and what happens
now well it's easy to verify we have
perfect completeness that's just as
before and now as we argued before we
had composable zero knowledge right
which means that once we have a
simulated common reference drink we have
perfect zero knowledge so that's also
done if we have perfect your knowledge
and what remains is the to show that we
have computational soundness that
unfortunately fails so and and it's
instructive to see why that fails okay
so here's a natural idea of how would
you prove
that we have computational Sounders so I
would start with age that has order n
some adversary that comes up with a
false statement and a valid proof now I
would switch such as H has order Q and
the adversary would still produce some
statement and a valid proof because
otherwise it could distinguish between
each having order n or each having order
q okay and now we think we're done and
if we're just concerned or none adaptive
soundness where the statement is chosen
independently over the common reference
ring we actually do have that okay
because well if it could pick a false
statement where H has order N and give a
proof then and and the statements picked
in pending Lee of the comb referee
string then it would also pick in the
next instance this false statement now H
has autocue and it has perfect soundness
and we have a contradiction because you
cannot prove a false statement with HS
autocue but it's not adaptively sound
well maybe it is but but we don't know
how to prove it ok and the problem while
roughly did consider something like this
statement that H has order which is some
some prime order for instance ok and
what about this statement here let's try
to go through the argument ok so H has
prime order and when H has order n
that's a false statement right and we
imagine the atmosphere makes this
statement and that gives a proof and now
we switch where 828 the case where H has
ordered few ok and now the adversary
comes up with this statement h-has prime
order um and and here's a proof oh I
guess it's the other way around isn't it
nope
no yeah okay yes okay that's okay and
and now we have sunday the statement is
true right it does actually have prime
motive when H has over Q ok so this
argument doesn't work when the statement
depends on the common reference string
statement might say something about the
common reference string so I said when
we switch from one common reference
Taylor from a real comer reference mean
to simulate a comatose drinking we have
a problem it breaks down so the natural
definition of Sam is it seems like we
cannot actually get better for this type
of argument so let me tell you what we
can get we can get something I called
adaptive culpable sounds okay yes
right so so when H has ordered n it's
not a proof of knowledge because when H
has order in all the commitments are
perfectly hiding they're just random
group elements and then you cannot
extract anything okay so so what does
this definition say well what I'm
looking at here is we generate a common
reference string but what I require now
from that Missouri is not only does it
prove an an unsatisfiable circuit
provide a false statement and the proof
but it also has to prove a witness that
this circuit is not satisfiable okay
that the state it has to come up with a
proof a witness for the fact that the
statement is false okay and if we put
this risk right so so again I mean now
we're placing some restriction on you
know what kind of adversary we are
looking at and we would specifically be
looking at languages for which it's
possible to give proofs that they're not
that some element is not in the language
so we suddenly so we're certainly
putting a restriction on what we can do
here yes okay
III don't know exactly which classes
this would fall in them in what so I'm
not I'm not able to give you a precise
statement of exactly which languages for
which we can do this yeah yeah yeah yeah
yeah I mean again again for for all I
know actually this this this particular
zero support might be fine for all of NP
I don't know but okay so okay so so for
this type of argument here then we say
we have computational a couple the
soundness if for polynomial time
adversary it's hard to find some
unsatisfiable some false statement and
the witness that is false and the proof
that's valid okay and that's the kind of
thing that we get okay so let me sketch
proof that we have computational
culpable soundness here ok so imagine
again an adversary that could break the
culpable soundness so after seeing a
common reference during wage has order n
it comes up with some unsatisfiable
circuit some witness that this circuit
is not satisfiable and a proof ok and
then by the subgroup decision assumption
it should have the same roughly the same
success probability when H has order
cube because otherwise it could
distinguish ok so in other words when H
has autocue comes up with some circuit
some witness that this is not a
satisfiable circuit and the proof and
now we are in the case where we have a
contradiction right because when H has
autocue you cannot prove a false
statement
right so so this is this is the the end
result this is the computational to
somnos we get I personally my belief is
this is the right way to define
soundness for non-interactive zero
knowledge arguments with perfect zero
knowledge so I'll go that to that in the
next slide and try to argue my case okay
okay so so I'm claiming this is the the
right definition we should use for
perfect zero knowledge non-interactive
zero and all the documents okay and the
argument goes as follows first of all we
have some impossibility results so for
instance if you want to do some some
direct black box security reductions
then we can show that that's not
possible for perfect non-interactive
zero knowledge proofs to falsifiable
assumptions so so there's simply a
limitation this is probably the best we
can get with the techniques we know okay
and the second argument is that well
it's a useful notion because very often
we do have and non satisfiability
witness okay so one example would be
verifiable encryption okay I give an
argument that I have encrypted a
particular value okay what is the
witness that this is a false statement
well it could be the decryption key
right then you can just decrypt then you
can see a this was definitely not what I
encrypted right so in practice when we
do cryptographic instructions typically
the wildy and with this somewhere in the
system that this is not a satisfiable
statement this is a false statement okay
and whenever we have a witness that this
is a false statement then we're fine we
can use this on it perfectly a
non-interactive zero-knowledge proof and
finally we can go get kind of like
abstract framework so this is the
universal composability framework which
is a theoretical work that describes how
can we actually compose protocols how do
they fit
together and so forth right and actually
based on this type of perfect
non-interactive they're not we can
construct universally composable
non-interactive Zima knowledgeable this
is exactly what we need to construct
universally composable non-interactive
zero knowledge proofs okay so so I think
it's a right notion of soundness because
essentially what it says is that well
maybe the adversary could prove a false
statement what the adversary would never
know that that was her had proved a
false statement and would never have an
impact on the world that would never
make any difference to anybody ok and
then well do we care about such false
statements being proof no right doesn't
make a difference to anybody so that's
why I think in this particular case and
the natural definition of sound is
actually not the right one I think this
is the right definition of somnos from
non-interactive Sarah Norris proves that
have perfect zero knowledge
ok so to summarize so now we have two
different ways yes okay
yes that that should be fine I think so
yeah because what you're coming up with
you are coming up with so your carnal
example is ok here is a ciphertext it
contains zero or one you know that it
contains zero one and your claim is that
it's zero and you come up with a proof
of that ok and if nobody knows how to
decrypt the ciphertext ok and they all
in distinguish from each other who cares
whether there's a zero or one inside ok
so it may may well we be that is a false
statement but it's just kind of an
uninteresting false statement is a false
statement that doesn't affect the world
yeah ok so what so what do we have now
so we have non Interactive's your nose
proof of circuit satisfiability right
and since second satisfiability is
np-complete this means we have
non-interactive zero-knowledge pros full
of NP and we can set it up in two ways
we have this perfect binding key ok
whether H has autocue and that case we
have perfect completely perfect
soundness and computational zeros or we
can set it up with a perfectly hiding he
wear H has order N and that case we're
perfect completeness we have this
culpable soundness notion and perfect
zero knowledge ok so these are the two
ways we can set up for the common
reference string and the adversary has
no clue which type of camera referenced
ring is looking at you ok any questions
so far on this part
right
are right right okay so okay so then
guarantee you get here from this type of
non-interactive cirno's proof is
essentially you have to trust the setup
hey so there's a um trusted setup okay
so maybe you trust this so you trusted
so right so if you trust that the setup
is with one where H has autocue then you
know you have perfect soundness and
you're you're happy depending on what
kind of properties you want from from
this right and and this is not so
different from what you have with any
other type of non-interactive is your
knowledge proof right because again you
trust the setup to come up with a cum
referenced ring that will give you the
statistical soundness right because
otherwise it could produce a simulation
come a reference ring and you wouldn't
have any soundness okay so i want to i
think i still have a little bit of time
so i think i want to start on the next
part
okay so so what I want to do now is I
want to move to more to what a practical
non-interactive zero-knowledge proof ok
so so again if we look at what kind of
efficiency do we get a 4 non-interactive
0 now this process well we know that
with these hidden encrypted it's it's
just horribly inefficient because the
sampling process took really very
wasteful okay and what I've shown you
now is you know how to get very
efficient than interactive zeros proof
for circuit satisfiability but in
practice people don't go around with
circuits and want to prove that these
are satisfied what they have is
something very concrete right they're
constructing some type of group
signature scheme and they want to prove
that something they have encrypted a
signature on something okay and we would
like to have proves that can work in
this type of context okay so the goal
here is to get something really high
efficient something that's practical
okay and and what I'm trying to do here
is to come up with a non-interactive
zherneau's proof that can be used in
pairing based protocols so whenever you
have some pairing based construction
these are the type of proof that you
should be using okay and and very
importantly here right what we want to
avoid is this kind of NT reduction you
get right i mean obviously we can prove
everything because we've just proven an
NP give improves for circuit
satisfiability which I np-complete so
you can always take some pairing based
statement and reduce it to a large
circuit and then give a proof but that
would be extremely wasteful this
conversion to a circuit so we would
rather have something we can use
directly so i'll give you one concrete
example so this is from boilin and
waters in 2007 they came up with a group
signature scheme okay and the statement
contained a bunch of elements both
modulo n and in a group and something in
the target group and the proof was
witnessed were were these four group
elements that would satisfy these two
equations here okay so this is the kind
of statement that comes up in
practice okay this is a pairing based
type of statement okay involves the
operations we can do in by linear groups
and what they would like to do is to
give an efficient non-interactive
zero-knowledge proof of knowledge that
they have these folk know these four
group elements that satisfy these
equations okay and they came up with a
six element proof of knowledge of this
consisting of these elements here okay
so more generally if we think about the
constructions we can do in by linear
groups okay so we can have elements in
in the group who can have some elements
in integers modulo n we can have some
elements in target group as well okay
and we cannot come up with some
constructions right we can add or
multiply elements modulo n okay or we
can do exponentiation of group elements
to some exponents or we can do some
pairings of different elements okay so
these are the operations we have
available in a bilinear group and now
suppose somebody has come up with some
constructions in a bilinear group right
and then there might be somebody else in
the scheme that says you know are these
constructions actually correct right and
here we would like to be able to say
yeah yes they're correct here's a proof
ok and this proof we would like to be
very efficient
okay so i'm going to use a new type of
commitment scheme a commitments keep to
group elements and it's very simple and
it's very similar to the commitment
scheme i used before so we can set up
the commitment eh this is how order q or
such as it has order n and to a commit
to a group element i'm just going to
take the element x and x h to the are
okay and if this is a real common
reference string where H has autocue
then this is perfectly binding to X in
the order P sub group right because H
lives in the order q sub group but does
not affect what happens in the order P
sub group okay so more precisely if I
let lambda be a value which is 1 modulo
P and 0 modulo Q then c e raise to
lambda is essentially a prediction down
on the order p sub group and it is
uniquely determine some eggs to the lamb
/ and of course if this is a simulation
common reference string well then each
has order n and what we get is just a
random group element and that's
perfectly hiding
and we have some very nice homomorphic
properties also for this commitment
scheme here okay so what we have now is
if we multiply two commitments to group
elements we get a commitment to the
product of the group element and of
course well as a special case we could
have G to the X then we have the
commitment scheme from before right
where we multiply two commitments to
exponents and we get a commitment to the
sum of the exponents we could also do
pairings of commitments so suppose would
care to commitments together commitment
to x and y and what we get now is a
commitment to the pairing of x and y ou
K similarly what if we well from before
we had if we pair two commitments to
exponents that we get a commitment to
the product of the exponents and then
finally we could mix and match ok so
what if we take a commitment to a group
element and pair that with a commitment
to an exponent and what it gets us is a
commitment to the group element raised
to the exponent so in other words with
these commitments to respectively group
elements and exponent we can do all the
bilinear group operations underneath the
commitments we just pair the commitments
together and we get respective pairing
commitments to pairings of group
elements or commitments to
exponentiation zuv group elements or
commitments to sums or products of
exponents
so this is a generalization of what we
had before and it turns out that it's
quite useful and gives us some very
efficient non-interactive zero-knowledge
proof okay I'll let me correct myself
non-interactive with this industry in
visual person okay so let's consider the
equation as an example so I want to
prove that here I have constants
publicly known a and and this target
element eid in the target group and I
want to prove that there's some x and y
that satisfy this equation here and what
I do is I commit to the variable so it
commits to the X I would commit to why
and I want to prove that these committed
values satisfy the equation okay so the
proof will be in on this form and what
we do to verify it well we repair a
publicly known value with a commitment
to y and we pair the commitment to X
with the commitment to why okay and we
would see that this is the same as the
target that we wanted to to hit and
something that has order q ok so now you
can do the computation you can plug in
this this pie here in this equation and
you can see that everything works out
essentially what we have is that the
randomness respectively h to the s used
to hide why and H to the are used to
hide eggs well it all goes out here and
gives us the proof so that gives us
completeness yes
right
yes
okay so you're thinking about say a
multi-party computation setting or
something like that where people have to
commit to their randomness and follow
the protocol is that would
right right right um I think you could I
think you could do that kind of kind of
thing with the weather it was a couple
of a couple of reservations okay so one
one thing is I think for for these type
of construction you actually need a
proof of knowledge of some randomness
are ok now the problem with these
constructions is if you commit to an
exponent which is lives in zp
essentially you may not be able to
compute the discrete logarithm and
extract that exponent so therefore these
proofs I'm going to talk about now
they're not it proves that knowledge
respect to the exponents and that may
interfere with whether what you have in
mind
okay so let me just show you that this
is a sound as well okay so consider an
equation okay so we have this equation
here and we have the corresponding proof
where we just basically take instead of
the variables we put in the
corresponding commitment right and see
check that that's the same as a pairing
of age with the proof okay so why does
this give us soundness when H has order
q well we just take this lambda here the
projection on the order P sub group and
apply that to both sides of the equation
okay and notice here that I chose this
projection such that we project twice we
still get the same thing so the lambda
is the same as lambda square so what we
can do is basically we put lambda square
on both sides and and by the properties
of binding you groups that splits into
the underlying group elements that we're
pairing right so we have here a to the
lambda D to the lambda C to the land d
to the lamp and so forth okay and what
does that give us well it gives us
immediately that in the order P sub
group X which is C to the lambda and y
which is d to the number satisfy the
original equation right because in the
order P sub group this thing just
disappears so that gives us soundness
near order P sub group
okay and finally why is this witness
indistinguishable okay so witnessing
distinguishable ability that's what we
get when we have h has order n okay so
what happens if the H has order in well
all the commitments are now perfectly
hiding and that means that there are
many possible openings of each
commitment right because it's just a
random commitment so there could be many
possible openings that satisfy this
equation here that many witnesses ok but
when H has order n there's one unique
proof which will satisfy this equation
here there's one unique n that will fit
in here that will satisfy the
verification equation because each has
order n ok so in other words even if we
have two or more different openings of
the commitments and they satisfy the
original equation they will all map to
the same unique proof and therefore its
witness indistinguishable all possible
openings of the commitments that would
satisfy the equation they all map to the
same unique proof so the proof does not
reveal which witness we started out with
and that gives us witness
indistinguishability um okay suggest to
recap from from the last part what what
assured was a simple example a simple
equation where we could take have
commitments to the values some of the
values in the equation and show that
these committed values satisfy the
equation right and what's really going
on is that whatever homomorphic
operations operations we can use in the
bi-linear group we can do the same on
the commitments and that the committed
values we are essentially doing the same
operations on the committed values okay
and that gives us a proof
so okay so this was just one equation
okay and this particular equation is
kind of trivial is satisfiable of course
there's some makes and why that satisfy
this equation but when we have many
equations then becomes more tricky right
then it becomes more interesting type of
this statement we can make so so more
generally we can consider statements
that have many equations and we want to
prove that there's some variables X eyes
and that satisfy all the equations at
the same time okay so we have some
variables and we have many equations
over these variables so what we can
prove is that the some secret values x1
throughs exam in the group let's satisfy
all of these equations and what we do is
exactly what we did before we commit to
each variable we just do this once and
then we have commitments to every
variable and then we plug every
commitment into to the equations and
give proofs for every single equation so
that gives us a non-interactive witness
industry improves for a very general
class of equations so these are called
pairing product equations right because
you're taking up trade products of
pairings of group elements and they can
evolve both publicly known constants
that I've known to the verify so the AI
is here or the exponent gamma IJ that
can be no they're known to the verifier
that's part of the statement and then
you have these secret excise and the
claim is that there's some set of secret
exits that satisfy all of the equations
at the same time and you can easily
generalize the example I had before you
commit to every single X I and then you
give a proof for each equation that
these committed values satisfy the
equation
okay and each commitment costs one group
element each proof costs one group
element so what you end up paying is a
price of the number of variables you
have plus the number of equations you
have
you can generalize this even more
because of course we don't have to just
do pairing operations we can also do
exponentiation operations and
multiplications in the group okay or we
can do quadratic equations over the
exponents so we can multiply an ad feel
the 11th module and okay and you can
actually generalize this and do proves
for all of these types of equations you
can commit to some group elements in the
sauce group you can commit to some
exponent values okay and you can prove
these committed source group elements
and exponents satisfy all these
equations where the equations can be
different types so you can have both
carrying products multi exponentiation
products and quadratic equations and
that gives you full generality right
because these are the operations you can
do in bilinear groups yes
right right so yeah so you could ask I
guess more general questions okay so say
you have an arithmetic circuit or
something like that and and you could
say you know if you have an arithmetic
circuit of depth be then you can compose
it in two layers that have depth to so
to speak write and compose them so if
you have some intermediate values you
commit to those intermediate values and
then you can do in full arithmetic
circuit for instance okay then you can
generalize Hera thematic Swagger's to
also include some pairing operations and
multi exponentiation yes so essentially
everything you want to do in the pairing
based world consists of pairing or
multiplications of exponentiation
multiplications and asians of relevance
module and okay I think there's one
exception here we can't really do things
that live in the target group so so we
can because our cook we can commit to
things that are in the sauce group we
can commit to exponents module n but we
can't really commit to things in the
target group into sensible operations on
those so that's still an open problem if
some way to to deal with target group
elements
okay so what are the properties of these
non-interactive witnesses
indistinguishable well the two types of
common reference spring right H can have
order q or H can have order n okay and
these are two indistinguishable types of
reference strings in both cases we get
perfect completeness if it's a real
common reference drink where each has
all the Q then we get perfect soundness
in the order P sub groups and if it's H
has order n then we get perfect witness
indistinguishability so even if you have
many different types of witnesses that
satisfy all these equations you cannot
distinguish with which witness has been
used to generate the proof okay so this
was an example of how to do that with
composite order groups and it's useful
to think a little about what is it
actually that makes things work okay so
try to draw that with some some diagrams
so what we have here are commuting
linear and by linear maps between these
groups right so if we take to source
group elements we can use a paring and
get a target group element so what are
we doing here in this proof well we have
some variables x and y that lived in the
sauce group right and what we did we
commit it to those values so you can see
the commitment as kind of a a mapping
from from the group into the group
itself but where we put some additional
randomness on top of it okay and we
could do some comparing operation on
these group elements and then we'll get
something in the target group right and
we could also map the target group
Baldwin's we could do some randomization
with something that has autocue which
does not affect what happens with order
in the order P sub group of the target
group okay so so we started out with an
equation that lifted in these groups
here and use the pairing and then we
mapped it into commitments and some
verification equation that have some
some proof okay and the proof here
together with H lift in the
you subgroup and then to prove soundness
would use this projection here right we
raised to the lambda exponent which was
one module p + 0 modulo Q so it kills
out anything that has order q okay and
what we get then is the projection of X
to the order P sub group and the
projection of Y to the order P sub group
okay and the projection of target group
element in your P sub group and they
satisfy this original equation but now
just in the order P sub group okay so
all of this construction from a high
level perspective is because we have
these maps that are linear and bilinear
and they commute with each other now I'm
going to generalize this okay go beyond
just the case where we have the sub
group decision assumption okay so more
general when we use pairing based
cryptography well one thing is it's not
to use prime order groups because it's
more efficient to use primordial groups
okay so one nice thing would be to
generalize such we can choose whether we
want prime order of composite order
groups okay also the pairing groups
these groups the source groups well
maybe they're identical or maybe they're
different okay
yes yes yes yes so so so once i get to
the non-interactive witnessed in truth i
will give you some assumptions on what
I'm thinking yes ok ok so suppose we
have modules a-one a-two and a target
module well the statement will be
quadratic equations it's changing right
so we can have some secret variables X's
in a one wise in a tube and the claim is
that while we have a bunch of equations
we have these secret exits and we have
the claim is that there's some secret
X's and Y's that will satisfy all the
equations and all the equations will be
quadratic equations of this form
okay and the provo will know this secret
witness and that satisfy all the
equations and and use that to give
proofs and to simplify things i'll try
to use some some linear algebra notation
okay so so consider this inner product
here right that's just the usual inner
product we take x1 with be one here x2
would be too and so forth and add them
up okay so this equation here can be
written simply in the simpler form like
this where now we have vectors a and why
and so forth so those are the types of
equations that I want to prove a
satisfiable so I want to prove that I
have some some X vector and some Y
vector that satisfy all these equations
have many equations this for me
okay so so I'm going to again do as
before us I would like to make
commitment to these values here okay so
i would like to commit to the X's and
Y's and for that purpose i'm going to
map them from the module a that the
living into a different module be and in
the module be i'll make the commitment
okay so i'm going to assume here that i
have an inclusion map that can map from
a into a module be and i'll assume that
have a projection map that can map from
B to a module C and actually later on
we'll see that its soundness is what we
get in the modules see the sea modules
okay so just if you have the mind in the
example we had before with the composite
all the groups right here the a module
that would be a groove the sauce group
the b-mode work module will also be the
source group right because the
commitments live in the same group and
the sea budget that would be the order P
sub group where we projected into it to
get soundness ok so the setup then the
common reference string will describe
some elements in the module be that we
use for commitments and we're going to
commit to a value by mapping it into B
and then adding random linear
combinations of these new elements
okay and if if the image of the
inclusion map lives in the span of these
elements here then this is perfectly
hiding right because this linear
combination will just give some
something random in the span of the you
values okay and then it's perfectly
hidden whatever element it was that we
mapped into here so that will give us
perfect hiding and then a commitment it
will be perfectly binding to the
projection of that commitment right so
and actually force honest purposes we
would like the projection of these use
to be zero so whenever we project
something we cancel out all the you
values that we have added and again this
is very similar to what we saw before in
composite or a case right here in the
composite order case this age would be
one of these you values here okay there
would just be one of them okay and then
whenever we did the projection right we
mapped it into the order P sub group and
we just killed off the age let me okay
so let me just note one thing that in
general this projection here will be
hard to compute okay that's infeasible
to compute so so we can actually even if
they verify knows the commitment it does
not know what we have committed to okay
on the other hand of the inclusion map
has to be easy to compute because we
have to be able to make these
commitments
okay so let me give you an example in
the order P group ok so here what we'll
do we'll do the inclusion will take so
we'll have one module the a module
that's just the source group okay the B
module that's a cross product of the
source groups okay so that's g2 and then
we'll do projection down again on the
sauce group okay and what does the
inclusion map look like well basically
just take X and map it into 1 comma X
and what does a projection look like
well if we have two group elements we do
this computation here and this is an El
Gamal decryption and what is the alpha
while these elements here have been set
up such as you one is essentially
el-gamal encryption key and then we have
you too which is this random age in H to
the alpha plus towel and there can be
two ways to set this up okay so i could
set it up with tau equal to zero a towel
being different from zero and that will
be kind of respectively a real common
reference stream or a simulation common
reference string okay and if the
decision diffie-hellman problem holes
holes in this group we cannot
distinguish whether we have chosen tau
equal to 0 0 tau different from 0
okay so commitment here while we would
take some linear combination so will
include first we will take X map it to 1
comma X right and then we would take a
linear combination of the you elements
and here we're using multiplicative
notation okay so linear combination of
the you elements would be we have here g
to the r1 okay and then we would have an
and here g to the alpha 2 r1 so that's
our one on the you one element and then
for the you two element we have our two
so we have h to the r 2 and h to the r22
the alpha plus tau
ok so if tau is different from zero this
is actually perfectly hiding commitment
scheme okay because what does it give us
it just gives us some random group
element here and some random group
element here ok so our one random as you
can see our one is randomizing the first
one and r2 randomizing the second one
completely on the other hand if tau is
equal to 0 then this is actually an LG
mal encryption of X because if tau is
equal to 0 well then it would just have
something raise to r 1 r 2 and the same
thing reefs are one or two raised to the
elk MLP alpha and this is just an LG mal
encryption of X and what is the
projection map that's an LG mount
decryption right so they'll kemal
decryption of this thing would give you
X
okay and it's useful to note that if you
do the elca mouth decryption on the
owner LG Malky then you just get one
right so these new elements they just
canceled out under the decryption with
them come up so what we have here is an
example of a commitment scheme which on
when tau is equal to zero is an El Gamal
encryption of X and if tau is not equal
to 0 then it's perfectly hiding
commitment scheme so that's one example
of how you could set these modules up
but there are many different ways you
can sit down and on many different types
of assumptions okay so back to the
modules okay so we have this common
reference string and what it will
specify our zp modules a 1 a 2 a target
B 1 B 2 B target c 1 c 1 c 2 and c
target and linear and by linear maps so
inclusions from a 1 so b1 okay and
projection from b1 2 c1 and simply the
inclusion from a 2 2 b 2 and projection
from b to c 2 and the same for the
target groups and then we have this
bilinear map from a1 a2 into the target
module a and from b1 b2 into the type of
module BTW be and from c1 c2 into the
target see and is useful to think about
where do they take different things take
place so the provers witness that's in
the a modules right the provo has some
X's and Y's that live in the a modules
let's satisfy all these equations so
what's the probe are going to do it's
going to commit to these values these
commitments live in the B modules and
it's going to give a proof that's in the
B modules and we're going to verify the
equation in the B modules and then when
we argue about soundness what we're
going to do we apply the projection map
and we get soundness in the sea modules
now in the example I gave you before we
actually had a module's and see modules
were the same and then you get soundness
in the original group that you wanted so
let me see if I have an example for that
okay and so what do these examples
things look out would look like with
this Elgar Mallos type encryption
commitment scheme okay so we had these
maps here okay and we saw that well if
we had an element X in GG 1 then we
would map it into 1 comma X and if you
project that and do el gamal encrypts
you just get out X again right so that's
that's fine okay and then we we have I
mean we have an equation of a g1 g2 into
the target group okay so we could let by
linear map here would be pairings of
group elements in g1 and g2 now a
corresponding bilinear map from g12 to
the g2 two would be this thing here it's
essentially a tensor product with a
parent and then you could do a
projection here you would essentially
get this last one here so I wrote down
here in details what these particular
maps are
so as one example of these modules here
we could use this particular setting
here and we will get proves
non-interactive with this industry group
rules for statements over this in this
case in a symmetric bilinear group with
a g1 and g2 mapping into a target group
okay and in this particular example here
we can see that the a modules are the
same as the sea modules we get soundness
for the original equation that we
started out with okay okay so what is
the setup here so the common reference
string describes all these modules all
these maps here and also elements that
we use for the commitments and we're
going to set up the common reference
string in two possible ways okay could
be an witness indistinguishability
string and in for that case we want all
the commitments to be perfectly hiding
so we want the inclusion of anyone to be
in the span of the you of the the
commitment elements you want through um
and the inclusion of a two to be in the
corresponding commitment elements in B 2
which is V 1 through VN okay so in that
case the commitments would be perfectly
hiding or we could have instead and
common reference string where we get one
to get soundness in that case we would
like the projection of all the elements
in B 1 to be 0 and the projection of all
the elements in B 2 to be 0 such they
will cancel out when we argue soundness
ok so again the statement consists of
these quadratic equations right which we
can simplify like this okay so we have
some inner product or some some vectors
and we want to show that a bunch of such
equations are satisfied simultaneous by
some X values in some Y values and what
are we going to do while we're going to
do the same thing as we did before we're
going to commit to all these secret x
values and y values plug them into
corresponding equations in the B modules
and give a proof in the B modules and
and that's it and then Sounders will be
argued by projecting down to the sea
modules ok so the first step we do to
give this proof is we commit to all the
X's and all the Y's and again now I'll
use this notation here the inclusion of
of a vector that's just the inclusion of
x1 inclusion of x2 and so forth so that
gives us another vector so we get a
vector of commitments to the X values
and the vector of commitments to the Y
values
okay and each of those commitments
contain a linear combination of the use
so if we have many such then it becomes
a matrix times this new elements and
corresponding thing in b2 for the video
elements okay so now what we do is we
take each of these equations and map
everything to the B modules okay so
we'll map all the eight public a values
into the B modules all the public p
values into the new modules the vector
the matrix gamma or containing some some
exponents that's just the same as before
the still elements in zp ok so we map
everything into the B modules and in the
B modules well we have these commitments
to the Y values and to the X values and
then we'll give some proofs ok so we'll
have from part of the proof will be a PI
vector that lives in bb2 module and
password with these five volume which
lives in be one module and a verified
we'll check that this equation holds
okay so let me ask you why we have
sounded here okay so we have these
equations here and for each equation the
verify will check that this holes so
what happens if we apply the projections
on these well we know that projections
of the you values give us 0 under sound
new string and the projection of the V
values give us 0 on a sounding string so
that means whatever we have over here
we'll just project 20 and whatever we
have here we'll just put it project 20
it will cancel out right because it has
something with the you values something
with v values and they are projected
down to zero and what we're left will
then is the interesting stuff that has
something to do with the secret
variables and the equation we wanted to
verify okay so if I just do some some
redefinition to avoid too much
notational clutter here so after the
inclusion of a and the projection we get
a prime and similar for the other things
what we end up is now this equation here
in the sea modules after projecting so
we'll have a prime times u prime Y Prime
and plus X prime inner product with the
B prime plus X Prime in a project with
gamma times y prime is the same as the
target prime plus 0 for 0 because these
things you and these they just project
it down to zero okay so essentially what
we have now is some X Prime and some
white prime values let's satisfy the
equation after having projected the
equation down to the sea modules okay if
the a modules and the sea modules happen
to be the same and this is the identity
map then we have proven soundness for
the original equation but as we saw
before right I mean for the composite
order case we couldn't get soundness for
original equation what we get was God
was soundness in the order P sub groups
okay so maybe the sea modules
other than the original eight modules
okay so i tried doing this for the
example from before based on el canal
the commitment schemes here so here we
have exactly that the a1 module that's
g1 and the c1 module that's g1 right so
those are the same and after including
and then projecting you just get the
same value as you had before ok so in
that case we get values X values and y
values that satisfy the original
equation that we wanted to prove was
satisfied
okay okay so then I have to argue that
it's complete okay and what we do for
that is essentially a lot of computation
ok so the probe has these commitments
here okay commitments to values the
witness that satisfy the original
equation you map everything down and you
want to construct proof here and prove
here that you can make this equation be
okay and what the proofs look like
something like this and then you do a
lot of linear algebra and you see that
everything works out essentially what's
happening here is after mapping down to
the B modules we have D which is
commitments to the Y values and we have
C which are commitments to the X values
okay but they have both of I of others
in the X values but they also have some
randomness and you take all this
randomness and pull it out and put it in
proof so you balance the equations
okay and finally we have targeted this
is witness indistinguishable okay so if
we have a witness indistinguishability
common reference string and we know that
by definition that the inclusions of a
one and inclusion of a two are respected
within the span of you values and the V
values and the commitments are perfectly
hiding ok so the commitments are
perfectly hiding and that's of course
great but we have to make sure that the
proofs don't leak any information part
of witnesses so what about the proofs
well if the proofs were unique then we
would have perfect witness
indistinguishability because that would
mean that all witnesses mapped to the
same unique proof ok so that was the
case we had in the composite / case now
in general that's not what we get and
generally the proofs are not unique ok
so in particularly in the example I gave
you based on LG mal commitments actually
the proofs are not unique there may be
several different proofs that satisfy
the verification equation so what do we
do if that's not the case well we'll try
to randomize the proofs so the proofs
are completely random ok so in other
words the proof looked like a completely
random proof that satisfies the equation
ok and since they completely randomly
means that any two witnesses they would
just map to some completely random proof
and you could not distinguish between
two witnesses so that's another way to
get perfect witness indistinguishability
make sure that the proof can be
completely randomized
okay so one way to randomize it is the
following so suppose we start out with
some some proof that we have for this
equation here well we can take this
proof pi and add some matrix t
multiplied with the v elements and then
subtracted over here okay and that's you
know those two just adding it here and
subtracting it here that just cancels
out okay so this would be a new proof
for the same statement but now we have
done some randomization of the proof
okay and since this B value here spans
everything that this proof will map into
if we look at the proof that the way it
was constructed actually this is a
completely random proof in the span of
the V vectors so this operation here
randomizes one of the proofs one of the
proof vectors now it's possible that the
second one is unique and then we're done
then we have completely randomized okay
and in the example I gave you based on
these DD age groups and elk Emily
commitments that's actually the case and
we're done we have done complete
randomization and we get witness
indistinguishability it's not always the
case you can come up with for instance
proves based on the decision linear
group where even after doing this
operation here now we have randomized
one per part but but the other part is
still not completely random what you can
do then is to ensure that you also have
some you just add some more randomness
here in the orthogonal space with we
took make it completely random
okay so that's the overview of the
construction so we start out with some
equation in a modules we commit to all
the values just plug them into the
equation the same way after mapping
everything to the B modules and then
we'll get some proofs here in the B
modules okay and essentially yeah we
showed completeness that you can do this
if you have a witness in May modules you
can map everything to something the B
modules that satisfy this equation okay
okay and then we show that well if you
apply the projections this one here
cancels out this one here cancels out
and we get soundness in the sea modules
okay and for witnessing distinguish
ability important thing was simply to
note that all these commitments in the B
modules they're perfectly hiding and we
can randomize the comp roof completely
using a bunch of linear algebra
okay any questions so far yes
that's yes yes okay so so what what do
you gain from from doing this apt
abstraction so what you get is you get
get first of all you get the
generalization that you can get
non-interactive witness individual
proofs in the cases that are not
composite order case but which are
really interesting right so for instance
the a symmetric case whether you had
decision difficult in both groups that's
an important case because that's why we
have the most efficient pairings and
where we get the most efficient schemes
so you get an efficiency again you get
applications in the most efficient
setting for pairings right you also get
some some resilience in terms of
assumptions right because you can
actually you can base this on you can
base it on decision day for helmet as I
did an example but you can also based on
decision linear assumption or you can
base it on the K linear assumption and
so forth so you automatically have a
large class of non-interactive witness
interesting visual proof depending on
the assumption you want to use so it
gives you a lot of flexibility yes so
the instantiations would be would be
different but we have a general compiler
that says you give me any assumption and
the groups and now you can i can give
you the corresponding proofs and system
okay so so what I want to talk about
next is zero knowledge okay so are these
proofs zero knowledge well they are
suddenly perfectly witness
indistinguishable if we happen with this
indistinguishable common reference
string but are they also zero knowledge
okay so do these proofs reveal anything
useful so that is serving okay and the
way to think about this is well if we
want to prove that there's their
knowledge we have to be able to simulate
right and how we're going to simulate
here well it's not clear right we have
we know that we cannot distinguish
between witnesses that if we don't have
a witness to start with we may not be
able to simulate yes
okay so the question is can we can we do
some sort of or proof um well you can do
that in some of these constructions you
can do or proves and if I have the time
I'll get back to that a little later um
but even so you actually get some some
trouble with the simulation even for the
or prove you still need a witness
something you could plug in that looks
plausible for the real construction so
so what you could do you could of course
do a general all or proof in the sense
you reduce it to a circuit which is an
or but then you're losing efficiency
right so you want to do something that's
direct for these groups you don't want
to lose efficiency by doing this kind of
reduction okay so the problem is we
cannot simulate proof without knowing a
witness and the way into to get around
this as I'll show you is that we can try
to set up this witness in this room
should will come a reference drink such
as similar it can actually find the
witness now we cannot do that in general
but we can do that in some special cases
in one special case is if one of the
modules is zp ok so this covers
multiplications of elements modulo P
this covers the exponentiation right but
it doesn't cover pairings of group
elements but it's an important subclass
of problems and here we can get zero
knowledge okay and the way it works is
as follows so suppose a one is instant
CP so this inclusion hear of a one on w
is us would be in the span of the you
elements that means since they're
perfectly hiding that we could set up
the commitments such the inclusion of
one is the same as inclusion of zero for
some known combination of the use
it's exactly the same as we did before
in composite or group we set up a trap
door commitment scheme where we can open
it as one or a zero and that's what
we're going to use as a simulation trap
door now we can rewrite the equations to
this form here so basically I'm taking
the t and moving it to the other side
okay and writing as one x minus T okay
so now we have a new equation okay we
rewrite all the equations that like that
that's fine but now what we can do is we
can pretend that the one is actually a
variable okay so the one here is a
variable eggs not and what we'll do is
we'll say the inclusion of one is a
commitment to X naught of course it's
easy for the verifier can check that
well yes the inclusion of one that's the
commitment see not and it has to be a
commitment to one on the soundness
string on a witness indistinguishability
stream their knowledge string right we
can actually open this X naught to both
a 0 or a 1 because we know a trapdoor
for the commitment scheme
okay and now we have a witness for every
equation the witness is set everything
to be 0 X nor 20 x is 0 Y is 0 now we
just have 0 all over the place that's a
witness so by this little rewriting of
the equations the simulator is now able
to find witnesses and then it can use
that witness to create proofs and buy
the perfect witness indistinguishability
this looks like a real proof okay so
this is a perfect simulation and we get
perfect zero knowledge
ok
the only remaining thing is water if we
have pairing product equation okay there
we can't do this trick here we can trap
door open commitments to group elements
unfortunately but if we restrict
ourselves so the only problem is we
might not be able to find some witness
such as we get that target element in
the end but what if we just restrict
ourselves and say the target element has
to be one okay or each pairing of G with
G rate to zero and in that particular
case now if we choose all the X's and
all the wife-to-be ones as well we
satisfy this equation here everything is
one and the equation is satisfied so in
this particular case restrict the space
of equations we can also give witnesses
for the pairing project equations ok so
in this case the simulator just picks
all the exercise to be one all the YJ is
to be one so these are group elements
and all the exponents to be zero and it
has a witness and it can give simulate a
proof
okay so what kind of efficiency do we
then get here okay so the cost of each
variable g1 if I use the example at
before based on the decision difficult
main assumption well each commitment to
a variable or an exponent in g1 zp
that's two group elements right because
each commitment was an essentially an El
Gamal encryption or two random group
elements and the same for commitments to
Y values just they just live in in g2
and the pairing project equations while
they cost for group elements each okay
and multi exponentiation are a bit
cheaper and the cheapest ones on the
credit radical equations so this gives
us really efficient non-interactive
witness indistinct through proof or if
all the target elements here are one
that gives us zero knowledge Bruce okay
now of course it's not as nice as the
composite or a case where the group
elements had just one group element for
the each commitment one group element
for each proof but these groups here are
much smaller so if we look at it in
practice these proofs actually much more
efficient than new composite order case
okay do I have some time left five
minutes okay let me just pop up some
slides and speed through five minutes
and see how far i get
okay so i just wanted to show a couple
of cool things that one one can do okay
so what we have now is is I guess what
you really want to use in practice we
have these non-interactive witness
indistinct roof non-interactive their
knowledge proof that you can use in
tearing settings right now focused here
on the on the isometric setting where we
have two different g1 and g2 with Prime
order because I think that's the one
that gives the most efficient
constructions in practice okay so let me
see what I can do in five minutes okay
so so one thing I want to remark is
first of all this this question here
what can we do if we don't have a common
reference string and we know that zero
knowledge proves that just out of the
question right that's what approved
before but the interesting thing is that
it turns out you can do non-interactive
proofs that are witnessing distinction
without a common reference string okay
and let me just try to briefly describe
the idea so the ideas are following okay
we could try first a naive idea what
would we do to convince the verifier
well approval would pick a common
reference string and send a proof to the
verifier and of course this is a stupid
idea right because the prover might take
a simulation common reference during and
simulate a proof and you know it
shouldn't convince the verifier ok so
the verify says no to that but what you
can do instead is you can pick tool
common reference string that are related
in a particular way such that the
verifier is guaranteed that one of them
is sound ok but the verify cannot tell
which one of them is the sound of string
but the verified doesn't care right just
catch that one of them is a sound in
string and it's easy a proof
corresponding to that string ok so what
will happen here is that the prove our
pics to related common reference strings
and gives proofs for each of those
common reference strings and if one of
them is sound then the verifier is happy
that we can set up okay let me see BGN
groups are not right yeah yeah proof
proof get two different proofs with the
same common reference string yeah one
might be able to do that I haven't
looked at it so maybe yeah okay right
yeah so that's both an assumption
question I mean because you need two
extra assumptions 2d randomizes apps and
and there's an efficiency question that
with this is an efficient construction
ok so I just wanted to briefly show you
two related crss so this is based on the
decision linear assumption it has a
bunch of group elements and the only
difference between the two camera
reference ring is in the last element
here we have W not here we have W naught
times age ok and then that will
guarantee that well essentially think of
this HS as the Tau that we had before
right so one of them could have tau
equal to zero but not both of them one
of the Taos has to be nonzero ok so
these are two common right for related
common reference rings so you know one
of them is a sounding string and now
we're happy we get witness
indistinguishability i'll skip the proof
of that since I'm short on time and I
wanted to mention briefly a little more
I have two minutes left if I'm correct
here ok so a couple of other nice
properties some things that you cannot
typically do with other types of zero
knowledge proof in particular you cannot
do these things with the fear me
heuristic ok so one of the thing no
things to notice that proves a group
elements what does this mean we can give
proofs of proofs for instance right
because proves are just things over you
prove things about group elements ok so
we can have a proof then we can prove
that we have a proof we can prove that
we have a proof that we have a proof
okay and things like that that would be
horribly inefficient with the field
shamir heuristic because you would have
to prove things about a hash function
and how it evaluates and so forth okay
another nice thing is that we can modify
and and randomized proves okay and this
is something that that Anna is going to
talk a little about tomorrow I think so
so she was one of the first to notice
this and come up with some nice
applications of that so let me just give
a brief example of how one can do that
so suppose we have this proof for this
equation here well you can just
randomize it you can modify the
commitment live you can modify the proof
correspondingly and then we still
satisfy the equation okay so we can
randomize the commitments we can
randomize the proofs and we can also do
other operations and we actually
modifies now we're proving different
statements from what we were proving
before but related to things we've seen
before and this is again is a unique
feature of pairing based proofs
something you cannot do with the future
mirrors take all the other proof systems
we know based on the hidden random bits
model okay and now I'm out of time I'm
afraid okay thank you
hello everybody in this video I will
show you how to implement to a pair
fighting algorithms namely die strong
and a star in Java so what does this
time
so this one adds our entry point class
which will actually execute the program
but since we're they don't be graphs I
think it's reasonable to start from
defining the graph nodes that graph is
short for directed graphics used
throughout literature so get used to it
sorry
so IDE zero actually identifying a
particular graph node and Everson
winning in this video is actually this
set of children I use a hash table so
that we can ask for children in like but
it personal is a child bound in constant
time L so sample going to put those de
Graaff notes in pairs table base data
structures we need to define at least
two methods
and the first is boolean false the
object and also 15 - code so on hash
code is easy just put on the ID it comes
to this 100 is you know or get class the
path come on one
which are false otherwise
yeah so if the nonsense MIT I consider
it to be the same s all when we bring to
it are something like yeah no I do yes
yes that's all it's a good practice to
put those annotations if nothing nothing
else for the sake of documentation L so
22 minutes topic deployed earth below
the note child see you then this has
imposter time finally
that we expose the internal data
structure but we can multiply it
sometimes we prep the set in sort of
unmodifiable wrapper okay let's go on
eat bread weight function yep
this is one this is going to be easy
so we need only to mediscare
yeah
finally okay not not quite finally but
we need the heuristic function for a
star but just we're going to be in
interphase and you see later why
next we're going into actual Euclidean
eristic
hmm
okay we don't
they stopped that time
all right here we go
I will explain you some details before I
go to implementing the a star so let's
start from the node class so once again
de Graaff stands for directed graph
don't don't stress is actually how
people call directly class in computer
scientific literature and the identity
of each notice in specific in just an
integer ID value and also we have this
overriding we'll have over on this
equals and hashcode minutes so basically
it allows us to put and manipulate our D
graphs in hash table data structures so
actually if you don't know what by the
way was over right is it means that we
are operating some method which is
present in some base plus the funky part
about override is that if you sort of
spoil something like the signature of
the method being overriding your ID will
most likely override this and not your
about this issue so it's nice to use
override annotation okay what's next
yeah we actually if you look at this we
have the set of children's children is
not the least but it said the the point
is that you can pretty efficiently add
notes and actually if we have this sort
of remove node operation blah blah blah
it will run in constant time as well I
mean constant I'll for removing note
from this children set so it's nice that
stretch to use is the setting okay next
I actually podcaster this diagraph white
white white function you could actually
sort of hard-code the weights in this
diagraph now type something like the red
pile map big rap now doubly like this
but there I think it's a good idea to
actually separate the concept of graph
from the concept of the weight function
for the graph so I use this explicitly
the graph point function as a pointy
part is that actually if you have some
graph with the Poggi you don't want to
change but you have different wave
functions I think it makes sense to
decouple the wave function from the
extra graph okay next we're gonna need
this
basically this diagraph coordinates cost
doesn't last nothing more but just Maps
the graph node to some point on the
two-dimensional plane so what comes to
heuristic function as a concept well we
just have one minute to get estimate
double bar between two node so it could
be and she's opening a heretic function
uses behind the scenes this distance
method which is an aquarium length
between two two-dimensional point so
let's go let's get back to the actual
search algorithm and start filling in
this code by the way I'm going to need a
helper class here
hmm
and transfer and we want to make it
comparable
you can implement your this place is
gonna be connections with our double
affair this distance to hold another
distance yes
so we need a priority queue this one is
a mineral heap actually but the pretty
efficient and simple to implement but
you don't want to implement it so we
just use whatever is available in that
double ability also
so basically open contains the so called
search point here or notes which are
assumed to be reached by the search in
the closed is the set of notes
who's the best known estimate we already
know show the status them there please
distance is a hash-table for mapping
each node to its best known estimate so
far
and this parents map is added structure
we need to actually reconstruct a
shortest path now we need to initialize
our data structures you entry source and
then estimate is zero actually the at
this point we can put any value because
affects nothing at this point but and we
know it's system based it is estimate
it's obviously zero and this now value
will be a sentinel value which was
signal at the arm we have constructed
constructed ahead the entire path
yeah I'll get back to this press that
path okay by the way I mean they're
actually too excessive so fast you
couldn't get it as well oh crap no and
you
the tentative distance of the channel is
then don't have the best non-technical
business of the current node which is
actually best at this point plus the
wave function so where we all would have
plain function I just want a function we
get from current no no - no now
or
in this case
to the distance or improve it and good
this means that we came to look into
child down from children No
and finally we put an energy panting out
with a shout out and thank the deep
distance loss eristic estimate
okay interesting function is called
poster function get estimated default
shoutouts to die
that's a lot
okay and okay I think the basic brain
structure is you have 1 loop 1 loop
inside another loop before somehow
somehow this open becomes empty before
we should target the things that the
target is not reachable at all for this
reason we return to step into path
signal this good situation
ok now let's get back to this phrase
backpack method and down
finally we need to reverse the path so
that the source not is the first and the
lock our target now is the last node in
the list called bad most specialist
again explain
yeah cool other an election enhances
distance it seems Tony false compare
method which seems budget for power to
kill so on
so here when calling a demonstration
program which will actually run and
measure the time taken by the algorithms
so on
the function the function part about
this saved value and reporting it in the
statement is that assassin if your
friend notes that something goes wrong
everything he needs to do is just to the
report ports it was for his test case
and you can replicate this the same the
very same computation which is nice so
fortunately to create some random graph
is actually a lead
and
random
all the new more readable personages and
oh yeah
get this so we have a graph consisting
of nodes and some arcs between those
some much
next we need to actually sort of PowerPC
right talking about the four units
van Gogh when in just random oil
function as well
metals away
okay is easy you point the double which
is a study from your class as far as I
understand so
okay
so
I need to grab weight function is the
next actually I think better name would
be like create something create
coordinates for get by function but all
over
holy Sh clean out up the glass reflects
to that fish smell and now
so each other across so our point tux
tea
you bring it for better efficiency
action
and the point too is
according out of the child next double
instance is simply c'mon basis to third
and the final weight function will get
something like water so you know child
let's say something like I will
understand our explain later what this
actually needs but does traffic we need
it when is it okay
this is started
mm-hmm
next we choose to note for us to some
know from draft which random graph mode
started to rap doing random south
sauce is them
everyone so actually let's see what we
have at this point okay in disgust
okay we have source and target
as you can see they bribe depending on
the time or the better one to see if is
the best in time
okay now let's see a waste
launch option new toll
okay and now long start as system
let's see um boss should be stuck this
is correct
source to target using wave function in
the healthy functional
f1 for each system of Ln okay
okay we have something let's continue
now you may ask how about Isis
aggravating it's so much work I thought
nah it's nothing for since we have a
star see see what happens
die ha oh my god yes beautiful
oh please
grep search um
now watch what it would be to you we
turn our star or a third sauce
finally it'll cleanse l function blend
and watch the certain zero the bed the
most optimistic estimate for a shopper
spare so
nice sparking and that is is finally
algorithms ugly and the path is simply
as yes
- okay fingers crossed let's see what
happens
actually it would have been really good
idea to actually warm up to Japan but da
goo goo actually I need to do is just
increase the size of the grip and let it
be like this
okay so first of all the paths are the
same and it opens this one and like this
algorithm it took like six times more
six times four times an a-star so I
think it's pretty much correct so on
little bit of visual separation I look
like a shape so I started certain
function hand from form playing back one
yes it takes 15 within the path to and
under if I wanted to play too old to
violence
yeah I think I think we got it
so let me just explain you one saying
why we actually get to a sort of two
birds with one stone but why don't we
just reuse the a start for our staff
Posada little well the point is that you
can sink that Dijkstra is the same as a
starter without heavy stick without in
this context means that every estimate
is always zero so the point about the
the a-star is that it's sort of knows in
what direction it should proceed but -
who doesn't know it so we sort of gross
this the shortest path free in all
possible directions of the graph and and
also but actually you asked me about it
I can tell you zero is so-called be
directional spread search algorithms
which are usually much more efficient
and - Drive and a star but I will leave
it to you so let's just skim through the
code just a little bit and uh so yeah
the crop is just working but was working
on we have like 50,000 nodes and ten is
much tons of arts but basically it's a
very sparse graph and sort of hmm
yeah in this scenario we just use the
Collegium heretics but service also
so-called Manhattan heuristics and some
chebyshev heuristic and long usually you
want your have a stick function to be as
efficient as possible so you don't spend
much time in completing an estimate but
the price is that regardless in the
heuristic function does your algorithm
in which direction to actually proceed
they do not necessarily take into
account so some obstacles they might be
only shortest path but well you get any
wing always and the podcasters estimates
there must be hockey stick which means
they under a teammate is a distance if
this is not the case you may come up
sometimes with a suboptimal path but
think about it was the most optimistic
well which is zero because negative
estimates does not make sense and
actually you are also remembers that
these algorithms doesn't perform are not
veteran best friends with negative
weight cycles so please don't do it
so finally
yeah I think this is pretty much this so
on I hope you enjoyed the fall story and
if you have if you have questions
comments or you want to sort of tell me
how how could they improve my video
tutorials please leave a comment and now
well maybe someday I will continue on
doing those tutorials because I already
like it but um well see you later
alligator
hello everyone so far in this series on
data structures we have talked about
some of the linear data structures like
array linked lists stack and queue in
all these structures data is arranged in
a linear or sequential manner so we can
call them linear data structures and
we've also talked about tree which is a
nonlinear data structure tree is a
hierarchical structure now as we
understand data structures are ways to
store and organize theta and for
different kinds of data we use different
kinds of data structures in this lesson
we are going to introduce you to another
nonlinear data structure and that has
got its application in a wide number of
scenarios in computer science it is used
to model and represent a variety of
systems and this data structure is graph
when we study data structures we often
first study them as mathematical or
logical models here also we will first
study graph as a mathematical or logical
model and we will go into implementation
details later okay so let's get started
a graph just like a tree is a collection
of objects or entities that we call
nodes or vertices connected to each
other through a set of edges but in a
tree connections are bound to be in a
certain way in a tree there are rules
dictating the connection among the nodes
in a tree with n nodes we must have
exactly n minus 1 edges one edge for
each parent-child relationship as we
know an edge in a tree is for a
parent-child relationship and all nodes
in a tree except the root node would
have a parent would have exactly one
parent and that's why if there are n
nodes there must be exactly n minus 1
edges in a tree all nodes must be
reachable from the root and there must
be exactly one possible path from root
to a node now in a graph there are no
rules dictating the connection among the
nodes a graph contains a set of nodes
and a set of edges and edges can be
connecting nodes in any possible way
tree is only a special
kind of graph now graph as a concept has
been studied extensively in mathematics
if you have taken a course on discrete
mathematics then you must be knowing
about crafts already in computer science
we basically study and implement the
same concept of graph from mathematics
the study of graphs is often referred to
as craft theory in pure mathematical
terms we can define graph something like
this a graph G is an ordered pair of a
set V of vertices and a set of edges now
I'm using some mathematical jargon here
an ordered pair is just a pair of
mathematical objects in which the order
of objects in the pair matters this is
how we write and represent an ordered
pair objects separated by comma put
within parentheses now because the order
here matters we can say that V is the
first object in the pair and E is the
second object an ordered pair a B is not
equal to B a unless a and B are equal in
our definition of graph here first
object in the pair must always be a set
of vertices and the second object must
be a set of edges that's why we are
calling the pair an ordered pair we also
have concept of an ordered pair an
unordered pair is simply a set of two
elements order is not important here we
write an unordered pair using curly
brackets or braces because the order is
not important here an ordered pair a B
is equal to B a it doesn't matter which
object is first and which object is
second okay coming back so a graph is an
ordered pair of a set of vertices and a
set of edges and G equal V E is a formal
mathematical notation that we use to
define a graph now I have a craft drawn
here in the write this graph has 8
vertices and 10 edges what I want to do
is I want to give some names to these
vertices because each node in a graph
must have some identification it can be
a name or it can be an
index I'm naming these vertices as V 1 V
2 V 3 V 4 V 5 and so on and this naming
is not indicative of any order there is
no first second and third node here I
could give any name to any node so my
set of what he sees here is this we have
eight elements in the set v1 v2 v3 v4 v5
v6 v7 and v8 so this is my set of
vertices for this graph now what's my
set of edges to answer this we first
need to know how to represent an edge an
edge is uniquely identified by its two
endpoints so we can just write the names
of the two endpoints of an edge as a
pair and it can be a representation for
the edge but edges can be of two types
we can have a directed edge in which
connection is one way or we can have an
undirected edge in which connection is
two way in this example graph that I'm
showing here edges are undirected but if
you remember the tree that I had shown
earlier then we have directed edges in
that free with this directed edge that
I'm showing you here we are saying that
there is a link or path from vertex u to
V but we cannot assume a path from V to
u this connection is one way for a
directed edge one of the endpoints would
be the origin and the other endpoint
would be the destination and we draw the
edge with an arrowhead pointing towards
the destination for our edge here origin
is U and destination is V a directed
edge can be represented as an ordered
pair first element in the pair can be
the origin and second element can be the
destination so with this directed edge
represented as ordered pair UV we have a
path from u to V if we want a path from
V to u we need to draw another directed
edge here with V as origin and u as
destination and this edge can be
represented as ordered pair V you
the upper one here is UV and the below
one is vu and they are not same
now if the edge is undirected the
connection is two-way an undirected edge
can be represented as an unordered pair
here because the edge is bi-directional
origin and destination are not fixed we
only need to know what two endpoints are
being connected by the edge so now that
we know how to represent edges we can
write the set of edges for this example
graph here we have an undirected edge
between v1 and v2 then we have one
between v1 and v3 and then we have v1 v4
this is really simple I'll just go ahead
and write all of them so this is my set
of edges typically in a graph all edges
would either be directed or undirected
it's possible for a graph to have both
directed and undirected edges but we are
not going to study such graphs we are
only going to study graphs in which all
edges would either be directed or
undirected a graph with all directed
edges is called a directed graph or
digraph and a graph with all undirected
edges is called an undirected graph
there is no special name for an
undirected graph usually if the graph is
directed we explicitly say that it's a
directed graph or digraph so these are
two types of graph directed graph or
digraph in which edges are
unidirectional or ordered pairs and
undirected graph in which edges are
bi-directional or unordered pairs now
many real-world systems and problems can
be modeled using a graph graphs can be
used to represent any collection of
objects having some kind of pairwise
relationship let's have a look at some
of the interesting examples a social
network like Facebook can be represented
as an undirected graph a user would be a
node in the graph and if two users are
French there would be an edge connecting
them a real social network would have
millions and billions of nodes I can
show only few in my diagram here because
I am short of space
now social network is an undirected
graph because friendship is a mutual
relationship if I am your friend you are
my friend too so connections have to be
two-way now once a system is modeled as
a graph a lot of problems can easily be
solved by applying standard algorithms
in graph theory like here in this social
network let's say we want to do
something like suggest friends to a user
let's say we want to suggest some
connections to Rama one possible
approach to do so can be suggesting
friends of friends who are not connected
already Rama has three friends Ella Bob
and Katie and Friends of these three
that are not connected to Rama already
can be suggested there is no friend of
Allah which is not connected to Rama
already Bob however has three friends
storm Sam and Lea that are not friends
with Rama so they can be suggested and
Katie has two friends Lee and Swati that
are not connected to Rama we have
counted Li already so in all we can
suggest these four users to Rama
now even though we described this
problem in context of a social network
this is a standard crafts problem the
problem here in pure graph terms is
finding all nodes having length of
shortest path from a given node equal to
two standard algorithms can be applied
to solve this problem we'll talk about
concepts like path in a graph in some
time for now just know that the problem
that we just described in context of a
social network is a standard crafts
problem okay so a social network like
Facebook is an undirected graph now
let's have a look at another example
interlinked web pages on the internet or
the world wide web can be represented as
a directed graph of web page that would
have a unique address or URL would be a
node in the graph and we can have a
directed edge if a page contains link to
another page now once again there are
billions of pages on the web but I can
show only few here the edges in this
graph are directed because
relationship is not mutual this time if
page a has a link to page B then it's
not necessary that page B will also have
a link to page a let's say one of the
pages on my code school comm has a
tutorial on craft and on this page I
have put a link to Wikipedia article on
graph let's assume that in this example
graph that I'm showing you here page B
is my my code school tutorial on graph
with this address or URL my code school
comm / videos / graph and let's say page
Q is the Wikipedia article on graph with
this URL wikipedia.org
/ wiki / graph now on my page that is
page P I have put a link to Wikipedia
page and graph if you are on page P you
can click on this link and go to page Q
but wikipedia has not reciprocated to my
favor by putting a link back to my page
so if you are on page Q you cannot click
on a link and come to page P connection
here is one way and that's why we have
drawn a directed edge here okay now once
again if we are able to represent web as
a directed graph we can apply standard
graph theory algorithms to solve
problems and perform tasks one of the
tasks that search engines like Google
perform very regularly is web crawling
search engines use a program called web
crawler that systematically browses the
worldwide web to collect and store data
about web pages search engines can then
use this data to provide quick and
accurate results against search queries
now even though in this context we are
using a nice and heavy term like web
crawling web crawling is basically draft
traversal or in simpler words act of
visiting all nodes in a graph and no
prizes for guessing that there are
standard algorithms for craft traversal
and we'll be studying graph traversal
algorithms in later lessons okay now the
next thing that I want to talk about is
concept of a weighted graph sometimes in
a graph all connections cannot be
treated as equal some connections can be
preferable to others like for example we
can represent intercity through a
network that is the network of highways
and freeways between cities as an
undirected graph I am assuming that all
highways would be bi-directional
intra-city road network that is road
network within a city would definitely
have one-way roads and so intra-city
road network must be represented as a
directed graph but intercity road
network in my opinion can be represented
as an undirected graph now clearly we
cannot treat all connections as equal
here roads would be of different lengths
and to perform a lot of tasks to solve a
lot of problems we need to take lengths
of roads into account in such cases we
associate some weight or cost with every
edge we label the edges with their
weights in this case weight can be
lengths off the roads so what I'll do
here is I'll just label these edges with
some values for their length and let's
say these values are in kilometers and
now edges in this graph are weighted and
this graph can be called a weighted
graph let's say in this graph we want to
pick the best route from City a to city
D have a look at these 4 possible routes
I'm showing them in different colors now
if I would treat all edges as equal then
I would say that the green route through
B and C and the red route through E and
F are equally good both these paths have
3 edges and this yellow route through E
is the best because we have only two
edges in this path but with different
weights assigned to the connections I
need to add up weights of edges in a
path to calculate total cost when I'm
taking weight into account
shortest route is through B and C
connections have different weights and
this is really important here in this
graph actually we can look at all the
graphs as weighted graphs and unweighted
graph can basically be seen as a
weighted graph in which weight of all
the edges is same and typically we
assume the weight as 1
okay so we have represented inter-cities
road network as a weighted undirected
graph social network was an unweighted
undirected graph and World Wide Web was
an unweighted directed graph and this
one is a weighted undirected graph now
this was anticipated what I think
intra-city road network that is road
network within a city can be modeled as
a weighted directed graph because in a
city there would be some one-ways
intersections in intra-city road network
would be nodes and Road segments would
be our edges and by the way we can also
draw an undirected graph as directed
it's just that for each undirected edge
we'll have two directed edges we may not
be able to redraw our directed graph as
undirected but we can always redraw an
undirected graph as directed okay I'll
stop here now this much is good for an
introductory lesson in next lesson we
will talk about some more properties of
graph this is it for this lesson thanks
for watching
all right in this video I just want to
talk a little bit about some graph
theory and just some basic terminology
and ideas they get used so definitely
not going to be a you know a complete
version of everything you need to know
but definitely some basic ideas so graph
theory got started by really kind of I
think really came about by Leonardo and
what he did is he solved a problem the
famous bridge of coningsburgh problem
and that kind of a put graph theory sort
of out there for people to start
thinking about and for a while graph
theories kind of kind of poo-pooed on it
was kind of considered I think sort of a
recreational branch of math not really a
ton of uses but uh definitely with the
advent here of computer science that's
changed all that graph theory gets used
all the time in computer science lots of
other places as well
definitely become a very hot area to
research and I like it just because the
problems are easy to understand you can
draw pictures and visualize I definitely
enjoy it but let's see so the definition
of a graph that we're going to use and
these vary again from person to person
things still aren't really set in stone
a lot of the notation and definitions
but for us a graph is going to be a
non-empty finite set of vertices some
people will let it be infinite with a
set of two elements subsets of V we call
the elements of V vertices and the
elements of a are called edges so that
sounds may be a little more confusing
that it is all a graph is it's just dots
and lines connecting that's all a graph
is okay so we talked about graph theory
we're not talking about y equals x
squared
just just points and lines connecting
them so we would say the vertex set V
for this
graphs maybe we'll call it G are just v1
v2 v3 v4 v5 and v6 and you can think
really you know maybe these are just six
people at a party and v1 knows v2 v3 v4
you can see that v5 only knows person v4
and v6 maybe that's what an edge
represents is if they know each other
okay you know and you can make the edges
represent whatever you want to so maybe
we'll just think about the edges as
meaning there's a connection between
them and they know each other so the
edge set that's just going to be all two
elements subsets and basically we just
list all the vertices that have an edge
between them so v1 and v2 v1 and v3 v1
and v4
let's see v4 is connected to V 5 and
then vertex V 5 is connected to V 6 and
I think that's everything we need you
know we don't need to list V 6 is
connected to V 5 for example it's just
redundant already so if I had you know
again basically just this set in this
set e again it's just basically telling
me all the information in this original
graph so I still know that a couple
things the cardinality the cardinality
of a graph just represents the number of
vertices
the notation I've seen is they'll put an
absolute value so the absolute value of
G the cardinality of G is just the
number of vertices which in this case is
six
let's see another thing that we often
talk about is the degree of a vertex so
for example the degree of vertex v1
which will abbreviate little deg v1 all
that tells you is the number of edges
coming out from vertex v1 so there's one
two three edges leaving v1 so we would
say the degree of vertex v1 is three
again so vertex v1 knows three other
people is all that says another kind of
convention for a typical graph we don't
let a vertex have a loop back to itself
okay I mean definitely that certainly
happens in a lot of applications but
when we lao graphs to have loops back to
themselves typically people will call
those multi graphs so multi grass have
loops regular graphs don't have loops so
pretend that loops not there and we just
got the original the original matrix
that we are the original graph we
started with a couple other things to
the way that you draw the graph is
irrelevant
so here's V one here's V two here's V
three here's V 4 V 5 down there I want
to make it too crazy v 6 you know they
don't have to be straight lines they can
be whatever they want so okay so V 1 is
still connected to V 2 V 1 should still
be connected to V 3 V 1 is still
connected to V 4
we'll have v4 still connected to v5 and
hey v5 is still connected to vertex v6
so all the original connections are
still preserved and there's sort of no
new connections in there that weren't
there before
so when you have a graph where basically
all the original information is
preserved the original connections
there's no new connections there's
nothing missing and again this is very
kind of loose definition but we would
say that the original graph and this new
graph are isomorphic and all that means
is from a graph theory point of view
they're one in the same they're exactly
the same graph okay so typically tribuna
will try to draw them as a you know in
the least confusing manner as possible
but definitely an important idea the way
that you draw the graph in general
doesn't matter let's talk about a couple
other ideas just a way to describe a
graph one way is with what's called an
adjacency list and I don't know how
useful these are I never really saw them
much but again I didn't take a
tremendous amount of graph theory so
that doesn't mean that they don't get
used all the time and I just haven't ran
into it but all an adjacency list is
exactly what you think so all we do is
just list vertex that our vertices that
are adjacent so for v1 it's adjacent to
v1
excuse me fee one's adjacent to v2 v3
and v4
so we'll list those v2 v3 v4 vertex V 2
is only adjacent to v1 v3 is only
connected to v1 v4 is connected to V 1
and V 5
v5 is connected to v4 and v6 and v6 is
connected to v5 and again it's just
another way of summarizing you know so
this is Jason C list this set V in the
set E and this graph again are telling
me all the exact same information
another way that I know gets used all
the time is instead of doing an
adjacency list we'll make what's called
an adjacency matrix okay so I'm going to
imagine v1 v2 v3 typically people won't
even write these but you know this is
what makes sense to me so a lot of times
I used to always stick them in there v1
v2 v3 v4 v5 v6 all we do is if there's a
loop if there's a connection from a
vertex to another vertex we'll put a 1
and if there's not we'll put a 0 so
since there's not a loop from v1 to v1
we'll put a 0 there but v1 is connected
to v2 v3 and v4 so V once connected to
v2 v3 and v4 but it's not connected to
v5 or v6 there's not an edge present
likewise v2 is only connected to v1 so
we'll put a 1 there and then we'll put
zeros everywhere else
let's see v3 is also only connected to V
ones we'll put a 1 there and zeros
everywhere else v4 is connected to v1
and also to v5 so we'll put ones there
zeros everywhere else v5 is connected to
v4 and v6 so put ones there zeroes
everywhere else
lastly v6 is only connected to v5 so
we'll put a one there
and zeros everywhere else so this is
nice because you can do math of major
Z's ok so definitely there's a lot of
study done with you know matrix
representations of graphs you can do
stuff with them two less things just
maybe two last ideas notice for any
vertex here if you you know so imagine
maybe these are islands now and there's
a little bridge connecting the islands
notice in this this graph if you ever
were to leave an island suppose I was at
Island v1 and I went to Island v4 the
only way I can get back to Island v1 is
the sort of backtrack you know I could
go all the way to v5 and v6 but
eventually to get back I have to take
you know the bridges back so there's no
loops or what are called circuits if
there are no loops or circuits we say
that this is an example of a what's
called a tree and the idea with trees is
you can always sort of rewrite them and
the reason why we call them trees is we
sort of can rewrite them you know so
here's v1 it's connected to V 2 V 3 V 4
V 4 is connected to V 5 and V five is
connected to V 6 so again these would be
isomorphic graphs but now it's kind of
if you flip it over and maybe it had
some more branches the idea that starts
to look like a tree trees get used all
the time for example you know imagine a
chess algorithm you know it's the first
move you know maybe you've got one two
three reasonable reasonable moves that
you're disposable at your disposal not
disposable at your disposal
you know and then maybe you know once
you consider this move maybe there's
only one logical move from that and then
from that there's only one logical move
so trees can help sort of represent sort
of searches you know a computer search
so definitely one place I know for sure
that they get studied again if a graph
so maybe this is a whole separate little
graph over here this graph we would say
has a circuit and the idea is a circuit
you know for example if I met this
vertex I can leave that vertex and still
manage to get back to it without really
ever backtracking through through an
edge or a vertice I don't have to visit
the same place twice as all it says ok
so this would be an example of a graph
that does have a circuit so graph theory
I think is really interesting you know
there's tons of open problems if you're
a budding math person out there and what
some challenging problems
there's definitely tons of open graph
theory problems that are very simple to
understand you know definitely you've
got to learn some of the techniques to
be able to attack things but a lot of it
is very sort of intuitive and I think
open you know sort of it's very user
friendly because what I'm trying to say
there's still some reasonable open
problems out there for people to tackle
for sure so if you are interested in
kind of getting your hands wet and doing
some harder problems
I say graph theory is a great place to
start maybe I can even post some open
questions so all right I hope this
little introduction makes some sense you
get nothing too heavy I definitely plan
on doing some more you know detailed
stuff but again hopefully this is a good
little warm-up and just a good little
intro to some of the ideas
