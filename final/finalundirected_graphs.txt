in our previous lesson we introduced you
to graphs we defined graph as a
mathematical or logical model and talked
about some of the properties and
applications of graph now in this lesson
we will discuss some more properties of
graph but first I want to do a quick
recap of what we have discussed in our
previous lesson a graph can be defined
as an ordered pair of a set of vertices
and a set of edges we use this formal
mathematical notation G equal V II to
define a graph here V is set of vertices
and E is set of edges ordered pair is
just a pair of mathematical objects in
which order of objects in the pair
matters it matters which element is
first and which element is second in the
pair now as we know to denote number of
elements in a set that we also call
cardinality of a set we use the same
notation that we use for modulus or
absolute value so this is how we can
denote number of vertices and number of
edges in a graph number of vertices
would be number of elements in set V and
number of edges would be number of
elements in set E moving forward this is
how I am going to denote number of
vertices and number of edges in all my
explanations now as we have discussed
earlier edges in a graph can either be
directed that is one-way connections or
undirected that is two-way connections a
graph with only directed edges is called
a directed graph or digraph and a graph
with only undirected edges is called an
undirected graph now sometimes all
connections in a graph cannot be treated
as equal so we label edges with some
weight or cost like what I'm showing
here and a graph in which some value is
associated to connections as cost or
weight is called a weighted graph a
graph is unweighted if there is no cost
distinction among edges okay now we can
also have some special kind of edges in
a graph these edges complicate
algorithms and make working with graphs
difficult but I'm going to talk about
them anyway an edge is called a self
loop or self edge if it involves only
one vertex
if both endpoints of energy are same
then it's called a self-loop we can have
a self-loop in both directed and
undirected graphs but the question is
why would we ever have a self-loop in a
graph well sometimes if edges are
depicting some relationship or
connection that's possible with the same
node as origin as well as destination
then we can have a self loop for example
as we have discussed in our previous
lesson interlinked web pages on the
internet or the world wide web can be it
presented as a directed graph a page
with a unique URL can be a node in the
graph and we can have a directed edge if
a page contains link to another page now
we can have a self loop in this graph
because it's very much possible for a
web page to have a link to itself have a
look at this web page my code school
comm / videos in the header we have
links for workouts page problems page
and read your age right now I'm already
on videos page but I can still click on
videos link and all that will happen
with the click is a refresh because I am
already on videos page my origin and
destination are same here so if I'm
representing world wide web as a
directed graph the way we just discussed
then we have a self loop here now the
next special type of edge that I want to
talk about is Multi edge and edge is
called a multi edge if it occurs more
than once in a graph once again we can
have a multi edge in both directed and
undirected graphs
first multi edge that I'm showing you
here is undirected and the second one is
directed now once again the question why
should we ever have a multi edge well
let's say we are representing flight
Network between cities as a graph a city
would be a node and we can have an edge
if there is a direct flight connection
between any two cities but then there
can be multiple flights between a pair
of cities these flights would have
different names and may have different
costs if I want to keep the information
about all the flights in my graph I can
draw multi edges I can draw one directed
edge for each flight and then I can
label
and edge with its cost or any other
property I just labeled edges here with
some random flight numbers now as we
were saying earlier selfloops and multi
edges often complicate working with
graphs the presence means we need to
take extra care while solving problems
if a graph contains no self-loop or
multi edge it's called a simple graph in
our lessons we will mostly be dealing
with simple graphs now I want you to
answer a very simple question given
number of vertices in a simple graph
that is a graph with no self loop or
multi-edge what would be maximum
possible number of edges well let's see
let's say we want to draw a directed
graph with four vertices I have drawn
forward DC's here I will name these
vertices v1 v2 v3 and v4 so this is my
set of vertices number of elements in
set V is 4 now it's perfectly fine if I
choose not to draw any edge here this
will still be a graph set of edges can
be empty nodes can be totally
disconnected so minimum possible number
of edges in a graph is 0 now if this is
a directed graph what do you think can
be maximum number of edges here well
each node can have directed edges to all
other nodes in this figure here each
node can have directed edges to 3 other
nodes we have 4 nodes in total so
maximum possible number of edges here is
4 into 3 that is 12 I have shown edges
originating from a vertex in same color
here this is the maximum that we can
draw if there is no self loop or
multi-edge in general if there are n
vertices then maximum number of edges in
a directed graph would be n into n minus
1 so in a simple directed graph number
of edges would be in this range 0 to n
into n minus 1 now what do you think
would be the maximum for an undirected
graph in an undirected graph we can have
only one bi-directional edge between a
pair of nodes we can't have two edges in
different directions so here the maximum
would be half of the maximum for
directed
so if the graph is simple and undirected
number of edges would be in the range 0
to n into n minus 1 by 2 remember this
is true only if there is no self loop or
multi-edge now if you can see number of
edges in a graph can be really really
large compared to number of vertices
for example if number of vertices in a
directed graph is equal to 10 maximum
number of edges would be 90 if number of
vertices is 100 maximum number of edges
would be 9900 maximum number of edges
would be close to square of number of
vertices a graph is called dense if
number of edges in the graph is close to
maximum possible number of edges that is
if the number of edges is of the order
of square of number of vertices and a
graph is called sparse if the number of
edges is really less typically close to
number of vertices and not more than
that there is no defined boundary for
what can be called dense and what can be
called sparse it all depends on context
but this is an important classification
while working with graphs a lot of
decisions are made based on whether the
graph is dense or sparse for example we
typically choose a different kind of
storage structure in computer's memory
for a dense graph we typically store a
dense graph in something called
adjacency matrix and for a sparse graph
we typically use something called
adjacency list I'll be talking about
adjacency matrix and adjacency lists in
next lesson ok now the next concept that
I want to talk about is concept of path
in a graph a part in a graph is a
sequence of vertices where each adjacent
pair in the sequence is connected by an
edge I'm highlighting a path here in
this example graph the sequence of
vertices a B F H is a path in this graph
now we have an undirected graph here
edges are bi-directional in a directed
graph all edges must also be aligned in
one direction the direction of the path
part is called simple path if no
vertices are repeated and if what
disease are not repeated then edges will
also not be repeated so in a simple path
both vertices and edges are not repeated
this path a bfh that I have highlighted
here is a simple path but we could also
have a path like this here start vertex
is a and end vertex is D in this path
one edge and two vertices are repeated
in graph theory there is some
inconsistency in use of this term path
most of the time when we say path we
mean a simple path and if repetition is
possible we use this term walk so a path
is basically a walk in which new
vertices or edges are repeated of walk
is called a trail if what disease can be
repeated but edges cannot be repeated I
am highlighting a trail here in this
example graph ok now I want to say this
once again walk and path are often used
as synonyms but most often when we say
path we mean simple path a path in which
vertices and edges are not repeated
between two different vertices if there
is a walk in which vertices or edges are
repeated like this walk that I am
showing you here in this example graph
then there must also be a path or simple
path that is a walk in which what
disease or edges would not be repeated
in this walk that I'm showing you here
we are starting at a and we are ending
our walk at C there is a simple path
from A to C with just one edge all we
need to do is we need to avoid going to
be e H D and then coming back again to a
so this is why we mostly talk about
simple path between two vertices because
if any other walk is possible simple
path is also possible and it makes most
sense to look for a simple path so this
is what I'm going to do throughout our
lessons I'm going to say path and by
path L mean simple path and if it's not
a simple path I will say it explicitly
our graph is called strongly connected
if in the graph there is a path from any
vertex to any other vertex if it's an
undirected graph we simply call it
connected and if it's a directed graph
we call it strongly connected in
leftmost and rightmost graphs that I'm
showing you here we have a path from any
vertex to any other vertex but in this
graph in the middle we do not have a
path from any vertex to any other vertex
we cannot go from vertex C to a we can
go from A to C but we cannot go from C
to a so this is not a strongly connected
graph remember if it's an undirected
graph we simply say connected and if
it's a directed graph we say strongly
connected if a directed graph is not
strongly connected but can be turned
into connected graph by treating all
ages as undirected then such a directed
graph is called weakly connected if we
just ignore the directions of the edges
here this is connected but I would
recommend that you just remember connect
it and strongly connected this leftmost
or undirected graph is connected I
removed one of the edges and now this is
not connected now we have two disjoint
connected components here but the graph
overall is not connected connectedness
of a graph is a really important
property if you remember intra-city road
network road network within a city that
would have a lot of one-ways can be
represented as a directed graph now an
intra-city road network should always be
strongly connected we should be able to
reach any street from any street any
intersection to any intersection ok now
that we understand concept of a path
next I want to talk about cycle in a
graph a walk is called a closed walk if
it starts and ends at same vertex like
what I'm showing here and there is one
more condition the length of the walk
must be greater than 0 length of a walk
or path is number of edges in the path
like for this closed walk
that I'm showing you here length is five
because we have five edges in this walk
so a closed walk is walk that starts and
ends at same vertex and the length of
which is greater than zero now some may
call closed walk a cycle but generally
we use the term cycle for a simple cycle
a simple cycle is a closed walk in which
other than start and end vertices no
other vertex or edge is repeated right
now what I'm showing you here in this
example graph is a simple cycle or we
can just say cycle a graph with no
cycles is called an acyclic graph a tree
if drawn with undirected edges would be
an example of an undirected acyclic
graph here in this tree we can have a
closed walk but we cannot have a simple
cycle in this closed walk that I'm
showing you here our edge is repeated
there would be no simple cycle in a tree
and apart from tree we can have other
kind of undirected acyclic graphs also a
tree also has to be connected now we can
also have a directed acyclic graph as
you can see here also we do not have any
cycle you cannot have a path of length
greater than 0 starting and ending at
the same vertex or directed acyclic
graph is often called a dag cycles in a
graph caused a lot of issues in
designing algorithms for problems like
finding shortest route from one vertex
to another and we will talk about cycles
a lot when we will study some of these
at one still go our thumbs and coming
lessons for this lesson I will stop here
now in our next lesson we will discuss
ways of creating and storing graph in
computer's memory this is it for this
lesson thanks for watching
hi welcome to the video on graph theory
my name is Hera Shani and today I am
going to continue the topic I had
started in the lecture 1 of graph theory
and then in the first lecture I had
given you some introduction about graph
and I told you the definition of grass
whatever vertices and edges and I had
discussed what is self loop multi edges
and one theorem that says that sum of
degrees of all the vertices is twice the
number of edges okay I had given you an
example also improved that it is true in
the end today's video I will discuss
simple graph quality graphs we will
graph what are these and after that
we'll see some theorems okay so so what
is simple graph y de Graaff and sugar
simple graph is one which does not have
which does not have self loop and multi
edges okay simple graph
gnarrk have self loop and
it does not have self loop and mighty
edges and the graph which contains multi
edges but not self loop is known as
multi claw
okay the graph which contains mighty
edges and does not contain self loop is
known as multi graph and the graph which
contains self loop as well as multi
edges is known as pseudo graph okay I
had told you in the last video that what
is a self loop and multi edges self loop
is that the edge which comes from the
same node and goes in the same node
which comes out and comes in in the same
node that edge which starts from the
same node and goes to the same node is
known as self loop and multi edges when
they are more than one what is one edges
in between two nodes then that type of
edges is known as mighty edges so simple
graph does not contain self loop as well
as multi edges party graph contains
multi edges and pseudo graph does not
contain self loop I'm sorry
pseudo graph contains self loop as well
as multi edges so by diagram if you want
to see
this circle is inside this circle and
this circle is inside the bigger circuit
and this one is simple graph and this
one is multigraph and the outer one is
pseudo graph so what I mean to say that
every simple graph is multi graph as
well as Hilda graph every simple graph
is multi graph as well a pseudo graph
and every mighty graph is pseudo graph
might reverse is not true how is it
possible when in the simple graph you
have my my changes and that job has
become bartylla
then simple zap it has multi graph as
well as my self loop then that will that
graph will become pseudo Graham but
reverse is not true okay every simple
graph is multi graph as well as pseudo
graph marty graph is multi graph is
pseudo rap but reverse is not true so
let me read this and you and we will
proceed further
now let's take an example this graph is
given which are having five vertices no
a vertex one vertex to vertex three four
five and let's find out what are the
degrees of each node so degree of vertex
one degree of vertex two degree of
vertex three degree of vertex four
degree of vertex
five what is the degree of vertex one it
is one two three four you all know very
well that what is degree how we find
degree the number of edges incident on
that vertex is known as its degree so
what is the degree of vertex one if it
is one two and three four because of
self-loop we will always count this
degree 2 so it is 2 here one is coming
and one it is going this is going what's
coming because since it action is not
given so we count it always twice in
case of degree but when we count for the
number of edges will count it as one so
the degree of vertex one is for degree
of vertex two is five degree of vertex
three is five degree of vertex four is
three degree of vertex v is one two
three again here it is a self-loop so
what we will count it as a two and one
is this so number which is incident on
that point x 5 is 3 now we'll count will
add it sum of all the degrees what will
be 16 + 4 xx and now find out number of
edges here total number of inches
Rodell number of edges 1 + 3 4 4 plus 2
6 plus 1 7 8 and the self-loop this one
is Vonage 9 and this one is 1 8 10
self-loop in case of edges self-loop is
counted once ok please make a point of
it that self-loop is counted as a one
edge in case of self-loop but in km when
we have to find the degree of that
vertex then you have to count it as a
twice okay
twice over 2 also what is the total
number of edges 10 and somehow degrees
of all the vertices are 20 so in that
theorem I had told you that
what is some our degrees of all the
vertices it will it will always be twice
the number of edges see here it is 10
and it is 20 I had shown you one one
example earlier also in the last video
ok so let's move on to other examples
another important property of graph
theory is that the number of vertices of
odd degree number of vertices of odd
degree will always be even what it means
that the vertices which are having odd
degree the number of vertices which are
having odd degree will always be will
means how many number of vertices will
have can have or degree either it can be
to either it can be for idle it can be
six either it can be a means it is we
are not talking about the deal vertices
which are having even degree we are
talking just about that those vertex
which are having odd degree those who
are the total number of are Texas whose
degrees is or should always be even
should always be even in number means
you can have any vertex any edges any
number of edges but what it is telling
that the vertex which are having all
degrees should always be even in number
in the last diagram also you have seen
now you have if you have where you have
written in your notes see in that page
that dog vertex is whose degrees are odd
are four and five four five two three
only the vertex number one was having
degree poor but the vertex two three
four five has even daily sorry
only the vertex one has even degree but
the two three four five four vertexes
have big odd degree what was the degree
three
degree of vertex one degree of vertex
two degree of vertex three degree of
vertex for it me a vertex v what it was
it was I think for this last fine isn't
it so whatever which are the vertex
which has having odd degree this one
this one this one this one how many are
there for this is having even degree but
it is only one vertex whose degree is
even but the vertex is whose degree is
or a four so how we can prove it also it
is like that the sum of degrees of
vertex which are are having even degree
and the sum of degrees of wanted which
are having odd degree total number of
sum of total sum any sum of all the
vertical degrees of all the vertices is
what twice the number of edges twice
means it is even now the degree sum of
the degrees of the vertex which are
having event degree I am separating it
as a this and these are the sum of the
degrees of all the vertices which are
having odd degree oh let me subtract
this this from this
Oh what will be the sum of degrees of
particles which are having odd degree it
will be even a minus event
so
some of these are worth texas which are
having or degree should we even okay I
am subtracting this from this this is
the event number this will be also be
event number because it s degrees are
even and the sum of all the even number
will be always even and here it is
slicer number of Ages it is event so if
n minus even will always give event even
number so sum of degrees of all the
vertices should be even and the degrees
of all the vertices which are odd should
be even for this the number of vortexes
should be even because if you add many
even numbers and one odd number the
number will make it odd suppose three
this is odd number and these are all
even number what will be the result
result will be odd
I'm not I'm just finding whether it will
be odd or even and suppose I am writing
three three to two to four what will be
the result even so the degrees which are
having odd degree the vertexes which are
having odd degree should be even in
number two odd numbers we can make it
number even but one odd number can never
make the sum even this so many even
numbers but one odd number will make
them number some odd but we want the sum
to be even therefore the number of
vertices whose degrees are art should be
always in if any number the number of
what this is of odd degree will always
be even okay okay
now another important thing is that we
have to know what is degree sequence
degree sequence apparently arranged the
arrangement of sequence of degrees in
non ascending order or non descending
order is known as degree sequence okay
the arrangement of degree sequence of
degrees in non ascending order or non
descending order is known as degree
sequence suppose both these two graphs
are given this one and this one now you
know right down the degrees of each
vertex the degree of this one exists to
degree of this vertex is 2 if you have
this vertex is 3 in degree of this
vertex is 1 degree of this vertex is 3
in degree of this vertex is 1 so what
are the degree is 2 2 3 3 1 1 let let us
write it in a non ascending order then
what will be that first we write 3 then
3 then 2 then 2 after that one this is
known as degree sequence
now let's light this degree sequence of
this graph its degree is 1 if Sigma is 2
it's degree is 3 as degree is 2 degrees
when its degree is 1 ok so what will be
the degree sequence of this graph
now in turn ascending order 3 2 2 1 1 1
okay so we'll use this degree sequence
in finding whether the simple graph
exists or not there is a theorem known
as heaven hikami theorem I will discuss
it just now I realizing you just pause
the video and note it down I'm
addressing it
now the procedure I was telling have a
heck of a procedure it says that I told
you that if this procedure is used to
find that with a simple graph exists or
not given a DNA sequence up you are
given degree sequence and you have to
find that the simple graph exists or not
with these degree signals here I have
written this I am getting out and you
what you're going to do you you just
write it down in your notes and we will
proceed I explain you this thing's for
and we will see lot of examples based on
this I hope you understand hell hikami
procedure it is used to fight whether a
given simple graph is valid or not for
that given degree sequence it is used to
find whether a simple graph is valid or
not for the given degree signal for this
you have half you are given degree
signals and you have to find that
whether a simple graph exists or valid
or not
so what there are some steps first step
is put the degree sequence in non
ascending order in first step what you
have to do put the degree sequence in an
ascending order and remove the highest
degree from that sequence in that
sequence what you have to choose the
highest degree and let it is okay we
name it as K subtract one from next K
increase and we have what we have to do
in the next step in first step you have
to send arrange it in a darkness in
order then second step remove the
highest degree and error let it rest K
third step you have to subtract one from
next K increase next K entries after
removing first the highest rate entry
you have to subtract one from all the
next game please K is what the highest
degree and then what am going to have to
fire undo we have to repeat this step
one two three and stop even
then we stop only when we find any of
these conditions we'll fill in the first
fourth first part says that if we get
all zero entries then we can say that
that simple graph exists if we get all
zero entries then we have to do what we
can say that simple graph exists first
point next one will say that if we get
at least one negative entry if we get
any any one entry also negative then we
can say that simple graph does not exist
and the Third Point says that if not
enough degrees or entries simple graph
does not exist in 2nd and 3rd both case
cases this says that if not enough
degrees are there not enough means if K
entries are not there after removing
highest degree which is K there are
there should be at least K entries and
you have to subtract one from each of
this K entries but you are not enough
you are not having nm degree or increase
then simple graph does not exist in both
the cases if you get any negative entry
then also simple graph does not exist if
you get large enough you are not getting
enough degrees and have degree Smith not
care degrees then the also simple graph
does not exist and if you get all the 0
entries then the simple graph exists and
if any of these conditions null does not
satisfy what you have to do you have to
repeat the steps 1 2 3 ok let's see some
examples
I will you just what you do just posit a
pause the video and note it down and we
will proceed further to the examples
but no
now let us take some example of degree
sequence and let's check it whether the
simple graph exists or not
okay so these are degree sequences are
given first of all check that the degree
sequence should be in on ascending order
first step and on ascending order if it
is given in your Mon Cindy what it is
okay if it is not given on ascending
order make it not ascending okay so this
is already not ascending order now the
second step is you have to see that how
many how many degrees are odd or degrees
are base and this two two two two two
degrees are odd this one in this one so
since it is two which is even so it is
of K now you'll see which is highest
degree this one we move this highest
degree and let it it is as K okay in the
next step what we have to do we have to
subtract one from the next K increase is
what three next K in this this one this
one this one we have to subtract one
from each of them so what will be that
we have removed this one okay so we have
removed this one and let it escape so
now we have to subtract one from
remaining three increase the many K
increases three increased so the when we
will subtract 2y from two it will become
while when you subtract one from one it
will become 0 when we subtract one
problems from zero it will become minus
one and what it is zero okay so now in
the last step we have to check if all
the degrees have become zero then simple
graph is reached but it will all the
degrees had not become zero in the next
step if any one of the entry has become
negative then simple graph does not
exist since it is negative so simple
graph does not exist here okay here see
what we have to do remove it is in non
ascending order six five four three
three one okay then find out how many
degrees are odd this is art this is art
this is art this is art how many degrees
one two three four four degrees are odd
for this even so it is okay what do you
have know that the degrees which are
having odd should be even in number so
here it is if any number so it's okay
now we move the highest our degree and
that it is K we have removed it okay now
what we have to do subtract one from
that remaining six increase how many
injuries are left here one two three
four five
only five entries are there but we'll
have what we have to do you had to do
subtract one from the C remaining six
entries so there are not enough degrees
and one of the condition it is says that
if you are not having nm degrees then
also the simple graph does not exist
here negative entry
simple trap does not exist
here
not enough degrees
so safer graph does not exist
let's see the third one it is it in
ascend on ascending order
No so first of all put it in now arrange
it in a non ascending order so it will
become fine three two one zero five
three two one zero
now remove the highest degree highest
degrees highest degree is five let it be
five K will be five and one more thing
you have to check whether the degrees
which are having odd degree number of
vertices number of devotees liver
disease degrees which are having odd
degree and how many so here this one is
odd this one is odd this one is odd one
two three
odd degrees
number of all degrees party says
whatever what it is three which is odd
in number but you know from the theorem
that the number or degrees vertices
should be even then also simple graph
does not exist
okay from here also you can check if K
is five we have to subtract one from the
next five increase next K increase K is
worth five and but here only four
degrees are remaining so there are also
not enough degrees and also number of
odd number of odd degree vertices are
odd which should be even so both way you
can say that simple graph does not exist
okay let us see some more examples
so now let's see some more examples here
degree sequences are given and again we
have to find whether the simple graph
exists or not okay so question number
one is the degree sequences are 7 6 5 4
4 3 2 1
first of all it is in non ascending
order it is ok let's check how many
degrees are or this one this one this
one this one 1 2 3 4 which is if any
number that is also okay next point
remove the highest degree
this one is highest degree and let as
you say that it is K here is 7 what we
have to do in the next step we have to
subtract 1 from the next 7 increase 1 2
3 4 5 6 7 1 2 3 4 5 6 7 so what will be
the after subtraction what will be the
increase we will subtract 1 from each of
them it will become 5 4 3 3 2 1 0 now
again see it is in non ascending order
and the odd degree is non ascending
order again now
highest degree is 5 so we have to do in
the next step what we have do we have to
repeat the all the steps there are what
the procedure says that if all the zeros
has come or any one of the entries has
become negative or there are not enough
deal is there all entries are not become
0 any one of them are not negative and
are not enough indeed there are in our
degree we have subtracted so we have to
repeat the steps again so for repetition
what we have to do we have to remove one
highest degree 8 highest degree and now
K has become 5 and what do you have to
do in the next step we have to subtract
one from the remaining five remaining
five entries what will be the value now
3 2 2 1 0 and this is already 0 we have
to subtract 1 from the 5 entries
remaining five entries only from here
next 5 entries not any next 5 entry so
we have subtracted 1 from the next 500
and 0 will be same now in the next step
what you have to do we have to find now
all other entries has not become 0 and
not any any of them is not also negative
and enough degrees are there so what you
have to do we have to repeat the
procedure for now K will become excuse
me 3 am now now what we have to do
subtract 1 from the remain x3 entries
next 3 in phase are 2 2 1 so when we
subtract 1 from these entries it will
become 1 it will become 1 it will become
0 and 0 0 will remain as it is after
subtracting 1 from these degrees 3
degree 3 entries remaining and next 3
entries the so we are getting 1 1 0 0 0
so it is not a 0 and not any entry is
not negative and enough degrees are
there so we can say that we have to
repeat the say stay all steps again so
in the next step what we have to do we
have to remove the highest degree from
this entries and which is 1 and what we
have to do in the next step we have to
subtract 1 from the next one entry 1
from the next one entry so what we are
getting 0 and this 0 will be copied else
as it is so all that it is have become
now 0 when we are when we get all the
degree is 0 it means the simple graph
exists so for the first case you note it
down and by pausing the video you note
it down ok note it down and then after
that I am erasing this and solve the
next problem
in this second one what I am to do
so--here simple graph exist in this one
this is in non ascending water already
non descending order and also find out
how many degrees are odd
so the degree that from this one and
this one means how many degrees are
there one and two so two degrees are odd
which is a very number therefore it is
okay and now if follow the procedure
what we have to do it is in non
ascending order then in the main the
next step remove the highest degree and
let it is here now in the next step what
we have to do we have to subtract one
from the next six increase next six
increase is what this one from here till
here so it will become 5 5 5 2 2 1 &amp; 2
will be as it is now what we see it is
not our 0 no degrees no entries negative
and there are enough degrees so we have
to do repeat the step again so it is in
non descending order
in the next step what we have to do we
have to remove the highest degree and
ever say it is okay now our case 5 and
what you have to do now subtract 1 from
the remaining five remaining 5 means
next 5 I am up air if it am saying by
mistake I have said remaining it is next
5 so we have to do 1 2 3 4 5 we have to
subtract one from here
four four one one zero and this is to
hear not all entries are zero knowing in
two is negative and LF degrees are there
so we have to do repeat the steps we
cannot find we cannot say at this point
that the simple graph exists or not
so we'll repeat the same procedure first
of all identity non ascending order
since it is not in a non ascending order
so we have to arrange it for for this is
not - this little bit this is not 1 this
will be 2 1 1 0 now it is it not a
sending order now remove the highest
degree and assume it is that ok now case
for what we have to do we have to
subtract one from the next for entry so
it will become 3 1 it will resemble
because the 0 + 0 is already here not
all that not not all the ingredients
become 0
no entry is negative so and enough
degrees out there what we have to do we
have to repeat the process procedure
again so it is in non ascending water
already
the word note don't need to arrange it
and the next step what we have to do we
have to remove the highest degree and
let it is K so working in the next step
what do you have to do you have to
subtract one from the next three
increase so it will become zero it will
become minus one it will
what we see here there are negative
interest so in the simple gap does not
exist okay simple graph does not exist
now you see this question part here you
have to find whether the simple graph
exists or not first of all see it is a
non ascending order it's okay how many
degrees are on this one this one so
there are two degrees which are all so
it is okay because the number of degrees
which are odd is even now what we have
to do
remove the highest degree and as you say
it is K now in the in the next step what
we have to do subtract one from the
remaining next seven degrees seven
increase one two three four five six
seven four five six seven seven in
breeze are there so we have to subtract
one from the index seven increase so it
will become 5 5 3 3 2 1 1 not all the
increase has become 0 any other entries
has not become negative and there are
enough degrees so in that we have to
repeat the all the steps it is in non
ascending order it's okay we have to
remove the highest degree highest entry
and let's say it is K now next 5 entries
we have to subtract one from the next 5
entries so we have to subtract one here
it will become 4 2 2 1 0 and H 1 now
this increases all the edges are not
become 0 not any am going to you has
become negative nothing against any of
the entries so in the next step and I
have degrees so we have to repeat the
steps
again so what is the next step we have
to arrange it acknowledged sending order
for 2 2 1 1 0 in the next step what we
have to do
remove the highest degree let us say it
is K and next and what we have to do
subtract 1 from the next 4 entries it is
1 1 0 0 0 all the entries have not
become 0 and any of the degrees is not
negative and adapting these are there so
we have to what we have to do we have to
repeat the steps so we have to arrange
it in an ascending order it is already
non ascending order you have to
understand we have to you remove the
highest degree and say it is K now in
the next step what we have to do we have
to subtract one from the next one entry
it will become 0 and use 0 0 is already
here we have to subtract 1 from the next
one entry early because here K is 1 so
it has become 0 and the all that remain
all entries it is already 0 and so it
has become all 0 when the entries has
become all 0 then we can say that simple
graph exists okay
you haven't had cami theorem says that
is all the entries becomes 0 then simple
graph exist okay so I am realizing it
you just pause the video and not it done
okay
so here simple glass exist here simple
graph exists here does not exist you
exist and in this one who is let's check
it it is given it is already non
ascending order and so first step is we
have to remove the highest degree and
say it is K now in the next step what
you have to do we have to subtract one
from the next K in peace next K entries
next cared entries but we are only
having 7 entry is here 1 2 3 4 5 6 7 and
what we have to do in the procedure says
that we have to subtract 1 from the next
8 it increase because since here highest
degree is 8 but you are having only 7
degrees are not enough degree so we can
say that it is in the simple graph does
not exist also let's check some modern
points that the how many degrees are or
1 2 3 4 yes ok but we are not having
enough degree so we catch not enough
degrees so we can say that simple graph
does not exist
okay so that's all for today if you like
my video don't forget to hit the like
button and subscribe to my channel if
you have any query write it in the
comments section and you can ask me any
related problems also all the topics you
are not getting and not understanding
and if you have a dad that also just
write it down okay thank you
so for this example we'll be looking at
a directed graph so the directed graph
is a little more complicated or a little
more complex than our undirected graph
so for this graph we will have edges but
we also will have directions of which
way the edge is actually going so for
our directed graph our rows and columns
are labeled and ordered ordered vertices
so what we need to do is we need to be
able to fill in the table by writing one
if there is one outgoing edge between
the row vertex on the column vertex and
0 if no edge exists between them so
let's just pick one as an example and
let's go between a and B so between a
and B so you can see here it is a there
is an edge and that's actually going
from A to B so from A to B should give
us 1 but if we're dealing with from if
someone asked is there an edge between B
and a we're going to say it's zero
because the it isn't going in the
outgoing direction is not going between
B and a the edge is going between a and
B and that's the basis of our population
so let's run short between a and a from
a to a ok there's no loop so that's
going to be very straightforward zero
between a and B so you can see here that
there is an outgoing edge from A to B ie
the edge is pointing in this direction
so that's perfect
that's going to give us a 1 between a
and C ok there's nothing so we can
pretty quickly put can are zero so zero
between a and D there is an edge but
it's going from D to a so the answer for
this one will be zero between a and E
there's no link between a and E so we
put them in as zero
I'm just going to quickly make one quick
change to our graph if I were on the fly
and we're just going to say that between
a and D that is going in this direction
okay okay and the last edge we're going
to do is between a and F so let's
quickly look back on top of our graph so
we have a to F so a is going from A to F
and the edge is going in that direction
so that's absolutely fine so we can put
in our 1 ok so we keep our iteration
going so it's sorted between a and B
there is an edge between a and B but
it's going from A to B not from B to a
so the answer for this one is 0
is there an edge between B and B ok very
quickly here we can see there's no loop
back on it so the answer is 0 between B
and C now there is an edge between B and
C but it's going from C to B not from B
to C so the answer for this one is 0
is there an edge between B and D there
is and it's going from B to D so the
answer is one instr 1 between B and E so
there's not so the answer is 0 and instr
1 between B and F so you can see here
there's no direct link between them so
the answer is 0 so we keep going let's
say between C and a so no direct link no
edge zero between C and B so let's
reline between C and B there is from C
to B and it's an in an outgoing
direction so the answer to this one is 1
let's try and make it look a little bit
like a 1 okay
so between C and C 0 between C and D so
where is D so there is one between C and
D but it's going from D to C not from C
to D 0 is the one between C and E so you
can see here yet or is an edge and its
outgoing from C to e
so we've won and then between C and F no
direct link zero okay so between D and a
D and a okay we have an edge and it's
outgoing so it's going from G to A one
okay
this handwriting is getting worse what
is during edge between D and B there is
what is going from B to D not from D to
B so the answer is going to be zero
is there an edge between D and C there
is and it's going from D to C so in one
it's turn edge between D and D there's
the third answer is zero in stir one
between D and either is what it's going
from E to D not from D to e so 0 and
it's Devon from D to F there is what is
going from F to D not from D to F the
answer is 0 so that's fine now the last
edge we're going to look at is between e
let's say e and a so no direct link
which is zero instead one between a and
B E and B no the answer is zero is there
one between E and C there is but it's
going from C to e not from E to C so
it's zero
and so let's just double check so we're
going from E to C now hold on oh I've
just missed one so I'm going to erase
this very quickly and we've said is real
link between E and C so there actually
is so I've been looking at this edge
here from C to e but there is one
between E and C so the answer for this
is one for the very reason that we have
an edge here going from E to C so
between E and D there is an edge so we
put in our one try and put in our one
and between E and E the answer is zero
between E and F the answer would be zero
as well so for the last line between a
and F subject from there is one from A
to F but not from F to a so we're going
hero between F and B beads on the other
side no edge zero between F and C okay
no direct link zero between F and D
there is here's F here's D it's going
out going so that's an answer 1 between
F and E no direct link zero and then
we're going from F to F so there's no
loop back on it so it's zero so that is
our main point now what we're going to
do is very quickly just to show that
some of the edges that we've actually
put in that they are only one
directional in so were you know it is
actually a directed graph there can only
be a link between between two between
two vertices or actually going to say
that the direction will be from one to
the other so it's not both ways it's
only one way so if we looked at a and B
as our example it's going from A to B
not from B to a so you know B if we're
taking this edge here we're looking at a
to B and we're going in this direction
so it's from A to B not from beach
so just be careful with it okay so
that's an example of our directed graph
hi today we're going to have a look at
networks for further mathematics so this
is basically chapter 23 our key
definitions and looking through the
applications of undirected graphs so to
begin with we need to start having a
look at one of our key definitions so a
network is basically just a group of
objects that are connected often we talk
about towns places or people and looking
at the connections between them a graph
is basically just a visual
representation of a network so each of
our vertices represent an object in that
Network and each of the edges show the
connections between them so the vertices
are points of vertex is singular
vertices of plural and the edges as I
said show the connections between them
some of our key things that we need to
know about networks we have adjacent
vertices and adjacent vertices mean that
there is a direct connection so we can
see here C and D are adjacent an
isolated vertex is one that has no
adjacent vertices so there's no edges
connecting into vertex F therefore it is
isolated multiple edges is when we have
more than one pathway between two sets
of vertices so we can see here a and B
have two pathways shown same with B and
C so there are multiple edges between B
and C as well a loop is a special type
of edge which begins and ends at the
same vertex an adjacency matrix shows
the direct connections between each
vertex so the way it is set up is
basically like a table but obviously in
a matrix form we can see here the column
headers and the row headers are just the
labels that are from the vertices and
each of those numbers show the number of
edges connecting between the two so as
we're reading a cross Rho a we can see
there are 0 connections from 8s and
there's no loop at a there are two
connections from A to B there is one
connection from
a to a thing to note with the loop
though we can see we do have a loop at E
and it is only counted as one connection
so be aware that a loop is only ever
counted as one in an adjacency matrix
the degree of the vertex talks about the
total number of edges leaving the vertex
so the total number of ways you can get
out of it if we look at a there are
three edges leaving a so it has a degree
of a B has six edges leaving it and we
can see C and vertex D the degrees
they're being mindful with a loop whilst
it only counts for one in an adjacency
matrix it does actually count as two
when we're talking about the degree so
we can see from E there are a total of
four ways or four pathways out of e so
just be aware of that when you're
looking at the degree and of course an
isolated vertex will always have a
degree of zero we can represent our
number of degrees there in a table and a
good thing to know that the total number
of degree so if we add all of those
numbers together / 2 that gives us the
total number of edges in that particular
graph some other key definitions that we
need to know a simple graph is basically
any graph at all that has no loops and
no multiple edges a degenerate graph has
only isolated edges so just a group of
vertices no edges at all a connected
graph means that there are no isolated
vertices at all so it can have loops it
can have multiple edges but the only
stipulation there with a connected graph
is no isolated vertices and finally a
complete graph means there is a direct
connection from each vertex to all
others so we can see here we've got a
complete graph with four vertices and
we'll come back and talk more about
those in a moment another style of graph
is a bipartite graph and you'll see more
of these in chapter 24 when we start
looking
applications basically a bipartite graph
shows two separate sets of data or
information and shows the connections
between those two sets so we can see
here we've got vertices a B and C form
one set of information and vertices d e
and f form a second set there's no
actual connection between a B and C or D
E and F but there are connections
between the two sets and that's what a
bipartite graph shows so if we have a
look at this in the context of save as
three countries competing the Olympics
so Australia Britain and Canada and
three events diving equestrian and
fencing we can see here that Australia
by a connection to D and 2e have meddled
in the diving and the equestrian and by
the same token both Britain and Canada
have meddled in the fencing so that's
one application of these bipartite
graphs moving on now to some of the
other applications when we're talking
about paths in networks we are talking
about a sequence of edges so basically a
pathway through a graph is just how you
would get from one point to another in
this graph there are five different
pathways from vertex a to vertex C so we
can go a through D to see a 3d around to
be and back to see directly from ADA
seen a ruby and finally a through B and
D to C so five different pathways from A
to C a circuit is any sequence of edges
or any pathway that begins and ends at
the same vertex so a possible circuit
through this particular graph would be a
2 D to C to B and back to a again one
way of showing circuits is to actually
show it is a sub graph so instead of
drawing on top of the original graph we
actually take the information that's
required and represent it as its own
little graph so
you can see that the vertices are still
the same a b c and d the original edges
still apply but we've just shown only
the pathway that we need rather than the
other information so it's easier to see
moving on to planar graphs so a planar
graph is a special type of graph it is
any graph that is shown where the edge
is only intersect at the vertices so we
can see we started off in this
particular diagram with F having some
intersections with other edges which
weren't at vertices so we need to be
able to read roar a graph to make it
planner one way of doing that is to
shift a vertex into the middle of of the
graph so that their intersections are
not occurring another way is actually
just to redraw edges around the outside
the reason we want to know about planta
graphs is so that we can apply Euler's
formula so whenever you see the words
planar graph or Euler's formula this is
what we're aiming to do we have our draw
a graph drawn as a planar graph and
therefore we can apply the following
rule where the number of vertices minus
the number of edges plus the number of
faces will equal to if it is indeed a
planar graph so looking at the diagram
here we have four vertices in our graph
there we have five edges and faces talks
about the number of regions okay so in
this case we have one region which is
shown in yellow one shown in blue and
one shown in pink so there's always what
you can see from the shape plus an
additional face for the outside and in
this case we've got 3 4 minus 5 plus 3
equals to the left hand side of that
equation equals the right-hand side
therefore this graph is planar and it
satisfies Euler's formula we have
another example drawn here so we gained
the number of faces is
we have five vertices in six edges this
time the graph is still planner and
therefore it does satisfy others rule in
the executive here at the moment our
graph is not planner because we have
some edges crossing where there are not
vertices present so before we can apply
oil as formula we must redraw this graph
so that it is planner and then that will
allow us to actually count the number of
faces correctly so once it's redrawn as
planner then we can see yes now I can
count the number of edges and faces and
vertices correctly and apply Euler's
formula moving on to complete graphs so
a complete graph as we said before
there's a direct connection between
every vertex and once we get above
complete graphs with four or five
vertices it becomes quite difficult to
count the number of edges therefore we
use this formula where we use a que to
represent that it's a complete graph and
the n is the number of vertices so by
taking a complete graph with five
vertices we can say well the number of
edges will be 5 times 4 divided by 2 by
using our wall there moving on to
special types of pods and circuits so
the first one we look at is oily paths
and circuits so an Euler path is
something that uses every edge in a
graph and obviously an Euler circuit and
use a pathway that uses every edge and
starts and finishes at the same vertex
there is a way to remember this Euler is
four edges so we have to use every edge
so we look here start an a3 b2 c2 a down
to a cross tadi up to see and then back
to a so there we go we've used every
edge only once I didn't have to lift my
pen from the graph and I was able to
trace around using all the edges and
only using each one once so one way to
know whether you do have an oil
path or an Euler circuit is that if we
have a connected graph we can only have
an Euler path if it contains two odd
vertices so when we talk about odd
vertices we mean the degree of the
vertex so we can see here that vertex a
has a degree of three and three is an
odd number vertex B has a degree of 22
is an even number so if we look at all
of the vertices there a is odd and E is
odd b c and d are all even so that means
i will have an Euler path it will start
at either vertex a or vertex a and
finish at the other one so before you
even try and find whether there's an
Euler path you should be looking to see
are there any odd vertices if so we want
to start at one of them and finish it
the other if there's only one odd vertex
we can't have an Euler path is there are
three odd vertices we can't have it
other paths it must be two or none if we
have to that actually means that we will
have an Euler circuit so if we look at
this graph here all of our vertices are
of an even degree so that means I could
technically start anywhere in the graph
and be able to use every edge and finish
back where I started from which would
make an entire circuit so here we can
see from A to B to C to D to e to see
back across to a down to E and then back
up to a again so I've managed to get all
the way around the graph and start and
finish at vertex a so we've created an
Euler circuit there the second type of
paths and circuits we have accord
Hamilton paths and circuits so unlike
Euler we don't have to use every edge
this time but for a Hamilton path I can
only use every vertex once so I can't go
through the graph more sorry through the
vertices more than once
so here we can see so here we can see in
the first example and Hamilton paths are
go from A to B down to a cross daddy up
to C and F I haven't used all of the
engines but i have used every vertex
just once in the second example I'm
going to make a Hamilton circuit so I'm
going to start at a go to B to C to F
down to D across two E and back up to a
again so I've started where I finished
I've used every vertex just once and
again there are some edges that I didn't
need to use and so this makes a Hamilton
circuit there's unfortunately no little
tricks or rules with Hamilton paths and
circuits it's just a matter of trial and
error unlike Euler where we know about
the degree and the odd degrees next
application we're looking at weighted
graphs so a weight is basically just a
value that's associated with an edge
normally a weight would represent the
distance between the vertices all the
time it takes to travel between one to
the other or the number of objects that
can actually flow along an edge at any
given time we tend to use weighted
graphs to help us find the shortest
paths and circuits and a lot of time
that's just trial and error a further
application is what we call a minimum
spanning tree and that basically says
let's take the original graph and find I
guess what we can call a bit of a
skeleton there are a couple of different
methods for this and your textbook goes
through one called prims algorithm where
basically you'll pick a starting point
and work your way through the graph
using the smallest edges I use a
slightly different method and basically
what we're doing is we start with our
graph here and we say well what is the
smallest possible number on the graph
once we find that so we can see where
there's some edges that are twos so
let's use
those twos in our skeleton or our
minimum spanning tree then we say well
the next smallest number is a three so
let's use those edges and we can see
those three edges there the next is a
four so let's use those and at this
point we we stop and have a bit of a
look and say okay so have I used all of
the edges are all the vertices connected
the next smallest number would be the
five at the top between F and H but both
of those vertices are already joined in
so instead of using that I've looked at
vertex D was the only one left that I
needed to connect in and so I look at
the shortest possible edge or the
smallest edge small most weight to
connect in D and that was the edge
joining to a which was a six we would
then add up those edges and give our
final value depending on what the
questions actually asking you to do note
with a minimum spanning tree you don't
need to be able to get from one point to
all the way through the graph without
lifting your pen it is meant to be like
a skeleton or I guess you have the
internal workings of the graph it
doesn't have to flow in a nice pathway
or a circuit the number of edges you
need will always be one less than the
number of vertices so if you started
with seven vertices you only need six
edges to make it a minimum spanning tree
because you just want the minimum number
of connections to be able to show the
work of that graph
another example here shows you again so
look for the smallest values
next we're going to look at a slightly
different graph processing application
but it's a graph processing algorithm
that's useful in many applications as
we'll see in a minute and slightly
different than depth and breadth first
search
it's called computing connected
components and I mentioned this a little
bit when we talked about basic
definitions so the idea is that if
there's a path between two vertices and
we say they're connected and what we
want to do is not reprocess a graph that
is going to build a data type that can
answer queries of the form is v
connected to W in constant time now we
want to be able to do that for a huge
sparse graph of the type that appears
and I in practice so we can't use the if
we could use the adjacency matrix in a
data structure maybe we could do that
but we can't so we're going to build a
class that uses our standard
representation that will enable clients
to find connected components really
interesting to think about this one
we're getting the job done and we could
get done if we had a huge sparse matrix
but if we have billions of vertices
there's no way we can have billions
squared in the matrix so we have to find
another way to do it so here's the data
type that we want to implement so it's
called Cici and it's going to the
constructor is going to build the data
structure that finds the connected
components in the grant given graph to
be able to efficiently answer these
connectivity query it'll also be able to
count the number of connected components
and it also assigns the identifier from
zero to count minus one that identifies
the connected component that every
vertexes then so now if you maybe this
sounds a little bit similar to what we
did for the Union flying problem so
unify problem we're taking edges and we
wanted to have queries that well Union
is like add an edge to the graph and
then find is like are these two things
connected yet
now with Union find we found that we
couldn't quite answer the thing in
constant time members are very slowly
growing questions constant in practical
terms but not not really so it's less
efficient than the algorithm that we're
going to talk about because it doesn't
quite get constant time on the other
hand in another way it's better than the
algorithm that we're going to talk about
because you can intermix the unions and
finds and in this case because we're
working with a graph it's like we're
taking all the unions and then we're
handling find requests so anyway what
we're going to use to implement this is
a depth-first search approach and also
we'll do that effort search will just
keep different data than we did then
when we're finding paths so the
algorithm is based on the notion that
connection is equivalence relation
so recall equivalence relation has these
three properties every vertex is
connected to itself if V is connected to
W then W is connected to V and if you
connected to W and W to X then V is
connected to X and those basic
operations underlies out of them that
we're going to talk about so the
equivalence relation
is a general mathematical concept that
applies in graph theory in this case and
as I already mentioned in the case of
graph and implies that the vertices
divided up into connected components
which are maximal sets of connected
vertices so our sample graph has three
connected components and what we'll do
is assign identifiers to each one of the
components in that will for every vertex
give us an identifier number for that
vertex and that's the data structure
that our depth-first search is going to
build and that immediately gives the
constant time implementation of the
connectivity query given two vertices
now you look up their ID and if they're
equal they're in the same connected
component if they're different they're
not so that's the data structure that
we're going to build it's like a
union-find tree where there's just and
all the trees are flat so that's where
just like in a given connected
components we can answer queries in
constant time so here's a big graph a
big grid graph that we use
when were talking about union-find and
it turns out that this one's got 63
connected components and then when you
really think about it it's kind of
amazing that we can do this computation
in linear time even for huge graphs and
it's really important to be able to do
so for those very huge graphs that we
talked about in so many applications if
you can process all the edges you can
also find out the connected components
and be set up to answer conductivity
conductivity queries this is a simple
algorithm a bit really you know it's a
genius okay so let's look at the
implementation so our goal is to
petition the vertices in two connected
components so we're going to use DFS and
marking and so what we're going to do is
for a general graph for every unmarked
vertex we're going to run DFS to find
all the vertices that are connected to
that one they're going to be part of the
same component so we use the marking to
help control the DFS but also to control
the connected components that the
vertices that have already been
processed and known to be in a given
connected component so let's look at a
demo to understand how this algorithm
works so again we're going to use
depth-first search and our summary of
depth-first search to visit a vertex we
mark it as visited and then recursively
visit all the unmarked vertices that are
adjacent and so in this case so we'll
start we're going to visit all the
vertices in the graph in order to
identify the connected compound so we'll
start by visiting 0 to visit 0 we have
to check 6 to 1 and 5 so we start by
checking 6 we mark it as visited
that's entry six in the array and now
we're going to keep this other vertex
indexed array which is the ID the
connected component number so all we're
saying by putting a zero in that entry
is that six and zero are in the same
connected component every vertex that we
encountered during the depth-first
search from zero we're going to find a
value of zero okay so so what do we have
to do to visit six we have to check zero
and then we have to check for and so in
four is unmarked so we're going to
recurse and visit four to visit four we
have to check five five is unmarked so
we recurse to visit five and to visit
five we have to check three four and
zero three is unmarked this is the same
depth-first search that we did before
but now we're just keeping track of the
connected component number and we're
assigning every vertex that we encounter
with the same ID is zero okay so now we
have to visit three not to visit three
we have to check five and four five was
marked nothing to do four with mark
nothing to do so we're done with three
done with three we can continue the
depth-first search from five we have to
check four and zero for with mark zero
is marked not so we're done and now we
can continue with the deficit to four we
have to check six and three six was
marked not three was marked and we're
done and we can now fix is done and now
we can continue with zero and we have to
check to check to it's not marked so we
mark it and give it a connected
component number of zero to visit two
all we do is check 0 which is mark so
we're done and then
do the same thing with one unmarked so
we visit it and I guess sign at zero and
then visit one do that we check zero
which is marked so we're done with one
and then to finish zero we have to check
five and that's marks and we don't have
to do anything and we're done with zero
so now we're done with the first
connected component but we're not done
with the whole graph so what we want to
do is go and look for so that's a
connected component corresponding to
zero now we want what we want to do is
go look for in unmarked vertex we
started at zero we check one two three
four or five and six and they're all
marked and so the next unmarked vertex
that we find in the graph is seven so
once we return from the depth-first
search for zero we increment counter
which is our how many connected
components have we seen and now we're
going to assign that number to
everything that's connected to seven on
the depth-first search from seven so
what do we do to depth research and
seven we check eight eight unmarked so
we go visit it also we assign it
connected component number of one same
as seven I mark it and then go ahead and
recurse to visit eight we check seven
which is marked so there's nothing to do
we're done with eight and then we're
done with seven so now we're done with
all the vertices that were connected to
seven we increment our counter of number
of components to two and look for
another vertex so now we check eight
which was already knows mark connected
to seven and so now nine is unmarked so
we're going to do a DFS from nine and
everybody connected to nine is going to
get assigned a connected component
number of two so to visit nine we have
to check eleven
and that was unmarked until we visit it
give it a - to visit 11 we have to check
9 which is marks and nothing to do in 12
which is unmarked so we visit it and
give it a number to the visit 12 we have
to check 11 which is marked and nine
which is also marked and then we're done
with 12 and then we're done with 11 and
then to finish doing 9 we have to check
10 and 12 10 is unmarked
so we mark it and give it a number of 2
to visit 10 we check 9 which is mark so
we're done and then finally to finish
the DFS now we check 12 from 9 and
that's mark out so we're done with 9 and
now we keep looking and we find that 10
11 and 12 are all marked so we've
completed the computation and for every
vertex we have a connected component
number and for any given query we can
test whether they're in the same
connected component simply by looking up
that number and seeing if it's equal
that's a demo of connected components
computation okay so here's the code for
finding connected components with DFS
which is another straightforward DFS
implementation just like the other one
it just keeps a slightly different data
structure so the we keep the marked data
structure which is the vertices that we
visited and then we keep this vertex
index array ID which gives the
identifier the component containing V I
think we call it CC on the demo and then
a count of the number of components that
we've seen so the constructor creates
the marked array and it creates this
idea ray
but now the constructor does a more work
than a single call
on DFS what it does is it grew through
this is the constructor goes through
every vertex in the array in this graph
and if it's not marked it does a BFS and
that DFS will mark a lot of other
vertices but when it's done that's all
of those are going to get assigned value
of count and we're going to increment
count then go and look for another
unmarked vertex anything that wasn't
marked by that first D affects DFS we'll
do a DFS from that one in Mark Wallace
vertices with the next value for the ID
so now let's look at the implementation
of DFS it's recursive array just like
the one that we did for for path finding
except all that we do when we mark a
vertex we also simply set its ID to the
current component name so all the
vertices that are discovered in the same
call of DFS have the same ID and to
visit a vertex now you go through all
its adjacent vertices I in any that are
not mark now you give a recursive DFS
call again this code is amazingly
compact and elegant when we're going
through the demo step by step maybe and
you could see that the underlying
computation is actually a kind of
complex but but recursion and the graph
processing API that we set up provides
compact and easy to understand
implementation so that's using BFS to
find connected components and then to
return the ID of a given vertex you just
look it up in the array and to return
the number of components just return
count and then you can build up the
conductivity API from those so that
depth-first search to find connected
components I will just talk briefly
about two applications from scientific
applications so here's an application of
sexually transmitted diseases at a high
school and simply the vertices are
people
bleuer men and speaker women and you
have an edge between if there was a
contact and so it's obvious that how
you're going to be interested in the
connected components of this graph to be
able to properly study of sexually
transmitted diseases these individuals
had no contact with these and I've been
beat and I which everyone has a disease
maybe it won't spread or if you add a
new edge then you maybe have a problem
that's just one example studying a
spread of disease there's another
example that we use for the similar to
the flood fill example this is
processing data from a scientific
experiment and in this case this image
is comes from a photograph in the white
things or particles that are moving and
all yet is a image where it's a
grayscale image and so what we'll do to
do this processing is everyone identify
the movement of these particles over the
time and the way we do it is build a
grid graph like the one for the flood
fill application and do an edge
connecting two vertices if they're
different to their grayscale values is
greater than less than some threshold
and so then if you do that and then find
the connected components then
you can identify blobs which correspond
to real particles in this simulation and
they do that every frame in a movie then
you can track moving particles over time
so these are maybe fairly high
resolution images these are graphs with
lots and lots of edges you need to need
to be able to do this computation
quickly in order to do this scientific
experiment and we use this as an example
in our first year programming course but
it's based on computing connected
components using depth-first search so
that's our third example of a graph
processing algorithm
for this example we'll be looking at the
undirected graph so we have rows and
columns which are going to be label
labeled with ordered vertices and we
want to be able to fill in our given
table by writing one if there is one
edge between the row vertex and the
column vertex and we're gonna write in 0
if no if there's no air if nobody exists
between them so for example between V
and W there is an edge so that would be
one and let's say for example between V
and X there is no edge there's no direct
line between them so that will be 0 so
that's at plugging in our example so for
our table between V and V there's no
edge so we can write in I can write in 0
so that's perfect let's say between V
and W well there is an edge so we put in
1 between V and X 2 is no edge so we can
put in 0 and let's say between V and why
there is an edge so we put in 1 and then
we continue one so between W there is a
bit of overlap overlap between these but
I will just iterate the whole way down
through the table
so between W and V yes there is we've
already dealt with that so that goes in
here as 1 for the next one between W and
W there is no edge so we have 0 between
W and X you can see here that there is
an edge so we put in 1 and then between
W and Y W and Y there is it as you can
see this line here so we put in 1 so
down to the next line between X and V
there is no edge we put in 0 between X
and W there is this is edge here so we
put in 1 between X and X which is here
there is no edge so we put in 0 between
x and y there is an edge this one here
but in one now for the next one it's
between Y and V yep so that edge is here
as we can see one between y and W there
is an edge so it's one between y and X
er is an edge so there's one between y
and y so this little line or this loop
line that we have here indicates that
there is an edge between Y so that goes
in as one so that is the basis for our
undirected graph
in this video we're going to have a look
at some of the applications of
undirected graphs so this is following
on from just our basic definitions so
the first application will be look at
our planner graphs so another definition
really but a planar graph is a way of
drawing a graph where the edge is joint
intersect unless there is a vertex so
you can see the example here we have
this is non planner because at this
point here there's no vertex with the
edges are crossing over it doesn't mean
that I can travel along this edge and
then divert to vertex a that way because
I can only change direction if there is
a vertex so to draw a graph as planner
it means i need to redraw that graph in
a way that the edges only intersect at
the vertex and so way of doing that is
either to draw an edge in a different
way or put a vertex in a different spot
so if we think about this one here I
have the option of redrawing so just the
edges that I can to begin with and then
consider this problem and how I can fix
it so if I draw everything so far except
for vertex F then one of the options
that i have is i can actually draw
vertex f here on the inside and then add
the connection from E to F and F 2d and
then we can see that the edges only
intersect at our vertices and no other
point on the graph another option if we
just remove that one there another
option is actually to put the vertex
where it originally was but then draw
the edges in a different way so if I
leave f on the outside and let's put
their connections in but this time
instead of this edge from A to D sorry I
didn't put the label on there and
running down here I can actually draw it
around the outside so if i actually just
take
the edge out and order on the outside
now it becomes planner the reason we
care about that is because of Euler's
formula so if we have a look at oil as
formula here it is a formula that helps
us link the vertices edges and faces of
a graph and allows us to find the
missing value if we know that a graph is
planar so one little thing that we need
to understand a face a face on a graph
is a region is abound by edges or around
the outside so it has to be a connected
graph so in terms of what that might
look like if I have a connected graph
that looks like this I have one face
bound by the edges and I also have one
face that if we think about around the
outside on the page so we have to
firstly we have our graph drawn as
planner before we can apply Euler's
formula so if we have a look at the two
examples here let's firstly redraw those
graphs as planner and now to help me do
that I always label my vertices so that
I can keep track of where the edges are
connecting and make sure that I've
redrawn everything that I should so if I
just redraw these vertices in a b c d n
E and F and connect what I can obviously
I've got a problem here in here so
they're going to be either the edges all
the vertices that I'm going to need to
remove so let's just join our original
connections that we can to start with ad
be a two E and A to D beam d bc
d z EF now the two that I have left are
this these to hear from be down to E and
B to F so I'm actually going to draw
those around the outside like that to
create a new graph planner isomorphic
graph it has the same information same
number of vertices the same connections
however it's just drawn in a slightly
different way so here we have one two
three four five six vertices we have one
two three four five six seven eight nine
edges and the faces we have one two
three four and one for the outside five
faces and so we're going to apply or
verify oil errs formula we're doing
vertice move- edges plus faces equals
two and check that the left-hand side
equals the right-hand side so 6 minus 9
plus 5 equals two left-hand side equals
our right hand side therefore we have
verified well as formula now usually a
question won't actually asks you to
redraw count and verify what it's more
likely to do is say a player connected
planar graph has six vertices and five
faces how many edges does it contain so
it's asking you to use your knowledge of
the fact that aunt play connected planar
graph has this property Euler's formula
and you will be told two of the three
pieces of information and asked to stall
for what's left and so as soon as you
see the word planar graph or Euler's
formula this is what you want to be
looking for in your bowel reference and
applying that rule
okay another application of undirected
graphs are complete graphs a complete
graph yet another gate definition is a
graph where there is a pair of all pairs
and vertices are connected by an edge so
we've got some examples here that means
in a connected graph of three vertices
so if I've got vertex a B and C I can
get from aim directly to be directly to
see by the same token from see I can get
directly to a and get directly to be and
obviously last one from be i can get
directly from A to B &amp; B to C so there
is a direct pathway and adjacent that
every vertex is adjacent to all other
vertices in the graph and so I connected
graph has a special property in terms of
how we work out how many edges there are
and we use this formula here so we use a
cave to denote a complete graph and so a
complete graph with n number of vertices
will have n times n minus 1 on to number
of edges so we can see here complete
graph of three will have 3 times 2 on 2
so 3 edges complete graph of four
vertices will have six edges of five
vertices will have 10 edges another
thing to note with a complete graph is
that we have an adjacency matrix which
obviously has only once for each of
jacent matrix so direct connections and
has no loops so there are always zeros
down the leading diagonal so it's quite
easy to draw an adjacency matrix for a
complete graph what we tend to see
complete graphs used for is round-robin
competitions so we have five teams every
team plays each other once how many
games were played so a scenario like
that expects that you would understand
that five teams could be represented by
a complete graph with five vertices and
therefore each edge represents a match
so ten matches in total
okay moving on now to paths and circuits
so we talked about in the first video a
path being a way through a graph or a
network and a circuit is just a path
that starts and finishes at the same
place now Euler pods are a special type
of path this is one where we have to use
every edge in the graph but only once so
it's the type of thing where I have to
be able to trace my way around the graph
without lifting my pen and without going
over the same edge more than one time I
can visit vertices more than once that's
not a problem but it's just the edges
can only use once and Euler circuit
obviously means I go over every edge
just once and finish where I started
from there's a special property with oil
or paths and circuits with an Euler path
we're looking at the degrees of the
vertices now we talked about the degree
of a vertex being the number of ways in
which I can leave a vertex so if I'm
looking at vertex a here it has a degree
of three okay so there are three ways
that I can leave vertex a let x be as a
degree of two two ways I can leave now
the special thing that we're looking at
with oil or paths and circuits as well
if we have a graph that has exactly true
vertices of an odd degree that is that
the vertex has a degree which is an odd
number if there are exactly two of those
then we know there will be an Euler path
and it will start at one of those odd
vertices and finish at the second odd
vertex if there are no odd vertices at
all that is all of the vertices have our
of even degree then there will be an
Euler circuit and it's a matter of trial
and error as to where you can start
generally if that anywhere you want if
there is one odd vertex for our vertices
5 7 10
anything but to then there will be no
Euler path and also know euler's circuit
so if we look at the examples that we've
got here I've given you an example down
the bottom of a possible Euler path so
if the first thing we should be doing is
actually looking at the graph and saying
let me check the degrees of the vertices
so eight has three so that odd be has
two it's even see has four so it's even
d2 even e3 odd so the example I given
you below i started at e or vertex and
finished at a the other blood vertex
another possible path let's start at a
so it is just a matter of working your
way around the graph going over every
edge once not lifting your pen and
finishing at the other odd vertex then
we want to actually list the values so
you can use arrows in between or you can
simply just invest the vertices in order
so that path that I went on went from A
to B c.a.e.c d e okay odd vertex one
vertex you can see I can repeat vertices
in the middle that's fine as long as
every edge is just useless in a second
graph so if we check the odds and evens
again a has two so it's an even vertex B
is even c is for even d even a even so
we know already that there will be an
Euler circuit and we can start where
we'd like I decided see for this example
and just where go out from a to b c d e
and back to see i started and finished
at sea so that makes it a circuit ok so
to list that c a b c d e c start and
finishing the same place every edge just
used once quite often a question like
this will actually ask you if I need to
turn
an Euler circuit I sorry on a path into
an Euler circuit where will I add the
edge so let's have a quick look at the
example in the next page and we'll go
through how we identify what edge and
where it should be added okay so let's
look have a look at the two examples
here so the first one check our odds and
even vertices so a is even the for even
see even d even E is even and f is even
so we know we'll have an Euler circuit
so let's start at F and I'll just go up
to a b.f a d b c d and f started and
finished in the same place I have an
Euler circuit and I can loose those
obviously more than one answer here so
let's look at the checkout odds and
evens again sir a there's two there so
that's an even D is for so even see has
three we've got an odd vertex so already
I know they won't be in oil a circuit so
let's make sure we can still do an Euler
path though d has four so even e again
for if has 2g has four and H again three
so odd so I know that my path must start
either at sea or H I cannot start at any
of the even vertices if I started to see
I will end up at H at my last vertex if
I've done the correctly okay so let's
have a look at it at a path sorry so I'm
going to start up see go through to e h
see the e g d be a d FG and finally
finishing at h and again there will be
multiple ways of doing that sometimes is
only one but most of the time you'll
finally do is more than one option now
let's look at the Patsy so for the graph
that has no Euler circuit so for graph B
it is possible to add one additional
edge to form a circle
between which two edges should this be
added so i started at sea and i worked
my way around and i ended up at h now i
want to go i want to finish back at sea
so logically the edge i should add is
from h back to see and that will allow
me to finish my circuit back where I
started from so what you're wanting to
do with any question where you have to
add an edge to make a circuit is always
add between the two odd vertices so in a
question like that you don't even have
to trial an error and find the path if
you know there are two odd vertices then
they as a true that you're going to
connect if it happened that you had four
vertices that were odd and you can
remove one edge then you're looking to
make one or so two of those odd vertices
even again by removing that connection
so it just depends on the context of the
question but if there are two odd
vertices you need to make them all even
if there's more than two then you need
to do what you can in order to either
reduce those so that you can have a path
or get rid of all of them add an edge
somewhere so they all add multiple edges
so that you can end up with a circuit or
even degrees ok so moving on from Euler
we have Hamilton paths so these are
different type Hamilton paths and
circuits again we're wanting to either
make a path through the graph or circuit
finishing where we started from the
difference with Hamilton is that this
time I don't need to use every edge but
I must use every vertex and I can only
visit each vertex once so if we look at
a graph one here so a possible Hamilton
path through this could be from a to b e
d c f so a be e d c f path a start and
finish in a different place and you'll
note this time I've only visited each
vertex black so I've only listed every
letter once if I've listed one multiple
times that I know I've made an error I
visited it more than once and that's not
all
how to make a Hamilton pass now in this
case it's not possible to make a
Hamilton circuit because I can't get
from F back to a ok there is no edge
connecting nose and there's no other way
of doing it because I only has one
degree or degree of one and if only has
a degree of one there's only one way out
of a I can't get back in and the same
with F so in that case I know that I'm
not going to be able to do a circuit so
there's no rule this time like there was
for Euler but there's some little things
that you can pick up on that will help
you along the way if we look at the
second graph so a possible paths I could
start at be a d.c and again there will
be multiple solutions or multiple
possibilities for that it's circuit if
we start at a and go a be d/c back to a
so I be d/c a start and finish in the
same vertex is he our only time you're
allowed to repeat the vertex the letter
when you're making a circuit and again
everything else is just being listed
once a nice little thing to note with
Hamilton because as I said there is no
rule like Euler about the odd and even
vertices so it's a bit difficult
sometimes to know whether you have
actually covered everything or whether
it's possible and this is handy when
you're doing multiple choice questions
if you look at the graph so graph too we
have four vertices to make a path I have
to list four vertices to make a circuit
it's always n plus 1 so I've listed five
vertices there so I have my circuit
nothing's repeated except for my start
and finish and so I'm pretty it can be a
pretty confident that that will be the
answer so you can understand in a
multiple choice question if they ask for
a Hamilton circuit then they're going to
give you an Euler circuit just to try
and trick you so knock out any answers
that have too many vertices listed or
things listed multiple times and that
will help you narrow down the answer so
looking now at the last
location of undirected graphs this is
where we add an extra layer so now
adding values to the edges and we call
these weighted graphs so usually the
values that we add to an edge are used
to represent in the time taken to travel
a distance or the actual distance itself
or the number of people who can move
along a pathway in a given time so it's
usually time distance or objects and we
call those values weights and so what we
tend to use these for is to determine
minimum paths and so it might be an
Euler path that will give us the minimum
or a Hamilton path will give us the
minimum between points the shortest
distance between two points and then we
also use standing trees or minimum
spanning trees so if we have a look at
the example here for a tree a tree the
definition of a tree is a connected
graph which has no circuits so
technically a tree does not have to
contain everything that was in the
original graph ok but we tend to work
with what we call spanning trees or
minimum spanning trees and they will
actually contain all of the original
vertices and then the minimum number of
edges required to make it a connected
graph so remember a connected graph has
no isolated vertices so here we have a
graph with five vertices so I know that
in order to make a spanning tree or a
minimum spanning tree if I had a weight
on each edge I need to use four edges
because I have five vertices and so
therefore to be 5 minus 1 edges so four
edges to make that a graph a sorry tree
so a couple of possibilities here for
you and if we use the graph that was at
the top of the page and look at drawing
a minimum spanning tree at a minimum
spanning tree so I had cities in
Australia so Perth Brisbane Sydney and
Mel
them and so if I just wanted to draw a
spanning tree I could do any number of
different connections so you have to use
edges that were in the original graph
you cannot add your own bonus edges and
so at this point here I have four
vertices and I've used three edges so I
know that that's the point at which i
stop if i was to keep going and add in
any of the other edges I all of a sudden
make a circuit okay or a closed space
and that's not what I want to do I want
to make sure it's an open graph no
virtus know your circuits so basically
that means you don't want to be able to
close off a face you were one single
face for this graph if I needed to make
a minimum spanning tree then this time I
need to consider the values on those
edges I need to consider the weights and
the only in values I want to use are the
smallest possible weights now there are
a couple of different algorithms or way
of doing it there's one called prims
algorithm which is in most textbooks the
one I use is kind of just a
trial-and-error type thing or a logic
type thing you look at the smallest
numbers on the graph and use those edges
first so in this case the smallest
distance represented is from Sydney to
Melbourne and that's a distance of 963
the next smallest distance is from
Brisbane to Sydney and if I adding that
edge I'm not going to create a circuit
so it's ok to use it the next smallest
distance is actually for isbin to
Melbourne but that will create circle
and I don't want to use that I only have
one vertex left perth to add in so i'm
going to see what is the shortest
distance or the smallest weight that
will connect perth into the rest of this
graph and by looking at the graph above
i can see that the smallest distance is
actually purse to melbourne with a value
of 3430 and so my minimum spanning tree
is
from Perth Melbourne Sydney Brisbane it
doesn't have to create a pathway in a
minimum spanning tree as you can see
from some of these examples above I
don't have to be able to traverse the
network it's just the minimum number of
edges and so our actual value of our
minimum spanning tree is when we add
those values together and that gives us
the total weight or the minimum weight
for that particular graph ok so one more
last quick example you can see Prem's
algorithm is written here but I'm going
to use my method so the first thing I
need to do is identify how many vertices
do I have therefore how many edges
should i be using so this graph has one
two three four five six seven vertices
which means I want to use sticks edges
only so it gives me a bit of a guide to
keep track of what I'm doing and then I
look in the graph and say ok which are
the edges that have the smallest waist
so I can see a couple of edges that I've
got a weight of two so I'm going to use
those first so I've got one there and
one there the next smallest number is a
three and by adding that I'm not
creating a circuit so i'll use that edge
as well the next smallest number is a
four and now there are three different
floors there and i only need to use six
edges and i don't want to create a
circuit so i need to be careful so this
one here in the middle that's ok it's
not going to create any circuits and
it's adding in a vertex that needed to
be connected I have to hear now I can
use either of them but I count is both
because if i use both I close off this
triangle and I create a circuit so I'm
just going to use the bottom on here at
the moment I've got five edges on my
graph that I've used I need six and you
can see at the moment there's no
connection between this side and the
other so I need to add in one more edge
and the shortest way of doing that is
the six across the top so I'm looking
all those three up three options 68 and
76 was the smallest number so that's the
one that I want to use for my
minimum spanning tree so my final answer
would look something like this okay and
then obviously to give my final final
answer I actually add those values
together and give the minimum wage if
that's what is asked for usually a
question like this would be these
vertices are representing different
points and I need to connect them with
some cable or something like that and
what's the minimum amount of cable that
i need to use and so in order to work
that out i work out the minimum spanning
tree and add together the weights so
there that one I've got a total of what
have we got 10 14 18 21 so the 21 is the
minimum weight of that particular graph
okay I hope that was helpful that's some
of the basic applications of undirected
graphs in the next video we'll start
looking through the directed graphs and
their key applications for Fermat's
great work we're now going to go a
little bit deeper into the network X API
and introduce a few more concepts that
you can use in network analysis Network
X allows us to model different types of
graphs for example there are social
graphs like Facebook which are
undirected graphs undirected graphs are
named as such because they are comprised
of edges that don't have any inherent
directionality associated with them with
Facebook for example when one user
befriends another the two are
automatically connected with an edge
this is most commonly drawn as aligned
with no arrows between two circles if we
explore this in the ipython terminal you
can instantiate an empty graph in
network X using an X graph and ask for
its type undirected graphs have the type
graph on the other hand
Twitter's social graph is a directed
Network this is because of the nature of
how users interact with one another
for example one user may follow another
user but that other user may not follow
back as such there's an inherent
directionality associated with the graph
if we explore this in the ipython
terminal you can instantiate an empty
directed graph in network X using and XD
graph if you query for its type it will
return a digraph object we can also have
graphs in which there are multiple edges
permitted between the nodes for example
we may want to model trips between bike
sharing stations each trip may be one
edge between the pair of stations if we
explore this in the ipython terminal we
can likewise instantiate a multi graph
using an XML Tigres if we check for its
type it will be of the multi graph class
and likewise for the multi digraph
object sometimes for practical reasons
may be two memory intensive to model
multiple edges per pair of nodes and so
one may choose to collapse the edges
into a single edge that contains a
metadata summary of the original
for example we may want to collapse
these three edges into a single one and
give them a weight metadata with the
value three indicating that it was
originally three edges between the pair
of nodes let's go through one final
concept the idea of self loops self
loops can be used in certain scenarios
such as in bike sharing data where trip
begins at a station and ends at the same
station one of the exercises you will
encounter will leverage what you've
learned so far about the network X API
to find edges that are self loops in a
graph alright let's move on to the
exercises now
now we're going to look at depth-first
search which is a classical graph
processing algorithm it's actually maybe
one of the oldest algorithms that we
studied surprisingly one way to think
about depth-first search is in terms of
mazes it's a pretty familiar way to look
at look at it and so if you have a maze
like the one drawn on the Left you can
model it with a graph by creating a
vertex for every intersection in the
maze and an edge for every passage
connecting to intersection and so if
you're at the entrance of this maze and
you want to find a pot of gold somewhere
what you're going to need to do is
explore every intersection or exploit
explore every edge in the maze so we're
going to talk about the Explorer ring in
your section option so that's our goal
have an algorithm for doing that by the
way this is a famous graph that some of
you might recognize that's the graph of
the pac-man game okay so one method
classic method that predates computers
for exploring a maze is called the tray
Moe maze exploration algorithm on the
idea is to think about having a ball of
string and what you do is when you walk
down a passage you unroll the string
behind you
and you also mark every place that
you've been so actually have a ball of
string and some chalk maybe so in this
case maybe we walked down this passage
here and now we have some choices about
where we might go so say we go down here
so we enroll our ball string high and
market and so now the next time at this
intersection we have no choice but to go
up here we go up here we see oh we've
already been there so we're not going to
go there and then we come back and
we have our ball Springs so we can
unroll it to figure out where we were
and we go back until we have some other
choice which is this this place now and
Mark that we've been these other places
and so now we take another option to go
down this way and here we take another
option go that way and then finally
again we go up this way and we see that
we've been there so we back up and take
the last option and then that gets us to
the last vertex in the graph so mark
each visited intersection and each
visited Paquette passage and retrace our
steps when there's no unvisited option
again this is a classical algorithm that
was studied a centuries ago and in fact
not some argue the first use was when
pcs entered the labyrinth and was trying
to find the Minotaur and every aadmi I
didn't want him to get lost in the maze
so she instructed Theseus to use a ball
of string not to find his way back out
that's the basic algorithm that we're
going to use and has been studied by
many many scientists in the time since
the knot Theseus and in fact Claude
Shannon the founder of information
theory I did experiments on mazes with
mice to see if they might understand
maze exploration this might help okay so
here's what it looks like in a typical
maze now one of the things to remember
is in a computer representation normally
we're just looking at the vertices in
the set of associated edges we don't see
anything other than that so it's
sometimes frustrating watching these hi
you know that it turned the wrong way
and it's going to get trapped here but
the computer doesn't really know that so
it has to back up along here now
and it continues to back up to find
another option until it gets free again
and finds the someplace to go and
sometimes it's very frustrating it seems
to be quite close to the goal like up
here and it turns the wrong way so we
can see it's going to take a long way
but no way the program could really know
that again all the programs working with
is vertex instead of edge is associated
with that vertex and there it finally
gets to the goal here's a bigger one
going faster now the key thing is not so
much getting lost them going the wrong
way the key thing is not going anywhere
twice that's the whole thing we have to
have the string to know to go back where
we came from and we have to be able to
mark where we've been and with those two
things we are the algorithm is able to
avoid going the same place twice if you
weren't marking if you try to do this
randomly or some other way might take
you a while to get to the goal so it
doesn't seem like much of accomplishment
maybe for amazed than actually to be
able to get there with going without
going anyplace try it twice is sort of a
profound idea in leads to an efficient
algorithm okay so our idea is given in
this meta code to do depth-first search
that is to visit all the places you can
get to from a vertex being what we're
going to do is this simple recursive
algorithm mark the vertex is visited and
then recursively visit all unmarked
vertices W that are adjacent to B that's
a very simple description and it leads
to very simple code it's so simple
actually it really
belies the profound idea underneath this
algorithm so again there's lots of
applications and for example this is one
way to find whether there exists a path
between two vertices or to find all the
vertices connected to a given source
vertex and we'll consider some less
abstract applications once we've looked
at the code so so how to implement well
here's what we're going to do for our
design pattern for graph processing it's
our first example so what we did when we
defined an API for graphs was to
decouple the graph data type from graph
processing the idea is we're going to
create a graph object using that API
which we know allows us to represent a
big graph it in the computer and gives
us the basic operations that we're going
to need for graph processing and then we
use that API within a graph processing
routine and the basic idea is that that
graph graph processing routine will go
through the graph and collect some
information and then a client of that
routine will query the API to get
information about the graph so in the
case of depth-first search here's a
potential possible API so the idea is
that what this what we're going to
implement is a program that can find
paths in a graph from a given source so
we give a graph in a vertex and that
constructor is going to do what it needs
in order to be able to answer these two
queries the first one is I give a vertex
client will give a vertex is there a
path in the graph from the source to
that vertex and want to be able to back
into that efficiently and then the other
thing is to just give the path what
the path from is VG me all the vertices
on the path anytime proportional to its
length so here's a client of this API so
it's going to take a source source
vertex F and it's going to build a path
finder or a path object and that object
is going to do the processing it needs
to be able to efficiently implement it
has bathtube and then what this does is
for every vertex in the graph if there's
a path from s to that vertex it'll print
it out so that prints out all the
vertices connected to it and that's just
one client of this data type you could
print out the pass or whatever else you
might so that's our design pattern that
we're going to use over and over again
for a graph processing routine and it's
important to understand why we use a
design pattern like this
we're decoupling the graph
representation from the processing of it
as I mentioned there's hundreds of
routines for our evidences but developed
for processing graph an alternative
might be to put all those algorithms in
one big data type that's a so-called fad
interface and that would be a bad plan
because these things maybe are not so
well related to each other and actually
all of them really are just iterating
through the graph and doing different
types of processing with this way we're
able to separate out and I articulate
what the graph processing clients are
doing and then the real applications can
be clients of these graph processing
routines and everybody's taking
advantage of an efficient representation
that we already took care of okay so now
let's look at a demo of how depth-first
search is going to work and then we'll
take a look at
implementation okay so here's a demo of
depth-first search in operation on our
sample graph again to visit a vertex now
we're going to mark it and then
recursively visit all unmarked versus
vertices that are adjacent so this is
our sample graph and so the first thing
we do is realize that we're going to
need a vertex indexed array to keep
track of which vertices are marked so
that'll just be array of boolean and
we'll initialize that with all false
we're also going to keep another data
structure a vertex indexed array of ents
that for every vertex gives us how the
vertex that took us there so let's get
started and you'll see how it works so
this is deafer search starting at vertex
zero so now to visit vertex zero we want
to mark it so that's a mark zero is true
and that's the starting points we know
anything with edge two and now what
we're going to do is we're going to need
to check all the vertices that are
adjacent to zero so that's six to one in
five the order in which they're checked
depends on the representation in the bag
we don't really necessarily care about
that most of the algorithms are going to
check them all it doesn't matter that
much about the order although it is some
cases it's wise to be mindful and maybe
use a bag that takes them out and random
order okay so to visit zero we have to
check six to one and five so let's go
ahead and do that so on this case that
six six is the first thing to get
checked and so now we mark 6 as visited
and now we're going to recursively do a
search starting from six the other
difference when we visit six from zero
we're going to put a zero in this
edge to entry to say that when we first
got the six the way we got there was
from zero and that's going to be the
data structure that'll help us implement
the client query to give us the path
back to zero from any path from any
vertex okay so what do we have to do to
visit six well six has two adjacent
vertices zero and four so we're going to
have to check them so first we check 0
and that's already marked so we don't
have to do anything we're only supposed
to recursively visit unmarked vertices
and then we check for in for is unmarked
so we're going to have to recursively
recursively visit it the next thing we
do is visit for mark 4 as having been
visited with a true in the marked array
fourth entry of the marked array and we
and we fill an edge to saying we got to
four from six and so now to visit four
we have to recursively check five six
and three and again that order is where
they happen to be in our bag not so
first we check five five is not marked
so we're going to visit five we're going
to mark it say we got there from four
and then go ahead and visit three four
and zero in that order from first we
visit three that one also is not yet
marked so we're going to recursively
visit it
so that's mark three say we got there
from five and then go ahead and to visit
three recursively we have to check five
and four check five well we just came
there it's marked not so we don't have
to do anything
check for that's also been marked so we
don't have to do anything so now finally
this is the first time in the recursive
calls that we're ready to return we're
done with depth-first search from three
so now we're done with three and we can
unwinding the recursion we can now
continue
our search from five and the next thing
we have to do from five we've already
checked three so now we're going to
check for and we've already visited four
so we don't have to do anything that's
already marked and we check zero and
that one's already marks and now we're
done with flies and we came back one
more level up in the recursion so now
for four we have to go through and look
at six and three six is marked so we
don't have to do anything three its
marked also enough to do anything and so
we're going to be done with four so that
after finishing four we're done with six
into an hour in the recursion back at
zero
we've already not checked six so now
we've got to check to next now we check
to and so we recurse and go there
mark two and then say we got there from
zero and now to visit two all we check
is zero and that's mark so I'm gonna
have to do anything and we're done with
two and then check one visit one that's
the last vertex we're visiting check
zero it's already mark so we don't do
anything we return now we're at the last
step is to from zero five is on its list
we have to check if we've been there we
can see that it's marked and we have
been there and also we're done with zero
so that's a depth-first search from
vertex zero and we have visited all the
vertices that are reachable from zero
number one and number two for each one
of those vertices we kept track of how
we got there from zero so if we now want
to know for any one of those vertices
how to get back to zero we have the
information that we eat for example say
we want to find the path from five back
to zero we know we get to five from four
we know we get to four from six we know
we get to six from zero
so we can go back through using that
edge to array to find the path so the
depth first search calculation built
these data structures and now clients
and these data structures built in a
constructor serve as the basis for being
able to efficiently answer client
queries
that's the depth-first search demo so
this is just a summary of the things I
talked about during that demo our goal
is to find all the vertices connected to
given vertex s and also a path in order
to be able to answer client query and
the algorithm we're going to use is
based on like maze exploration where we
use recursion mark each vertex keep
track of the edge we took to visit it
and return when there's no unvisited
option we're using two data structures
to implement this both vertex indexed
arrays one named mark that will tell us
which vertices we've been to and another
one edge to that maintains that tree of
path where edge 2w equals V means the VW
was taken of the first time that we went
to W so now let's look at the code that
given all this background now the code
for implementing depth-first search is
remarkably compact so here's our private
instance variable the mark and edge to
vertex indexed arrays and I in the
source s and the constructor just goes
through and creates the arrays and
initializes them we won't repeat that
code and so here's the last thing that
constructor does after creates the
arrays is does a DFS on the graph from
the given source and it's a remarkably
compact implementation to do depth-first
search from a vertex V what we do is
Mark V to mark to true and for everybody
adjacent to the
we check if it's marked if it's not
marked then we do a recursive call and
we set high edge 2w equals three again a
remarkably compact code that gets the
job done so now let's look at some of
the properties of depth-first search so
first thing is we won't want to be sure
that convince ourselves that it marks
all the vertices connected to s in time
proportional is sum of their degrees one
of which for sparse graphs going to be
small so the first thing is convince
yourself that if you mark the vertex
then there has to be a way to get to
that vertex from that and so well that's
easy to see because the only way to mark
Evert axes get there through a sequence
of recursive calls and every recursive
call corresponds to an edge on a path
from s to W but you also have to be able
to show that you get to every vertex
that's connected to F and that's a
little more intricate in this diagram is
supposed to help you out in
understanding that if you had some
unmarked vertex then maybe there's a
bunch of unmarked vertices and so in
it's connected s and it's not marked
that means there has to be an edge on
the path from s to W that goes from a
mark vertex to an unmarked one but the
design of the algorithm says that
there's no such edge if you're on a mark
vertex then you're going to go through
and look at all the adjacent ones and if
it's not mark you're going to mark it so
that's
the outline of the proof that DFS marks
all the vertices in the running time is
only visits each mark vertex once or
each vertex connected at once and so it
reads one of them it goes through all
the adjacent vertices so that's the
basic properties of depth-first search
so now the other thing that is important
is that a client who has uses this
algorithm after the depth-first search
after the constructor has done a
temporary search and built these data
structures a client can find the
vertices connected to the source in
constant time and it can find a path to
s if one exists in time proportion to
its length
well the marked array provides the first
part and the second part is just a
property of the edge to edge to array
it's a what's called a parent link
representation of a tree rooted at s so
if a vertex is connected to s then its
edge two is its parent in the tree so
this code here is going to for a given
well has passed through so that just
returned mark that's the first part and
then to actually get the path to a given
vertex so here's the code for doing that
how we actually use a stack not to keep
track of the path because we get it in
reverse order if there's no path we
return null otherwise we keep a variable
X and we just follow up through the edge
to array pushing the vertex onto the
stack and then moving up the tree in the
array and then finally push that itself
onto the path and then we have a stack
which is interval which will give us our
path so that's in time time proportional
to the length of the path
in it's worthwhile to check your
understanding of how stacks an iterator
works iterators work to take a look at
this code to see that it does the job
so that's depth-first search now it's
not the optimal graph searching method
for all applications and I and here's an
amusing representation of how
depth-first search can maybe create
problems sometimes so I'm getting ready
for a date with situations who I prepare
for well medical emergency dancing food
too expensive okay what kind of medical
emergencies could happen well it could
be snake bite or a lightning strike or
fall from a chair well what about snakes
and eyes never have to worry about corn
snakes or garter snakes or Copperhead
and then well I would better make a
straight and better study snakes and
then the date says I'm here to pick you
up you're not dressed and well so I
really need to stop using depth-first
search so we're going to look at other
graph searching algorithms but if you
always try to expand the next thing that
you come to that step first search on
this lot of natural situations for that
naturally and I comes to mind here's
another example I took this photo of the
Taj Mahal a couple of years ago and I
didn't like the color of the sky so I
use Photoshop magic wand to make it more
blue and the implementation and now this
is a huge graph that pictures got
millions of pixels in the way that the
flood-fill the magic wand works is to
build from a photo what's called a grid
graph where every vertex is a pixel and
every edge connects not to pixels that
are the same color approximately the
same color and it builds a blob of all
the pixels that have the same color as a
given pixel so when I click on one it
does a depth-first search to find all
the connected
pixels and therefore change into the new
color
that's a fine example of depth-first
search on a huge graph that people use
that I everyday so that's our first
non-trivial graph processing algorithm
depth-first search
you
I'm very happy today Julia times get us
off Julie Elsa professor just got tenure
fleet at ok what Billy I got tenure at
the joys of homogeneous attune in
Chicago toi tu ti is on the ocean campus
but two separate academic institutions
Julia got her PhD at economic technion
under subpoena or um and then she did
post Docs Mike if you order right or
even a name strides and rotating bokra
incident is okay hello she lived in
austin for some of that time and then
she can t TI yep and I wat by beaters
right I'm sorry and this is going to be
one of her stock paper she's in by
single author session Julia blames me no
it's not like that's what they did your
fault yes I know different it is
anyone's going to talk about routing and
undirected graphs with concentration and
then I had this kind of into that camera
thanks and again this will talk about
routing problems so general in the
routing problem you have a graph and
again
in Paris that we also call sourcing
fears which are just clear the florists
in the content of each other that's why
I want the 51 and still wanted a 42 and
so on so what we want to do is to route
as many of these peers as possible while
minimizing suggestion so what do we mean
by by routing appear throughout the pier
we just need to connect the spear with
the past for instance here we can decide
if you're out s 1 2 t1s redpath so we
can decide to route all peers or maybe a
subset of Spears like here right s 131
is a red path as you don't go past as we
2 tsp green path and so on and once we
decide on the routing the congestion is
just the maximum load on any H is the
maximum number of tabs that share the
same age for instance here we have these
two paths the Chelsea mhm and this is
the largest you can get over all edges
so the condition of the solution is to
so just a few words about notation m so
as usual in these problems the number of
grafts where justice is denoted by n the
number of the demon peers s21 dress
Katie cadets k and a vertices that
participate in the demand here's what we
call them terminals so you can think
about the number of terminals being
rough the key also won't change anything
so as we already seen we can roll all
three pairs and get conditioned to but
what if we already stripped was
conditioned we cannot allow any
congestion what do you do then then you
can for example around two peers and get
condition one so in routing problems you
have these two conflicting objective
functions you want wrote as many peers
as possible what you also want to
minimize the condition and in some
locations again this structure on one of
them you really have to you know a fix
one of these parameters and then you try
to be more flexible and optimize the
other
all the other way around or maybe your
flats alone both of these parameters in
any case because the here is tanisha two
parameters we naturally get two problems
that are the classical routing problems
the first one is the adjoint pest
problem and the other one is conditioned
minimization so energy is Jen path
problem you want to route as many peers
as possible but the past have to be
completely a disjoint so we don't allow
any congestion we're very strict on
congestion and then we try to do what we
can what we can deal with the number of
pairs about it the other extreme is
conditioned minimization where you want
to route all pairs so you are very
strict on the number of Paris wrote it
but then you want to minimize the
congestion so let me just briefly these
are really the classical problem so i
will briefly show what we know about
them so for the condition minimization
problem there is thus classical
randomized rounding algorithm of
raghavan and thomson and it gets Logan
over Logan approximation again we need
to roll up here so this is just the
condition and this is a very old
algorithm right now it's classics and we
don't know how to improve it we also
don't know if it's the best possible the
Western harness approximation is roughly
local again so this is really this is an
open problem in a very fascinating 1m
yep you know anything about it we
instead looking fashion okay oh yeah so
you can get it can get poly log K
congestion and possible summation so now
we switch to the design path problem
which will be like more the central the
focus of this talk so here we want the
condition is Turk now condition we want
to write as many pairs as possible so
when the number of the demand Paris is a
constant and then the work of Robertson
and see more gives a polynomial time
algorithm so they have this really long
work on the graph minor C
that is like 25 papers so if you go all
the way to paper number 13 or so I think
one of the side result that they get is
this volatile temper pull an all time
algorithm for solving this problem but
when K the number of yours is not a
constant then the problem is not be hard
it's even NP hard to say whether or not
you can route all cares with no
condition so um there is a pretty simple
root an approximation algorithm for this
problem and this is the best algorithm
that we know for this problem so as far
as approximation factors though we don't
really want better approximation factors
than lieuten but we don't know any
better approximation factors and so is
it the best possible to the rism they
say Bush miss miss my shades of
concentrate yeah one case constant you
can solve yeah okay okay and then I get
this cake I'm going to show the example
they have escaped okay so is it as
possible so i won't think they want to
mention is that if a very standard way
to solve arousing problems is first cast
it as a flow problem we're instead of
connecting every pair with the path you
want to route one flow unit between
every pair so what you get is a maximum
commodity maximal multi commodity flow
problem where you want to route as much
as possible between the demand fears and
you can think about it as an LP
relaxation of this problem because you
can solve it using LP so so this is a
standard way to get approximation
algorithms first to get the flow and
then you round it and not only the
standard rate of doing it is the only
way that we know how to do it for this
routing problems okay there are some
exceptions but on general graphs this is
how it is done now if we look at this LP
relaxation there is a very simple
example that chosen to go to gap or food
them so I'm going to show this to you
because it's a really simple and
constructive example and instructive I
mean
so we start to look great and these are
the parents s1 instead of the t1i so 2 T
2 and so on and now every intersection
of this grid we replaced by this gadget
so what is get it does is if we want you
have to pass one going vertically not
horizontally through this intersection
point of a grid they have to share an
edge so if you look at a fractional
solution then everything I can find one
hopeful unit is going happen to the left
like this so in total Wilson k over to
flow units with no congestion but if you
look for an integral solution then you
can see the maxim that you can get is
one because even if you try to roll to
the Pearson no matter how they are out
that they have to cross and this place
where they cross this is really going to
share an edge and get magician too so
this is a very simple game example it
has alone for a very long time they show
that they to go dig applet LPS root em
and it feels to be a fundamental
difficulty in solving this problem we
basically don't know how to get rounded
very interesting me the reasons without
the bra and judith was kind of
surprising is that in some cases you can
get around this gap and get a good
approximation and the cases are when the
graph is well connected well connected
means that the value of the minimum cut
of the graph is at least look to the
fifth set design particularly degree of
every vertex has to be also folio a
great week here so if this is the case
then you can get a hold of an
approximation for EDP and on the latex I
the hardest approximation to know is
roughly root log n so we are between
lieutenant loop again and this is
another very very interesting open
problem so i just want to mention that
there are some special cases in which
the situation is much better on this
special kid that we will also use a lot
today is expand your graphs so in
expanded graphs you can solve a DP well
and there is a large number of results
each of them was slightly different
parameters depending on what kind of
expanded grass or so
things so just I'm just going to your
site one result a freeze that says that
if we have a strong enough expander
constant degree expander then no matter
how we select any collection of sourcing
peers that only involves another log and
vertices any such collection can be
routed on the joint path this is a very
very strong reload okay and there is no
more content across street and so on
that I don't want to get into just that
this problem was studied a lot on these
special cases okay so here is the
situation on condition realization of a
stable standing between Logan and a
rough a local gun on EDP we stand
between the root and and roughly root
log n so one thing that we can ask okay
we are kind of stuck here what if we
hello just a little bit of congestion
let's say we allow for too fast to share
night no more can we get much better
than this and you know so if you think
about applications it's not clear that
in every application we have to be very
strict on one of these parameters maybe
we need something in between maybe we
can relax things so this is where this
EDP was condition comes in so we want to
get a factor alpha vaccination with
condition see meeting of year out
october alpha demand pairs of condition
it must see now what is opt so
traditionally in a diffuse condition we
define up to be the optimum number of
fears that can be routed with no
congestion alternatively you can also
define it as the optimal number of fear
scandinavian auditors condition c and
the result of time where the show will
be valid for both of these definitions
we just stick with this because this is
how it's you should define so so if you
think about again these two parameters
the number of pairs routed and the
congestion then edit and finish
immunization they start they study the
two extremes but if you want to study
there what happens in the middle if you
want to study the trade-off between
these two parameters then this seems to
be just the right framework to do it
so let me know sure what is known about
80 people condition so again if we use
the standard randomized running
algorithm of further one and Thompson
they get conditioned logon / local gun
and constant approximation well this is
pretty high condition what if we want to
do below this congestion so until
recently for a very long time the only
thing that we knew is n to the 1 over C
approximation was conditioned see for
instance if you want condition to this
will give you wrote an approximation no
better than ATP itself and then there
was the original breakthrough from I
guess two years ago of messy Andrews we
showed a poly log and approximation was
conditioned poly local again so this was
the first algorithm that broke this
Logan of a local again congestion of
Roman and Thompson and got reasonable
approximation factor Polly Logan still
if we want a constant position you'll
get only polynomial approximation factor
and yes we are recently collaboration
cooperation of the condition too and
they improved their root an
approximation factor to enter the 37 so
the result i'm going to show today is a
holy lockheed approximation was
conditioned 14 so this gives us a
constant foundation so this is the paper
that is about to appear in stock and so
i was trying to get a constant
approximation constant position and the
concern that came up was 14 and since
then i worked with a shilling with a
student from princeton and we brought
the condition down from 14 to condition
too so what happens is that this result
it really builds on the main ideas from
this result and it's very technical in
burning the position down from 14 22
because i'm not going to get into our
technical details in any case today i'll
just stick to this it just easier to
present okay so just going back to this
picture so we have seen here that if you
want condition one then the integrality
gap is root m so if we use this
framework and you want to get better
wrote an approximation you have to incur
condition too so the condition 2 is they
spend the best you can get if you go
with what flows yes but then it might be
that someone can a lot of your friends
out that's right yeah mm okay and just a
complete this picture oh then answer the
people or not there's a long list of
authors here anyway so so if I go for
any see if you want to get conditioned
see then there is locked to the one
overseer a flip I harness approximation
so basically if you want to get a high
constant condition you have to get a
boiler going to make approximation you
cannot get a bit better than that so in
this sense we are kind of close to
optimal even though they're poly log
that totally in the log is kind of a
higher than what's here okay so this is
the picture so now if we just allow a
tiny bit the condition condition to the
post definition one we can get
dramatically better pull okay it doesn't
even depend on them instead of poly log
in and and there is this almost matching
hardest approximation so um I will focus
on this result except as i said i'll
just show a constant congestion and and
so as somebody here mentioned we still
don't really know what is the truth
about EDP so we know that if you use
that LP relaxation you will not get
better than no time but maybe there are
other ways to get the better of
oxidation here and this is a really
interesting open question but still this
results show that there is some
fundamental way in which routing this
condition one is different from routing
was conditioned to and higher so let me
show you how it is different selected at
a start with some solution where I rod X
peers some position C and I want to get
lower congestion but still route pretty
many of these pairs so what this results
show is that you can still roll x over
sea porque PSS condition too so you can
reduce the condition all the way to to
and the only a little sea por lo que
fraction of the you still route see full
you locate fractional appears but what
if we wanted to reduce it all the way to
one what if to wasn't enough for us then
using exactly the same great example of
a show before you can show that you may
have to lose I would n factor here even
if you start do the routing or condition
is too so if you have some running this
pretty low condition you can reduce it
all the way to two but you cannot reduce
it all the way to one if you don't want
to lose that much in the numbers be
routed are we supposed to see how to do
this again how to do this sort of a
second this one this ah so basically if
you're out experimentation see it's like
hearing a fractional solution where
you're out one over C flow on each path
so get a fractional solution of letter x
over see em now congestion and then
because this was all the selkie rolling
rounding this this will give you this so
this result gives full of heads of
summations condition to today office
ocean ok so now I'm going to switch to
showing this and i'll go ahead and
achieves cause some condition and routes
poly log yeah and i just put a lot
approximation so one of the ideas that
has been wrong for a long time is that
we know how to route well on expanders
there are very good at brooks all girls
floating and expanders so what we want
to do is to have somehow turn our
problem into a problem of routing and
expanders so it would be good to claim
that our graph is an expander this is of
course not necessarily the case it would
be also go to them like the next best
day to kind of cut this graph up into
pieces say that each one of these pieces
is kind of like expander and then try to
sell them separately we also don't know
how to do that so what you do instead we
define something that's a little bit
weaker than the expansion property but
is kind of connected and then we work
with this property so this weaker
expansion property is called
yes it has been used before in a lot of
work on the rolling problems so what is
this ruling Katniss so let's see if we
have a job G and these red vertices of
the terminals remember terminals are the
Lord you see that participate in the
sourcing pairs so normally when we talk
about graph expansion we sell it for any
partition of the vertices into two
subsets the number of edges going
between them should be at least
comparable to the number of vertices on
the smaller side right stuff like that
now for the volume goodness we just
ignore vertices and we just look at the
terminals so we said of the graph is
alpha welding if for any partition AV of
the vertices of the graph into two
subsets the number of edges going across
has to be at least comparable to the
number of terminals on the smaller side
not all the vertices so the number of it
is going between them is at least often
times the minimum between the number of
terminals on each side so this is like
expansion except that its expansion with
respect to the terminals so if you're
familiar this is Lake looking at
uniforms parcel Scott or not you're an
offense vs. cut in expander super get
uniform on here at non uniform doesn't
matter if you know it so this is willing
goodness and I'm going to define the
link goodness again in a little bit
different setting because we use this
later again so let's say that we have
some subset s furnaces in this graph GM
and we look at the set of edges that
stick all os's red edges we even call
them all the risk and now we want to add
how well is s well linked with respect
to this red edges so in this case you
can think about eventually we'll want to
routes and flows across this set s so in
a way you can think about this front
edges as being the terminals and the
graph you can think about the professor
to do set s and then you can ask how
well is this graph well link to the spec
to these terminals so the definition is
going to be the same only the
read pages and the graph is a graph we
used by s so again we say that s is
alpha well linked if for any partition
of its vertices the number of edges
going across its least alpha times the
minimum of the number of the red edges
sticking out of these two sides so in
general this link in this parameter
alpha today it's going to be something
like 1 over poor little case so when I
say things are rolling this is what I
mean and m and the other city s is our
focal length then for any set of demands
that we find over these red I just let's
say that these demands defines our
matching you can you can roll this
matching in service at us with a little
with my condition ok so now over here
described to you we have the selection
of sourcing fears and we define this
notion of rolling goodness it would have
been convenient if this graph G was well
linked for the terminals again this is
not necessarily the case but luckily for
us in previous world of cricket and
Shepherd they basically reduce the
general case to this case what they did
is they show that for any instance you
can take a graph G you can cut it up
into small sub instances such that on
the one hand each sub instance is
willing for the terminals on the other
hand if you so visually service and
separately and you find this fractional
flow and then you add them all up then
you are pretty close to the global
optimal solution so you did you
graphically up into small instances each
instance is real linked but you don't
lose too much in the value of the
solution so basically what this says
forget about the statement is yourself
that you can assume that you're given
the gravity that is willing for the
terminals if you know how to sew it here
you know
solid overall so now we hear this graph
G it is really for the terminals where
is it useful for us so remember our
motivation was that we have very good
algorithms for rolling and expanders and
rolling goodness it's kind of like
expansion property only expansion of
those printed terminals so we would like
to use these algorithms for outing and
expanders and use them here the problem
is that even if you're willing for the
terminals you can be really far from
being expander because you can imagine
the situation where you just have a few
terminals a huge number of non terminals
merton internal vertices so you can
easily make a graph holding for the
terminals but to be far from being a
general expander still the intuition is
that if you are so willing so well
connected for the terminals then through
or inside this graph there must fit and
expand their spending these terminals so
this is what we want to do we want to
turn this expanded since instead is no
of G that spans the terminals and then
so the routing problem on this expander
in other words what you want to do is to
find an expander on a subset alert
subset of this terminals that is
embedded inside the graph G so by
embedding expander we mean that expanded
vertices a map to the terminals and
expand their edges they become pass
inside this graph G collecting the
terminals and once you find such a
limiting we just want to roll itself to
the little man PS in the expander and
write the way when we find this real
thing the embedding of this expander
gives us the routing in the graph G so
this high-level idea was for you it was
proposed by jacory common Shefford a few
years back they only usage more general
term of a cross bar which is a graph
through which you can route efficiently
but here are the clothes were that we
use is an expander so we'll just stick
will expand this and we'll forget about
the crossbars so I want if I station
embedding the congestion
the embedding is the maximum load on NH
so this is a Juicery a pass inside of
Chi we don't require a very different
paths but we wonder congestion due to
this pass to be pretty small so the
bottom line here is that we started with
this issue and path problem and it turns
out that it's enough to just find a good
embedding of an expander into your
breath and then you're done so the whole
problem of EDP boils down to being able
to find an expander and embedded in
Geographic spender into our graph the
reason really really needs to we just
call the card matching game that I'm
going to share in the next slide so for
the next slide just forget about the
fact that you are trying to embed an
expander Intergraph I'll just show you
the game itself and then we'll see how
this game helps us to to do this so I
know what is this card matching game
it's a game that's played between two
players they cut player and dimension
player so the gut player wants to build
an expander and the matching player
wants to stop the Cutler from perfect
building the expander so they start on
this graph that only has end vertices no
edges and then the game is performed in
iterations in the first situation the
cut player compute some provision of the
vertices of the graph into two equal
sized subsets and the matching player
returns any matching it once complete
matching over these vertices the edges
of its matching are then added to the
graph second iteration the gut player
computes a new partition of the vertices
matching player returns a new matching
again add it to the graph and so on
until the graph here is an expander so
what kind of car on with Ronnie have
shown is that there is a strategy for
the cut player such that no matter what
the matching player does after log
square n iterations this is going to be
an expander
and here and is again the number of
vertices in this extender so the
matching player you can assume its
adversarial but there is an algorithm
for the cup player to compute these cuts
in every iteration so that after looks
for intuitions we are done so now how is
it useful to embedding an expander into
a graph so let's say that we have this
grad G is well linked for the terminals
and now I want to define an expander
over the same terminals and embed it
into gym so we use the cut player to
find a partition of the services into
two subsets and then what I'm going to
do is I'm going to try to find flow
between vertices on the left and
vertices on the right like this now just
why I wanted to be integral flaw I want
them to be passed now if I tell you I
wanted to connect this vertex to that
one this one to get one on this one to
that one then this is like so in
addition path problem we don't know how
to do it but if I tell me here is a
bunch of vertices on the left and a
bunch of for this is on the right I want
you to connect everyone on the left to
somebody on the right then you can do it
the way you can do it is this is you
compute the maximum to a problem between
the two sides this is like a single
source single sink flow problem and then
you use into Galatea flow because you
don't care who clashed boom it's like a
single source single sink flow problem
so once again this path you they define
a matching between these vertices and
you treat us matching as the answer of
the matching player remember that the
matching player can be adversarial so it
doesn't matter what we get here is good
enough for us we just add it here so in
the second iteration we get a new
partition again we compute this flow
edit here and so on so the cut mating
game and guarantees that after locks for
K traditions we get an expander and
vanity to G it sir so what what what KO
really gives us is afterwards with
iteration to get an expander here but
the way we found this expander gives us
right away the embedding of the sink
things expander into our graph
so they won't leak this is good too so
visuals yes yeah there is a problem with
this solution right yeah what is the
problem inversion right yeah so this is
this is a good thing about the problem
is that we get conditional books for K
because we compute this matching socks
for K times right every time we can
accumulate conditions are in the end
from the condition of Sparky and this is
a really serious problem because it's
kind of inherent in this algorithm the
card matching game in in vail garden for
the cut player the ecology computed in
iteration it really depends on what
happened in previous iterations you
really have to do them one by one you
can't do all these stocks Corky flows in
one shot so this is a problem this is
why we don't have these algorithms for
ED piece how do you begin around this
problem so at a high level the problem
here is that in every iteration we
compute this matchings over an hour over
the same set of edges if it would
somehow separate these edges and an
average duration use a fresh subset of
edges but we still want to be linked
then maybe we could get around this
problem ok so just to be clear all this
is previous work it's just there was a
lot of previous work to to describe ok
I'm this will the idea around you so
what they did was it is Rho G and if
they wanted to split it in two lakhs
quirky sub graphs for every sub graph
take the same set of vertices every age
basically select one of the sub graphs
uniform at random and they want to make
sure that these GI is still the link for
the terminals so you can do that using
techniques of kharghar only if the value
of the minimum cut is angie is lakhs
worth it it's easier largest answer
another large fully log so so this is
the steering
that you can take these edges randomly
each edge will randomly select one of
the sub graphs and still all the cuts
who are roughly present they preserve
this world to the scenario where the min
cut angie is fully logarithmic if it's
not political ethnic then we basically
know how to do that and then finally the
uncle knew of Andrews a basically tried
to do this and to get around this
problem that the main card is not for
the logarithmic so it wasn't even a
little complicated solution and in the
end it gave a poly log log and position
you say some words about how yeah so the
display it very easily just every edge
randomly selects one of the graph one of
the grouse it's going to belong to
that's it this is the algorithm of
kharghar i think you call it a graph
skeletons that you can basically example
the edges of the graph for some
probability and still the cats will be
preserved if the min cut is large enough
ok this is wearing your stuff yes sir so
how do we get a constant condition it's
the first thing ok we start the game
from the same starting point behave the
same gravity the same collection of the
man fears and as before we assume that
the graph is rolling for the terminals
so the first thing that I'm going to do
I'm going to define embedding of
expander in to graph a little bit
differently that will make it a little
easier to work with so let's say that
they want to embed an expander of our
subset of terminals into G so first of
all every verdicts instead of embedding
it as a vertex our murder as a connected
component in G that contains that
terminal so this is this way like this
red fern and so on and this connected
components they don't have to be
discerned as long as every edge belongs
to only constant number of them so this
is one thing the second thing how do you
embed edges so an edge between these two
terminals
it's embedded as a path from the ping
sound artists of this conference on
vortex of that component and again we
want to hear a small condition so every
edge of G may only belong to conference
number of these components and only a
concept number of this red pass so this
you'll call it the constant conditional
inning so now why is this embedding
enough it turns out that if you find
routing on vertex disjoint paths in the
expander then this gives you good
rolling here let me convince you why
this is true so let's say there is an
stp are in that expander and I wrote it
on this red pass and now which one of
these red edges it translates into this
pass so which it is embedded in G here
right but now you simply use the fact
that each one of em is a connected
component right so you can just patch
them up in any way just choose the path
connecting these two end points so
together with its path inside is
connected components it gives me a pass
for nothing as two teeth now if I have a
bunch of pants in X that our vertex
disjoint not digestion but what is this
giant and I do this kind of translation
then i will use each one of these guys
on once because we vertex disjoint and
each one of these guys only ones now
because each edge of g participates in a
constant number of these for the
components and a concept number of this
red path will get a routing response on
condition here so even this kind of
embedding is fine you'll say just easier
you'll see um ok so the only thing ok we
know one further issues valley instead
of education sprouting on the expander
it will not be a big problem because the
expanders that we built and we'll use
this again a card matching game so all
this expanders ready
bree is bounded it's not constant it's
fully logarithmic but that's still okay
so we can handle such expanders ok so
again as before the problem of solving
biblically boils down to the problem of
finding an expander and embedding it
into J only we change the definition of
expansion a little bit to make things
easier for us ok so from now on we'll
try to find its expander and embed it
into G so the tool that I'm going to use
to do it is called a massive good vertex
upsets let me define it so let's say
have the graph G these are my terminals
this is a subset of vertices I want to
tell you when is the subset considered
good for me so this tops it is good if
two things happen up there three things
first of all it cannot contain any
terminals it has to be a welding this
edges and the third thing is that it can
send a lot of flow to the tunnels a lot
sk over foil ok if I find a sound like
that I'm happy it's a good set now what
is a good family of sets its locks qrk
such good sets and they have to be
disjoint ok so we have here locks for
key sets each of them can send k over 50
chi flow to the terminals so if you put
the oldest close together and get lost
working condition and they're all real
exchange unrolling it for the edges
coming
so now the proof has two parts the first
and more technical part is to show that
you can find such a family of good
subsets I will not show it here the
second part is if you have this family
of good subsets then you can embed an
expanded geograph so this i will show
you at a high level oh ok so let's say
we have this family of four exceptions
so i'm going to show you that from here
it's pretty ok how easy that it's
possible to get an embedding of the
expander into your graph so you start
with this vertex upset yeah it's
something about there yeah the graph
itself can take all utilities and even
you mean a star notice is no other notes
acceptance of itself already ok so the
way you do so first of all the way I
didn't say it but you do the top of
steps where you make sure that the graph
is a constant agree graph by replacing
every vertex big weight so you do that
first listen yeah you can only find it
if you graph is constant degree but you
can do it without loss of generality but
even that please I can happen expander
yourself constantly yeah we want to know
then you can now constant degree
expander on the terminals ok then
distribute I don't need to find expand
over so get a good ok so the
pre-processing step first to ensure that
every terminal has degree 1 by adding
more terminals if you need second step
if you have words to the top high degree
then you replace them with a grid from
here you can ok so so we have this looks
rocky and Boo subsets and now what we
are going to do will build a bunch of
trees each one of these trees will
contain one terminal and one edge from
each one of these days
so we want a lot of such trees here or
poly locate trees they don't have to be
disjoint but we want every edge to only
participate in a constant number of such
trees and again each stage three we
wanted to contain and expect a terminal
a distinct terminal and this thing edge
from each one of these debts so the way
we think about this if we look philip ii
this orange terminal you think about
this orange edge there as being the copy
of this terminal for that set this
orange here is the copy of signal for
the second so on so the way we build
them is that all these terminals are
participating the trees in each such
steps each set contains a copy of one of
each search terminal again so usage
terminal hidden age in each one of them
okay so I want to say a few words how we
go from here to here so if we were to
take his verdict subsets and from Jack
each one of them into a super node is
the vertex then the problem of finding
such trees is that the problem
half-pakistani trees and now if you look
at these flows you can turn these flows
into a fractional solution for this
packing of sanitary problem I don't
expect you to see that but indeed agree
this is what it does and we know how to
route this fractional solution to get a
single solution this can be done now
unfortunately the sonorous antibiotics
it's a subset so in general it looks
more like packing groups and trees which
is a much more difficult problem but
because the subsets are were linked for
these edges we kinda can use them to
stimulate the super node to a limited
extent but we can still do it so it's
not straightforward but but you can do
it condition box okay
so long story i got these three is it's
really easy to take an egg to build an
expander and embed it into the graph let
me show you how so first of all we'll
only below its founder / term health and
participate in the trees there are K
over pull okay sighs Tommy also they are
fine now the way we map every vertex of
the expander this was your question I
guess is everybody is mapped to the tree
that is connected with Colonel so the
blue Charlie now is mapped to blue tree
the orange turn onto this orange tree
and so on so the connected components
representing every terminal is the tree
containing the terminal and now to
define the edges we just use the ax cut
matching game again of KRV so they got
player compute the partition of the
vertices of the expander it into two
equal size subsets what we do is we go
to this first good set and this petition
gives us a partition of these edges
right because we have a copy of each
turn out here and now because the cell
is will linked we can connect this yes
you can find some matches just like we
did before and this defines amazing over
needs they connecting these two subsets
we added to the graph and the second
iteration we get a second partition now
we go to the second set again we look at
the pollution induced on these terminals
on these edges here find this matching
and so on so the end the number of say
that we have here is locked score k
exactly the number of rounds in the k RV
game in the cut matching game so after
looks for generations or we build here
is going to be an expander and here are
these meetings of edges will give us a
bending of this expanded into our graph
wisconsin position so there is one
summer point that i did mention is each
one of the set itself our length one for
alpha is one or a poly log k and i said
ok we can roll instead of it was
constant condition
is not sure right you can only bear out
with political condition so the way I
get around this is something called
grouping technique of chicken and
Shepherd well they show is that given
size upset you can efficiently find a
sub set of edges a pretty large subset
about you boost double Lincoln Estill
oligomers become so good that if you
want to look at this edges that you have
selected then you can roll anything
there was condition one sober research
subset instead of taking on the edges
you can run this grouping technique
select a subset of edges which is still
pretty large log of this edges and but
you boost their willingness so this is
how we get the routing inside here with
congestion the Wisconsin condition so to
summarize this algorithm right the first
step is to find a good family apart
except said something that I didn't show
you how to do from there you build these
trees and using these trees you and by
the expander into GM then we just use
one of the standard outworlders for
outing and expanders to find ver
technician routing on that expander and
translate this welding into routing
Angie so now I want to take a few
minutes to talk about some consequences
of this result so let us again look at
this graph G and as you can look at the
sourcing pairs let's say these are the
source in fear as we want to route them
so they all go to will return a rolling
of sample ok fraction of the Pierces
condition 14 and now which pr's really
trout we really don't know we have no
control we just found this algorithm it
returns us you know these are the fierce
i routed well we would like to tell it
these are the fears I want to route and
with like this algorithm through all
these pairs the travel is that if I tell
the algorithm which beer they want to
route this is like I acid to solve the
EDP problem itself I can do it so we
want to meet somewhere in the middle I
want to have a lot of control over which
pairs do get rather than the end
but they can't go all the way there
because then I feel like solving the ETP
problem so here is what we can do so
let's say that we have this Grove g and
the set of terminal such a GSR power
linked what we can do is efficiently
find a partition of the vertices of G
into groups where Reggie group is not so
big that is fully low-key over alpha but
now I'm afraid to define the sourcing
peers in any way I want as long as each
one of these groups only participate in
one pair so i can define the periods in
any way I want like that and then you're
guaranteed that the algorithm will route
them Wisconsin position so this gives me
freedom to tell the algorithm which pier
they want to route but i am constrained
in the way that they can only select one
guy from everett Koop so yes yeah so why
is this useful okay so there are
applications they worked on the world it
is very useful to know that you know you
can tell the algorithm which things
throughout as long as they are this
constraint I'm going to show now the
next application is from here you can
very easily get some kind of a slow
specifier so initially but this is
useful in general for outing problems
okay so um just a few minutes i'm going
to show to say something about flow
specifiers so close for so far they were
introduced by moisture and the later
moitra so here is there we have some
well gee and we have a set of terminals
and let's and appearances so sounds low
problem over these terminals and I don't
even know beforehand which what kind of
flow problems i'm going to want to so
maybe i'm going to want to solve message
flow problems everyday problem thanks
like that okay so the idea was is what
if we can represent this graph G by a
much smaller broth h so the terminals in
age of the same isn't here so every 40
mg belongs to H but the graph H is much
smaller at the same time we are hoping
the page
also preserve all the flows in graph G
may be approximately so the reason to do
it is first to save time if you want to
solve flow problems on a smaller graph
then it will just take less time
especially if we have to solve many many
flow problems on this graph you just
compute the small graph once and then
you save time one thing another thing we
have many algorithms that achieve some
poly log and approximations whatever
approximation that filling them up there
that depends on them here so if instead
we can solve this problem on the smaller
graph maybe we can get also a better
approximation in fact they do you manage
to show some really nice black box and
ways to get better Williams now okay so
more formula what does it mean the view
on page to preserve old flows we say
that any set of demands that is
fractionally routable here can be also
routed in age with no condition and the
other way is if you can roll it in H
with no condition then you can roll it
ng with sanitation q so this is a
quality q sparse player so am so there
are these three previous papers that
showed that you can build quality look
here below get specifier specifiers even
if the specifier is only allowed to have
K vertices just the terminals nobody
else and then there's a recent book of
mine that shows existence of course the
coldest party fires of this size were
seeing the photo capacity instant on the
terminals hey this is I want to talk
about something a little bit different
so what is framework let's do is if we
want to solve some flow problem on G you
can solve a donation go back to G but
what happens if you want to saw some
integral routing problem like the
decision path problem condition
minimization problem so on we can try to
do the same thing right first you
compute the fractional solution the
foreign graph G then given this let's
parse afire you go to h and the same
fractional solution is still good there
so you can get
fractional solution of the same value of
H then I can solve the Raleigh problem
in graph H get a jiggle solution and
after that we'll do you want to do is to
be able to take this integral solution
this this collection of fats connecting
the different pairs and take it back to
graph G now the problem is that we're
this proud tells us is that well given a
fractional solution there you can get
the fractional solution here well given
in single solution there it doesn't tell
us that the sensible solution exists
here and even if it exists it doesn't
let us find it we don't know how to find
it so this motivates the definition of
integral specifiers the basic i'll try
to address this problem I want to make
this long specifiers also work for
integral routing problems so here what
you want to do it is any set of demands
that can be fractionally rounded here
can also be frictionally rather they are
we allow some loss of hue one in the
condition there but this is the same as
saying that we lose the orc you will
lose a key one factor in their total
demand rounded so we don't really humid
conditions mission by that we just lose
something on the quality of their on the
on the amount of flow rounded on the
other hand when we take an integral
solution to our page we want to be able
to go the sensible solution and grouchy
our condition goes up only by some small
factor future so if you take this
building with grouping it's very easy
from there to get this result that you
can get integral specifier the first
perimeter is how much you lose in the
fractional solution going from here to
there is pulling okay the second
parameter which is the final congestion
that you get is only constant factor
loss no one selected we have a party to
them yeah so we didn't really compute it
out it is better it's a totally
straightforward because the group in
theorem it will not work with condition
to it will be little worse maybe three
or four but this will be a little better
again the size of the terminal of the
oldest first fire is the total degree
incidental the terminals so so in a way
thanks will now depend on K and not on
em it's like a black box reduction that
does it okay so the way you use it again
you take this ramji you take optimal
fractional solution and then you look
for the optimal fractional solution
graph age and you are going to the
people of low key function in bed then
you compute some alf approximation in
graph age with some condition see you
turn it into a solution that there are
35 years with the new condition 31 seen
in the original graph so overall you
accumulate on a constant composition and
was fully locating the number of beers
routed okay so i'll end up with the open
problems so one of the fascinating open
problems here is condition minimization
where we are between an upper lower
upper bound rafi log and lower roughly
double again so we are how to tackle
this problem but you can ask some
intermediate questions for instance what
if your graph is well linked can you do
something then or worry if instead of
rolling all peers we only want to ride a
constant fraction of beers so this will
be like the other side of the spectrum
we were looking at very small condition
now we want to roll almost appears so we
still don't know that now EDP problem is
a very very fascinating problem where so
this route and approximation is the best
currently known and there are these
really simple family of graphs coldwell
with a prequel grass it for the grass
and even on DD graphs we don't know how
to get better than wrote an
approximation basically the integer the
gap of food and all also still hold here
so this is like the simplest graph that
we can figure out and it's it's strange
when you have such concrete examples
that you still can't figure out what's
going on
well you can start with terminals on the
border and then maybe you can solve it
also four terminals anywhere this is the
same yeah i think in graph theory they
use this more often sigrid and yeah so
so when we saw the results for partition
14 the power of the log is like just
below 20 but the result to get for
condition 2 is like lock to the 93 I
think okay so it would be really nice to
get some clean the tool problems to be
cleaner algorithm that gives a better
like power plug em and then of course
and then you can also ask if we can get
better integrals for surfers so stop
here thank you really quick question
tricks that you need to do to get from
14 to what parts are tight so what
happens there is that there are a few
steps first you find this a good family
then we build the trees and then you
also get to roll the terminal PR series
is run our steps first of all itself is
more than two condition but then you add
them they just accumulate so one of the
most difficult things is to do all these
three things you are shoved so the
condition don't have unit you just have
to be really really careful and really
technical
welcome back everyone we're going to be
working on undirected graphs today so
let's consider an example here where a
hockey team competition with six teams
obviously D&amp;F and the following is known
and I won't read it out but you can see
that ice played a few and beating them
be also CDP and if so when we graph this
this is a graph that where you get now
the e the D the ABC and if these things
here that we're shouting in right now
they're called teams tasks towns that's
what they could there could be anything
at all but we know them as vertices or
another name for a being knows vertices
I am believe because they're they are
known as adjacent vertices because we
have an edge that goes from A to B ok
now this graph we can represent it by a
table or a matrix where we have one
being used if there's an edge connecting
the two vertices and a zero being used
if there's no edge connecting the two so
for the above this is what we get I'm
not going to go back but there was no
edge connecting a and I said zero there
one for the blue a to be nothing
connecting A to C so zero nothing
connecting A to D and then I don't leave
it was one edge and either if there was
an inch then lead a 1-liter B is zero B
to C is one then we had zero zero and B
to F is 1 now I'll quickly fill them in
zero and we'll go down down the column
so 0 0 1 and 1 and then the next one is
1 0 0 1 and the next one is 0 1 1 0 and
the next one is 1 double 0 1 and E is 1
triple 0 and F is 0 1
zero-zero okay so that's the actual
table now this is we can also do that as
a matrix it's exactly the same except of
course instead of being in a table we
have it in a matrix form so again we're
just going to quickly fill them in okay
and all again I fill these two in and
we'll go down again so zero deeds are
there 1 1 and underneath the C 1 double
O one going across and then straight
down is 0 0 1 1 1 0 0 1 0 double 1 0 1
double O 1 1 triple 0 and 0 1 0 0 and
this is known as the adjacency matrix
now if there's more than one edge
linking to vertices then we call it a
multiple each ok so let's have a look at
one there's one there we've got a
multiple edge
hey I and so you can see that there are
two edges that connect a and C we also
have a loop at being excuse the loop I
sort of couldn't get the right angle
it's best to be a secure okay and they
is sitting all the way by itself Lee
with that nothing that can mix to it
okay you realize that this is our
selective abilities it's example
constructor type 1 matrix corresponding
to put the graph shine which represents
three houses a b and c connected to
three utilities gas water and
electricity so there we have the graph
but this is also called a bipartite
graph it is called a bipartite graph
then reason being is because we have a
tissue
this into two disjoint six a B and C
being the houses mgw and the the the
utilities so you can see that we sort of
draw a line between them and they are
split so all right let's say we're gonna
be doing a matrix here by itself we
won't do a table because the table is
you can tell is the same so straight
across the top of got our house is a B
and C and we also have a utilities gwv
and of course we need to do that along
side and as well because we have to be
able to show whether they connect to
each other or not so we know that house
a does not connect to house a so put a
zero and house a of course does not
connect house B or to the house C so
zero zero zero straight across and then
it does connect to the gas water and
electricity so you put a one there a one
and A one possibly of course does not
connect any of the houses so 0 0 0 and
then 1 1 1 again and the house sees
exactly the same can't connect to the
houses that will connect to the guests
water and electricity then when we're
looking at it from the TV side it
changes so the utilities do connect to
their houses so we've got 1 1 and 1 but
the utilities don't connect to each
other so we've got 0 0 0 and that
belongs to all the utilities as well ok
so we have to make sure that we do that
properly we have to show them all along
the top and along the side because we
have to include every vertex
yeah the degree of a vertex that's the
number of edges that count from that
vertex itself
ok that's the degree so and we should be
putting brackets around degree of I so
deg brackets the I should be there and
that should all be this I even the
billion seen the D and they be okay so
we need to put brackets around all of
them you know the degree of I how many
vertices how many edges are coming out
of very well these four count them
there's one two three four so the degree
of a is four
the ages are coming out of that one
Blee there is one and two don't include
the look twice there's only two out of
City if we count them there's one two
and three there's that's not a loop that
- they're two different edges connecting
ONC so we've gotta count them both a
degree of ds2 and good old sitting out
there all on its line sandwich of course
is zero there's nothing that connects it
all right
the graph below is known as a simple
graph there are no loops and there's no
multiple edges now for this graph the
sum of the degrees is equal to twice the
number of edges and is even okay
the sum of the degrees he's an equal to
twice the number of edges and he's even
so there's the son of god of the degrees
three two two three and two and in the
map we get twelve okay
twelve so it's even we've worked that
out and it's twice the number of edges
let's count the edges one two three four
five six twice two times six is twelve
okay
so for a simple graph that actually
works out okay so be aware of that
sometimes it's easier to quickly work
that out if required
all right a path a path is a series of
vertices connected by edges a graph is
said to be connected if there is a path
between each pair of vertices it's got
to be a path between each pair of
vertices so let's have a look at an
example there we go a circuit is a path
which starts and finishes at the same
vertex I could start so that's going to
finish it I it's not to be it's going to
finish your feet and you can't travel
along more travel along the edges more
than once because you can only travel
along the edge at once so for the above
example
here's an example of a circuit and I'm
starting at I I believe - C - D - B - f
and back to a I've only travelled along
each vertex once or go E F D and back to
e okay but which shouldn't call break
all the vertices a subgraph that's only
part of a graph so we don't need to have
all the original graph listed okay
that's only part of it - 23i is the what
you're doing
should citizens in bathing power pure
technically, the press plus you have to
only the day of the victim as relevant
operations of its seemingly childhood
youth will one day blow it
used for pink lake city is the city
we now have e mail marketing technology
the top of the dax
the trading contacts are present
rihannas only and is no go so wants to be like
but halves the day in svs Thursday
to view or eternal love push
marketing
she hates the enev than a cent offering
necessary love buddy and Thursday
some sequences market the binger
Thursday is CSD only bad news or
good people Thursday
as it has flowing double village
Thank you
welcome back everyone we're going to be
working on undirected graphs today so
let's consider an example here where a
hockey team competition with six teams
ABCD an F and the following is known and
I won't read it out but you can see that
ice played a few and bleeding them be
also CDP and if so when we graph this
this is a graph that where you get now
the eat the D the ABC and if these
things here that I'm shouting in right
now they're called teams tasks towns
that's what they could there could be
anything at all but we know them as
vertices or another name for a min nodes
vertices I am bleep because they're
layin owners adjacent vertices because
we have an edge that goes from A to B ok
now this graph we can represent it by a
table or a matrix where we have one then
used if there's an edge connecting the
two vertices and the zero being used if
there is no edge connecting the two so I
fully above this is what will you get
I'm looking to go back but there was no
edge connecting alien high side 0 there
one for the be a to be nothing
connecting A to C side 0 nothing
connecting A to D and then either their
bills one edge and ADA if there was in
each then be a 1 b 2 b is 0 bc is one
then we had 0 0 and beta F is one now
quickly fill them in 0 and we'll go down
down the column so 0 0 1 and 1 and then
the next one is 1001 and the next one is
0 1 1 0 and the next one is one double 0
1 and E is 1 triple 0 and f is 0 1
00 okay so that's the actual table now
this is we can also do that as a matrix
it's exactly the same except of course
instead of being in a table we have it
in a matrix form so again we're just
going to quickly fill them in okay and
all again I feel these two in and we'll
go down again so zero they'd 0 there 11
and underneath the c1 double 0 1 going
across and then straight down is 0 0 1 1
1 0 0 1 0 double 101 double 0 1 1 triple
0 and 0 1 0 0 and this is known as the
adjacency matrix now if there's more
than one each linking two vertices then
we call it a multiple each okay so let's
have a look at one there's one there
we've got a multiple edge I and see you
can see that there are two edges that
connect a and C we also have a loop at
being excuse the lupus or couldn't get
the right angle it's supposed to be a
circular ok and they're sitting all the
way by itself Lee with that nothing that
connects to it ok well and will realize
that later on that this is an isolated
there's no I just write that one down
this is called also like to do ok so
isolated abilities now it's such an
example to school cuz subscribe to type
1 matrix corresponding to put the graph
shown which represents three houses a B
and C connected to three utilities gas
water and electricity so there we have
the graph but this is also called a
bipartite graph it is called a bipartite
graph then reason being is because we
have some petitioned this into
to destroy sex AB&amp;C being the houses mgw
and the the the utilities so you can see
that we can sort of draw a line between
them and they are split so all right so
we're going to be doing a matrix yeah by
itself we went into a table because the
tables you can tell is the same so
straight across the top we've got out
houses AB&amp;C and we also have a utilities
gwe and of course we need to do that
alongside as well because we have to be
able to show whether they connect to
each other or not so we know that house
a does not connect to house a so put a
zero and how safe course does not
connect house be or to house see so 000
straight across and then it does connect
to the gas water and electricity so you
put a one there a one and A one possibly
of course does not connect to any of the
houses and 0 0 0 and then 1 1 1 again
and how sees exactly the same can't
connect to the houses that will connect
to the guests water and electricity then
when we're looking at it from the tility
side it changes so the utilities do
connect to their houses so we've got 11
and one but the utilities don't connect
to each other I've got zero zero zero
and that belongs to all the utilities as
well ok so we have to make sure that we
do that properly we have to show them
all along the top and on the side
because we have to include every vertex
with this example we're looking at the
degree of a vertex which is the number
of edges that come from that vertex so
having a look now here down here we've
got the degree of a degree a bit but we
need brackets around the a the B the sea
and so on so make sure that we put the
brackets around it if it's not no
brackets then it is incorrect with the
degree of a we just count how many edges
there are that's coming off it so we've
got an edge there another one here
another one there and another one that
makes four so the degree of a is 44 look
at BB has a loop-the-loop counts as two
and then we also
has another edge over here so the degree
of B is three looking at see we've got
of course one two three here so that's
the degree of cs3 the degree of D we've
got two lines coming out of d so we put
two and the degree of e that sitting by
itself there's nothing there at all so
we put 80 all right the graph below is
known as a simple graph there are no
loops and there's no multiple edges now
for this graph the sum of the degrees is
equal to twice the number of edges and
is even ok the son of the degrees is
equal to twice a number of edges and
he's even so there's the summer go to
the degrees 3 2 2 3 and 2 and in the
muck we get 12 okay 12 so is even we've
worked that out and it's twice the
number of edges let's count the edges
123456 twice two times six is 12 ok so
for a simple graph that actually works
out ok so be aware of that sometimes
it's easier to quickly work that out if
required alright a path a path is a
series of vertices connected by inches a
graph is set to be connected if there is
a path between each pair on versus ok so
it's got to be a path between each pair
of vertices so let's have a look at an
example there we go a circuit is a path
which starts and finishes at the same
vertex so if it starts oh it's going to
finish it i start to be it's going to
finish it be you can't travel along more
travel along the edges more than once
because you can only travel along the
edge of once so for the above example
he's an example of a circuit and i'm
starting at i I B to C to D
to be 2f and back to AI vai only
traveled along each vertex once or go e
FD and back to e okay but which should
incorporate all the vertices a sub graph
that's only part of it rough so we don't
need to have all the original graph
listed okay that's only part of it 223 I
easy and what you're doing
Greenberg is where do that percent up
here would know the backbone to the
course drop the books in a bigger where
this is ago if you would run everywhere
dot result in a consistent pattern and
quality at the edges so I don't know any
different and then you because then
we're not even your row where they stood
I don't know and it is mister in the
reference so I be in our regard it will
converge to this different
axel Smith another highly effective
follow me
Katy's life 20:41 effort Fulton a fool
platform are they are are you any you
can write up the order diagnostic unit
goodbye though but to do that I would
for the video port forward to the full
Senate when it was battered order they
differ accessible at least video press
movie
he hungered for both are infinite
we got for the teachers put too much so
a universe offer if you read it oh yeah
you drive in any reputation
no little ROK haven't you learned
anything but what they believe to be
true to move you with other performances
one in one two three four supported the
dear
well a 1x2 we go
where you will be given one more
[Music]
are we not relevant
[Music]
you want to draw a lot better protected
that is who is going to fool who are you
so you unique
[Music]
help
if you walk on water twice to the upward
expiry time again where excuse me your
excellency
so the drop
so you let it go for existence Google
homework no but I tried other things too
so I was very accustomed to this epic
web
ah
everybody up like everything dried up
Julie
good luck up in the editor
so every mother my relative
I did not enjoy relevant community here
in India in any NGO offices are
disobedient can you heat up never like
this are you should beat it by an
amusement this morning are there not
much fun are these marbles right up
dealin sincerity you attracted planning
planning trigger and of participation
should be so good is not wonderful
driver you deal with an awkward I'm a
community a little Omaha thought he
should be it was including her should be
here is no haha everyone's well so the
government please so you are
although
here in the heat the oddest unit because
of currently - so big are so human and
mother Valentina
Avila we're here today to encourage ha
ha
our principal
yes fellas gotta get in here
turn over to this one so it is not going
to dry up degrees what you can at
maximum again de th from one in poverty
God - Little Rock created plane with
that ability by linear it is massively
she is a simple graph itself in growth
does not have loose and palette similar
to the Fantasy Bra similar smokehouse
circles and others so it is not all to
God awkward to cancel so here we are
hypothesis so you can take attack mode
diggity is not only up
we never we don't have a 34 Ford another
people I swear
as this one table mat will never forget
eager to is almost empty
the default word finding maximum not
appear when I cover with a null value
another disappear here period forward
drop from economic differently forces on
the three papers
that's enough I hear good luck and in
the gossamer
a puzzle
[Music]
absolutely
on twitter october MGMT to it all
finding maximum elaborate they never
anywhere near our food images by another
to the fun and consumer to girl
it all feels the lack of an attacker
what again ad will appear another
parable basic digital 21 iron it a dark
forest so the added a complicated one
available numerous enact battle where
the nominee Institute
so maximum repair
I like to run by the
to be possible it is starting whatever
it that black number all the aliens are
abomination bond exceed more than tool
into a commodity
all these should not exceed more than
willing to acknowledge and welcome what
it is already
what they often it is all drydock it is
one let it flourish it activated the
electronic one PDF
Alexis survey which one to the provision
under the graph forwarded sent a rocket
forward anyone will you
I want the American burger
so this autograph and this is a this one
the other experiment on 101 doesn t want
to go is fucking break up together
if this was at the end to drive up that
PLO what restriction
get back up piracy put it in our often
Black Voices at our cover
you're not loved Delilah I gotta get
back
[Music]
maybe people on foot where's the I you
know
before it was universal
we are to get under another five four
three two one is that little and
bragging I hope for an open forum for
democracy people among those for one
Malaysian Aeronautics and this one / -
type it all over then there'll be no
versus video footlocker
[Music]
have a friend the difference is 4 3 2 1
and so are these
[Music]
the initial report physical anonymous or
someone who is under a pivotal for
taking one record 42 wellif I registered
by a possibility that there is irises
are my regret
one way is be for a week and order so
there is no if we open up of the record
of any alcohol remember what it is quite
good but Imahara
but for my tequila operative I got every
element when I hired and then we will
also do it so you want to go ahead
you walked right to whether from a tap
into versus event you can second
Institute
this is already a branded protest
towards it from a different words in X
with Y and saturated animal fat ability
to battle and battle wherever you are
you can write and after as any type a
transpose a inverse to capital factory
go back
this is Apollo finding maculopathy
leader
so naughty number of gas one will be a
little mad number is a God parable is a
pivoted if given an error e return home
her that appearances from the syllabus
all nations
knocking our to both in ever see our God
our God
alert
News 4 no
so that example to board any camera
somewhere to given drug is emerald is
recovered so - por favore
the agent not part of the team here
congenial the Heather
[Music]
Peter Thomas - whirring mmm where you
can see her happy to do this for
Discipline you will find equipment so
forward that has a hardness rating was
some specification graph for what
right apostle
Oh Cynthia
so we write the complete run and got a
only 100 of them talking rich eat what
is his daddy country
Oliver but come across the clock in it
he was it rejected the error come to
order
embedded of was this we believe is one
other people there will be no edge
between what's up this what does the
difference of it we were a little and
there will be no edge between was such
same so we will not diversity with a BP
we do still here is we know I haven't
gave me at least and there will be more
that you give room for us by water
divide your recipe to soft subjects and
this would be no edge between what
substances and the Hydra something that
word on each what is seen that one
should be applicant with every other
objective of it these whatever it was it
was too lightly axis of the ability of
it a diameter D please atmosphere
antipsychotic dear each one s in the
pebble to the garden whether he what is
English without an algorithm is Linda is
for a company better so that
because it will just here at the one
contributor to the left Kayla
I am pretty much number workers at one
and even come up with a specific you can
please
singleton as requested so we can to
address give maximum colleges in the
country by 500 and we do the whole
finding and blockages company where drug
and there even are something on words to
forgive you boys filling it with it so
it Wendy and my native place
okay we will be adding something
for my question one more time people
good luck
in the other area this was on the
correct has been directing students in
what are we do there's more
this is one block over
since about
progress here on the lawn you can give
Michael and I'll be there
so what if two is more accurate area
with marketers so they got lost where
Africa in desire becomes Patanjali
Jeremy Thomas Gibson Tommy can you see
how adorable
but on behalf
but remember it is two homes across
determine maximum of did it involve in
on a very common temperature
Thank You Derrick Favors
convenient people in authority eight
nine one my friend who sinned with image
our County where area under a curve in
the river so much mobile is permissible
only in common
all right standing there before
so maximum our distant home program the
and remove our neo-realist preferable
that unless it's not over Europe and
very poor you have fully extend winters
in if the supernal come up with the
hardest part will be our considerable
public eight hosted happy
can he gave a teaspoon three months full
around help for fish market
Narayana what
against opposing anemia in time but
Latin America North America should enter
the fence definite death currently
implemented it is about our smart will
be indifferent the center that the
people might not be tolerated
[Music]
I go you know what is the very nautical
blah blah Phil did not eleven
individuals is also a technology and the
doc I'm upgradeable addresses for all
opposition ticket a participative and it
is consistent and if you have as I just
sent it till all we have a government
initiative initially it is relative if
you have readily federal health care
devotion house
the other one was the bottom and still
that you bought the Sun entrance one one
[Music]
more horrible
that's our ambition let active can you
hear this D what happens as it is
useless do you give her calendar and for
people to be half as an example today
Lincoln Wow
what was happening not to ducks with my
life
one two three four this month we see
you have to go to slack compass if
elected
let you make a what I mean given
entirely taken one day fucking angular a
certain policy relax
suddenly similar who is making little
indigo I want to speak at Nike indeed
until another
you started from one
these and put these Network
so we select this network isn't it for
operation and 108 system such a 24 and
operations of the peaceful so how about
Christian it is penguin it accompanied
by trouble for hippocampal - in the
computer right level capable another
widget is DC so it's a remember area
that we rely on the way foldout again 1
2 3 4 5 7 8 9 not reducing that will it
work
and on the other we got one worker get
coordinated as well good for our ticket
eliminated not let idle little
what
all over all your muscles
so okay popping a separate medical
reporter do I need any one thing in
order to be a disease in order to deport
who you are using any one sec this is so
risky
Oh buddy come into thanks Tony
ultimate 26 or 30 of the government for
another rock to rock he wanted with her
effectiveness for one that is network
there is an example
heart heart rate in tip one part is a
2010 election 57 what if you
[Music]
one two three four
[Music]
my place is missile hot
recently
this is a race that uses water I need to
start walking
within the defendant
this way you get one okay
[Music]
perfect
so very simply 2.11
what
we're sucking what is on camera why do
people watch
[Music]
we can see
inside the workshop
one
so one b44 to be working
for me
[Music]
so there's a team that won the SNMP and
got lost little bit what there's our
offer
so this would I needed and the relative
to work with any and money and not
therapy are wanting and we sit relevant
any economical param up set without one
ankle now but he said never again okay
and Armenia or giving of that one subbu
our double by a negative atop our kids I
do
and this is about 2000 and my general
attitude to enter my wealth with God one
and the water and water they were ending
here a BB or I wanted literally like
take that individual you literally order
and indeed the information filters one
work 21 days know what I created one so
Dima and history on Iowa given desire of
the individual tomorrow whether he will
devote a human delightful to take on
this planet as from from gate previous
period again
his variances for walking gait document
just have a little hole or the lesson
operation a physical for the duck this
is the words about I'm up I didn't fight
back mommy job from a DA
a classical determine water for tea
after our second detector also a
incompetently
giggles ever haha see very much close
enough not only getting that same one
cool people
- honey bunch of people for a bit
an American individual because it for
there's no one for DC 1 DC for Piratas
did he - I told you
okay see the mini series will repeat
that there is no movie
[Music]
this is my Volvo flat thin rotten
whatever you pay in the middle so with
his mother very in it very hard
i beautiful be he that is difficult one
to England in India he is not able to do
this one so anyway there she never stood
up not only towards the river
well is that we went experiment universe
are people are like this so they want
visual range NP is idols rapport is the
excess ten-foot putt in Quadra a local
temple so what difference here but the
name for this is
oh she holla back on the poverty level
Israel done with it over this larger
area advisor as Marie de Tocqueville a
simple non and Monica Kelly Drott
people like monitor North America the
drug was a little short on time you are
so remarkable what the quad and rock up
as the dr. Hager this random
bizarre
to our party so the pyramid to the my
most poor time they look at for example
the poor defender an Oracle panic
it is all committed it is a powerful
version cause that's one beautify your
fuckin bucket even what that goal is
super hot the call order 11:55 it is
muggy and look at that talk all this
example famous so he see a peak in what
you contributed in just a lot in this
class inserting one piece is not got a
10-1 this is bright commas for getting
whether a graph rehearsal father he
branded a hero who pursued our degree
then a dot money to the poor
this Jenga is started you can graph have
zero of students to versus tough economy
there's a tropical tenure zero are
towards this story is zero are to work
this is our degree as a touch your butt
so badness
zero-zero oculus story as the others p v
universe often and the limited support
for the river is the Gujrat starter and
can generate and innovative and one DVD
cannot desert near the north to pusuk on
beep beep beep
yes easy with give up too dangerous but
then this beautiful
Parappa Hawaii anemometer in fantasy
land ages 60 government and is 0-2 was
very generous
it is Canada he's up against who was
going what is real is so iconic
- were so sorry so internet universe yes
if you rockin it nobody to sorry that
you missed your session you should
reflect and no one says sorry and set up
this happen
[Music]
di don't worry my god condition
and one is organic unified command unit
plus memoral Audrey's to be
people are 11 societies created run why
are you sharpening weapon sorry you are
not his girl
I'm on top Alexis party liquor Nia hold
1111 everyone else just all these these
muscles palapa and gay according to
Gideon copy global English from opera
Sofia farmer Sultana of chaos uff Matt
what you didn't move on us being normal
this article so what are you gonna do a
result a refuge equal diameter
in the north are careful
but the connectivity on blankness that
what advice do
[Music]
maybe our part
they were for particular things he did
not Espino was decided that are retired
policemen the normalizer
divided so big and little
so I am but if if any even is anything
change much others
if a bigger cage without delivery even a
given demon in the even even even even
while it's not hot here if it is hot
living here there is no relative I mean
give all on the job is an inner circle
period between what and four hours of my
energy Kano at the county level drop in
the West the book el ataque water either
there is
I don't get along what comment on
eternity since we left
forgive the area over here there is no
yes and a word even when another for
hiding here
other clips
- roll - Jennifer separated interior
mama deliver this ooga in living miracle
you can read operator the miracle but it
is the one sound
[Music]
you
well what is it Rajesh be the office
you're doing has good
so he's got their full review here is my
country
Oh
Oh Reverend here
ever
[Music]
[Music]
[Applause]
[Music]
[Music]
Falcon marimba decent human or only
people I look very Mexican
but our model feels great mm
[Music]
[Applause]
our location to the company because of
this baby up
[Music]
our goalie
[Music]
so I'm John Connor and this is a very
long title talk about how to solve max
flow and some of its generalizations in
almost linear time and so the top coming
up today it's going to be about joint
work with three well people if you don't
know them you will soon they're all
exceptional so with Lorenzo rakia who's
a postdoc at MIT and the intently and
Erin's headford who are grad students at
MIT and they're all great i should add
that and stress that ok so today the
over people going to do is I'm going to
focus mainly on max flow but and about a
higher level I'm to talk about a new
general approach for a bunch of the sort
of basic kind of fundamental problems in
algorithmic graph theory and you know in
general i guess this works for ones i'll
talk about will be max low me a nasty
cut multi commodity and maximum
concurrent flow and i'll define these
shortleaf you don't remember but more
broadly i'm going to give an approach
that lets you break a bunch of very long
open running time barriers for solving
these problems approximately but kind of
I guess a more generally I think there's
a nice methodology that's emerging and
I'm trying to give a general sense of
what this methodology is and today I'm
really going to focus on max flow and
then I'll very briefly just talk about
how to generalize it to the other
problems so for the rest of the talk
when I say graph I mean undirected graph
and I just want to say that advance and
you know some of the things that I'm
going to brush under the rug are just
for convenience this is not one of those
things right this one really what we're
doing I don't know how to make it work
for directed graphs so this is an actual
problem that I don't know how to solve
not just a thing that's going to save me
notation about the before I forget I'm
going to possibly on these sort of
background stuff kind of accelerate
until somebody stops me so stop me if
I'm accelerating too much and yeah ok ok
good oh that was a good example uh-huh
so okay so I guess for the very brief
background and I'm really not going to
do justice to the background on this
because it's kind of a very well studied
problem briefly I that's one of those
sort of basic problems in optimization
it's one of the ones that motivated a
lot of the historical dances in it and
more importantly it seems to capture
certain core issues in
rhythmic graph theory so it seems that
if you look at a lot of other
algorithmic questions speeding up max
flow leads to better algorithms for a
whole bunch of other things and the
running time barriers that it presents
seems sort of in order to improve them
you have to actually figure something
out and they seem to capture a certain
intrinsic challenges they've also shown
up a lot both in the theory in the
practice and AP of algorithms and they
kind of motivated a lot of the
development of combinatorial
optimization and they are subroutine all
over the place so I'm going to keep that
as my my background just because I think
people here would probably be a little
bit bored if I said too much more but
I'm happy to give the longer description
okay so let me tell you what the problem
is and today I'm going to talk about max
flow and not really about multi
commodity flow just to keep things
simple but actually the framework them
to describe will with almost no
modification go through for the general
case so okay the setup is I'll all the
graph G which I'll just two kicks
imitation I'll call that ve it's going
to have n vertices and edges throughout
the talk so whenever I say and I mean
number of vertices and Emmas number of
edges so here is a graph every edge is
assigned to capacity so it's a
non-negative number in our e which is RM
and the problem will look at I'm going
to again for another simplification you
could ask for more general demands I'm
going to talk about Max st flow which is
a special case again these are actually
are not actual restrictions these are
just conveniences for the talk so today
we'll talk about a max st flow so i'll
give you a source s and a sink t every
edge as a capacity and the goal is going
to be defined what's called the maximum
value st flow so a flow is an assignment
of numbers to edges and it has to meet a
couple constraints one is that it has to
have flow conservation so think of it as
pushing stuff along the edges of the
graph flowy n equals flow out for all
the vertices so stop flow doesn't appear
disappear every edge cannot exceed its
capacity and because we're undirected
this is an absolute value so an edge can
carry some amount of flow forward or
backward and the capacity you is an
upper bound on how much flow you can
send along an edge and the value of the
flow is the amount of stuff you
send along the network so because of
flow conservation the amount how de
casas the amount into T and that is the
value of the flow is the amount you send
from s to T so our goal is going to be
to send as much flow as possible from s
to T subject to flow conservation and
the capacity constraints and we're going
to look at the approximate problem so
we're going to look for the epsilon
approximate very into this so our goal
is going to be to find an ST flow of
that's at least 1 minus epsilon times
the optimal flow so that's the problem
we're going to study it has a long
history that again I'm going to do
nothing resembling justice to but it's
been studied a lot and it has a fair
amount of previous work that I really
not going to review and the instead of
gonna kind of skipped with the most
recent data point on it and I'm going to
talk about undirected graphs and one my
stepson approximate flow and for this
the best previous running time was in a
paper that I wrote with Paul Cristiano
Alexander Madrid and Spielman and Sean
ma Chang and then later there was a
paper by Lee round-trip estava that
worked in the unit capacity case gave a
sort of similar result by a very clean
kind of beautiful different way of doing
it that didn't seem to generalize to the
non to the capacitated case but was
intrinsically different and maybe a
little more related to what I'm talking
about today and the best previous run
tom was MN to the one-third times poly
one over epsilon and I wrote a note
tilde whenever I read an ode tilde it
means I'm just dropping long terms I'm
gonna do that pretty aggressively today
just to keep rotation simple and for
maximum concurrent flow paper that I
wrote was Gary Miller in cha-am and
Richard Peng gave something sort of
similar so if you kind of pretend I'm
equals n which is really the tricky case
here like over over the decades there
was a lot of improvement from if you
were to look at what change from 1970
something till now there was a lot of
improvement in what you could do in
terms of dense versus sparse graphs or
large capacities versus no capacities
versus capacity one but kind of the
thing that really seemed to be the core
obstruction was just the dependence on
em and on in the sparse case on em which
was a bad n so if i gave you a sparse
graph for a long time that was m it was
something
if you said em was like and it was
something to the three halves and
previous and then these kind of were the
first ones in a while that made it four
thirds so for three halves there was the
right so it was actually the oddly
enough the best thing known to do in the
exact or approximate case and for the
exact case now there's other stuff you
can do that based on some of this and
some other ideas that pushes it a little
past it but I'm thinking to the
approximate that was sort of but I was
excusing myself for with the big list
and yeah for it turns out the fact that
we can't do directed graphs and the fact
that we can't make this epsilon
completely go away or actually strongly
related questions ok so the best for
smallish k for maximum multi-commodity
flow was em to the four thirds also um
and our main result today is going to be
to make the four thirds into a 1 plus
little of one so for both max flow and
multi commodity flow we're going to make
our main result be saying that I'm gonna
say is almost linear in em and almost
linear is going to mean something so
more precisely this is what I'll give so
it's going to give a max flow result
that's em to the one plus something
little o of 1 and then x poly epsilon
where the epsilon isn't that bad here
and for multi commodity flow it's almost
linear in M it still got that kind of
annoying k squared as opposed to k which
may be keeps me from setting
legitimately almost linear if K is large
but for small K it is and that's
probably broadly speaking the epsilon is
going to take something smart to fix the
K squared probably just takes a little
more work okay so those are the main
results i'll talk about and i should
mention offhandedly that it actually
gives as a subroutine you just kind of
plug it into other people's papers and
you get faster algorithms for some other
things so you get a faster algorithm for
you know sparse cotton balance cuts by
using the Aurora now that's irani
relaxation solved with similar to
methods and for example okay so that is
my background and now I want to actually
kind of talk a bit about the content Oh
before I forget I should mention that
this result was concurrent with another
work which was a beautiful paper it was
by Jonah Sherman who's
now finishing up his PhD at berkeley and
he got a similar running time for the
single commodity case and it used kind
of different but similar techniques it's
actually if you look at it carefully
it's in some strong sense the dual of
our algorithm and you actually could
read arrive it as a dual to our
algorithm so we work with flows and he
works with cuts and when you get to the
end of the talk i can say this little
bit more carefully but roughly we are
going to iteratively take a flow and try
to make it send more flow and always
have an actual flow working towards
optimality he's going to kind of go the
other way which is he's going to start
with a dual object and work towards
feasibility so he's going to start with
something it sends a lot of flow but
isn't a feasible flow it doesn't obey
conservation and then work towards
getting rid of that okay so that's
awesome and what i want to do to
describe the actual algorithm is
actually talk about some background
tools that motivated the algorithm the
algorithm itself was actually pretty
strongly motivated sent by the things
that didn't we couldn't quite do with
previous papers and so i'm going to give
a kind of quick background of not it's
not meant to be a background of actual
things on max flow its tools that we're
using in our paper so i'm kind of you
know for the first couple decades of it
and for the fastest maxvill algorithms
really tended to be deterministic and
combinatorial in this sort of like add
an edge at a path push flow along dispo
flow along that kind of things to
grossly over simplify and there's
culminated in the best exact algorithm
until recently for and actually for some
parameter range is still the best exact
algorithm which was the goldberg rao and
i'm going to encourage you to sort of
ignore many of the terms and that and
just think of that as three-halves em to
the three-halves sort simplicity anyway
recently there's been this nice
confluence of kind of techniques based
on randomization numerical linear
algebra iterative methods continuous
optimization where the two fields really
have been very strongly feeding into
each other and what i think is really a
growth feel like I think there's still a
lot to do here where there's been this
very strong confluence of kind of
numerical methods and numerical stuff
where instead of using discrete objects
you're going to model these as
continuous problems
you're going to solve the continuous
optimization problems using
combinatorial techniques then use the
ability to solve them to feed back into
graph algorithms and sis very nice kind
of developing theory and again I won't
really try to describe the actual
literature this is meant more just to be
the things that motivate the actual
algorithm today ok and again I'm going
to talk about single commodity pretty
much entirely for the till right at the
end ok so the first tool that we're
going to build on and we're really
motivated as much by the tools as by
their limit as much for the limitations
or the tools as their tools and so I'm
going to do is kind of tell you what the
tools were tell you what they didn't do
and that's going to kind of motivate
what we had to do in our paper so the
first tool were going to build on was
farsa fication which I guess I would
trace back to beggar kharghar and the
idea here and these were all things that
were used in the general context of
things like flows not necessarily
Maxwell this one was them okay so sparse
ification the idea is just I give you a
dense graph M is much bigger than n you
don't want that and so you're going to
find a much sparser graph G prime that's
going to approximate all the cuts in the
original graph up to some multiplicative
factor of 1 plus or minus epsilon and
the at the time I think fairly
surprising assertion was that you can
very efficiently fine and even
surprising existentially you can find a
graph with a average degree poly log n
so n log n over epsilon squared edges
and that actually will get every cut in
the graph right up to a multiplicative 1
plus or minus epsilon and on top of that
they came with a very nice algorithm
that lets you find it very quickly so
you can find it nearly linear time so
the way it worked is it was based on a
very carefully set up sampling scheme
but what's more important for the
structure here is that it was a sampling
scheme the idea was is that using the
fair amount of graph theoretic structure
you carefully compute a probability for
every edge you then are going to
independently sample every edge in the
graph with that probability and the good
news and then what you get is a much
smarter graph so you should think of it
as just sampling you know your
subsampling the edges of the graph and
you show that if you do it right then
every cut is going to
the right expectation and will be
concentrated enough that something that
happens now the good news on this was
that you know max-flow min-cut theorem
if i get all the cuts in the graph right
you get all the flows right so you get
so if I were to take this much sparser
graph and solve max flow on it um I will
get the flood the value of that new flow
will be within a one plus or minus
epsilon of the value of the flow on the
original graph so if I were to say to
you you know you want to approximate the
value of the max flow on a graph this
says that more or less if you're willing
to tolerate someone plus or minus
epsilon then you can basically pretend
all graphs are sparse and turn your ends
and pans and now this is great both for
this problem in for many problems now
the thing that kind of made it tricky
for us to use in arc setting was and it
was a limitation that will see why we
need it later why we worry about it
later but morally you get the cuts right
and you get a flow on the subsample
graph you don't get a flow on the
original graph so kind of if you think
about it what you're basically doing is
every edge of this subsample graph which
is supposed to represent a bunch of
edges in the original graph and you're
relying on sampling right like the idea
here is if you pick stuff random leaving
things concentrate but if I then gave
you a flow on the much sparser graph
there's no obvious way to take a flow on
this randomly subsampled thing and
understand bullet and get a flow back on
the original yeah so it's a weighted sub
graph so it's a sub graph with
capacities that are much larger right
because like I should have said a few
subsample if you have M edges that will
say they're all unit capacities you know
then you have to have a total capacity
that's roughly you have to go to support
the original flow right so I mean the
weights the weight should yes or the
yeah I mean you should expect that the
so the expected value of every edge is
its original the expected value of every
cut is the original value so that means
if you sample an edge with probability P
it comes in with weight 1 over P and so
the weights could actually be pretty big
right the weights if they were against
graph the weights could be linear
because your your subsampling
you're you're you're making a weighted
sparse crash right and you have to have
the average every cut be the same size
so if you're taking out a large fraction
of edges then the average way it goes
way up and that means that actually
routing on so if you r out on the sub
graph you are going to not give you'll
give a flow but it will be on the sub
graph that's supposed to represent them
at bigger graph and you'll grossly
exceed the actual original capacities um
I mean it depends on what you mean by
typical plausibly in so it's i mean if i
were to make a graph that's like you
know for example if i were to take a
complete graph a complete graph and an
edge you know then this edge is going to
be really important and this edge won't
be and so you'll get an N ah I guess
depending on what how precisely defined
typical but you know roughly the point
is that you shouldn't think of these
subsampled edges as actually being in a
sub graph because they're scaled way up
and so the right like and so does that
make sense are there any questions on
that yeah
yeah right now the problem is just that
if i gave you a flow on this subsample
graph i just have no I've no it actually
even slowly without just solving the
problem over again if i gave you a flow
on a graph that's got big capacities on
a small subset of the edges there's no
known way to push things back into the
original graph and this actually led to
algorithmic gaps like for a very long
time actually really up until these
papers there were substantial gaps
between the running time for the best
approximate flow algorithms and the best
approximate cut algorithms basically
your ability to term two ends in two
ends there was a legitimate asymptotic
gap between how many of your ends you
could turn into end because of this so
that sorry right so the point is that
you could get the value by solving the
cut problem to actually get a flow there
was not there was a slower running time
to get the best flow like you know if
you look at banks or kharghar maybe a
paper after it by the same authors or
some of the same authors you know
venture kharghar would let you say that
it would be M plus n log n plus whatever
long takes this held n log n sighs you
know m equals n log n type problems and
so you get like an M plus n to the
three-halves kind of thing and then it
would become like an M rude and instead
an angry one of the two so there's like
an actual asymptotic gap in your ability
to turn to get to spar safai is that so
again you can find the size of the cut
by duality but not the actual flow
because there's just no way to take this
flow here and write it back in the
original graph that make sense to people
is with me okay good so that was my
first tool and the limitation we're
gonna have to deal with we're really
gonna have to deal with this one because
we're going to want to find an actual
flow okay so number two is the other
kind of thing we're going to build on is
iterative methods and i'll talk about
iterative methods for flow problems so
if you look at both of the M to M times
n to the one-third algorithms for
approximately X load that preceded this
they all used electrical flows and the
fact that you could compute them very
quickly so electrical flow is basically
say take your graph pretend to
edges or resistors somehow intelligently
play with the size of the resistances
and route current through the graph see
what electrical current would do and
then do something iterative to make that
into an actual max-flow problem solving
the wrong problem it's sound like
electrical flow not max flow so do
something iterative to fix it and they
were a little bit different in how they
did their iterative schemes but broadly
they both had that general huddle and
the fact they leveraged was that you can
compute electrical current flows very
quickly using laplacian solvers so
graphs you can associate to a matrix to
a graph and make sure it's called
applause ian solving a linear system in
the laplacian gives you at what lets you
answer the question of what electrical
current does in a graph and so it and it
turns out you can solve graphic las
Ian's due to some beautiful recent work
you can solve it in almost linear time
there was a new time so that's which is
surprising like if you think about what
you can get in m log n typed on em
pollywog in time you know you can sort
stuff for I don't know do breadth-first
search or you know compute arbitrary
linear system solutions with arbitrary
coefficients an arbitrary right hand
sides using a graph based on the matrix
so it's a very powerful tool to probe
the graph live and people made very good
use of this new powerful tool now
electrical flow doesn't equal max flow
and thus you couldn't just solve it once
but what you do is you kind of
iteratively play with the resistances in
the algorithm that I was on and the
demands and the end the other one to get
the max to get an actual max flow so
you'll take edges that are flowing too
much and push the resistance down up or
something and and I guess abroad thing
take away from it was naively there was
a root in the actual naive analysis was
rude n 4 but rude n iterations for both
of them which would give an M root n
algorithm which wouldn't be new and then
in both cases you do something smart
with your iterative scheme to make that
one half into a one-third but what's
kind of important is that really the
root n is the actual difficulty of the
problem and there's something smart on
the iterative side and that was really
the limit of it like if you were to do
something like this that you're not
going to use the same primitive and push
it farther like the end to the one-third
was already back
the kind of tricks of iteration and they
kind of hit this roadblock and and you
know the good news is that it's actually
a nice framework your these very
powerful primitives for probing a graph
and you have an iterative method for
turning bad solutions din to good
solutions right solutions is bad
approximate problem into good ones but
the bad news was that it really was a
pretty hard root n in the quality and
that meant that it really was the end to
the one-third really seemed like an
actual limitation of the present
techniques and so the reason I would
kind of this stage in the talk say this
comes from is really if I give you any
iterative method every iterative method
is basically the same thing right you
want to solve some problem you get an
iteration that solves something that's
vaguely similar to your problem and then
you repeat it until you you know you get
a way of crudely solving something
vaguely related and inner loop and you
just keep calling it to push yourself
towards the answer and you know in
general you have this crew dinner
algorithm that you're using to probe the
complicated outer one and the running
time depends very strongly on how bad
your bad solution is right like that how
many iterations you take is always
related just to the quality of the crude
algorithm solution and the root end that
I said was there for real reasons was
the difference between l2 and l infinity
electrical flows minimize an energy
which is a quadratic thing it's the l2
norm of something you want to minimize
the max you want to make a max flow so
you want to get everything under a max
capacity it's now infinity that's your
route and that kind of shows up and it's
really there and it's if you just use
electrical flow stuff it's not going to
go anywhere okay so that was the second
one and now the last one is the one that
we're going to make most extensive use
of which is oblivious routing and so the
first tree like claim work sort of
fairly obviously related to max flow in
the sense that one of them gave us a
better algorithm for max flow the other
was an algorithm for next slow this one
is going to feel a little different but
bear with me it's actually a core
technical tool and you'll notice that as
I said this it will give a very bad
solution but a solution to Maxwell give
a log an approximate answer by the end
of the slide but not one that's easy to
amplify
okay so oblivious routing a high-level
motivation is you want to route all
motivated by not from a max flow
perspective but from an oblivious
routing perspective and then we'll come
back to excellent so the idea is roughly
you have you want to route traffic
between many pairs of users on the
internet and if you're building a router
you really don't want to solve an N
cubed algorithm every time you rather
the pack and the internet you want some
sort of my surroundings scheme and so
here's my internet and you know I guess
since its a math talk I should define my
terms and and I guess based on empirical
work you can if you're not familiar with
internet based on recent traffic studies
you can kind of more or less model it is
a finite capacity medium for
distributing pictures of cats you can't
smell and you know so you have users who
want to distribute these pictures it's
down to either application since then
but you know the ideas you have these
users and you have a bunch of sources a
bunch of sinks and what your goal is
going to be is to route stuff from
source to sink subject to capacities as
before so here we have s one wants to
route this picture to t 1 s 2 wants to
send that to t2 and and the goal is
going to be to do so efficiently but so
it's a general routing thing the idea is
that what is a routing a routing is
going to say i want to send traffic from
s1 to t1 and what a routing done is is
just you pick a distribution over path
so we're gonna think of a probabilistic
every packets going to follow a
probabilistic route which you could
think of as a probability distribution
over paths which dust is a flow and you
know the idea is that you can think of
so it's not we're not sending along one
path we're sending along distribution of
paths so think of a lot of traffic going
between the pair is and you randomly
sample you could equivalently think of a
random choice of paths and an oblivious
routing is to say that you don't you
know solving this problem as it is is a
multi commodity flow problem that you
can get a pretty good handle on but it's
slow it's much slower than you want it
to be if you're routing on the internet
and instead what you're going to do is
you're going to want to be able to
pre-compute and program your routers and
what it's going to do is it's not going
to solve some global optimization and
what it's going to do is in advance at
the beginning once you
build your network it's going to for
every pair S&amp;T decide how it wants to
route flow from s to t the oblivious
part of it is that how a packet gets
routed from s1 to t1 has nothing to do
with the other network traffic so the
routing and oblivious routing scheme is
one where the routing of a single packet
is if you have a fixed distribution of
paths for every Paris run into S&amp;T and
you know if I so you'd think that this
would make a huge difference because you
can imagine loading up the network with
all sorts of different traffic patterns
and you think you'd want to very
differently route certain pairs if you
know that other pairs are trying to use
the same edges right so in oblivious
routing is something where you're not
allowed to use that information every
packet gets routed independently of
every other packet so that's the setup
and it I was kind of a long history it
went back to the early 80s for specific
graphs and the measure that you use here
is called the competitive ratio is the
standard measure and what it says is
that there's two ways throughout traffic
way one is to solve this optimization
problem for your actual explicit demands
and find the single best way to route
stuff between all of your pairs that's
slow but right here instead you're just
going to use your oblivious thing which
doesn't get to use this information but
you'll decide to advance you're
oblivious scheme and then you'll just
use it and then the competitive ratio is
the worst case over all possible pairs
of all possible demands Saul passable
sets a veces antes of the congestion of
your oblivious scheme versus the actual
best thing you could do right and um if
you think about this there is no obvious
reason at least to me that this should
be anything bounded right like it's
really you know it's pretty strong if
you think about it it says that no
matter what the traffic is you can
ignore all the traffic um and so there's
this beautiful result that I thought was
really surprising by Ricky that said
that every graph G has a single
oblivious routing scheme you can pick so
that the competitive ratio is log n over
log n which I think was a real surprise
and this is actually feels kind of nice
right because in particular that says if
I gave you this oblivious routing scheme
for your graph you could just say route
the demand st and then you have a flow
when you get a log in approximate flow
and that sounds great and the fact it
even works for multi commodity flow so
this gives you a log and approximate
algorithm for single and multi commodity
flow now the bad news here is actually
fairly daunting little because one of
them is that it's way too slow like the
best known algorithms were substantially
slower than max flow so to sell to find
the oblivious routing scheme depending
on how you read the literature they were
somewhere between m to the fourth and M
Squared depending on if you slightly
tweaked constructions in the literature
think you can get em two or three the
best stated ones were three or four but
definitely not and definitely much worse
than Maxwell right so it actually it
would it lets you do assuming you could
sell the second problem which was that
you want to get actual answers right so
this would still be useful if you could
do if you're willing to amortize that
over a bunch of computations because you
compute it once but the Edit one the one
that was a little bit more crucial for
this though both of them actually kind
of are but the other crucial problem is
that it gives you this log approximation
and this log approximation is right like
it's there isn't a better oblivious
routing scheme words involving the word
flow cut gap are the things that will
roughly convince you of that and I
believe that you can prove at least that
there isn't depending on how exactly
defined Bolivia sprouting there is this
is really an intrinsically bad thing
like you're not going to make the law
better and it's really not clear how to
take a small number of these things and
get a better flow right it's not obvious
how to take a bad answer to the problem
that actually fix it yeah
well so um so you could think yeah great
so you can the answer is also depends on
how you define it so that was why I kind
of said about you can think of this have
a probability distribution over paths or
explicit flows so it's a randomized
distribution of pabst you could think of
it as a deterministic choice of flows um
so I defined it as as choosing not a
path between S&amp;T but a flow between smt
right in which case so flow is you can
deterministically do it with flows so
think of a flow is a probability
distribution over paths and so it's a
deterministic thing get where you r
outflows and so I think it's a little
bit cleaner to talk about instead of
talking about probability distributions
of paths talk about deterministic
choices of flows which implicitly are
saying expectations but there because
i'm using congestion and close i dodged
happen to put another round of
expectations in that other questions
right
is that everybody happy oh okay good so
that's the setup and largely our whole
algorithm is motivated by just kind of
trying to cross off the limitations here
and so our new technical primitives are
going to kind of solve each of these
that really basically so force
participation which we're really going
to need um what we're going to do is
introduce what we'll call flow sparsa
fires with slight apologies to other
people who have used the same word for
everything's but we couldn't think of a
better word so we're going to call these
flows bars fires and what they're going
to do is they're going to give you a
sparse ification scheme along with the
ability to efficiently route not just
that you get the cuts right but you also
get an actual way of efficiently routing
things back in the original graph with a
little bit more of a loss but we'll talk
about that so yes it will be a cut far
so tired plus routing I plus an
efficient routing it still is I mean it
the efficiently is going to ok so i
guess i should be careful in how I said
said what we got so it partially solves
it but it gives you is the ability to
specify so it gives you the ability to
turn dense graphs into sparse graphs but
it doesn't give you the ability to solve
the problem on the sparse graph so this
solves the problem of given the answer
on your sparse graph getting one in your
dentist graph but for sparse graphs it's
still em to the four thirds or three ABS
depending on how you count yeah yeah the
short answer is kind of everywhere but
the the longer answer is well if we were
able to make so ok here's a unsatisfying
answer and then later in the after maybe
afterwards I'll gives the more
satisfying one once I put some of the
machinery in place but I guess one
answer is the oblivious routing
completely doesn't exist so the actual
competitive ratio guarantees for
directed graphs are not
there may be another way of saying it is
that actually it turns out that max flow
on directed graphs and lacks low when I
say exactly max flow with a log 1 over
epsilon dependents are equivalent
problems so if you could do directed
graphs then you could do exact you know
log window frames lon running time and
vice versa and so in some sense i would
say one way one answer to your question
is if we could get a better epsilon
dependence then we'd have it the other
one is that the words were using at
least like a Bolivia surrouding instead
and competitive ratio if you define them
in terms of directed things they just
have lower bounds that make things great
family and then later I can answer I can
go back and gesture it things to say
which things break but that good so
close partial fires we will will be our
first tool the second tool have is just
a you know an iterative method so again
we had this what we're going to do is
we're going to take these iterative
methods we're going to ascribe a general
scheme for iterative methods it's not
going to use L to write like you know
gradient descent is kind of one is one
way of doing it ur ative stuff it's
really kind of got l2 hard-coded into it
and that rude n is done not going
anywhere maybe it's going to a third one
to one third but not any worse and so
we're going to describe but i'll call
non-euclidean gradient descent and we'll
use this to reduce the problem i'll use
this to show you can actually take max
flow and turn it into oblivious routing
so i'll use it to reduce the problem of
solving the flow problem to getting a
good oblivious routing scheme and then
i'll so the ideas will then give you a
fast oblivious routing scheme and then
the iterative method will let you fix
this you can't turn crude into exact
problem right so the iterative method
will take the ability to use a greedy a
decent oblivious routing scheme and
repeatedly call it to get a good next
one algorithm so um I should say this
one the new the really new part is the
reduction using it is how you use it to
solve max flow is oblivious routing
schemes we it's nominally new but not
really new in the sense that there's a
number like for the actual iterative
method it we couldn't find someone who
formalized in the way we liked and could
use black box we will be reform alized
things and what we think is a nice way
but there's a non
woodville number of people who wouldn't
be surprised by the general iterative
methods but we kind of repackaged it in
a nice general way and the new part
really is more just the how you use
oblivious routing the south max level
yeah in so it's I'll define it in a
second but yeah I mean what I mean by
that is using best at it got your
iterative steps are not going to be over
l two balls in some other ball yeah yeah
and so it's still yet still be and
actually yeah so I'll define it very
exactly the next slide but yes and then
kind of ideological point that I wanted
to push here was just that you'll notice
that throughout the talk what we're
doing is we're going to be using the
grass truck we have this iterative
method which is a continuous object and
we're not going to use the naive basis
we're not going to write things in terms
of vertices and edges if we did as our
sort of basic objects we'd more or less
get stuck back with the previous
algorithms that would do electrical flow
but instead we're going to do is we're
actually going to more careful use the
graph structure to get the right
representations of our you know the
right numerical representations of our
objects and actually I think this is
maybe a one of the crucial insights in
the field right now is that I know I
think the I wanted to maybe contra a
slightly risky surgeon for almost every
problem i think the edge vertex basis is
the wrong one to use for almost anything
so here we're going to find a better one
and a better representation is going to
give us a lot of the power okay and then
the last thing is by now i guess i'm
surprised we're going to give a fast
oblivious routing scheme so we're
actually going to show how to get an end
to the little o of 1 competitive
oblivious routing scheme that runs in
almost linear time so it runs in some
more done and you know the end to the
level of one you could push to a little
better you could push it to something
like and poly log but we're not going to
because it's not necessary okay so
that's the setup so that again the high
level set up these are our main tools
and what's going to happen in our
approach is going to be we're just going
to put them together so I'm going to now
for the rest of the talk and make all my
capacities one this is just for notation
in the paper we write it with capacities
it's just cutting down
so the first thing we're going to do is
we're going to just rephrase the same
problem so instead of trying to send us
so every edges has capacity one instead
of saying we're going to send as much as
we can so that no edge flows more than
one excuse me we're going to just
rescale it and instead we're going to
send one unit of flow and minimize the
max over every edge so we're just going
to divide things down by the answer so
the problem we're going to solve is find
the unit st flow so send one unit of
flow from s to t subject and you're
going to minimize subject to that the
most flow of ready edge and then our
algorithm is going to be kind of I guess
not a surprising one at a high level
start with some flow and fix it yeah oh
it won't be but you're going to minimize
the number you're going to tell you're
going to you're going to minimize the
maximum amount of flow on any edge so if
I were to tell you that we send one unit
of flow no edge flows more than point2
then that tells you the max flow is five
right now there's no integer requirement
here so yeah you're just get you're just
dividing by the answer essentially and
it's just more convenient for the inner
disk scheme and then what we're going to
saw our whole algorithm is really just
start with some guess make it not
atrocious it's not going to be have to
be too careful and then repeatedly fix
it and we're going to fix it we're going
to take our present flow improve it
repeat and the high level structure is
that will have n to a little of one
iterations in each iteration so I wrote
this this is the actual answer it's two
to the root log n log log n the way to
think of two to the root login I guess
is take a log of it so you'll see that
it's between pollywog and a polynomial
so it's strictly less than any
polynomial but strictly more than poly
log so that I'm just get right into the
little of one and it's going to take
similar amounts of time so M so each
each iteration takes a little pigs em to
the one plus little o of one time and
the number of iterations is n to the
little o of 1 so that gives you the sort
of result okay so the two main parts now
when you of this are going to be as you
might guess the iterative scheme in the
inner loop the iterative scheme is this
non-euclidean gradient descent which
will use to reduce the problem to
constructing a certain matrix with a
certain set of properties which I'll
describe in a sec and then this will be
alcohol to projection matrix because it
is and then given the projection matrix
that given the setup the iterative
schemes is a you need to use this
projection matrix a small number of
times and then I'll say how to construct
the projection matrix and for that by
that I mean you'll be able to multiply
by it fast enough that you can actually
use it in an algorithm ok so the outer
loop is this iterative scheme and the
inner loop is constructing this
projection matrix and the projection
matrix it's going to be an easy
calculation to say that the properties
we need from this congestion matrix will
be us you can get them from a good
oblivious routing scheme with good
competitive ratio and then the harder
part is going to be actually
constructing the oblivious routing
scheme with the necessary properties so
I'll do all these in a bit of yet but
the I guess super high level picture
here is
we're going to start with our grass and
we're going to do routing by recursively
reducing it to simple as in boy graphs
until something that happens so oh right
and flows participation is going to come
in the recursively reducing yet we're
going to have steps to make the number
of edges smaller and the number of
vertices smaller that will kind of train
off against each other okay so that's
the very high level picture again it's
iterative scheme construct projection
matrix projection matrix comes from
oblivious routing oblivious routing
comes from slow slow star sapphires and
a whole bunch of other stuff so let me
quickly run through the gradient descent
and it's basically what you think
gradient descent should be but with a
slight tweak so generally gradient
descent what we're going to look at is
when you try to minimize a convex
function f high-level clip shows start
at some X improve it right so take x 2x
plus some Delta and generically it's
just something that makes you better
scandal gradient the Stanton says the
thing you're going to use is the
gradient right and the way I want to
phrase it is think of your function f as
its value at a point plus a linear term
gradient of F dotted with the
displacement plus some other stuff
that's smaller that really should be a
little low or else that's super
interesting assertion and right so it
says linearly approximate your function
and then what grading descent says is
you look at a ball around your present
value so you take an l2 ball around
where you are take are small enough that
your linear approximation is still
pretty good right that your functions
well approximated by its gradient then
find the point in the ball that
minimizes your linear approximation I
say your functions pretty close to its
approximation and you're minimizing the
approximation vest you're making
progress on your function and then you
repeat right and so if you were to write
it out it says but your new step is
going to be your new point is going to
be is they're going to take the men
overall points in a ball of some radius
that's small enough of the linear
approximation of your function and
because l2 is nice it turns out the
answer to that is actually the direction
you want to go is actually the gradient
but note that the gradient here was the
direction not by necessity but because
if you minimize the x over the ball you
get something
the direction of V okay so all we're
going to do here is just dude radiant
sent for general norms so the idea is
that same thing but we're not going to
look at an l2 ball so we're going to
step in the direction of the thing that
minimizes the same quantity the linear
approximation of your function but like
we're not going to use the l2 norm we're
going to use some arbitrary norm here so
for any normally put in there I can do
the same thing now it's no longer in the
direction of gradient of F actually
because you could be minimizing or
something other than a ball and what you
really need to catch is i'm going to
give a little bit of notation is the
right thing to work with is the dual
norm so the dual normal right the little
star is the vector Z is the maximum over
the unit ball and again when i use this
this these double bars this is an
arbitrary norm not an LG on the dual
norm will just be the max over that ball
of Z dot y so I and ok so I gave you the
dual norm so i can define the qualities
will need and the qualities we need are
you know i said that what you'll do is
you'll pick some are where your
approximation is good i need to tell you
what that approximation is and what's
going to govern how far you can go is
how quickly the derivatives change right
but here it's not just it's not second
derivatives those are sort of tune tell
to write what it's going to be is how
badly the gradient can change over the
ball that you actually are looking at
which is now not round so we'll define
the Lipschitz constant of the gradient
to be the smallest L such that and the
dual alarm is the right one to put there
you should just trust me your ticket but
the idea is that you want to measure you
look at the dual norm of the gradient
between x and y and you'll say the
Lipschitz constant is the worst case of
the ratio between how far away x and y
are on the dual norm of the change in
the gradient so the way to think about
that is to think about essentially how
much the gradient can change over the
unit like you're kicking a little ball
in your norm and you're going to ask how
far can you go before the gradient
changes a lot and the way that we care
about the gradient is what it does is
how bad it is as an approximation of the
objective function
oh um the Lipschitz content will be a
global will be a function only if it I
mean really it's only of F's that you'll
ever see in your algorithm but we're not
going to you know like if but you know
it's here oh yeah right you could do
that more carefully with a general
setting but we won't need it and then
we're going to find this thing extra and
what it's going to be is it's just going
to be the point that says you're going
to this is roughly saying take a take
your best step and it's going to be the
max over X overall s so instead of
saying maximize over a ball what we're
really going to do is say kick the you
know Britt let the radius be chosen kind
of by minimizing us so here you have
objective function and here you have
penalty for being far away so you're
going to sorry
oh wow hmmm i think in the way i did
this actually I made XP your original
point and why be your new point right uh
oh I certainly yeah why should be X ray
sorry good like I said I'm good thanks
if I made this all with Euclidean norms
it would be straight steepest descent
yeah the analysis the exact guarantees
of the analysis or a little tweaked is
why we did this what the it's very close
to the standard right up to these things
but the the way the in a second the
guarantees that we get out of it were
just phrased in the way that was more
convenient so it was just what how we
defined all the constants and stuff so
the answer is as I said I couldn't find
it verbatim prepackaged but I'm sure
that if I told this to Boyd he would not
be surprised but right it's more an
organization not a new result and anyway
so now the algorithm is this right the
algorithm is take a step scaled by the 1
over L in the direction that this thing
tells you to do so really it is draw a
ball around your point take a step
repeat and that's it now the quantities
were to need to define so what governs
the running time for ya
you
right
you
yeah we're gonna use the same linear
approximation right which will still be
small oh I mean it will still you'll get
so the we're going to use the actual
linear approximation of the function
which the right thing that is the right
if you're approximating a function by
polynomials out to is the right way to
do it and then the how like there is a
unique answer to the right linear
approximation here in the space of
linear functionals right like it there's
only one answer to that part of the
question but the apt all over the ball
is the part where we're using the norm
so right like if you were to linearly
approximate a function that there is a
right answer here that in the space of
gradients right in the face forms and
then we're using the norm just to
actually get a step and that's where the
norm showing up
yeah it's one of the pieces yeah and the
construction of everything but yeah
right like morally you can't hope to get
from one corner of a cube to another
corner of a cube if you put balls inside
of it so we're putting cubes inside of
it um right like so we needed to this
the iterative scheme was the fact that
we're using searching / L infinity balls
was necessary all right but the idea is
that there's two parts there's
approximate your function and then
optimize your approximation and so we're
using a standard the only way to
linearize the function but then we're
approximating it over the box over we're
news l infinity as our local and that is
what's going to you know the larue dan
is coming from the fact that if i just
kind of take only steps in balls cubes
don't look like balls and there's a root
down there so we're going to use tubes
inside cubes and will be better but yeah
so again the way we're using the norm is
in this part of it it's not and choosing
the approximation it's in choosing the
bits and what you do with the
approximation we're maximizing it over a
local neighborhood defined with the ball
we're going to use that infinity for a
local arm yeah yeah
so if you do just gradient descent there
are lower bounds for this class of you
know for I give you Oracle's that meet
certain properties then given that there
are lower bounds roughly the analysis
that we're giving will be tight for a
thing that only obey is exactly what
we're giving it so if you're only
allowed to do what we're doing you know
compute and linear approximations of
things this is going to meet the lower
bounds but there's no general lower you
know depending on how if i give you to
specify it properly have to say here's
what I'm allowed to use and if all
you're allowed to use is first order
methods then there are a lot of bounds
I'm sorry this is not going to meet them
uniformly because there's a slight speed
up you can do for some of these norms
like for l2 there's this thing by
nesterov that does accelerated
coordinate creating percent which is
actually a little bit faster but not not
much faster and we couldn't get it we
actually don't know how to make it work
in the in the infinity setting with the
useful set of guarantees so the answer
is there are lower bounds gradient
descent is not the best first order
method our out analysis is right for the
analysis of gradient descent it's off by
square root somewhere carefully chosen
for the analysis of any first order
method for l2 and 4l infiniti were a
little fuzzy on exactly whether whether
we can get that square root to happen
yeah a square root of the so the
difference between K and root K
iterations for us it's going to be the
square root of a something that's end to
the epsilon so it won't matter when
you're I guess the right analogy is
think of the difference between
conjugate gradient and like gradient
descent for linear system solving one of
them takes the condition number the
other takes the square root of the
condition number it's actually the
master of things are very strongly
analogous to conjugate gradient um their
primal dual and but we don't there's a
there's some substantial technical
roadblocks to making them work and other
norm kind of setting that we don't
having a best so we're just using
gradient
other questions okay so that's our setup
and the thing that's going to govern it
its running time it's just going to
basically be I tell you here's how big
your steps they're allowed to be and
there's a diameter of how many little
blobs that you're allowed to take steps
over that it takes to get from one side
to the other and that's what this R will
be basically so we'll say you'll take
the max over all X's in space and all
points that you might ever hit in a
gradient descent things you're only
going our so you can look at stuff whose
values are better than the starting
point of this thing the number of steps
you need to take basically so this is
just a lower down of diameter if I tell
you your step size if you work it out
right and after k iterations you can
show that this is kind of the midpoint
your distance from your optimal answer
so x star will be the actual solution
you're trying to find the optimum you'll
show that your objective value value
minus the optimal objective function
value is going to be bounded by some
stuff that falls off linearly and k so k
is the number of iterations and the
numerator is l r squared it's a function
of the Lipschitz constant in the radius
so that this step is so in general it's
basically it's one matrix vector
multiply with your radiant I'll say the
second our skin our case it's very
simple it's compute the gradient and
minimize it over your norm well and
depending on how good and access you
have to the ball and your norm if it's
the Infinity norm you just take the
biggest coordinate it's not complicated
i guess i gave you a complicated of f
norm i'd have to talk about articles to
give you a good answer but it's a very
simple step there's the point and for us
it's going to be dominated by computing
one major chapter multiply two okay so
let me actually say here and then I'll
hold fan she ate it um so for max flow
we're going to use we're going to queer
going to just instantiate the scheme for
max for our max flow problem so I'll
find this matrix B to be the advert X
incidence matrix and so by that what I
mean is just I just my last piece of
notation I think but what I'm going to
do is it's just going to be something
where Rose our edges columns are virgin
cease and for every edge in the graph
you'll have a row of the matrix which
will have a 1 and a negative one in the
things corresponding to the vertices and
it doesn't matter what order use
arbitrarily fix which one's the one to
it like you're in arbitrarily fix which
is the one in which is the negative one
and it won't change anything it's just a
sign convention and so this is our edge
vertex incidence matrix so one and a
negative one for the two vertices in
thousand every edge so it's an m-by-n
matrix um and it's convenient and that
it lets us write things about the
demands rounded by a certain flow I gave
you a flow f so the vector on a number
on edges then B transpose F you can
convince yourself is what i'll call the
demands it's the so it's the net it's a
number for every vertex that's the net
flow out of the vortex so here we want B
transpose F to be like one and ass and
negative 1 and T and 0 / or else and so
no B transpose takes a flow produces the
demands routed by the flow which you can
think of as a vector of net flow out of
each of the vertices so we can now write
our problem is this right it's going to
be minimized overall flows such that
they route the right and the Infinity
norm I'm going a little slow so I'm
accelerated it but so this is an
algorithm right so the idea is if I you
start with any initial flow that routes
the demands which you'll find by
something not too complicated because
it's not supposed to be that great then
you're going to minimize the Infinity
norm of F 0 plus gamma where gamma is a
circulation right if I route the demands
and then I look at everything that ranch
those demands their difference is going
to route noth-nothing going to be a
circulation which it means B transpose
gamma 0 and this is not exactly how
we're going to do it so roughly the
constraints are going to make things a
little annoying the such that thing here
so what we're gonna do instead is
instead of powermat rising it like this
we're actually going to do an
unconstrained problem where we're going
to instead of forcing gamma to be a
circulation we're going to project onto
circulations so i'll define p to be a
circulation projection matrix
M by M and it will have two properties
one is if I give you any flow it
projects it to a circulation so b
transpose p f is 0 and the other is that
it routes any circulation to itself so
if i give it a circulation and I project
it it stays the same so these so it's
pretty it's just a projection onto the
space of circulations a linear
projection and we're going to solve the
unconstrained problem of minimizing f+
pc so instead of forcing it to be
circulation we're going to let c be
anything and then only then apply p do
it now the one thing i want to be a
little careful with here is note that p
is not necessarily symmetric p is not
the l2 projection it's an arbitrary
production matrix so it's a non
symmetric matrix possibly um and you
know if p or equal to P transpose this
would be orthogonal projection onto the
space of circulations and we basically
get the previous algorithms but instead
we're going to use alcohol an oblique
projection I try to draw a picture of
it's a not orthogonal projection so it's
a linear projection it's a linear
operator that projects onto the subspace
but not necessarily orthogonal II I mean
they said yeah
um so it's not an approximation is that
you could think of it as or found them
as an orthogonal projection in some
other norm some other L to type norm
right it's we'll see how we construct it
in a sec but you know if you use
straight orthogonal projection you're
going to end up with standard L true
gradient descent basically are going to
be computing electrical flows what we're
going to do instead oh so standard
projection will be electrical flows and
then you'll get stuck with all the
problems they introduced instead we're
going to construct our projection matrix
using combinatorial structures of the
graph and we have additional freedom now
and how to do it because we can be able
whole class of ways to project so right
all we just needed was that it's a thing
that lets us parameterize our space by
PC but it's not an approximation it's an
exact thing but it's an exact thing
constructed very carefully and this is
where I said you're using combinatorial
structure to describe your numerical
characterization and it is crucial so if
i gave you a circulation projection i
claim would be in super good shape
because what you do is we'd write down
the minimization problem we have now
it's straight unconstrained because we
don't have to force the thing to be a
circulation we just projected into
circulations okay little issues the
first issue is that L infinity is not
really good for gradient descent because
it doesn't have gradients it's not
differentiable not a huge deal that one
you sub gradient or something it was my
answer to it like there's ways to get
around the corners but there's a bigger
problem the bigger problem is that the
gradient even where there are gradients
is just the wrong thing to use on the
problem is that it picks out the biggest
coordinate even if the others are close
right like if I were to look at the
derivative of the Infinity norm at a
point like 100 and then 99.999 and then
a bunch of zeros it's going to say you
want to decrease the first coordinate
and it's just not going to see the
second coordinate because the gradient
will just be in one basis direction and
that's really bad right you could it
will basically fix one coordinate at a
time in somewheres case in which case
you'll get out live iterations um
morally you want to kind of fix both of
the first two and not the others I mean
so there's a standard answer to this
which is to replace our infinity with
the softmax function which is like the
mack self
and it's just a thing with a bunch
exponentials in there that blows up I'll
write the properties will use of it but
if things are markedly different in size
then it becomes the max but when things
are roughly the same size it lets you
actually take steps in all of them so
this is the function sorry so this part
of it actually it we could almost read
our paper with multiplicative weights we
would have needed a weirder Oracle
guarantee because we needed so you
wouldn't actually be able to use an
oblivious routing scheme because you
wouldn't be able to change there's one
you'd need an extra degree of freedom in
it I'll answer this offline or at the
end just cuz I want to get through this
but multiplicative weights you could do
with a not an oblivious routing but a
another Oracle that was a little more
contrived feeling um and this is roughly
paralleling something that you could
make mouths like you could do this is
multiplicative weights but it would
require oblivious routing plus a little
bit more stuff in your description ah
not in print but hopefully in print one
day yeah and so yeah the other thing is
that the way that if you duplicated
Lisa's current version he loses a little
bit on the running time like he loses
some Epsilon's and stuff I'm not sure if
you can fix that maybe you could but at
least as is his paper has an extra
epsilon floating around that you can get
out out with a great ascent analysis I
suspect if you did multiplicative
weights right you could also get rid of
it but I don't know for sure in this
paper because these phases that you have
to do and those add on an epsilon
analogue anyway right so this is broadly
similar in terms of what it does to two
multiplicative weights but not quite and
yeah and Joan is actually so much more
nap there's a much more natural mapping
to multiplicative waits here it would
feel a little bit contrived inning but
it would still exist and this is this
looks a lot like the stuff that shows up
in multiple complaints okay so in case
you're wondering that's what the tea is
in these expressions it's a thing that's
tuned to make those about the right size
so that they blow up when things are bad
okay so here the properties we're really
going to need the properties are this
that are all just calculations
is one is that the Infinity norm softmax
is close to the Infinity norm in the
sense that it's above bounded by the
infinite Norman lower bounded by the
infinity or minus this T log to them so
T here is epsilon times opt over some
logs ok good let me get after that I'll
get back to that yet but it's not a huge
deal yeah we could little better but
yeah we can do a little better cuz we
will have a sense of what octaves but
yeah yeah right so then the next thing
is Lipschitz constant of the gradient in
this thing so the nice thing about the
softmax thing is that it's actually tune
to be good with gradient descent in the
Infinity nor matter so L two things are
nice for l2 gradient descent this
function is the thing that works nicely
for L infiniti gradient descent so it
has the property that if you were to
look at our definition of lipsticks
constant it's good for infinity norm
reading doesn't um and and right so the
end the softmax therefore of f + pc if
you just do the calculation from the
previous thing and take some derivatives
you'll see that the Lipschitz constant
of f + pc as a function of C remember f
0 is a fixed constant is the Infinity
norm the L infinity norm squared of the
matrix P the infinity to infinity arm so
I feed it vectors of infinity norm one
and look at the maximum infinity norm of
what comes out and if you just compute
what use the previous line you can
compute this and so the Lipschitz
constant of our function f 0 plus PC its
gradient is the 1 over T from that and
then the numerator is this P infinity
squared and so our goal is going to be
to do that it's going to be to find
something with small p infinity and then
we're in good shape so given all of this
stuff what we've done is we've reduced
it to constructing a circulation
protection where the iteration bound is
some nice function of P infinity and all
you need to know is its polynomial
because we're going to not we're not
going to worry about which how many long
factors we get and we're only going to
the infinity arms going to be small
enough that it won't really matter so
we're going to what we'll do is if I
could give you a P matrix P with
Infinity norm that's n too little of one
then i will get in an epsilon
approximation in n to the little of one
poly one over epsilon iterations and
then we'll be in good shape assuming a
whole bunch things like that we can
actually do it quickly yeah is really
only one projection matrix refugee
symmetry and it will have a root enemy
Lipton's yeah be redone so you'll
basically get back to the UNAC seller
ated versions of the previous four thurs
papers you'll get the three halves and
if any time so the poise we're going to
construct our projection matrix to match
our goal our people would be all this
okay so now we've there's another line
of disk that's gonna say I claim
projection matrices and oblivious
rounding schemes are the same thing um
I'm running a little bit over sorry is
10 minutes okay okay and then 10 more
minutes I could do it sorry yeah I think
I didn't okay so this next page is just
now we have projection matrix and we're
done right then we just call it a bunch
of times we're going to construct it I
claim only kind of just by messing
around with semantics will be able to
reduce constructing a projection matrix
to constructing an oblivious routing
scheme so what we're going to do so let
me tell you how to define oblivious
routing and I should give the warning
I'm going to define only linear
oblivious routings so when people talk
about oblivious routings more generally
they might not be linear so I'm giving a
linear bloody routing and I'm going to
forget to say the word linear probably
don't worry about it you know it is it
there was a more general class and some
things I say might be only true for
linear bloody surrounding schemes um ok
so a linear oblivious outing is an
m-by-n matrix an operator that you feed
it demands and it spits out a flow
and the way it does it's going to have
the property that B transpose a kaya
Scotty so what that means is that i take
kire my demands a chi is a flow that
routes the demands that I'm given so
that's what i mean by your routing
scheme right it's you give me demands it
gives me a flow and the competitive
ratio is the competitive ratio defined
before and if you were to kind of mouse
kind of expand stuff out so b transpose
in so just make sure i'm just gonna put
this all up in one shot right so let me
now i'm going to now compute the
competitive ratio is an algebraic
quantity and so be
it's any year yeah it's rectangular
right I meant but yes if I were doing
and also yeah you could if you did that
the right way you could get a linear
projection standard I'll to pick action
but yeah these things get a little bit
bunched together when you're doing not
standard projection okay so B transpose
maps flows to demands the oblivious
routing scheme a Maps demands to flows
so if you want to look at flows to Flo's
you'll get a B transpose um so a B
transpose map slows to flows in a way
that preserves demands and I claim that
if you compute the competitive ratio
it's just the Infinity norm of the
matrix a B transpose roughly the idea is
you take the actual optimal thing to do
feed it through a B transpose and you
look at how bad that is and there's only
one oblivious you're oblivious routing
scheme that will route the same demands
and not be any worse than infinity norm
in terms of connection so this is so the
important point here was now we've
actually you know we can measure the
competitive ratio is just the Infinity
norm of a B transpose and note that
conveniently if i take i minus a B
transpose it's a circulation projection
right because it routes the day be
transposed routes the demands I routes
the demands i subtract my route nothing
right I get a circulation so this matrix
P of I minus a B transpose to the
circulation production and the Infinity
norm of the circulation projection is
the one coming from the ended by 1 plus
Row thing so in particular if I give you
a small row of a I give you a small
infinity norm which gives you a good
down under iteration count and so that
actually means that now we've reduced
the problem of constructing a projection
matrix to constructing a good oblivious
routing scheme where the cost of each
iteration this was the answer to your
question from before so the number of
iterations depends on the competitive
ratio which makes a lot of sense because
the competitive ratio says it's the
ratio of how well you should be routing
demands to how in the best case to how
well you actually do which is how crude
your Oracle is and that's how many
iterations should be related to it and
then the cost of each iteration is going
to be dominated by matrix vector
multiplies with P and P transpose and so
our goal is going to be to get Rho small
and the multiple
patience to be asked and so the rest of
the talk will just be the sketcher
construction of an oblivious routing
algorithm a such that these things are
good so row of a the competitive ratio
is going to be m2 little of one and the
time to do it is going to be is going to
time to apply it note it's going to be a
little bit it's almost going to be
linear it's going to em to the 1 plus
little o of 1 and so putting that
together that will give us you then left
call this thing em too little of 1 times
and you'll get the claimed algorithm I'm
just gonna give a notation to have it
i'm going to write t of a for the time
to x p and p transpose the worst of the
two so that's our goal and the overview
this I'm going to really sketch because
it's this is where a lot of the
technical work is and this one is going
to have some sketching but I want to
give you the basic picture which i think
is pretty clean so roughly to
oversimplify previous stuff oblivious
routings what they do is they the way
most previous schemes workers they
routed using a probability distribution
over trees I give you one tree it
specifies a unique way of routing any
demands I give you a probability
distribution over trees that's nipple of
your surroundings scheme it gives you a
flow and the idea is that the reason
that you ran into these major major
problems with all previous with using
previous stuff like the reason that M
Squared was not going anywhere was that
you can actually prove to get a decent
competitive ratio you actually need at
least entries and just to write down M
trees takes n squared and so that's bad
and and so even writing down the answer
is too slow and so the solution is kind
of obvious in that setting right you
don't write them down so we're going to
do is we're going to describe them
implicitly and recursively um and so the
way we're going to do that is by kind of
recursively reduced routing on one graph
to writing on better and better graphs
so for that we'll need one more
definition which is just which is going
to be the following so suppose I give
you two graphs on the same vertex set on
the talk about how to route one on the
other so if I gave you their incidence
matrices and I'll define an embedding
em to be a matrix M prime by M matrix so
that B prime transpose M equals B
transpose so unwinding what that means
what it says is I take every edge of G
and i routed on g prime as a flow um so
morally what we're going to do is leave
a routing of one graph on the other then
you can take a route on the first graph
and then push it through this embedding
to get around it on the second graph and
the congestion is going to be what you
think it's the Mocs overall edges of the
amount of stuff rounded over an edge in
your jaw graph in the new graph and so
our theorem our theorem is going to be
the whole abilities routing scheme is
going to involve two things one is going
to say take your graph and reduce the
number of edges and the other isn't to
say reduce the number of vertices and
we're going to repeat them so the edge
reduction thing and I'm not going to
quite say the word embedding in certain
cases because it's almost an abetting
bitmap right I'll say that Zack it's a
couple lines away from in abetting but
ok what the idea is I'm going to give
giving G and i'm going to i claim you
can find a G prime in almost linear time
so that the new graph is sparse so this
is that's this is our theorem it could
be very close to flows MRSA tires so
you're going to I claim you can
construct a sparse graph with and it
will come with the ability to route
stuff back so it will come with given an
oblivious routing scheme on the sparse
graph you'll be able to pull it back to
an oblivious routing scheme on the
original graph and the running time will
be linear plus the time to do the other
bonus routing scheme and also the
competitive ratio won't blow up much it
will be up to some long factors the same
as before ok so the this is one of our
pieces the other piece is going to be
vertex reduction so this says I give you
a dense graph I can reduce routing on
iterating on a sparse graph um the
vertex reduction thing isn't and the
only reason I get it as a reduction
instead of an embedding is just because
kind of little silly algorithmic
concerns it's think of it more or leas
and abetting but I just want to be able
to actually State running times and
stuff um ok so for vertex reduction what
we're going to do now is we're not going
to route
one grant we're not going to reduce
routing to routing in a graph with fewer
vertices are going to do sitter routing
in a bunch of graphs and fewer vertices
so the ideas well you'll give me a graph
G and I'll give you t graphs in time Oh
tilde of T M time so I'll give you a
bunch of graphs and reduce routing in
the first one to reading in the others
so in the previous stuff think of it as
a distribution of trees I'll reduce
routing in my graph to routing in
entries or entries now we're going to
instead of going all the way to trees
we're going to go to simpler graphs but
not quite trees and that's where we're
going to kind of get the recursion so
vertex reduction is I give you a bunch
of graphs T of them each graph is going
to have 0 till de of em over T vertices
and at most M edges and given an
oblivious routing on each of the new
graphs you can construct an oblivious
routing on the original graph with the
running time that you kind of want to
just add up all the numbers so no real
loss and the competitive ratio is going
to be just bounded by the worst
competitive ratio with some kill this so
if you look at these two things the way
to think about it is if you look at the
second one this says that if I give you
that I can the amount of complexity of
routing on this new thing it's going to
depend on em right so it's em over T so
if i gave you a dense graph bad things
would happen right this has complexity
it reduces the number of vertices in
terms of the number of edges of the
original graph this reduces the number
of edges to something sparse so what you
do is you interleave these right you're
going to say take a dense craft create a
sparse graph use the sparse graph now
this is much smaller that gives you the
tribution then you repeat and that's the
hole and then put those into a simple
recursion and you'll get the algorithm
so actually I claim these two things
just + writing out the recursion is all
you need to do the whole thing and I
just have to give you those two pieces
and then you're done and so the reason
we again reason we needed the Med
reduction was because of the vertex
reduction had an M they're not an end so
otherwise would be in trouble and the
extreme case of the previous one was
just trees was making these smaller
graph trees what we're going to do
instead is not go all the way to trees
but
go to simpler graphs that aren't trees
and then recursively so okay flows barsa
fires the main tool is their basic
they're almost syntactically equivalent
to introduction I actually do only have
four minutes left this is surprisingly
fast the so a flow sparsa fire is going
to be the object will construct that's
basically the introduction lemma but
more or less so what it's going to do is
you give me a graph it's going to spit
out a new graph on the same vertices and
give you an embedding of your new graph
interval graph that's the new piece and
the properties will have one is it's a
spark sparse and a cut approximator so
this is just the standard stuff the
standard cut approximation things and
notice a one plus or minus epsilon kind
of proxima shin and then on top of that
it's going to be a flow approximation so
what you're going to have is not only do
you have that your new graph has all the
cuts about right but also it's going to
come with an embedding of the new graph
into the original graph so that the
congestion isn't too big bounded by some
alpha and that's a parameter of your
construction right so it's kind of what
you'd expect so this will be waiting it
yeah and the other thing we're going to
want on it is that it's fast right so
the last parameter on this list is just
how long it takes to give it and we're
going to require it to be 0 tilde of em
so almost linear and our theorem is that
we construction Oh tilde of n epsilon 0
I want to say 0 hat rather a little
thing that mean like end of a little of
one not quite a lot of factors um sparsa
fire for any constant epsilon and the
one thing is going to point out is note
the alpha here this isn't an epsilon so
what we're going to get is that you cuts
are approximated up to an arbitrarily
than epsilon the flows you'll lose a log
and here we'll lose a little worse but
we could lose a log and that actually is
kind of real roughly to act if you don't
actually use the demands you run into
something resembling a float cap kind of
issue which is that you're trying to
route all demands and you get some
congestion from the worst case over all
of them so we get the cuts right but the
flows looks up to a log but what how can
you really
okay now here's my picture for how it
works this will be a slight lie but not
a terrible lie roughly the whole
construction of flows parser fires are
kind of two steps which is figure out
how you'd want to do it in expanders and
then figure out how to pretend
everything as a bunch of expanders so
you how to do it and expanders is pretty
easy you could actually choose one of
several ways to answer tan extenders but
you know roughly the idea is it's easy
enough to subsample expanders to get
sparse graphs but the problem is the
embedding for the embedding we're
actually just going to use electrical
routing on expanders routing in any kind
of reasonable way should work pretty
well electrical routing is a good one
and so what you can do is you can show
that more or less the competitive ratio
of routing something with electrical
flows depends only on how good an
expander it is and so if I just want to
write on expand doors electrical flow is
actually a good enough competitive
algorithm so for then for general graphs
are just going to chop it up into
expanders so for general graphs the
ideas you'll show you can break your
graph into a bunch of not going to say
expanders I'm saying well connected
because it's not quite expanders but
morally expanders a bunch of
well-connected clusters that contain a
constant fraction of the original number
of edges of the original edges so you
show that you can cluster any graph into
a bunch of well connected components
connected by fewer than constant
fraction of the remaining edges and then
on each of those on each other well
connected components you're going to
find sparsa fires and embeddings because
they're expanders and we're good at that
and now we've removed a constant
fraction of the edges and then we're
just gonna repeat so we're going to take
our new graph and to run it up again etc
and that's kind of the core of the flow
sparse fire construction for the vertex
reduction roughly the idea is what we're
going to do is we're going to embed not
into trees but into trees plus a little
bit so if i gave you a graph that was
you could have done it as trees plus a
couple edges or trees plus a couple of
vertices let's do trees plus a couple
produces here the idea is if I give you
a graph that is a arbitrary graph on
some number of things plus a bunch of
trees then you can not
pay for the tree part of it ratting on
trees is really fast and so what we're
gonna do is embed into graphs that look
like that they're like m / t vertices
plus some trees coming out of them and
then you can actually get this with
embeddings and the claim is that you can
reduce routing on one of these graphs so
the previous stuff showed this for cuts
and we're going to show you can do
embeddings to and roughly the ideas you
can reduce routing on one of these
graphs to routing just on the core in
the middle because you can just kind of
contract out the hair at the edge right
like routing on pads and leaves there's
only one way to do it and so you can
just contract them out and so putting
that together you get vertex reduction
the idea is you show that you can reduce
you embed into a distribution of core
plus trees and you collapse the trees
and that gives you right up ok so that's
actually the whole things just to recap
the whole picture outer loop is l
infinity gradient descent to minimize
congestion to do that each iteration
you're going to use circulations to
improve the congestion iteratively so
find a circulation to improve repeat to
find the circulation you will apply a
circulation projection matrix the
circulation projection you construct
with an oblivious routing scheme the
oblivious routing scheme you construct
recursively to construct oblivious
routing rules being occur sibley you'll
show how to reduce the number of edges
something that depends the number of
vertices and we've student vertices
something depends on a number of edges
in repeat and for this one that was the
flows parts of fires for the other one
it was distributions over things a
little more complicated than trees which
lets you use a lot fewer of them and
gets us her blessing representation and
putting that all together gives max whoa
multi commodity flow is really not much
change you use the same everything you
just change the objective function and
the regularization and the norms but
like use the same circulation projection
right the right thing with gradient
descent to do it so it's really not a
major change and you don't need to redo
the combinatorial stuff you can just
redo the outer loop um ok so that's it
and if you have any questions let me
know
when we hear the word Network all sorts
of things bring to mind like social
networks and the Internet in particular
but the power of network theory is
really in its high degree of abstraction
so the first thing for us to do is try
and start back at the beginning by
forgetting about what we think we know
about networks and embracing the
abstract language of networks what we
call graph theory in the formal language
of mathematics a network is called a
graph and graph theory is the area of
mathematics that studies these objects
called graphs the first theory of graphs
goes back to 1736 the first textbook
came about in 1958 but most of the work
within this field is less than a few
decades old
in its essence a graph is really a very
simple thing it consists of just two
parts what are called vertices and edges
firstly vertices a vertex otherwise
called a node is a thing that is to say
it is an entity and we can describe some
value to it so a person is an example of
a node as is a car planet farm city or
molecule all of these things have static
properties that we can quantify such as
the color of our car the size of our
farm or the weight of our molecule
within Network science vertices are more
often called nodes so will be typically
using this term during the course edges
can be defined as a relation of some
sort between two nodes this connection
may be tangible as in cables between
computers on a network or the roads
between cities within a national
transportation system or edges may be
intangible such as social relations of
friendship edges may also be called
links ties or relations and we will be
more often using this latter term during
the course the nodes belonging to an
edge are called the ends endpoints or n
vertices of the edge within graph theory
networks are called graphs and a graph
is defined as a set of edges and a set
of vertices a simple graph does not
contain loops or multiple edges but a
multi graph is a graph with multiple
edges between the nodes so where as a
simple graph of a transportation system
would just tell us whether there is a
connection between two cities a multi
graph would instead show us all the
different connections between the two
cities a graph can be directed or
undirected with an undirected graph
edges have no orientation for example a
diplomatic relation between two nations
may be Mutual and thus have no direction
to the edge between the nodes these
undirected graphs have unordered pairs
of nodes that means we can just switch
them around if Jane and Paul are married
we can say Jane is married to Paul or we
can say Paul is married to Jane it makes
no difference and thus it is an unknown
in contrast to an undirected graph we
have directed graphs which is the set of
nodes connected by edges where the edges
have a direction associated with them
this is typically denoted with arrows
indicating the direction for example if
we were drawing a graph of international
trade the graph might have arrows to
indicate the direction of the flow of
goods and services so directed graphs
have some order to the relations between
the nodes and this can be quite
important a graph is a weighted graph if
we associate a number to each edge these
numbers quantify the degree of
interaction between the nodes or the
volume of exchange so with our trading
example earlier if we wanted to convert
this into a weighted graph you would
then ascribe the quantitative value to
the amount of trade between the
different nations
so this is the basic language of graphs
but we can extend this language to talk
about graphs that have multiple types
and nodes and edges what are call
multiplex networks that will add a whole
new level of complexity to our
representation allowing us to capture
how different networks interrelate and
overlap to affect each other but this is
beyond the scope of our course as the
basic language we've outlined above will
be surveys for our introduction to
network theory
in this video we're gonna talk about a
different family of graphical models
called undirected graphical models so
we'll start by defining what I mean by
an undirected graphical model and I'll
give you a the more formal term for the
the types that we're gonna look at which
is something called a Markov random
field and we will discuss then what the
independence of some assumptions are
that are encoded in Markov random fields
then finally we'll talk about the
relationship between Markov random
fields and Bayesian networks that we've
seen previously in fact we'll ask about
ask ourselves whether Bayesian networks
are just instances of MRFs
so as a quick review this is the slide I
showed you a couple of videos ago about
Bayesian networks and in a Bayesian
network you have nodes representing
variables and edges representing
conditional probability tables between
variables and the rule was that you have
a conditional probability table for
every single node that that is
conditioned on its parents so one thing
to note here is that the the edges in
the Bayesian network graph are directed
right there's there's an arrow there's a
notion of a parent and a child but one
thing that comes up when you when you
have this construction is that these
networks have to be a cyclic so this is
an example of a cyclic Bayes net and
it's invalid or it doesn't really make
sense there there's you know some way
that it can make sense but it doesn't
mean anything particularly useful so the
joint probability according to the the
rule of interpreting a Bayes net here is
that it's the probability of B given a
the probability of C given B and the
probability of a given C right it's the
product or it factorizes the joint
probability into this this form and if
you do some combinations of you know the
conditional probabilities you end up
with a joint probability of B and C
given a times a given C and then you end
up finally with the joint probability of
a B and C
given see which doesn't make too much
sense but then you can do the same for
the same transformation to get this
again same expression with with a B or C
in the conditional which only makes
sense in quotes if P of a P of B and P
of C are 1 and that's that that's not
useful right that would imply that we
can only write down a probability that's
that's always 1 so a lot of weird stuff
happens if we have cycles in our Bayes
Nets so all meaningful Bayes nets are
directed acyclic graphs so if we want to
think about the relationships between
different variables that may exist in
cycles then we have to think about
undirected graphical models and it has
to take on a different form because we
saw just from the previous slide that if
this were a cycle and a Bayes net then
it doesn't make sense so the in an
undirected graphical model we say that
the edges represent potential functions
between variables so there's just some
function in some factor in the
factorized probability distribution
between variables and in general the the
formula is that if you give a graph as
an undirected graphical model where the
nodes again represent the variables but
the edges represent something else the
way we interpret that is that it means
the probability distribution the joint
probability distribution of the
variables in the graph factorize into
individual clique potential functions
right so potential function
corresponding to each cleek of variables
where we mean clique in the graph theory
sense as defined here or not from the
Wikipedia article on queex
which is or which says that a clique is
a subset of the graph where every Tues
distinct vertices in the clique are
adjacent so going back to the picture
you know the cliques in this graph
you're like they're actually just the
particular edge pairs so
a B BC B D and D are the clicks now this
could be slightly different and we could
if we change the structure as a graph we
would end up with something different so
if we added an edge between D and E C we
would end up with or these clicks were
no longer be the maximal Gleeks and we'd
actually have this triangle here would
be one click B BC D would be a click and
then CDE would be another click so you
could also write this out as as this as
a potential function between a and B a
potential function between BC and D and
a potential function between C D and E
and one very general class of these
undirected graphical models is the is
one a class of models called Markov
random fields so in a Markov random
field we have certain independence
properties that obey what are known as
Markov properties so the most general
form of this is that in the graphical
model in the graph representing the
probability distribution any two subsets
of variables s and T are conditionally
independent giving given a separating
subset you can think of this as a as a
wall of variables between s and T so
that there's no way to get between s and
T without going through that wall so our
more formally slightly more formally all
paths between s and T must travel
through the separating subset so an
example of this would be you know if we
if I we consider the two subsets s and T
where s is just a node a and T is the
note C then we can think about all the
paths that go between a and C so the
paths between a and C well there's ABC
which looks like that
and then there's another one which is a
B EC a B D EC which looks like this and
if you want to find a separating subset
that that blocks both of these pads
there's a couple options or three
options actually there's B and E would
block both of these paths B and D would
also bought flock both of these paths
and also B D and E all together it would
also block the paths so these are the
separating subsets so if you're if
you're if you observe these variable
values then that makes s and T
independent conditional and
conditionally independent so this basic
property is the most general form but
there's other rules of thumb that that
can be derived from this general general
Markov property which is one is that any
two non adjacent variables are
conditionally independent given all
other variables right so you can see
that you know once you're is once you
see all the other variables any non
adjacent variables you know that the
rest of the variables must act as a
separating subset for those two non
adjacent variables a second corollary is
that any variable is conditionally
independent of all the other variables
given its neighbors and this should be
is reminiscent of something we saw with
the Bayes nets and in fact it is another
form of a Markov blanket right the
Markov blanket in a Markov random field
is essentially much simpler to think
about than in a Bayes net right in a
Bayes net we had the proud of the the
strange fact that that the parents of
your children are also part of your
Markov blanket now in a Markov random
field the Markov blanket is just
characterized by anything that you're
connected to so one important thing to
think about is what the relationship is
between bayesian networks and MRFs our
Markov random fields and we can look at
a few structures and think about how
they relate so if we just have two
variables connected through an edge in a
Bayes net we have something a
probability distribution that factorizes
into the probability of a and then the
probability of B given and in a Markov
random field this this doesn't factorize
at all is actually just
single potential function so in this
case it's actually everything is nice
because this table can capture anything
right we can we can represent any
function of a and B with this fee
function so converting a single edge to
a pairwise cleek potential is easy but
now if we consider a slightly more
complicated scenario where we have a
chain of variables linked through a
directed edges the Bayesian network
probability is the joint probability of
these three variables is probability of
a time's the probability of B given a
time's the probability of C given B and
the Markov random field factorization
looks like this right we have two
potential functions for the edge cliques
one for each right one for a B and one
for BC and you can think about it for a
minute and you can see whether or not we
can fit these you know the upstairs
equation into the downstairs equation by
setting fee the fees to some appropriate
values and the answer in the if you
think about it you'll you'll realize
that you can and one way to do it
there's there's actually many ways to do
it one way to do it is just to set the
the potential function between a and B
to the joint probability of a and B and
then the potential function between B
and C to the conditional probability
between C and B and it's important to
note here that the parameterization is
not unique here but the bottom line is
that chains are easy to we can we can
take a chain structured Bayesian network
and just plug it right into a Markov
random field formulation okay so let's
look at some other structures now this
is not a chain this is a Bayesian
network where a is the parent and it
points down to B and Z so the
probability distribution here once again
we can just read off the edges it's the
probability of a and then the joint has
then the conditional probability of B
given a and C given a
and the Markov random field
factorization of a similarly structured
graph would look like this right where
we have a potential function for the a/b
edge and a potential function for the AC
edge and you can think about it again
let's think about it so can we can we do
this can we write down a definition for
fee a B and fee a AC that mimic the
probability distribution above and we
can one way we can do it is to write
that V ay B is going to be equal to the
joint probability of a and B so P P a P
of a and P of B given a and then AC we
can set it to again the the conditional
probability this time of C given a right
it's a little different from the chain
but it's but it's a similar in form and
one interesting thing here in this case
it's a little bit easier to see that
there's this is clearly not a unique
this is not a unique solution because we
could easily put the P of a in the AC
term right now we have in the a B term
so the a B potential function has the
has P of a times P of B given a but we
could have put that downstairs and it
would have been the same equation so
there's a minor typo here just ignore
the comma in the in the Markov random
field equation here so but the bottom
line is that shared parents is also an
easy case right we can always just we
can essentially just just encode
directly encode the potential functions
or the the the Bayesian net edge
functions as potential functions in a
Markov random fueled okay so I showed
you a bunch of easy cases but now this
case may or may not be so easy so this
is different from the previous slide
because instead of having one parent and
two children we have two parents in one
child right a and B are the parents of
see in this picture so there's a shared
child between the variable a and B so
the the Bayes net probability here is
the P of a
times P of B times P of C given a and B
given both of the parents both of the
incoming variables and the market random
fueled factorization ends up looking
very similar to what we had before it's
just the potential function between a
and C and a potential function between B
and C and we can think about this to
again ask ourselves can we write down
some fee functions that mimic the the
probability above but we can also think
about some other more general properties
here so one of the things that we we
talked about in the in the class
discussion and in the videos was the
idea that when we have this situation
where we have a shared child that the
the variables are actually become
dependent on each other when that when
the child variable is observed all right
so a and B are dependent given C this is
the famous explaining away effect of
probability so if we run that X so we
can run this exercise upstairs where we
say okay look what happens if we observe
C and we know from the from what we
studied about bayesian networks that
well if we observe C a and B are
dependent on each other but now if we
look at the Markov random field the
undirected graphical model on the bottom
if we observe C then a and B are
separated there like C is the set the
separating subsets between a and B which
means that a and B are independent given
C so these contradict each other these
these two statements about the
probability distribution exactly
disagree with each other so this can't
be correct or there can't be a way to
write down a few functions or fee
functions here the two fee functions
that mimic the probability distribution
above so here's how we do it the way we
have to do this kind of thing is we have
to what do something called moralizing
the parents and it all comes from the
family tree analogy and it's basically
saying that if you have
two shared children you have to connect
them to make it a more moral connection
it's is kind of a outdated analogy but
but it's um it's how people think about
this in the field of machine learning so
right the idea is if a and B share C as
a child then a and B has to be connected
in the Markov random field which means
we get a new potential function
essentially or it could equivalently
mean that we have to then write down a a
click function for the ABC click and
that fixes the independence problem
right now now a and B are dependent
given C but there is also something lost
here so the that's basically the whole
story for converting a Bayes net into a
Markov random field and and the the main
twist that makes it slightly more
challenging than then just directly
reading off the edge potentials from the
Bayes net is that you have to moralize
all the co-parents all the nodes that
share a common and a child variable and
but one of the things that you lose when
you do that is you lose the marginal
independence of the parents remember if
we go back to the the the Bayes net we
can see that the a and B if we don't
observe C are they're independent of
each other but in the Markov random
field a a and B are always dependent on
each other no matter what so we lose
some something we lose some information
but by this conversion and that gives us
a hint that the relationship between the
class of all Bayes Nets in the class of
all Markov random fields or equivalently
the class of directed graphical models
and in the class of undirected graphical
models are different but overlapping
classes right and one doesn't subsume
the other and and it that's a common
misconception which is that a lot of
times is easy to think about you know
since we can convert a Bayes net to an
mr and mrs we think that oh and mr MRFs
encompass all days nets but that's not
true we lose something when we make that
conversion
so to summarize I showed you so this was
this video I guess was a brief
introduction to undirected graphical
models specifically Markov random fields
I talked about the independence
consequences of the Markov random field
factorization scheme and we talked about
whether bayesian networks are MRFs and
the answer is no MRFs are also not
bayesian networks it doesn't it doesn't
work either way but you can convert to
reasonably equivalent formulations all
right so so far I've only shown you you
know the definitions here and in the
next video we'll talk about inference V
owes an algorithm called belief
propagation
